{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /home/mkarunar/.local/lib/python3.9/site-packages (0.23.0)\n",
      "Requirement already satisfied: torch==2.8.0 in /home/mkarunar/.local/lib/python3.9/site-packages (from torchvision) (2.8.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /apps/cent7/jupyterhub/lib/python3.9/site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: numpy in /apps/cent7/jupyterhub/lib/python3.9/site-packages (from torchvision) (1.20.3)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/mkarunar/.local/lib/python3.9/site-packages (from torch==2.8.0->torchvision) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/mkarunar/.local/lib/python3.9/site-packages (from torch==2.8.0->torchvision) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/mkarunar/.local/lib/python3.9/site-packages (from torch==2.8.0->torchvision) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/mkarunar/.local/lib/python3.9/site-packages (from torch==2.8.0->torchvision) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/mkarunar/.local/lib/python3.9/site-packages (from torch==2.8.0->torchvision) (12.8.90)\n",
      "Requirement already satisfied: jinja2 in /apps/cent7/jupyterhub/lib/python3.9/site-packages (from torch==2.8.0->torchvision) (2.11.3)\n",
      "Requirement already satisfied: networkx in /apps/cent7/jupyterhub/lib/python3.9/site-packages (from torch==2.8.0->torchvision) (2.6.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/mkarunar/.local/lib/python3.9/site-packages (from torch==2.8.0->torchvision) (4.15.0)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/mkarunar/.local/lib/python3.9/site-packages (from torch==2.8.0->torchvision) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/mkarunar/.local/lib/python3.9/site-packages (from torch==2.8.0->torchvision) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/mkarunar/.local/lib/python3.9/site-packages (from torch==2.8.0->torchvision) (1.13.1.3)\n",
      "Requirement already satisfied: filelock in /apps/cent7/jupyterhub/lib/python3.9/site-packages (from torch==2.8.0->torchvision) (3.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/mkarunar/.local/lib/python3.9/site-packages (from torch==2.8.0->torchvision) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/mkarunar/.local/lib/python3.9/site-packages (from torch==2.8.0->torchvision) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/mkarunar/.local/lib/python3.9/site-packages (from torch==2.8.0->torchvision) (2.27.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/mkarunar/.local/lib/python3.9/site-packages (from torch==2.8.0->torchvision) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/mkarunar/.local/lib/python3.9/site-packages (from torch==2.8.0->torchvision) (11.3.3.83)\n",
      "Requirement already satisfied: fsspec in /apps/cent7/jupyterhub/lib/python3.9/site-packages (from torch==2.8.0->torchvision) (2021.8.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/mkarunar/.local/lib/python3.9/site-packages (from torch==2.8.0->torchvision) (1.14.0)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/mkarunar/.local/lib/python3.9/site-packages (from torch==2.8.0->torchvision) (3.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/mkarunar/.local/lib/python3.9/site-packages (from torch==2.8.0->torchvision) (12.8.93)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /apps/cent7/jupyterhub/lib/python3.9/site-packages (from triton==3.4.0->torch==2.8.0->torchvision) (58.0.4)\n",
      "Requirement already satisfied: importlib-metadata in /apps/cent7/jupyterhub/lib/python3.9/site-packages (from triton==3.4.0->torch==2.8.0->torchvision) (4.8.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /apps/cent7/jupyterhub/lib/python3.9/site-packages (from sympy>=1.13.3->torch==2.8.0->torchvision) (1.2.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /apps/cent7/jupyterhub/lib/python3.9/site-packages (from importlib-metadata->triton==3.4.0->torch==2.8.0->torchvision) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /apps/cent7/jupyterhub/lib/python3.9/site-packages (from jinja2->torch==2.8.0->torchvision) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!module load ngc pytorch\n",
    "!pip install --user torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "baT2YUQrDfhO",
    "outputId": "44cf3909-216a-40c6-9744-c4191326f124"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 18 layers from ResNet-18\n",
      "Global Round 1/100\n",
      "Global Round 2/100\n",
      "Global Round 3/100\n",
      "Global Round 4/100\n",
      "Global Round 5/100\n",
      "Global Round 6/100\n",
      "Global Round 7/100\n",
      "Global Round 8/100\n",
      "Global Round 9/100\n",
      "Global Round 10/100\n",
      "Global Round 11/100\n",
      "Global Round 12/100\n",
      "Global Round 13/100\n",
      "Global Round 14/100\n",
      "Global Round 15/100\n",
      "Global Round 16/100\n",
      "Global Round 17/100\n",
      "Global Round 18/100\n",
      "Global Round 19/100\n",
      "Global Round 20/100\n",
      "Global Round 21/100\n",
      "Global Round 22/100\n",
      "Global Round 23/100\n",
      "Global Round 24/100\n",
      "Global Round 25/100\n",
      "Global Round 26/100\n",
      "Global Round 27/100\n",
      "Global Round 28/100\n",
      "Global Round 29/100\n",
      "Global Round 30/100\n",
      "Global Round 31/100\n",
      "Global Round 32/100\n",
      "Global Round 33/100\n",
      "Global Round 34/100\n",
      "Global Round 35/100\n",
      "Global Round 36/100\n",
      "Global Round 37/100\n",
      "Global Round 38/100\n",
      "Global Round 39/100\n",
      "Global Round 40/100\n",
      "Global Round 41/100\n",
      "Global Round 42/100\n",
      "Global Round 43/100\n",
      "Global Round 44/100\n",
      "Global Round 45/100\n",
      "Global Round 46/100\n",
      "Global Round 47/100\n",
      "Global Round 48/100\n",
      "Global Round 49/100\n",
      "Global Round 50/100\n",
      "Global Round 51/100\n",
      "Global Round 52/100\n",
      "Global Round 53/100\n",
      "Global Round 54/100\n",
      "Global Round 55/100\n",
      "Global Round 56/100\n",
      "Global Round 57/100\n",
      "Global Round 58/100\n",
      "Global Round 59/100\n",
      "Global Round 60/100\n",
      "Global Round 61/100\n",
      "Global Round 62/100\n",
      "Global Round 63/100\n",
      "Global Round 64/100\n",
      "Global Round 65/100\n",
      "Global Round 66/100\n",
      "Global Round 67/100\n",
      "Global Round 68/100\n",
      "Global Round 69/100\n",
      "Global Round 70/100\n",
      "Global Round 71/100\n",
      "Global Round 72/100\n",
      "Global Round 73/100\n",
      "Global Round 74/100\n",
      "Global Round 75/100\n",
      "Global Round 76/100\n",
      "Global Round 77/100\n",
      "Global Round 78/100\n",
      "Global Round 79/100\n",
      "Global Round 80/100\n",
      "Global Round 81/100\n",
      "Global Round 82/100\n",
      "Global Round 83/100\n",
      "Global Round 84/100\n",
      "Global Round 85/100\n",
      "Global Round 86/100\n",
      "Global Round 87/100\n",
      "Global Round 88/100\n",
      "Global Round 89/100\n",
      "Global Round 90/100\n",
      "Global Round 91/100\n",
      "Global Round 92/100\n",
      "Global Round 93/100\n",
      "Global Round 94/100\n",
      "Global Round 95/100\n",
      "Global Round 96/100\n",
      "Global Round 97/100\n",
      "Global Round 98/100\n",
      "Global Round 99/100\n",
      "Global Round 100/100\n",
      "Saved all raw distances to: /home/mkarunar/FL_results_alpha_5avged/raw_distances.csv\n",
      "All plots saved in: /home/mkarunar/FL_results_alpha_5avged\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# ============================================================\n",
    "# 1. Setup save directory\n",
    "# ============================================================\n",
    "save_dir = os.path.join(os.path.expanduser(\"~\"), \"FL_results_alpha_5avged\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. CIFAR-10 Dataset (Non-IID Dirichlet Split, instructor’s alpha)\n",
    "# ============================================================\n",
    "def dirichlet_split_noniid(dataset, num_clients, alpha, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    n_samples = len(dataset)\n",
    "\n",
    "    # ----- Special case: alpha = 0 => IID -----\n",
    "    if alpha == 0:\n",
    "        all_indices = np.random.permutation(n_samples)\n",
    "        splits = np.array_split(all_indices, num_clients)\n",
    "        return {cid: splits[cid] for cid in range(num_clients)}\n",
    "\n",
    "    # ----- alpha > 0 => Dirichlet-based non-IID -----\n",
    "    dirichlet_conc = 1.0 / alpha\n",
    "    dirichlet_conc = float(np.clip(dirichlet_conc, 1e-3, 1e3))\n",
    "\n",
    "    if hasattr(dataset, \"targets\"):\n",
    "        labels = np.array(dataset.targets)\n",
    "    elif hasattr(dataset, \"labels\"):\n",
    "        labels = np.array(dataset.labels)\n",
    "    else:\n",
    "        labels = np.array([dataset[i][1] for i in range(n_samples)])\n",
    "\n",
    "    num_classes = int(labels.max()) + 1\n",
    "    client_indices = defaultdict(list)\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        class_idx = np.where(labels == c)[0]\n",
    "        if len(class_idx) == 0:\n",
    "            continue\n",
    "        np.random.shuffle(class_idx)\n",
    "        proportions = np.random.dirichlet(dirichlet_conc * np.ones(num_clients))\n",
    "        split_points = (np.cumsum(proportions) * len(class_idx)).astype(int)\n",
    "        class_split = np.split(class_idx, split_points[:-1])\n",
    "\n",
    "        for client_id, idx in enumerate(class_split):\n",
    "            client_indices[client_id].extend(idx.tolist())\n",
    "\n",
    "    for client_id in range(num_clients):\n",
    "        idx = np.array(client_indices[client_id], dtype=int)\n",
    "        np.random.shuffle(idx)\n",
    "        client_indices[client_id] = idx\n",
    "\n",
    "    return client_indices\n",
    "\n",
    "def get_cifar10_dirichlet_clients(data_root=\"./data\", num_clients=10, alpha=1.0, batch_size=64, seed=42):\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    trainset = datasets.CIFAR10(root=data_root, train=True, download=True, transform=transform_train)\n",
    "    client_idcs = dirichlet_split_noniid(trainset, num_clients, alpha, seed)\n",
    "\n",
    "    client_loaders = {}\n",
    "    for cid, idxs in client_idcs.items():\n",
    "        subset = Subset(trainset, idxs)\n",
    "        loader = DataLoader(subset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "        client_loaders[cid] = loader\n",
    "\n",
    "    return trainset, client_idcs, client_loaders\n",
    "\n",
    "# ============================================================\n",
    "# 3. Extract 18 leaf layers of ResNet-18\n",
    "# ============================================================\n",
    "def get_resnet18_layers(model):\n",
    "    layers = []\n",
    "    for name, module in model.named_modules():\n",
    "        if len(list(module.children())) == 0:\n",
    "            layers.append((name, module))\n",
    "    return layers[:18]\n",
    "\n",
    "# ============================================================\n",
    "# 4. Euclidean distance between layers\n",
    "# ============================================================\n",
    "def layer_distance(layer_global, layer_client):\n",
    "    dist = 0.0\n",
    "    for p1, p2 in zip(layer_global.parameters(), layer_client.parameters()):\n",
    "        dist += torch.norm(p1.data - p2.data).item()\n",
    "    return dist\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. Local training with BatchNorm-safe handling\n",
    "# ============================================================\n",
    "def train_local(model, loader, epochs=2, lr=0.01, min_batch_for_bn=2):\n",
    "    \"\"\"\n",
    "    model: PyTorch model\n",
    "    loader: DataLoader for local client\n",
    "    epochs: number of local epochs\n",
    "    lr: learning rate\n",
    "    min_batch_for_bn: minimum batch size required for BatchNorm\n",
    "    \"\"\"\n",
    "    model = copy.deepcopy(model).cuda()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        for x, y in loader:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Check batch size for BatchNorm layers\n",
    "            # If batch is too small, temporarily switch to eval mode\n",
    "            if x.size(0) < min_batch_for_bn:\n",
    "                model.eval()\n",
    "                with torch.set_grad_enabled(True):\n",
    "                    outputs = model(x)\n",
    "                    loss = criterion(outputs, y)\n",
    "                model.train()\n",
    "            else:\n",
    "                outputs = model(x)\n",
    "                loss = criterion(outputs, y)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. Load CIFAR-10 clients\n",
    "# ============================================================\n",
    "alpha = 5  # you can also use 5\n",
    "num_clients = 10\n",
    "train_dataset, client_idcs, client_loaders = get_cifar10_dirichlet_clients(\n",
    "    data_root=\"./data\", num_clients=num_clients, alpha=alpha, batch_size=64\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 7. Initialize global and client models\n",
    "# ============================================================\n",
    "global_model = models.resnet18(num_classes=10).cuda()\n",
    "client_models = [copy.deepcopy(global_model) for _ in range(num_clients)]\n",
    "res_layers = get_resnet18_layers(global_model)\n",
    "num_layers = len(res_layers)\n",
    "print(f\"Using {num_layers} layers from ResNet-18\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8. Federated training loop\n",
    "# ============================================================\n",
    "\n",
    "records = []\n",
    "global_rounds = 100\n",
    "local_epochs = 1\n",
    "\n",
    "for r in range(global_rounds):\n",
    "    print(f\"Global Round {r+1}/{global_rounds}\")\n",
    "    updated_clients = []\n",
    "\n",
    "    for i in range(num_clients):\n",
    "        # Train local model\n",
    "        updated_model = train_local(client_models[i], client_loaders[i], epochs=local_epochs)\n",
    "\n",
    "        # Compute layer-wise distances BEFORE FedAvg\n",
    "        for layer_id, (layer_name, _) in enumerate(res_layers):\n",
    "            global_layer = dict(global_model.named_modules())[layer_name]\n",
    "            client_layer = dict(updated_model.named_modules())[layer_name]\n",
    "            dist = layer_distance(global_layer, client_layer)\n",
    "            records.append([r, layer_id, i, dist])\n",
    "\n",
    "        updated_clients.append(updated_model)\n",
    "\n",
    "    # Perform FedAvg aggregation\n",
    "    with torch.no_grad():\n",
    "        for p_global, *p_clients in zip(global_model.parameters(), *[m.parameters() for m in updated_clients]):\n",
    "            stacked = torch.stack([p.data for p in p_clients], dim=0)\n",
    "            p_global.data.copy_(torch.mean(stacked, dim=0))\n",
    "\n",
    "    # Update all client models to the new global model\n",
    "    client_models = [copy.deepcopy(global_model) for _ in range(num_clients)]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 9. Save CSV\n",
    "# ============================================================\n",
    "df = pd.DataFrame(records, columns=[\"round\", \"layer_id\", \"client_id\", \"distance\"])\n",
    "csv_path = f\"{save_dir}/raw_distances.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(\"Saved all raw distances to:\", csv_path)\n",
    "\n",
    "# ============================================================\n",
    "# 10. Generate 18 plots\n",
    "# ============================================================\n",
    "for layer_id in range(num_layers):\n",
    "    plt.figure(figsize=(7,5))\n",
    "    for c in range(num_clients):\n",
    "        d = df[(df.layer_id == layer_id) & (df.client_id == c)]\n",
    "        plt.plot(d[\"round\"], d[\"distance\"], label=f\"Client {c}\")\n",
    "    plt.title(f\"Layer {layer_id} Euclidean Distance\")\n",
    "    plt.xlabel(\"Global Round\")\n",
    "    plt.ylabel(\"Distance\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plot_path = f\"{save_dir}/layer_{layer_id}.png\"\n",
    "    plt.savefig(plot_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "print(\"All plots saved in:\", save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0: {0: 1, 1: 2, 2: 12, 3: 381, 4: 87, 5: 282, 6: 925, 7: 700, 9: 1597}\n",
      "Client 1: {0: 187, 1: 34, 2: 350, 3: 204, 4: 3949, 6: 155, 7: 11, 8: 626, 9: 1}\n",
      "Client 2: {0: 1, 1: 1168, 2: 120, 3: 143, 4: 781, 6: 152, 8: 1}\n",
      "Client 3: {0: 1540, 1: 414, 2: 1, 6: 21, 8: 1, 9: 293}\n",
      "Client 4: {0: 3194, 2: 6, 5: 73, 6: 2250, 8: 27, 9: 173}\n",
      "Client 5: {0: 10, 1: 170, 2: 2977, 3: 17, 4: 2, 5: 3466, 8: 3128}\n",
      "Client 6: {0: 47, 2: 1223, 4: 6, 5: 37, 6: 1485, 7: 4234}\n",
      "Client 7: {0: 6, 1: 3083, 2: 12, 3: 4225, 4: 10, 5: 913, 7: 51, 9: 40}\n",
      "Client 8: {0: 7, 1: 111, 2: 296, 3: 29, 4: 164, 5: 166, 6: 7, 7: 3, 8: 993, 9: 2258}\n",
      "Client 9: {0: 7, 1: 18, 2: 3, 3: 1, 4: 1, 5: 63, 6: 5, 7: 1, 8: 224, 9: 638}\n"
     ]
    }
   ],
   "source": [
    "# labels = np.array(train_dataset.targets)\n",
    "\n",
    "# for client_id, indices in client_idcs.items():\n",
    "#     client_labels = labels[indices]\n",
    "#     unique, counts = np.unique(client_labels, return_counts=True)\n",
    "#     print(f\"Client {client_id}: {dict(zip(unique, counts))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean plots saved in: /home/mkarunar/FL_results_alpha_5avged/mean_plots\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined plot (client 8 excluded) to: /home/mkarunar/FL_results_alpha_5avged/all_layers_one_plot_no_client8.png\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 10A. Plot ALL layers in ONE plot (excluding client 8)\n",
    "# ============================================================\n",
    "\n",
    "EXCLUDED_CLIENT = 8\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for layer_id in range(num_layers):\n",
    "    # Filter out client 8\n",
    "    d = df[(df.layer_id == layer_id) & (df.client_id != EXCLUDED_CLIENT)]\n",
    "    \n",
    "    # Compute mean across remaining clients\n",
    "    mean_d = d.groupby(\"round\")[\"distance\"].mean()\n",
    "\n",
    "    plt.plot(mean_d.index, mean_d.values, label=f\"Layer {layer_id}\")\n",
    "\n",
    "plt.title(\"Mean Euclidean Distance Across Global Rounds (α = 5)\")\n",
    "plt.xlabel(\"Global Round\")\n",
    "plt.ylabel(\"Mean Euclidean Distance\")\n",
    "plt.grid(True)\n",
    "plt.legend(ncol=2, fontsize=8)\n",
    "\n",
    "combined_plot_path = f\"{save_dir}/all_layers_one_plot_no_client8.png\"\n",
    "plt.savefig(combined_plot_path, dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved combined plot (client 8 excluded) to:\", combined_plot_path)\n",
    "# alpha - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0: {0: 1, 1: 2, 2: 12, 3: 381, 4: 87, 5: 282, 6: 925, 7: 700, 9: 1597}\n",
      "Client 1: {0: 187, 1: 34, 2: 350, 3: 204, 4: 3949, 6: 155, 7: 11, 8: 626, 9: 1}\n",
      "Client 2: {0: 1, 1: 1168, 2: 120, 3: 143, 4: 781, 6: 152, 8: 1}\n",
      "Client 3: {0: 1540, 1: 414, 2: 1, 6: 21, 8: 1, 9: 293}\n",
      "Client 4: {0: 3194, 2: 6, 5: 73, 6: 2250, 8: 27, 9: 173}\n",
      "Client 5: {0: 10, 1: 170, 2: 2977, 3: 17, 4: 2, 5: 3466, 8: 3128}\n",
      "Client 6: {0: 47, 2: 1223, 4: 6, 5: 37, 6: 1485, 7: 4234}\n",
      "Client 7: {0: 6, 1: 3083, 2: 12, 3: 4225, 4: 10, 5: 913, 7: 51, 9: 40}\n",
      "Client 8: {0: 7, 1: 111, 2: 296, 3: 29, 4: 164, 5: 166, 6: 7, 7: 3, 8: 993, 9: 2258}\n",
      "Client 9: {0: 7, 1: 18, 2: 3, 3: 1, 4: 1, 5: 63, 6: 5, 7: 1, 8: 224, 9: 638}\n"
     ]
    }
   ],
   "source": [
    "labels = np.array(train_dataset.targets)\n",
    "\n",
    "for client_id, indices in client_idcs.items():\n",
    "    client_labels = labels[indices]\n",
    "    unique, counts = np.unique(client_labels, return_counts=True)\n",
    "    print(f\"Client {client_id}: {dict(zip(unique, counts))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved at: /home/mkarunar/FL_results_alpha_5avged/mean_plots_with all clients/mean_all_layers.png\n",
      "Mean plots saved in: /home/mkarunar/FL_results_alpha_5avged/mean_plots_with all clients\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 11. Generate averaged plots (ALL clients, ALL layers in ONE plot)\n",
    "# ============================================================\n",
    "\n",
    "mean_plot_dir = os.path.join(save_dir, \"mean_plots_with all clients\")\n",
    "os.makedirs(mean_plot_dir, exist_ok=True)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "for layer_id in range(num_layers):\n",
    "\n",
    "    # Filter rows for this layer only\n",
    "    d_layer = df[df.layer_id == layer_id]\n",
    "\n",
    "    # Mean distance over clients per round\n",
    "    mean_curve = d_layer.groupby(\"round\")[\"distance\"].mean()\n",
    "\n",
    "    # Plot this layer’s mean curve\n",
    "    plt.plot(mean_curve.index, mean_curve.values, linewidth=2, label=f\"Layer {layer_id}\")\n",
    "\n",
    "plt.title(\"Mean Euclidean Distance Across Global Rounds (α = 5)\")\n",
    "plt.xlabel(\"Global Round\")\n",
    "plt.ylabel(\"Mean Euclidean Distance\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plot_path = f\"{mean_plot_dir}/mean_all_layers.png\"\n",
    "plt.savefig(plot_path, dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(\"Plot saved at:\", plot_path)\n",
    "print(\"Mean plots saved in:\", mean_plot_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved at: /home/mkarunar/FL_results_alpha_5avged/mean_plots_with all clients/mean_all_layers.png\n",
      "Mean plots saved in: /home/mkarunar/FL_results_alpha_5avged/mean_plots_with all clients\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "for layer_id in range(num_layers):\n",
    "\n",
    "    # Filter rows for this layer only\n",
    "    d_layer = df[df.layer_id == layer_id]\n",
    "\n",
    "    # Mean distance over clients per round\n",
    "    mean_curve = d_layer.groupby(\"round\")[\"distance\"].mean()\n",
    "\n",
    "    # Plot this layer’s mean curve\n",
    "    plt.plot(mean_curve.index, mean_curve.values, linewidth=2, label=f\"Layer {layer_id}\")\n",
    "\n",
    "plt.title(\"Mean Euclidean Distance Across Global Rounds (α = 5)\")\n",
    "plt.xlabel(\"Global Round\")\n",
    "plt.ylabel(\"Mean Euclidean Distance\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Right-aligned legend with white background\n",
    "plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5), facecolor=\"white\", framealpha=1)\n",
    "\n",
    "plot_path = f\"{mean_plot_dir}/mean_all_layers.png\"\n",
    "plt.savefig(plot_path, dpi=300, bbox_inches='tight')  # bbox_inches ensures legend isn't cut off\n",
    "plt.close()\n",
    "\n",
    "print(\"Plot saved at:\", plot_path)\n",
    "print(\"Mean plots saved in:\", mean_plot_dir)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9 (Default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
