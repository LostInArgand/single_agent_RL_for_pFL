RL will choose number of shared layers in [1, 6] for each client.

=== Global Round 1/100 ===
  Client 0: layers_shared=2, local_acc=0.9527
  Client 1: layers_shared=3, local_acc=0.9597
  Client 2: layers_shared=3, local_acc=0.9272
  Client 3: layers_shared=3, local_acc=0.8409
  Client 4: layers_shared=2, local_acc=0.9634
  Client 5: layers_shared=4, local_acc=0.9331
  Client 6: layers_shared=6, local_acc=0.8930
  Client 7: layers_shared=5, local_acc=0.9687
  Client 8: layers_shared=3, local_acc=0.9645
  Client 9: layers_shared=3, local_acc=0.9599
  Client 0: mean_dist=1.66, base_reward=0.1235, violation=0, comm_penalty=0.0000, reward=0.1235
  Client 1: mean_dist=2.11, base_reward=-0.0930, violation=0, comm_penalty=0.0000, reward=-0.0930
  Client 2: mean_dist=2.16, base_reward=-0.1516, violation=2, comm_penalty=0.2000, reward=-0.3516
  Client 3: mean_dist=2.14, base_reward=-0.2281, violation=1, comm_penalty=0.1000, reward=-0.3281
  Client 4: mean_dist=1.59, base_reward=0.1685, violation=0, comm_penalty=0.0000, reward=0.1685
  Client 5: mean_dist=2.37, base_reward=-0.2541, violation=0, comm_penalty=0.0000, reward=-0.2541
  Client 6: mean_dist=2.33, base_reward=-0.2710, violation=5, comm_penalty=0.5000, reward=-0.7710
  Client 7: mean_dist=2.32, base_reward=-0.1915, violation=0, comm_penalty=0.0000, reward=-0.1915
  Client 8: mean_dist=2.12, base_reward=-0.0948, violation=1, comm_penalty=0.1000, reward=-0.1948
  Client 9: mean_dist=2.16, base_reward=-0.1196, violation=0, comm_penalty=0.0000, reward=-0.1196
  RL policy loss: 0.020003
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9296
  Client 1 model accuracy on test set: 0.9305
  Client 2 model accuracy on test set: 0.9072
  Client 3 model accuracy on test set: 0.8424
  Client 4 model accuracy on test set: 0.9391
  Client 5 model accuracy on test set: 0.8888
  Client 6 model accuracy on test set: 0.8677
  Client 7 model accuracy on test set: 0.9492
  Client 8 model accuracy on test set: 0.9449
  Client 9 model accuracy on test set: 0.9286

=== Global Round 2/100 ===
  Client 0: layers_shared=4, local_acc=0.9823
  Client 1: layers_shared=5, local_acc=0.9839
  Client 2: layers_shared=1, local_acc=0.9886
  Client 3: layers_shared=5, local_acc=0.9836
  Client 4: layers_shared=5, local_acc=0.9943
  Client 5: layers_shared=3, local_acc=0.9803
  Client 6: layers_shared=2, local_acc=0.9884
  Client 7: layers_shared=2, local_acc=0.9697
  Client 8: layers_shared=3, local_acc=0.9377
  Client 9: layers_shared=4, local_acc=0.9886
  Client 0: mean_dist=2.64, base_reward=-0.3390, violation=1, comm_penalty=0.1000, reward=-0.4390
  Client 1: mean_dist=2.69, base_reward=-0.3609, violation=0, comm_penalty=0.0000, reward=-0.3609
  Client 2: mean_dist=0.45, base_reward=0.7646, violation=0, comm_penalty=0.0000, reward=0.7646
  Client 3: mean_dist=2.75, base_reward=-0.3902, violation=3, comm_penalty=0.3000, reward=-0.6902
  Client 4: mean_dist=2.75, base_reward=-0.3800, violation=1, comm_penalty=0.1000, reward=-0.4800
  Client 5: mean_dist=2.25, base_reward=-0.1429, violation=0, comm_penalty=0.0000, reward=-0.1429
  Client 6: mean_dist=1.61, base_reward=0.1835, violation=1, comm_penalty=0.1000, reward=0.0835
  Client 7: mean_dist=1.58, base_reward=0.1783, violation=0, comm_penalty=0.0000, reward=0.1783
  Client 8: mean_dist=2.14, base_reward=-0.1332, violation=1, comm_penalty=0.1000, reward=-0.2332
  Client 9: mean_dist=2.59, base_reward=-0.3076, violation=0, comm_penalty=0.0000, reward=-0.3076
  RL policy loss: 0.075172
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9558
  Client 1 model accuracy on test set: 0.9451
  Client 2 model accuracy on test set: 0.9627
  Client 3 model accuracy on test set: 0.9577
  Client 4 model accuracy on test set: 0.9627
  Client 5 model accuracy on test set: 0.9577
  Client 6 model accuracy on test set: 0.9663
  Client 7 model accuracy on test set: 0.9525
  Client 8 model accuracy on test set: 0.9087
  Client 9 model accuracy on test set: 0.9682

=== Global Round 3/100 ===
  Client 0: layers_shared=1, local_acc=0.9973
  Client 1: layers_shared=6, local_acc=0.9861
  Client 2: layers_shared=2, local_acc=0.9993
  Client 3: layers_shared=6, local_acc=0.9984
  Client 4: layers_shared=5, local_acc=0.9983
  Client 5: layers_shared=5, local_acc=0.7384
  Client 6: layers_shared=6, local_acc=0.9961
  Client 7: layers_shared=4, local_acc=0.9924
  Client 8: layers_shared=1, local_acc=0.9948
  Client 9: layers_shared=6, local_acc=0.9993
  Client 0: mean_dist=0.45, base_reward=0.7740, violation=0, comm_penalty=0.0000, reward=0.7740
  Client 1: mean_dist=3.17, base_reward=-0.5992, violation=1, comm_penalty=0.1000, reward=-0.6992
  Client 2: mean_dist=1.50, base_reward=0.2470, violation=1, comm_penalty=0.1000, reward=0.1470
  Client 3: mean_dist=3.25, base_reward=-0.6252, violation=4, comm_penalty=0.4000, reward=-1.0252
  Client 4: mean_dist=3.22, base_reward=-0.6128, violation=1, comm_penalty=0.1000, reward=-0.7128
  Client 5: mean_dist=3.30, base_reward=-0.9119, violation=0, comm_penalty=0.0000, reward=-0.9119
  Client 6: mean_dist=3.21, base_reward=-0.6068, violation=5, comm_penalty=0.5000, reward=-1.1068
  Client 7: mean_dist=2.70, base_reward=-0.3567, violation=0, comm_penalty=0.0000, reward=-0.3567
  Client 8: mean_dist=0.43, base_reward=0.7799, violation=0, comm_penalty=0.0000, reward=0.7799
  Client 9: mean_dist=3.24, base_reward=-0.6231, violation=1, comm_penalty=0.1000, reward=-0.7231
  RL policy loss: 0.094757
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9708
  Client 1 model accuracy on test set: 0.9520
  Client 2 model accuracy on test set: 0.9782
  Client 3 model accuracy on test set: 0.9733
  Client 4 model accuracy on test set: 0.9646
  Client 5 model accuracy on test set: 0.6891
  Client 6 model accuracy on test set: 0.9661
  Client 7 model accuracy on test set: 0.9682
  Client 8 model accuracy on test set: 0.9717
  Client 9 model accuracy on test set: 0.9744

=== Global Round 4/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=0.9992
  Client 2: layers_shared=1, local_acc=0.9993
  Client 3: layers_shared=1, local_acc=0.9991
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=0.9962
  Client 6: layers_shared=5, local_acc=1.0000
  Client 7: layers_shared=4, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=0.9998
  Client 9: layers_shared=2, local_acc=0.9999
  Client 0: mean_dist=1.39, base_reward=0.3034, violation=0, comm_penalty=0.0000, reward=0.3034
  Client 1: mean_dist=0.44, base_reward=0.7779, violation=0, comm_penalty=0.0000, reward=0.7779
  Client 2: mean_dist=0.45, base_reward=0.7723, violation=0, comm_penalty=0.0000, reward=0.7723
  Client 3: mean_dist=0.47, base_reward=0.7660, violation=0, comm_penalty=0.0000, reward=0.7660
  Client 4: mean_dist=1.67, base_reward=0.1648, violation=1, comm_penalty=0.1000, reward=0.0648
  Client 5: mean_dist=0.45, base_reward=0.7735, violation=0, comm_penalty=0.0000, reward=0.7735
  Client 6: mean_dist=1.67, base_reward=0.1657, violation=4, comm_penalty=0.4000, reward=-0.2343
  Client 7: mean_dist=1.57, base_reward=0.2164, violation=0, comm_penalty=0.0000, reward=0.2164
  Client 8: mean_dist=0.44, base_reward=0.7816, violation=0, comm_penalty=0.0000, reward=0.7816
  Client 9: mean_dist=1.08, base_reward=0.4602, violation=0, comm_penalty=0.0000, reward=0.4602
  RL policy loss: 0.020083
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9773
  Client 1 model accuracy on test set: 0.9690
  Client 2 model accuracy on test set: 0.9766
  Client 3 model accuracy on test set: 0.9781
  Client 4 model accuracy on test set: 0.9702
  Client 5 model accuracy on test set: 0.9724
  Client 6 model accuracy on test set: 0.9788
  Client 7 model accuracy on test set: 0.9789
  Client 8 model accuracy on test set: 0.9763
  Client 9 model accuracy on test set: 0.9766

=== Global Round 5/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=2, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=2, local_acc=1.0000
  Client 6: layers_shared=4, local_acc=0.9998
  Client 7: layers_shared=5, local_acc=1.0000
  Client 8: layers_shared=4, local_acc=1.0000
  Client 9: layers_shared=6, local_acc=1.0000
  Client 0: mean_dist=3.20, base_reward=-0.5985, violation=2, comm_penalty=0.2000, reward=-0.7985
  Client 1: mean_dist=2.26, base_reward=-0.1275, violation=0, comm_penalty=0.0000, reward=-0.1275
  Client 2: mean_dist=0.45, base_reward=0.7744, violation=0, comm_penalty=0.0000, reward=0.7744
  Client 3: mean_dist=1.67, base_reward=0.1673, violation=0, comm_penalty=0.0000, reward=0.1673
  Client 4: mean_dist=3.11, base_reward=-0.5570, violation=1, comm_penalty=0.1000, reward=-0.6570
  Client 5: mean_dist=1.72, base_reward=0.1407, violation=0, comm_penalty=0.0000, reward=0.1407
  Client 6: mean_dist=2.82, base_reward=-0.4106, violation=3, comm_penalty=0.3000, reward=-0.7106
  Client 7: mean_dist=3.07, base_reward=-0.5332, violation=0, comm_penalty=0.0000, reward=-0.5332
  Client 8: mean_dist=2.80, base_reward=-0.4005, violation=2, comm_penalty=0.2000, reward=-0.6005
  Client 9: mean_dist=3.14, base_reward=-0.5697, violation=1, comm_penalty=0.1000, reward=-0.6697
  RL policy loss: 0.091218
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9796
  Client 1 model accuracy on test set: 0.9743
  Client 2 model accuracy on test set: 0.9819
  Client 3 model accuracy on test set: 0.9820
  Client 4 model accuracy on test set: 0.9742
  Client 5 model accuracy on test set: 0.9786
  Client 6 model accuracy on test set: 0.9787
  Client 7 model accuracy on test set: 0.9778
  Client 8 model accuracy on test set: 0.9787
  Client 9 model accuracy on test set: 0.9782

=== Global Round 6/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=6, local_acc=1.0000
  Client 2: layers_shared=4, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=0.9828
  Client 6: layers_shared=5, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=6, local_acc=1.0000
  Client 0: mean_dist=3.27, base_reward=-0.6350, violation=2, comm_penalty=0.2000, reward=-0.8350
  Client 1: mean_dist=3.15, base_reward=-0.5753, violation=1, comm_penalty=0.1000, reward=-0.6753
  Client 2: mean_dist=2.83, base_reward=-0.4155, violation=3, comm_penalty=0.3000, reward=-0.7155
  Client 3: mean_dist=0.46, base_reward=0.7689, violation=0, comm_penalty=0.0000, reward=0.7689
  Client 4: mean_dist=3.20, base_reward=-0.6021, violation=1, comm_penalty=0.1000, reward=-0.7021
  Client 5: mean_dist=2.33, base_reward=-0.1831, violation=0, comm_penalty=0.0000, reward=-0.1831
  Client 6: mean_dist=3.18, base_reward=-0.5901, violation=4, comm_penalty=0.4000, reward=-0.9901
  Client 7: mean_dist=0.44, base_reward=0.7786, violation=0, comm_penalty=0.0000, reward=0.7786
  Client 8: mean_dist=2.24, base_reward=-0.1203, violation=1, comm_penalty=0.1000, reward=-0.2203
  Client 9: mean_dist=3.23, base_reward=-0.6158, violation=1, comm_penalty=0.1000, reward=-0.7158
  RL policy loss: 0.021644
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9798
  Client 1 model accuracy on test set: 0.9757
  Client 2 model accuracy on test set: 0.9827
  Client 3 model accuracy on test set: 0.9823
  Client 4 model accuracy on test set: 0.9746
  Client 5 model accuracy on test set: 0.9235
  Client 6 model accuracy on test set: 0.9810
  Client 7 model accuracy on test set: 0.9799
  Client 8 model accuracy on test set: 0.9798
  Client 9 model accuracy on test set: 0.9799

=== Global Round 7/100 ===
  Client 0: layers_shared=4, local_acc=1.0000
  Client 1: layers_shared=6, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=2, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=6, local_acc=1.0000
  Client 7: layers_shared=6, local_acc=1.0000
  Client 8: layers_shared=2, local_acc=1.0000
  Client 9: layers_shared=5, local_acc=1.0000
  Client 0: mean_dist=3.09, base_reward=-0.5426, violation=1, comm_penalty=0.1000, reward=-0.6426
  Client 1: mean_dist=3.26, base_reward=-0.6280, violation=1, comm_penalty=0.1000, reward=-0.7280
  Client 2: mean_dist=2.57, base_reward=-0.2860, violation=2, comm_penalty=0.2000, reward=-0.4860
  Client 3: mean_dist=1.82, base_reward=0.0910, violation=0, comm_penalty=0.0000, reward=0.0910
  Client 4: mean_dist=2.54, base_reward=-0.2712, violation=0, comm_penalty=0.0000, reward=-0.2712
  Client 5: mean_dist=2.65, base_reward=-0.3253, violation=0, comm_penalty=0.0000, reward=-0.3253
  Client 6: mean_dist=3.29, base_reward=-0.6437, violation=5, comm_penalty=0.5000, reward=-1.1437
  Client 7: mean_dist=3.26, base_reward=-0.6280, violation=0, comm_penalty=0.0000, reward=-0.6280
  Client 8: mean_dist=1.80, base_reward=0.0996, violation=0, comm_penalty=0.0000, reward=0.0996
  Client 9: mean_dist=3.29, base_reward=-0.6433, violation=0, comm_penalty=0.0000, reward=-0.6433
  RL policy loss: 0.093210
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9796
  Client 1 model accuracy on test set: 0.9760
  Client 2 model accuracy on test set: 0.9832
  Client 3 model accuracy on test set: 0.9823
  Client 4 model accuracy on test set: 0.9756
  Client 5 model accuracy on test set: 0.9816
  Client 6 model accuracy on test set: 0.9808
  Client 7 model accuracy on test set: 0.9792
  Client 8 model accuracy on test set: 0.9795
  Client 9 model accuracy on test set: 0.9792

=== Global Round 8/100 ===
  Client 0: layers_shared=6, local_acc=1.0000
  Client 1: layers_shared=2, local_acc=1.0000
  Client 2: layers_shared=5, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=5, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=3.15, base_reward=-0.5726, violation=3, comm_penalty=0.3000, reward=-0.8726
  Client 1: mean_dist=1.66, base_reward=0.1719, violation=0, comm_penalty=0.0000, reward=0.1719
  Client 2: mean_dist=3.08, base_reward=-0.5419, violation=4, comm_penalty=0.4000, reward=-0.9419
  Client 3: mean_dist=2.42, base_reward=-0.2093, violation=1, comm_penalty=0.1000, reward=-0.3093
  Client 4: mean_dist=3.05, base_reward=-0.5262, violation=1, comm_penalty=0.1000, reward=-0.6262
  Client 5: mean_dist=3.18, base_reward=-0.5918, violation=0, comm_penalty=0.0000, reward=-0.5918
  Client 6: mean_dist=2.41, base_reward=-0.2060, violation=2, comm_penalty=0.2000, reward=-0.4060
  Client 7: mean_dist=2.40, base_reward=-0.1979, violation=0, comm_penalty=0.0000, reward=-0.1979
  Client 8: mean_dist=0.43, base_reward=0.7825, violation=0, comm_penalty=0.0000, reward=0.7825
  Client 9: mean_dist=2.44, base_reward=-0.2219, violation=0, comm_penalty=0.0000, reward=-0.2219
  RL policy loss: 0.060017
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9807
  Client 1 model accuracy on test set: 0.9763
  Client 2 model accuracy on test set: 0.9826
  Client 3 model accuracy on test set: 0.9819
  Client 4 model accuracy on test set: 0.9751
  Client 5 model accuracy on test set: 0.9819
  Client 6 model accuracy on test set: 0.9805
  Client 7 model accuracy on test set: 0.9798
  Client 8 model accuracy on test set: 0.9793
  Client 9 model accuracy on test set: 0.9783

=== Global Round 9/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=5, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=4, local_acc=1.0000
  Client 4: layers_shared=6, local_acc=1.0000
  Client 5: layers_shared=6, local_acc=1.0000
  Client 6: layers_shared=6, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=2, local_acc=1.0000
  Client 9: layers_shared=4, local_acc=1.0000
  Client 0: mean_dist=0.44, base_reward=0.7776, violation=0, comm_penalty=0.0000, reward=0.7776
  Client 1: mean_dist=3.23, base_reward=-0.6159, violation=0, comm_penalty=0.0000, reward=-0.6159
  Client 2: mean_dist=2.42, base_reward=-0.2086, violation=2, comm_penalty=0.2000, reward=-0.4086
  Client 3: mean_dist=2.99, base_reward=-0.4932, violation=2, comm_penalty=0.2000, reward=-0.6932
  Client 4: mean_dist=3.34, base_reward=-0.6691, violation=2, comm_penalty=0.2000, reward=-0.8691
  Client 5: mean_dist=3.44, base_reward=-0.7200, violation=0, comm_penalty=0.0000, reward=-0.7200
  Client 6: mean_dist=3.29, base_reward=-0.6473, violation=5, comm_penalty=0.5000, reward=-1.1473
  Client 7: mean_dist=2.38, base_reward=-0.1895, violation=0, comm_penalty=0.0000, reward=-0.1895
  Client 8: mean_dist=1.64, base_reward=0.1784, violation=0, comm_penalty=0.0000, reward=0.1784
  Client 9: mean_dist=3.00, base_reward=-0.4976, violation=0, comm_penalty=0.0000, reward=-0.4976
  RL policy loss: 0.044157
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9801
  Client 1 model accuracy on test set: 0.9755
  Client 2 model accuracy on test set: 0.9839
  Client 3 model accuracy on test set: 0.9822
  Client 4 model accuracy on test set: 0.9751
  Client 5 model accuracy on test set: 0.9791
  Client 6 model accuracy on test set: 0.9810
  Client 7 model accuracy on test set: 0.9788
  Client 8 model accuracy on test set: 0.9794
  Client 9 model accuracy on test set: 0.9786

=== Global Round 10/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=4, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=4, local_acc=1.0000
  Client 4: layers_shared=4, local_acc=1.0000
  Client 5: layers_shared=5, local_acc=1.0000
  Client 6: layers_shared=5, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=6, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=3.34, base_reward=-0.6715, violation=2, comm_penalty=0.2000, reward=-0.8715
  Client 1: mean_dist=2.90, base_reward=-0.4521, violation=0, comm_penalty=0.0000, reward=-0.4521
  Client 2: mean_dist=2.28, base_reward=-0.1391, violation=2, comm_penalty=0.2000, reward=-0.3391
  Client 3: mean_dist=2.96, base_reward=-0.4820, violation=2, comm_penalty=0.2000, reward=-0.6820
  Client 4: mean_dist=2.94, base_reward=-0.4701, violation=0, comm_penalty=0.0000, reward=-0.4701
  Client 5: mean_dist=3.39, base_reward=-0.6928, violation=0, comm_penalty=0.0000, reward=-0.6928
  Client 6: mean_dist=3.24, base_reward=-0.6212, violation=4, comm_penalty=0.4000, reward=-1.0212
  Client 7: mean_dist=0.44, base_reward=0.7775, violation=0, comm_penalty=0.0000, reward=0.7775
  Client 8: mean_dist=3.23, base_reward=-0.6161, violation=4, comm_penalty=0.4000, reward=-1.0161
  Client 9: mean_dist=0.46, base_reward=0.7712, violation=0, comm_penalty=0.0000, reward=0.7712
  RL policy loss: 0.002150
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9803
  Client 1 model accuracy on test set: 0.9769
  Client 2 model accuracy on test set: 0.9831
  Client 3 model accuracy on test set: 0.9826
  Client 4 model accuracy on test set: 0.9754
  Client 5 model accuracy on test set: 0.9803
  Client 6 model accuracy on test set: 0.9802
  Client 7 model accuracy on test set: 0.9802
  Client 8 model accuracy on test set: 0.9795
  Client 9 model accuracy on test set: 0.9798

=== Global Round 11/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=2, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=2, local_acc=1.0000
  Client 5: layers_shared=4, local_acc=1.0000
  Client 6: layers_shared=2, local_acc=1.0000
  Client 7: layers_shared=5, local_acc=1.0000
  Client 8: layers_shared=5, local_acc=1.0000
  Client 9: layers_shared=4, local_acc=1.0000
  Client 0: mean_dist=2.96, base_reward=-0.4794, violation=2, comm_penalty=0.2000, reward=-0.6794
  Client 1: mean_dist=1.66, base_reward=0.1687, violation=0, comm_penalty=0.0000, reward=0.1687
  Client 2: mean_dist=0.45, base_reward=0.7743, violation=0, comm_penalty=0.0000, reward=0.7743
  Client 3: mean_dist=2.21, base_reward=-0.1053, violation=1, comm_penalty=0.1000, reward=-0.2053
  Client 4: mean_dist=1.66, base_reward=0.1679, violation=0, comm_penalty=0.0000, reward=0.1679
  Client 5: mean_dist=2.78, base_reward=-0.3910, violation=0, comm_penalty=0.0000, reward=-0.3910
  Client 6: mean_dist=1.69, base_reward=0.1558, violation=1, comm_penalty=0.1000, reward=0.0558
  Client 7: mean_dist=2.83, base_reward=-0.4163, violation=0, comm_penalty=0.0000, reward=-0.4163
  Client 8: mean_dist=2.83, base_reward=-0.4174, violation=3, comm_penalty=0.3000, reward=-0.7174
  Client 9: mean_dist=2.69, base_reward=-0.3465, violation=0, comm_penalty=0.0000, reward=-0.3465
  RL policy loss: 0.070433
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9805
  Client 1 model accuracy on test set: 0.9762
  Client 2 model accuracy on test set: 0.9833
  Client 3 model accuracy on test set: 0.9827
  Client 4 model accuracy on test set: 0.9753
  Client 5 model accuracy on test set: 0.9816
  Client 6 model accuracy on test set: 0.9804
  Client 7 model accuracy on test set: 0.9796
  Client 8 model accuracy on test set: 0.9798
  Client 9 model accuracy on test set: 0.9800

=== Global Round 12/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=6, local_acc=1.0000
  Client 2: layers_shared=5, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=1.0000
  Client 5: layers_shared=5, local_acc=0.9969
  Client 6: layers_shared=6, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=4, local_acc=1.0000
  Client 9: layers_shared=6, local_acc=1.0000
  Client 0: mean_dist=3.83, base_reward=-0.9174, violation=2, comm_penalty=0.2000, reward=-1.1174
  Client 1: mean_dist=3.69, base_reward=-0.8440, violation=1, comm_penalty=0.1000, reward=-0.9440
  Client 2: mean_dist=3.73, base_reward=-0.8628, violation=4, comm_penalty=0.4000, reward=-1.2628
  Client 3: mean_dist=2.53, base_reward=-0.2660, violation=1, comm_penalty=0.1000, reward=-0.3660
  Client 4: mean_dist=2.51, base_reward=-0.2567, violation=0, comm_penalty=0.0000, reward=-0.2567
  Client 5: mean_dist=3.87, base_reward=-0.9399, violation=0, comm_penalty=0.0000, reward=-0.9399
  Client 6: mean_dist=3.72, base_reward=-0.8601, violation=5, comm_penalty=0.5000, reward=-1.3601
  Client 7: mean_dist=0.45, base_reward=0.7772, violation=0, comm_penalty=0.0000, reward=0.7772
  Client 8: mean_dist=3.19, base_reward=-0.5937, violation=2, comm_penalty=0.2000, reward=-0.7937
  Client 9: mean_dist=3.76, base_reward=-0.8806, violation=1, comm_penalty=0.1000, reward=-0.9806
  RL policy loss: -0.023508
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9802
  Client 1 model accuracy on test set: 0.9760
  Client 2 model accuracy on test set: 0.9834
  Client 3 model accuracy on test set: 0.9830
  Client 4 model accuracy on test set: 0.9743
  Client 5 model accuracy on test set: 0.9607
  Client 6 model accuracy on test set: 0.9810
  Client 7 model accuracy on test set: 0.9805
  Client 8 model accuracy on test set: 0.9801
  Client 9 model accuracy on test set: 0.9791

=== Global Round 13/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=6, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=6, local_acc=1.0000
  Client 7: layers_shared=2, local_acc=1.0000
  Client 8: layers_shared=5, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=0.45, base_reward=0.7775, violation=0, comm_penalty=0.0000, reward=0.7775
  Client 1: mean_dist=1.87, base_reward=0.0634, violation=0, comm_penalty=0.0000, reward=0.0634
  Client 2: mean_dist=2.56, base_reward=-0.2791, violation=5, comm_penalty=0.5000, reward=-0.7791
  Client 3: mean_dist=0.46, base_reward=0.7680, violation=0, comm_penalty=0.0000, reward=0.7680
  Client 4: mean_dist=2.56, base_reward=-0.2806, violation=1, comm_penalty=0.1000, reward=-0.3806
  Client 5: mean_dist=1.96, base_reward=0.0205, violation=0, comm_penalty=0.0000, reward=0.0205
  Client 6: mean_dist=2.54, base_reward=-0.2691, violation=5, comm_penalty=0.5000, reward=-0.7691
  Client 7: mean_dist=1.36, base_reward=0.3209, violation=0, comm_penalty=0.0000, reward=0.3209
  Client 8: mean_dist=2.52, base_reward=-0.2587, violation=3, comm_penalty=0.3000, reward=-0.5587
  Client 9: mean_dist=0.46, base_reward=0.7716, violation=0, comm_penalty=0.0000, reward=0.7716
  RL policy loss: 0.023936
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9800
  Client 1 model accuracy on test set: 0.9758
  Client 2 model accuracy on test set: 0.9844
  Client 3 model accuracy on test set: 0.9824
  Client 4 model accuracy on test set: 0.9757
  Client 5 model accuracy on test set: 0.9796
  Client 6 model accuracy on test set: 0.9808
  Client 7 model accuracy on test set: 0.9803
  Client 8 model accuracy on test set: 0.9796
  Client 9 model accuracy on test set: 0.9800

=== Global Round 14/100 ===
  Client 0: layers_shared=6, local_acc=1.0000
  Client 1: layers_shared=6, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=5, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=5, local_acc=1.0000
  Client 8: layers_shared=2, local_acc=1.0000
  Client 9: layers_shared=2, local_acc=1.0000
  Client 0: mean_dist=3.02, base_reward=-0.5092, violation=3, comm_penalty=0.3000, reward=-0.8092
  Client 1: mean_dist=2.92, base_reward=-0.4581, violation=1, comm_penalty=0.1000, reward=-0.5581
  Client 2: mean_dist=0.45, base_reward=0.7734, violation=0, comm_penalty=0.0000, reward=0.7734
  Client 3: mean_dist=2.07, base_reward=-0.0337, violation=1, comm_penalty=0.1000, reward=-0.1337
  Client 4: mean_dist=2.92, base_reward=-0.4610, violation=1, comm_penalty=0.1000, reward=-0.5610
  Client 5: mean_dist=3.05, base_reward=-0.5257, violation=0, comm_penalty=0.0000, reward=-0.5257
  Client 6: mean_dist=0.44, base_reward=0.7818, violation=0, comm_penalty=0.0000, reward=0.7818
  Client 7: mean_dist=2.90, base_reward=-0.4515, violation=0, comm_penalty=0.0000, reward=-0.4515
  Client 8: mean_dist=1.50, base_reward=0.2481, violation=0, comm_penalty=0.0000, reward=0.2481
  Client 9: mean_dist=1.55, base_reward=0.2226, violation=0, comm_penalty=0.0000, reward=0.2226
  RL policy loss: 0.062278
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9798
  Client 1 model accuracy on test set: 0.9760
  Client 2 model accuracy on test set: 0.9836
  Client 3 model accuracy on test set: 0.9831
  Client 4 model accuracy on test set: 0.9758
  Client 5 model accuracy on test set: 0.9815
  Client 6 model accuracy on test set: 0.9807
  Client 7 model accuracy on test set: 0.9807
  Client 8 model accuracy on test set: 0.9812
  Client 9 model accuracy on test set: 0.9803

=== Global Round 15/100 ===
  Client 0: layers_shared=6, local_acc=1.0000
  Client 1: layers_shared=5, local_acc=1.0000
  Client 2: layers_shared=4, local_acc=1.0000
  Client 3: layers_shared=5, local_acc=1.0000
  Client 4: layers_shared=4, local_acc=1.0000
  Client 5: layers_shared=6, local_acc=1.0000
  Client 6: layers_shared=5, local_acc=1.0000
  Client 7: layers_shared=5, local_acc=1.0000
  Client 8: layers_shared=5, local_acc=1.0000
  Client 9: layers_shared=2, local_acc=1.0000
  Client 0: mean_dist=4.37, base_reward=-1.1873, violation=3, comm_penalty=0.3000, reward=-1.4873
  Client 1: mean_dist=4.15, base_reward=-1.0732, violation=0, comm_penalty=0.0000, reward=-1.0732
  Client 2: mean_dist=3.62, base_reward=-0.8118, violation=3, comm_penalty=0.3000, reward=-1.1118
  Client 3: mean_dist=4.23, base_reward=-1.1136, violation=3, comm_penalty=0.3000, reward=-1.4136
  Client 4: mean_dist=3.61, base_reward=-0.8039, violation=0, comm_penalty=0.0000, reward=-0.8039
  Client 5: mean_dist=4.44, base_reward=-1.2182, violation=0, comm_penalty=0.0000, reward=-1.2182
  Client 6: mean_dist=4.19, base_reward=-1.0949, violation=4, comm_penalty=0.4000, reward=-1.4949
  Client 7: mean_dist=4.14, base_reward=-1.0694, violation=0, comm_penalty=0.0000, reward=-1.0694
  Client 8: mean_dist=4.16, base_reward=-1.0785, violation=3, comm_penalty=0.3000, reward=-1.3785
  Client 9: mean_dist=1.87, base_reward=0.0646, violation=0, comm_penalty=0.0000, reward=0.0646
  RL policy loss: 0.097151
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9808
  Client 1 model accuracy on test set: 0.9764
  Client 2 model accuracy on test set: 0.9834
  Client 3 model accuracy on test set: 0.9822
  Client 4 model accuracy on test set: 0.9752
  Client 5 model accuracy on test set: 0.9825
  Client 6 model accuracy on test set: 0.9807
  Client 7 model accuracy on test set: 0.9806
  Client 8 model accuracy on test set: 0.9801
  Client 9 model accuracy on test set: 0.9800

=== Global Round 16/100 ===
  Client 0: layers_shared=6, local_acc=1.0000
  Client 1: layers_shared=5, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=5, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=4, local_acc=0.9873
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=5, local_acc=1.0000
  Client 9: layers_shared=4, local_acc=1.0000
  Client 0: mean_dist=3.62, base_reward=-0.8123, violation=3, comm_penalty=0.3000, reward=-1.1123
  Client 1: mean_dist=3.49, base_reward=-0.7448, violation=0, comm_penalty=0.0000, reward=-0.7448
  Client 2: mean_dist=1.70, base_reward=0.1500, violation=1, comm_penalty=0.1000, reward=0.0500
  Client 3: mean_dist=3.55, base_reward=-0.7743, violation=3, comm_penalty=0.3000, reward=-1.0743
  Client 4: mean_dist=3.55, base_reward=-0.7728, violation=1, comm_penalty=0.1000, reward=-0.8728
  Client 5: mean_dist=3.28, base_reward=-0.6517, violation=0, comm_penalty=0.0000, reward=-0.6517
  Client 6: mean_dist=0.44, base_reward=0.7820, violation=0, comm_penalty=0.0000, reward=0.7820
  Client 7: mean_dist=2.41, base_reward=-0.2058, violation=0, comm_penalty=0.0000, reward=-0.2058
  Client 8: mean_dist=3.51, base_reward=-0.7527, violation=3, comm_penalty=0.3000, reward=-1.0527
  Client 9: mean_dist=3.16, base_reward=-0.5786, violation=0, comm_penalty=0.0000, reward=-0.5786
  RL policy loss: 0.029663
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9806
  Client 1 model accuracy on test set: 0.9763
  Client 2 model accuracy on test set: 0.9838
  Client 3 model accuracy on test set: 0.9830
  Client 4 model accuracy on test set: 0.9766
  Client 5 model accuracy on test set: 0.9632
  Client 6 model accuracy on test set: 0.9817
  Client 7 model accuracy on test set: 0.9802
  Client 8 model accuracy on test set: 0.9798
  Client 9 model accuracy on test set: 0.9798

=== Global Round 17/100 ===
  Client 0: layers_shared=4, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=6, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=5, local_acc=1.0000
  Client 9: layers_shared=5, local_acc=1.0000
  Client 0: mean_dist=2.44, base_reward=-0.2180, violation=1, comm_penalty=0.1000, reward=-0.3180
  Client 1: mean_dist=0.44, base_reward=0.7784, violation=0, comm_penalty=0.0000, reward=0.7784
  Client 2: mean_dist=0.45, base_reward=0.7731, violation=0, comm_penalty=0.0000, reward=0.7731
  Client 3: mean_dist=2.03, base_reward=-0.0136, violation=1, comm_penalty=0.1000, reward=-0.1136
  Client 4: mean_dist=0.44, base_reward=0.7796, violation=0, comm_penalty=0.0000, reward=0.7796
  Client 5: mean_dist=2.11, base_reward=-0.0568, violation=0, comm_penalty=0.0000, reward=-0.0568
  Client 6: mean_dist=2.55, base_reward=-0.2750, violation=5, comm_penalty=0.5000, reward=-0.7750
  Client 7: mean_dist=2.00, base_reward=-0.0023, violation=0, comm_penalty=0.0000, reward=-0.0023
  Client 8: mean_dist=2.52, base_reward=-0.2622, violation=3, comm_penalty=0.3000, reward=-0.5622
  Client 9: mean_dist=2.57, base_reward=-0.2846, violation=0, comm_penalty=0.0000, reward=-0.2846
  RL policy loss: -0.017045
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9804
  Client 1 model accuracy on test set: 0.9766
  Client 2 model accuracy on test set: 0.9837
  Client 3 model accuracy on test set: 0.9827
  Client 4 model accuracy on test set: 0.9766
  Client 5 model accuracy on test set: 0.9797
  Client 6 model accuracy on test set: 0.9813
  Client 7 model accuracy on test set: 0.9801
  Client 8 model accuracy on test set: 0.9803
  Client 9 model accuracy on test set: 0.9801

=== Global Round 18/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=2, local_acc=1.0000
  Client 2: layers_shared=6, local_acc=1.0000
  Client 3: layers_shared=5, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=5, local_acc=1.0000
  Client 7: layers_shared=5, local_acc=1.0000
  Client 8: layers_shared=4, local_acc=1.0000
  Client 9: layers_shared=6, local_acc=1.0000
  Client 0: mean_dist=4.24, base_reward=-1.1194, violation=2, comm_penalty=0.2000, reward=-1.3194
  Client 1: mean_dist=1.82, base_reward=0.0885, violation=0, comm_penalty=0.0000, reward=0.0885
  Client 2: mean_dist=4.13, base_reward=-1.0664, violation=5, comm_penalty=0.5000, reward=-1.5664
  Client 3: mean_dist=4.12, base_reward=-1.0608, violation=3, comm_penalty=0.3000, reward=-1.3608
  Client 4: mean_dist=4.14, base_reward=-1.0692, violation=1, comm_penalty=0.1000, reward=-1.1692
  Client 5: mean_dist=2.82, base_reward=-0.4093, violation=0, comm_penalty=0.0000, reward=-0.4093
  Client 6: mean_dist=4.09, base_reward=-1.0463, violation=4, comm_penalty=0.4000, reward=-1.4463
  Client 7: mean_dist=4.03, base_reward=-1.0148, violation=0, comm_penalty=0.0000, reward=-1.0148
  Client 8: mean_dist=3.47, base_reward=-0.7325, violation=2, comm_penalty=0.2000, reward=-0.9325
  Client 9: mean_dist=4.14, base_reward=-1.0705, violation=1, comm_penalty=0.1000, reward=-1.1705
  RL policy loss: 0.058789
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9809
  Client 1 model accuracy on test set: 0.9768
  Client 2 model accuracy on test set: 0.9837
  Client 3 model accuracy on test set: 0.9823
  Client 4 model accuracy on test set: 0.9766
  Client 5 model accuracy on test set: 0.9815
  Client 6 model accuracy on test set: 0.9814
  Client 7 model accuracy on test set: 0.9801
  Client 8 model accuracy on test set: 0.9799
  Client 9 model accuracy on test set: 0.9803

=== Global Round 19/100 ===
  Client 0: layers_shared=4, local_acc=1.0000
  Client 1: layers_shared=5, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=2, local_acc=1.0000
  Client 8: layers_shared=2, local_acc=1.0000
  Client 9: layers_shared=4, local_acc=1.0000
  Client 0: mean_dist=1.80, base_reward=0.1000, violation=1, comm_penalty=0.1000, reward=-0.0000
  Client 1: mean_dist=1.75, base_reward=0.1267, violation=0, comm_penalty=0.0000, reward=0.1267
  Client 2: mean_dist=0.45, base_reward=0.7733, violation=0, comm_penalty=0.0000, reward=0.7733
  Client 3: mean_dist=0.47, base_reward=0.7673, violation=0, comm_penalty=0.0000, reward=0.7673
  Client 4: mean_dist=1.52, base_reward=0.2392, violation=0, comm_penalty=0.0000, reward=0.2392
  Client 5: mean_dist=0.45, base_reward=0.7764, violation=0, comm_penalty=0.0000, reward=0.7764
  Client 6: mean_dist=0.44, base_reward=0.7816, violation=0, comm_penalty=0.0000, reward=0.7816
  Client 7: mean_dist=1.21, base_reward=0.3939, violation=0, comm_penalty=0.0000, reward=0.3939
  Client 8: mean_dist=1.20, base_reward=0.3989, violation=0, comm_penalty=0.0000, reward=0.3989
  Client 9: mean_dist=1.78, base_reward=0.1092, violation=0, comm_penalty=0.0000, reward=0.1092
  RL policy loss: -0.027002
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9811
  Client 1 model accuracy on test set: 0.9766
  Client 2 model accuracy on test set: 0.9839
  Client 3 model accuracy on test set: 0.9832
  Client 4 model accuracy on test set: 0.9757
  Client 5 model accuracy on test set: 0.9811
  Client 6 model accuracy on test set: 0.9814
  Client 7 model accuracy on test set: 0.9802
  Client 8 model accuracy on test set: 0.9807
  Client 9 model accuracy on test set: 0.9800

=== Global Round 20/100 ===
  Client 0: layers_shared=4, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=6, local_acc=1.0000
  Client 3: layers_shared=6, local_acc=1.0000
  Client 4: layers_shared=2, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=4, local_acc=1.0000
  Client 8: layers_shared=5, local_acc=1.0000
  Client 9: layers_shared=5, local_acc=1.0000
  Client 0: mean_dist=2.84, base_reward=-0.4181, violation=1, comm_penalty=0.1000, reward=-0.5181
  Client 1: mean_dist=0.44, base_reward=0.7785, violation=0, comm_penalty=0.0000, reward=0.7785
  Client 2: mean_dist=3.08, base_reward=-0.5388, violation=5, comm_penalty=0.5000, reward=-1.0388
  Client 3: mean_dist=3.07, base_reward=-0.5359, violation=4, comm_penalty=0.4000, reward=-0.9359
  Client 4: mean_dist=1.53, base_reward=0.2341, violation=0, comm_penalty=0.0000, reward=0.2341
  Client 5: mean_dist=2.27, base_reward=-0.1357, violation=0, comm_penalty=0.0000, reward=-0.1357
  Client 6: mean_dist=0.44, base_reward=0.7818, violation=0, comm_penalty=0.0000, reward=0.7818
  Client 7: mean_dist=2.72, base_reward=-0.3614, violation=0, comm_penalty=0.0000, reward=-0.3614
  Client 8: mean_dist=3.01, base_reward=-0.5043, violation=3, comm_penalty=0.3000, reward=-0.8043
  Client 9: mean_dist=3.07, base_reward=-0.5362, violation=0, comm_penalty=0.0000, reward=-0.5362
  RL policy loss: -0.004060
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9812
  Client 1 model accuracy on test set: 0.9773
  Client 2 model accuracy on test set: 0.9843
  Client 3 model accuracy on test set: 0.9828
  Client 4 model accuracy on test set: 0.9762
  Client 5 model accuracy on test set: 0.9809
  Client 6 model accuracy on test set: 0.9805
  Client 7 model accuracy on test set: 0.9806
  Client 8 model accuracy on test set: 0.9803
  Client 9 model accuracy on test set: 0.9804

=== Global Round 21/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=0.9272
  Client 6: layers_shared=4, local_acc=1.0000
  Client 7: layers_shared=4, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=5, local_acc=1.0000
  Client 0: mean_dist=0.45, base_reward=0.7762, violation=0, comm_penalty=0.0000, reward=0.7762
  Client 1: mean_dist=2.25, base_reward=-0.1270, violation=0, comm_penalty=0.0000, reward=-0.1270
  Client 2: mean_dist=0.45, base_reward=0.7728, violation=0, comm_penalty=0.0000, reward=0.7728
  Client 3: mean_dist=2.28, base_reward=-0.1415, violation=1, comm_penalty=0.1000, reward=-0.2415
  Client 4: mean_dist=2.73, base_reward=-0.3647, violation=1, comm_penalty=0.1000, reward=-0.4647
  Client 5: mean_dist=2.39, base_reward=-0.2683, violation=0, comm_penalty=0.0000, reward=-0.2683
  Client 6: mean_dist=2.61, base_reward=-0.3033, violation=3, comm_penalty=0.3000, reward=-0.6033
  Client 7: mean_dist=2.59, base_reward=-0.2956, violation=0, comm_penalty=0.0000, reward=-0.2956
  Client 8: mean_dist=2.25, base_reward=-0.1249, violation=1, comm_penalty=0.1000, reward=-0.2249
  Client 9: mean_dist=2.75, base_reward=-0.3739, violation=0, comm_penalty=0.0000, reward=-0.3739
  RL policy loss: -0.021959
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9818
  Client 1 model accuracy on test set: 0.9768
  Client 2 model accuracy on test set: 0.9834
  Client 3 model accuracy on test set: 0.9826
  Client 4 model accuracy on test set: 0.9761
  Client 5 model accuracy on test set: 0.8820
  Client 6 model accuracy on test set: 0.9817
  Client 7 model accuracy on test set: 0.9800
  Client 8 model accuracy on test set: 0.9811
  Client 9 model accuracy on test set: 0.9808

=== Global Round 22/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=5, local_acc=1.0000
  Client 4: layers_shared=4, local_acc=1.0000
  Client 5: layers_shared=6, local_acc=0.9999
  Client 6: layers_shared=4, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=2, local_acc=1.0000
  Client 9: layers_shared=2, local_acc=1.0000
  Client 0: mean_dist=0.45, base_reward=0.7757, violation=0, comm_penalty=0.0000, reward=0.7757
  Client 1: mean_dist=0.45, base_reward=0.7774, violation=0, comm_penalty=0.0000, reward=0.7774
  Client 2: mean_dist=1.55, base_reward=0.2267, violation=1, comm_penalty=0.1000, reward=0.1267
  Client 3: mean_dist=2.44, base_reward=-0.2219, violation=3, comm_penalty=0.3000, reward=-0.5219
  Client 4: mean_dist=2.33, base_reward=-0.1671, violation=0, comm_penalty=0.0000, reward=-0.1671
  Client 5: mean_dist=2.57, base_reward=-0.2854, violation=0, comm_penalty=0.0000, reward=-0.2854
  Client 6: mean_dist=2.32, base_reward=-0.1625, violation=3, comm_penalty=0.3000, reward=-0.4625
  Client 7: mean_dist=1.95, base_reward=0.0262, violation=0, comm_penalty=0.0000, reward=0.0262
  Client 8: mean_dist=1.50, base_reward=0.2480, violation=0, comm_penalty=0.0000, reward=0.2480
  Client 9: mean_dist=1.56, base_reward=0.2208, violation=0, comm_penalty=0.0000, reward=0.2208
  RL policy loss: -0.024088
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9810
  Client 1 model accuracy on test set: 0.9774
  Client 2 model accuracy on test set: 0.9840
  Client 3 model accuracy on test set: 0.9823
  Client 4 model accuracy on test set: 0.9754
  Client 5 model accuracy on test set: 0.9706
  Client 6 model accuracy on test set: 0.9817
  Client 7 model accuracy on test set: 0.9800
  Client 8 model accuracy on test set: 0.9805
  Client 9 model accuracy on test set: 0.9800

=== Global Round 23/100 ===
  Client 0: layers_shared=4, local_acc=1.0000
  Client 1: layers_shared=5, local_acc=1.0000
  Client 2: layers_shared=6, local_acc=1.0000
  Client 3: layers_shared=6, local_acc=1.0000
  Client 4: layers_shared=6, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=4, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=4, local_acc=1.0000
  Client 9: layers_shared=2, local_acc=1.0000
  Client 0: mean_dist=3.22, base_reward=-0.6115, violation=1, comm_penalty=0.1000, reward=-0.7115
  Client 1: mean_dist=3.41, base_reward=-0.7069, violation=0, comm_penalty=0.0000, reward=-0.7069
  Client 2: mean_dist=3.52, base_reward=-0.7585, violation=5, comm_penalty=0.5000, reward=-1.2585
  Client 3: mean_dist=3.51, base_reward=-0.7538, violation=4, comm_penalty=0.4000, reward=-1.1538
  Client 4: mean_dist=3.51, base_reward=-0.7549, violation=2, comm_penalty=0.2000, reward=-0.9549
  Client 5: mean_dist=2.59, base_reward=-0.2938, violation=0, comm_penalty=0.0000, reward=-0.2938
  Client 6: mean_dist=3.14, base_reward=-0.5697, violation=3, comm_penalty=0.3000, reward=-0.8697
  Client 7: mean_dist=0.45, base_reward=0.7753, violation=0, comm_penalty=0.0000, reward=0.7753
  Client 8: mean_dist=3.12, base_reward=-0.5585, violation=2, comm_penalty=0.2000, reward=-0.7585
  Client 9: mean_dist=1.73, base_reward=0.1346, violation=0, comm_penalty=0.0000, reward=0.1346
  RL policy loss: -0.015037
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9800
  Client 1 model accuracy on test set: 0.9761
  Client 2 model accuracy on test set: 0.9842
  Client 3 model accuracy on test set: 0.9830
  Client 4 model accuracy on test set: 0.9754
  Client 5 model accuracy on test set: 0.9832
  Client 6 model accuracy on test set: 0.9810
  Client 7 model accuracy on test set: 0.9807
  Client 8 model accuracy on test set: 0.9809
  Client 9 model accuracy on test set: 0.9800

=== Global Round 24/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=5, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=6, local_acc=1.0000
  Client 4: layers_shared=4, local_acc=1.0000
  Client 5: layers_shared=2, local_acc=1.0000
  Client 6: layers_shared=4, local_acc=1.0000
  Client 7: layers_shared=6, local_acc=1.0000
  Client 8: layers_shared=4, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=2.39, base_reward=-0.1960, violation=0, comm_penalty=0.0000, reward=-0.1960
  Client 1: mean_dist=3.06, base_reward=-0.5313, violation=0, comm_penalty=0.0000, reward=-0.5313
  Client 2: mean_dist=1.71, base_reward=0.1474, violation=1, comm_penalty=0.1000, reward=0.0474
  Client 3: mean_dist=3.13, base_reward=-0.5625, violation=4, comm_penalty=0.4000, reward=-0.9625
  Client 4: mean_dist=2.90, base_reward=-0.4498, violation=0, comm_penalty=0.0000, reward=-0.4498
  Client 5: mean_dist=1.77, base_reward=0.1156, violation=0, comm_penalty=0.0000, reward=0.1156
  Client 6: mean_dist=2.90, base_reward=-0.4501, violation=3, comm_penalty=0.3000, reward=-0.7501
  Client 7: mean_dist=3.09, base_reward=-0.5437, violation=0, comm_penalty=0.0000, reward=-0.5437
  Client 8: mean_dist=2.88, base_reward=-0.4387, violation=2, comm_penalty=0.2000, reward=-0.6387
  Client 9: mean_dist=0.46, base_reward=0.7695, violation=0, comm_penalty=0.0000, reward=0.7695
  RL policy loss: -0.006228
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9821
  Client 1 model accuracy on test set: 0.9770
  Client 2 model accuracy on test set: 0.9833
  Client 3 model accuracy on test set: 0.9833
  Client 4 model accuracy on test set: 0.9749
  Client 5 model accuracy on test set: 0.9828
  Client 6 model accuracy on test set: 0.9815
  Client 7 model accuracy on test set: 0.9805
  Client 8 model accuracy on test set: 0.9810
  Client 9 model accuracy on test set: 0.9797

=== Global Round 25/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=5, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=4, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=5, local_acc=1.0000
  Client 7: layers_shared=2, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=5, local_acc=1.0000
  Client 0: mean_dist=0.45, base_reward=0.7758, violation=0, comm_penalty=0.0000, reward=0.7758
  Client 1: mean_dist=2.84, base_reward=-0.4214, violation=0, comm_penalty=0.0000, reward=-0.4214
  Client 2: mean_dist=1.70, base_reward=0.1498, violation=1, comm_penalty=0.1000, reward=0.0498
  Client 3: mean_dist=2.68, base_reward=-0.3408, violation=2, comm_penalty=0.2000, reward=-0.5408
  Client 4: mean_dist=2.33, base_reward=-0.1640, violation=0, comm_penalty=0.0000, reward=-0.1640
  Client 5: mean_dist=2.46, base_reward=-0.2315, violation=0, comm_penalty=0.0000, reward=-0.2315
  Client 6: mean_dist=2.86, base_reward=-0.4308, violation=4, comm_penalty=0.4000, reward=-0.8308
  Client 7: mean_dist=1.67, base_reward=0.1669, violation=0, comm_penalty=0.0000, reward=0.1669
  Client 8: mean_dist=2.31, base_reward=-0.1536, violation=1, comm_penalty=0.1000, reward=-0.2536
  Client 9: mean_dist=2.89, base_reward=-0.4470, violation=0, comm_penalty=0.0000, reward=-0.4470
  RL policy loss: 0.009306
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9815
  Client 1 model accuracy on test set: 0.9770
  Client 2 model accuracy on test set: 0.9844
  Client 3 model accuracy on test set: 0.9830
  Client 4 model accuracy on test set: 0.9749
  Client 5 model accuracy on test set: 0.9830
  Client 6 model accuracy on test set: 0.9803
  Client 7 model accuracy on test set: 0.9809
  Client 8 model accuracy on test set: 0.9802
  Client 9 model accuracy on test set: 0.9806

=== Global Round 26/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=4, local_acc=1.0000
  Client 2: layers_shared=5, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=2, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=0.9960
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=6, local_acc=1.0000
  Client 8: layers_shared=5, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=0.45, base_reward=0.7757, violation=0, comm_penalty=0.0000, reward=0.7757
  Client 1: mean_dist=2.75, base_reward=-0.3770, violation=0, comm_penalty=0.0000, reward=-0.3770
  Client 2: mean_dist=2.98, base_reward=-0.4915, violation=4, comm_penalty=0.4000, reward=-0.8915
  Client 3: mean_dist=2.44, base_reward=-0.2205, violation=1, comm_penalty=0.1000, reward=-0.3205
  Client 4: mean_dist=1.68, base_reward=0.1594, violation=0, comm_penalty=0.0000, reward=0.1594
  Client 5: mean_dist=2.59, base_reward=-0.2965, violation=0, comm_penalty=0.0000, reward=-0.2965
  Client 6: mean_dist=2.44, base_reward=-0.2175, violation=2, comm_penalty=0.2000, reward=-0.4175
  Client 7: mean_dist=2.94, base_reward=-0.4679, violation=0, comm_penalty=0.0000, reward=-0.4679
  Client 8: mean_dist=2.94, base_reward=-0.4688, violation=3, comm_penalty=0.3000, reward=-0.7688
  Client 9: mean_dist=2.46, base_reward=-0.2309, violation=0, comm_penalty=0.0000, reward=-0.2309
  RL policy loss: -0.001055
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9805
  Client 1 model accuracy on test set: 0.9779
  Client 2 model accuracy on test set: 0.9843
  Client 3 model accuracy on test set: 0.9825
  Client 4 model accuracy on test set: 0.9758
  Client 5 model accuracy on test set: 0.9584
  Client 6 model accuracy on test set: 0.9818
  Client 7 model accuracy on test set: 0.9810
  Client 8 model accuracy on test set: 0.9808
  Client 9 model accuracy on test set: 0.9805

=== Global Round 27/100 ===
  Client 0: layers_shared=4, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=6, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=6, local_acc=1.0000
  Client 8: layers_shared=6, local_acc=1.0000
  Client 9: layers_shared=4, local_acc=1.0000
  Client 0: mean_dist=2.55, base_reward=-0.2760, violation=1, comm_penalty=0.1000, reward=-0.3760
  Client 1: mean_dist=2.00, base_reward=-0.0013, violation=0, comm_penalty=0.0000, reward=-0.0013
  Client 2: mean_dist=0.45, base_reward=0.7734, violation=0, comm_penalty=0.0000, reward=0.7734
  Client 3: mean_dist=2.73, base_reward=-0.3636, violation=4, comm_penalty=0.4000, reward=-0.7636
  Client 4: mean_dist=0.44, base_reward=0.7787, violation=0, comm_penalty=0.0000, reward=0.7787
  Client 5: mean_dist=0.46, base_reward=0.7718, violation=0, comm_penalty=0.0000, reward=0.7718
  Client 6: mean_dist=2.01, base_reward=-0.0041, violation=2, comm_penalty=0.2000, reward=-0.2041
  Client 7: mean_dist=2.68, base_reward=-0.3392, violation=0, comm_penalty=0.0000, reward=-0.3392
  Client 8: mean_dist=2.67, base_reward=-0.3341, violation=4, comm_penalty=0.4000, reward=-0.7341
  Client 9: mean_dist=2.49, base_reward=-0.2453, violation=0, comm_penalty=0.0000, reward=-0.2453
  RL policy loss: -0.080011
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9802
  Client 1 model accuracy on test set: 0.9767
  Client 2 model accuracy on test set: 0.9840
  Client 3 model accuracy on test set: 0.9828
  Client 4 model accuracy on test set: 0.9762
  Client 5 model accuracy on test set: 0.9822
  Client 6 model accuracy on test set: 0.9815
  Client 7 model accuracy on test set: 0.9810
  Client 8 model accuracy on test set: 0.9806
  Client 9 model accuracy on test set: 0.9805

=== Global Round 28/100 ===
  Client 0: layers_shared=6, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=6, local_acc=1.0000
  Client 5: layers_shared=6, local_acc=0.9999
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=5, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=4, local_acc=1.0000
  Client 0: mean_dist=3.22, base_reward=-0.6089, violation=3, comm_penalty=0.3000, reward=-0.9089
  Client 1: mean_dist=2.27, base_reward=-0.1336, violation=0, comm_penalty=0.0000, reward=-0.1336
  Client 2: mean_dist=0.45, base_reward=0.7730, violation=0, comm_penalty=0.0000, reward=0.7730
  Client 3: mean_dist=0.47, base_reward=0.7668, violation=0, comm_penalty=0.0000, reward=0.7668
  Client 4: mean_dist=3.13, base_reward=-0.5666, violation=2, comm_penalty=0.2000, reward=-0.7666
  Client 5: mean_dist=3.36, base_reward=-0.6793, violation=0, comm_penalty=0.0000, reward=-0.6793
  Client 6: mean_dist=2.29, base_reward=-0.1474, violation=2, comm_penalty=0.2000, reward=-0.3474
  Client 7: mean_dist=3.07, base_reward=-0.5369, violation=0, comm_penalty=0.0000, reward=-0.5369
  Client 8: mean_dist=2.28, base_reward=-0.1404, violation=1, comm_penalty=0.1000, reward=-0.2404
  Client 9: mean_dist=2.80, base_reward=-0.3996, violation=0, comm_penalty=0.0000, reward=-0.3996
  RL policy loss: -0.061679
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9811
  Client 1 model accuracy on test set: 0.9769
  Client 2 model accuracy on test set: 0.9840
  Client 3 model accuracy on test set: 0.9829
  Client 4 model accuracy on test set: 0.9760
  Client 5 model accuracy on test set: 0.9743
  Client 6 model accuracy on test set: 0.9819
  Client 7 model accuracy on test set: 0.9808
  Client 8 model accuracy on test set: 0.9809
  Client 9 model accuracy on test set: 0.9797

=== Global Round 29/100 ===
  Client 0: layers_shared=6, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=0.9787
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=2, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=5, local_acc=1.0000
  Client 0: mean_dist=3.24, base_reward=-0.6221, violation=3, comm_penalty=0.3000, reward=-0.9221
  Client 1: mean_dist=2.69, base_reward=-0.3425, violation=0, comm_penalty=0.0000, reward=-0.3425
  Client 2: mean_dist=2.73, base_reward=-0.3668, violation=2, comm_penalty=0.2000, reward=-0.5668
  Client 3: mean_dist=2.72, base_reward=-0.3576, violation=1, comm_penalty=0.1000, reward=-0.4576
  Client 4: mean_dist=3.16, base_reward=-0.5785, violation=1, comm_penalty=0.1000, reward=-0.6785
  Client 5: mean_dist=2.90, base_reward=-0.4707, violation=0, comm_penalty=0.0000, reward=-0.4707
  Client 6: mean_dist=2.72, base_reward=-0.3581, violation=2, comm_penalty=0.2000, reward=-0.5581
  Client 7: mean_dist=1.83, base_reward=0.0827, violation=0, comm_penalty=0.0000, reward=0.0827
  Client 8: mean_dist=2.69, base_reward=-0.3450, violation=1, comm_penalty=0.1000, reward=-0.4450
  Client 9: mean_dist=3.21, base_reward=-0.6041, violation=0, comm_penalty=0.0000, reward=-0.6041
  RL policy loss: 0.022316
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9809
  Client 1 model accuracy on test set: 0.9775
  Client 2 model accuracy on test set: 0.9839
  Client 3 model accuracy on test set: 0.9832
  Client 4 model accuracy on test set: 0.9764
  Client 5 model accuracy on test set: 0.9499
  Client 6 model accuracy on test set: 0.9815
  Client 7 model accuracy on test set: 0.9808
  Client 8 model accuracy on test set: 0.9804
  Client 9 model accuracy on test set: 0.9796

=== Global Round 30/100 ===
  Client 0: layers_shared=4, local_acc=1.0000
  Client 1: layers_shared=2, local_acc=1.0000
  Client 2: layers_shared=5, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=1.0000
  Client 5: layers_shared=2, local_acc=0.5905
  Client 6: layers_shared=5, local_acc=1.0000
  Client 7: layers_shared=6, local_acc=1.0000
  Client 8: layers_shared=5, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=3.16, base_reward=-0.5775, violation=1, comm_penalty=0.1000, reward=-0.6775
  Client 1: mean_dist=1.84, base_reward=0.0825, violation=0, comm_penalty=0.0000, reward=0.0825
  Client 2: mean_dist=3.37, base_reward=-0.6847, violation=4, comm_penalty=0.4000, reward=-1.0847
  Client 3: mean_dist=2.60, base_reward=-0.2992, violation=1, comm_penalty=0.1000, reward=-0.3992
  Client 4: mean_dist=2.59, base_reward=-0.2955, violation=0, comm_penalty=0.0000, reward=-0.2955
  Client 5: mean_dist=1.96, base_reward=-0.3915, violation=0, comm_penalty=0.0000, reward=-0.3915
  Client 6: mean_dist=3.35, base_reward=-0.6759, violation=4, comm_penalty=0.4000, reward=-1.0759
  Client 7: mean_dist=3.32, base_reward=-0.6586, violation=0, comm_penalty=0.0000, reward=-0.6586
  Client 8: mean_dist=3.32, base_reward=-0.6613, violation=3, comm_penalty=0.3000, reward=-0.9613
  Client 9: mean_dist=2.63, base_reward=-0.3131, violation=0, comm_penalty=0.0000, reward=-0.3131
  RL policy loss: 0.008063
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9814
  Client 1 model accuracy on test set: 0.9775
  Client 2 model accuracy on test set: 0.9835
  Client 3 model accuracy on test set: 0.9827
  Client 4 model accuracy on test set: 0.9769
  Client 5 model accuracy on test set: 0.5297
  Client 6 model accuracy on test set: 0.9818
  Client 7 model accuracy on test set: 0.9810
  Client 8 model accuracy on test set: 0.9802
  Client 9 model accuracy on test set: 0.9802

=== Global Round 31/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=4, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=5, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=2, local_acc=1.0000
  Client 0: mean_dist=0.45, base_reward=0.7754, violation=0, comm_penalty=0.0000, reward=0.7754
  Client 1: mean_dist=2.12, base_reward=-0.0593, violation=0, comm_penalty=0.0000, reward=-0.0593
  Client 2: mean_dist=1.92, base_reward=0.0388, violation=2, comm_penalty=0.2000, reward=-0.1612
  Client 3: mean_dist=1.92, base_reward=0.0424, violation=1, comm_penalty=0.1000, reward=-0.0576
  Client 4: mean_dist=2.25, base_reward=-0.1249, violation=1, comm_penalty=0.1000, reward=-0.2249
  Client 5: mean_dist=0.46, base_reward=0.7676, violation=0, comm_penalty=0.0000, reward=0.7676
  Client 6: mean_dist=2.24, base_reward=-0.1197, violation=4, comm_penalty=0.4000, reward=-0.5197
  Client 7: mean_dist=0.45, base_reward=0.7743, violation=0, comm_penalty=0.0000, reward=0.7743
  Client 8: mean_dist=1.88, base_reward=0.0584, violation=1, comm_penalty=0.1000, reward=-0.0416
  Client 9: mean_dist=1.40, base_reward=0.3011, violation=0, comm_penalty=0.0000, reward=0.3011
  RL policy loss: -0.043675
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9811
  Client 1 model accuracy on test set: 0.9773
  Client 2 model accuracy on test set: 0.9840
  Client 3 model accuracy on test set: 0.9829
  Client 4 model accuracy on test set: 0.9764
  Client 5 model accuracy on test set: 0.9824
  Client 6 model accuracy on test set: 0.9810
  Client 7 model accuracy on test set: 0.9811
  Client 8 model accuracy on test set: 0.9803
  Client 9 model accuracy on test set: 0.9804

=== Global Round 32/100 ===
  Client 0: layers_shared=2, local_acc=1.0000
  Client 1: layers_shared=5, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=6, local_acc=1.0000
  Client 7: layers_shared=4, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=1.93, base_reward=0.0365, violation=0, comm_penalty=0.0000, reward=0.0365
  Client 1: mean_dist=2.91, base_reward=-0.4533, violation=0, comm_penalty=0.0000, reward=-0.4533
  Client 2: mean_dist=1.87, base_reward=0.0639, violation=1, comm_penalty=0.1000, reward=-0.0361
  Client 3: mean_dist=2.61, base_reward=-0.3061, violation=1, comm_penalty=0.1000, reward=-0.4061
  Client 4: mean_dist=2.60, base_reward=-0.3022, violation=0, comm_penalty=0.0000, reward=-0.3022
  Client 5: mean_dist=2.80, base_reward=-0.4024, violation=0, comm_penalty=0.0000, reward=-0.4024
  Client 6: mean_dist=2.94, base_reward=-0.4679, violation=5, comm_penalty=0.5000, reward=-0.9679
  Client 7: mean_dist=2.82, base_reward=-0.4081, violation=0, comm_penalty=0.0000, reward=-0.4081
  Client 8: mean_dist=2.59, base_reward=-0.2937, violation=1, comm_penalty=0.1000, reward=-0.3937
  Client 9: mean_dist=2.64, base_reward=-0.3197, violation=0, comm_penalty=0.0000, reward=-0.3197
  RL policy loss: 0.023997
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9818
  Client 1 model accuracy on test set: 0.9770
  Client 2 model accuracy on test set: 0.9847
  Client 3 model accuracy on test set: 0.9830
  Client 4 model accuracy on test set: 0.9769
  Client 5 model accuracy on test set: 0.9837
  Client 6 model accuracy on test set: 0.9815
  Client 7 model accuracy on test set: 0.9809
  Client 8 model accuracy on test set: 0.9804
  Client 9 model accuracy on test set: 0.9798

=== Global Round 33/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=6, local_acc=1.0000
  Client 4: layers_shared=4, local_acc=1.0000
  Client 5: layers_shared=4, local_acc=1.0000
  Client 6: layers_shared=4, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=6, local_acc=1.0000
  Client 0: mean_dist=3.37, base_reward=-0.6861, violation=2, comm_penalty=0.2000, reward=-0.8861
  Client 1: mean_dist=2.43, base_reward=-0.2161, violation=0, comm_penalty=0.0000, reward=-0.2161
  Client 2: mean_dist=1.72, base_reward=0.1413, violation=1, comm_penalty=0.1000, reward=0.0413
  Client 3: mean_dist=3.32, base_reward=-0.6601, violation=4, comm_penalty=0.4000, reward=-1.0601
  Client 4: mean_dist=3.06, base_reward=-0.5290, violation=0, comm_penalty=0.0000, reward=-0.5290
  Client 5: mean_dist=3.32, base_reward=-0.6593, violation=0, comm_penalty=0.0000, reward=-0.6593
  Client 6: mean_dist=3.06, base_reward=-0.5323, violation=3, comm_penalty=0.3000, reward=-0.8323
  Client 7: mean_dist=2.45, base_reward=-0.2246, violation=0, comm_penalty=0.0000, reward=-0.2246
  Client 8: mean_dist=0.44, base_reward=0.7809, violation=0, comm_penalty=0.0000, reward=0.7809
  Client 9: mean_dist=3.33, base_reward=-0.6668, violation=1, comm_penalty=0.1000, reward=-0.7668
  RL policy loss: -0.056337
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9815
  Client 1 model accuracy on test set: 0.9765
  Client 2 model accuracy on test set: 0.9846
  Client 3 model accuracy on test set: 0.9832
  Client 4 model accuracy on test set: 0.9764
  Client 5 model accuracy on test set: 0.9830
  Client 6 model accuracy on test set: 0.9818
  Client 7 model accuracy on test set: 0.9808
  Client 8 model accuracy on test set: 0.9802
  Client 9 model accuracy on test set: 0.9807

=== Global Round 34/100 ===
  Client 0: layers_shared=4, local_acc=1.0000
  Client 1: layers_shared=5, local_acc=1.0000
  Client 2: layers_shared=5, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=6, local_acc=1.0000
  Client 7: layers_shared=4, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=2, local_acc=1.0000
  Client 0: mean_dist=3.10, base_reward=-0.5497, violation=1, comm_penalty=0.1000, reward=-0.6497
  Client 1: mean_dist=3.30, base_reward=-0.6500, violation=0, comm_penalty=0.0000, reward=-0.6500
  Client 2: mean_dist=3.36, base_reward=-0.6788, violation=4, comm_penalty=0.4000, reward=-1.0788
  Client 3: mean_dist=2.44, base_reward=-0.2212, violation=1, comm_penalty=0.1000, reward=-0.3212
  Client 4: mean_dist=3.35, base_reward=-0.6754, violation=1, comm_penalty=0.1000, reward=-0.7754
  Client 5: mean_dist=0.46, base_reward=0.7684, violation=0, comm_penalty=0.0000, reward=0.7684
  Client 6: mean_dist=3.32, base_reward=-0.6599, violation=5, comm_penalty=0.5000, reward=-1.1599
  Client 7: mean_dist=2.99, base_reward=-0.4945, violation=0, comm_penalty=0.0000, reward=-0.4945
  Client 8: mean_dist=2.41, base_reward=-0.2046, violation=1, comm_penalty=0.1000, reward=-0.3046
  Client 9: mean_dist=1.72, base_reward=0.1423, violation=0, comm_penalty=0.0000, reward=0.1423
  RL policy loss: -0.057358
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9798
  Client 1 model accuracy on test set: 0.9772
  Client 2 model accuracy on test set: 0.9840
  Client 3 model accuracy on test set: 0.9832
  Client 4 model accuracy on test set: 0.9765
  Client 5 model accuracy on test set: 0.9831
  Client 6 model accuracy on test set: 0.9809
  Client 7 model accuracy on test set: 0.9807
  Client 8 model accuracy on test set: 0.9803
  Client 9 model accuracy on test set: 0.9808

=== Global Round 35/100 ===
  Client 0: layers_shared=6, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=5, local_acc=1.0000
  Client 4: layers_shared=6, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=4, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=5, local_acc=1.0000
  Client 0: mean_dist=2.90, base_reward=-0.4483, violation=3, comm_penalty=0.3000, reward=-0.7483
  Client 1: mean_dist=2.00, base_reward=-0.0003, violation=0, comm_penalty=0.0000, reward=-0.0003
  Client 2: mean_dist=0.45, base_reward=0.7725, violation=0, comm_penalty=0.0000, reward=0.7725
  Client 3: mean_dist=2.85, base_reward=-0.4242, violation=3, comm_penalty=0.3000, reward=-0.7242
  Client 4: mean_dist=2.83, base_reward=-0.4143, violation=2, comm_penalty=0.2000, reward=-0.6143
  Client 5: mean_dist=0.46, base_reward=0.7684, violation=0, comm_penalty=0.0000, reward=0.7684
  Client 6: mean_dist=2.49, base_reward=-0.2430, violation=3, comm_penalty=0.3000, reward=-0.5430
  Client 7: mean_dist=2.01, base_reward=-0.0066, violation=0, comm_penalty=0.0000, reward=-0.0066
  Client 8: mean_dist=0.44, base_reward=0.7810, violation=0, comm_penalty=0.0000, reward=0.7810
  Client 9: mean_dist=2.85, base_reward=-0.4225, violation=0, comm_penalty=0.0000, reward=-0.4225
  RL policy loss: -0.121884
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9811
  Client 1 model accuracy on test set: 0.9767
  Client 2 model accuracy on test set: 0.9841
  Client 3 model accuracy on test set: 0.9832
  Client 4 model accuracy on test set: 0.9773
  Client 5 model accuracy on test set: 0.9826
  Client 6 model accuracy on test set: 0.9813
  Client 7 model accuracy on test set: 0.9806
  Client 8 model accuracy on test set: 0.9798
  Client 9 model accuracy on test set: 0.9800

=== Global Round 36/100 ===
  Client 0: layers_shared=6, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=6, local_acc=1.0000
  Client 8: layers_shared=2, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=1.94, base_reward=0.0276, violation=3, comm_penalty=0.3000, reward=-0.2724
  Client 1: mean_dist=1.64, base_reward=0.1781, violation=0, comm_penalty=0.0000, reward=0.1781
  Client 2: mean_dist=0.46, base_reward=0.7724, violation=0, comm_penalty=0.0000, reward=0.7724
  Client 3: mean_dist=0.47, base_reward=0.7658, violation=0, comm_penalty=0.0000, reward=0.7658
  Client 4: mean_dist=0.44, base_reward=0.7782, violation=0, comm_penalty=0.0000, reward=0.7782
  Client 5: mean_dist=0.46, base_reward=0.7687, violation=0, comm_penalty=0.0000, reward=0.7687
  Client 6: mean_dist=1.65, base_reward=0.1761, violation=2, comm_penalty=0.2000, reward=-0.0239
  Client 7: mean_dist=1.89, base_reward=0.0552, violation=0, comm_penalty=0.0000, reward=0.0552
  Client 8: mean_dist=1.21, base_reward=0.3971, violation=0, comm_penalty=0.0000, reward=0.3971
  Client 9: mean_dist=1.66, base_reward=0.1699, violation=0, comm_penalty=0.0000, reward=0.1699
  RL policy loss: -0.041263
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9806
  Client 1 model accuracy on test set: 0.9770
  Client 2 model accuracy on test set: 0.9848
  Client 3 model accuracy on test set: 0.9835
  Client 4 model accuracy on test set: 0.9763
  Client 5 model accuracy on test set: 0.9810
  Client 6 model accuracy on test set: 0.9817
  Client 7 model accuracy on test set: 0.9807
  Client 8 model accuracy on test set: 0.9802
  Client 9 model accuracy on test set: 0.9804

=== Global Round 37/100 ===
  Client 0: layers_shared=4, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=4, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=0.9999
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=5, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=2.04, base_reward=-0.0185, violation=1, comm_penalty=0.1000, reward=-0.1185
  Client 1: mean_dist=1.74, base_reward=0.1288, violation=0, comm_penalty=0.0000, reward=0.1288
  Client 2: mean_dist=2.02, base_reward=-0.0105, violation=3, comm_penalty=0.3000, reward=-0.3105
  Client 3: mean_dist=0.47, base_reward=0.7660, violation=0, comm_penalty=0.0000, reward=0.7660
  Client 4: mean_dist=1.75, base_reward=0.1226, violation=0, comm_penalty=0.0000, reward=0.1226
  Client 5: mean_dist=0.46, base_reward=0.7695, violation=0, comm_penalty=0.0000, reward=0.7695
  Client 6: mean_dist=0.44, base_reward=0.7805, violation=0, comm_penalty=0.0000, reward=0.7805
  Client 7: mean_dist=0.45, base_reward=0.7743, violation=0, comm_penalty=0.0000, reward=0.7743
  Client 8: mean_dist=1.99, base_reward=0.0063, violation=3, comm_penalty=0.3000, reward=-0.2937
  Client 9: mean_dist=1.78, base_reward=0.1090, violation=0, comm_penalty=0.0000, reward=0.1090
  RL policy loss: -0.074502
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9817
  Client 1 model accuracy on test set: 0.9772
  Client 2 model accuracy on test set: 0.9846
  Client 3 model accuracy on test set: 0.9832
  Client 4 model accuracy on test set: 0.9771
  Client 5 model accuracy on test set: 0.9814
  Client 6 model accuracy on test set: 0.9812
  Client 7 model accuracy on test set: 0.9806
  Client 8 model accuracy on test set: 0.9808
  Client 9 model accuracy on test set: 0.9804

=== Global Round 38/100 ===
  Client 0: layers_shared=4, local_acc=1.0000
  Client 1: layers_shared=4, local_acc=1.0000
  Client 2: layers_shared=6, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=4, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=2.74, base_reward=-0.3689, violation=1, comm_penalty=0.1000, reward=-0.4689
  Client 1: mean_dist=2.64, base_reward=-0.3179, violation=0, comm_penalty=0.0000, reward=-0.3179
  Client 2: mean_dist=2.68, base_reward=-0.3387, violation=5, comm_penalty=0.5000, reward=-0.8387
  Client 3: mean_dist=0.47, base_reward=0.7660, violation=0, comm_penalty=0.0000, reward=0.7660
  Client 4: mean_dist=0.44, base_reward=0.7783, violation=0, comm_penalty=0.0000, reward=0.7783
  Client 5: mean_dist=2.48, base_reward=-0.2412, violation=0, comm_penalty=0.0000, reward=-0.2412
  Client 6: mean_dist=2.31, base_reward=-0.1548, violation=2, comm_penalty=0.2000, reward=-0.3548
  Client 7: mean_dist=2.64, base_reward=-0.3193, violation=0, comm_penalty=0.0000, reward=-0.3193
  Client 8: mean_dist=2.29, base_reward=-0.1441, violation=1, comm_penalty=0.1000, reward=-0.2441
  Client 9: mean_dist=2.33, base_reward=-0.1638, violation=0, comm_penalty=0.0000, reward=-0.1638
  RL policy loss: -0.073022
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9811
  Client 1 model accuracy on test set: 0.9771
  Client 2 model accuracy on test set: 0.9843
  Client 3 model accuracy on test set: 0.9832
  Client 4 model accuracy on test set: 0.9760
  Client 5 model accuracy on test set: 0.9807
  Client 6 model accuracy on test set: 0.9813
  Client 7 model accuracy on test set: 0.9810
  Client 8 model accuracy on test set: 0.9805
  Client 9 model accuracy on test set: 0.9810

=== Global Round 39/100 ===
  Client 0: layers_shared=6, local_acc=1.0000
  Client 1: layers_shared=4, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=6, local_acc=1.0000
  Client 4: layers_shared=6, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=2, local_acc=1.0000
  Client 9: layers_shared=4, local_acc=1.0000
  Client 0: mean_dist=3.27, base_reward=-0.6347, violation=3, comm_penalty=0.3000, reward=-0.9347
  Client 1: mean_dist=2.91, base_reward=-0.4537, violation=0, comm_penalty=0.0000, reward=-0.4537
  Client 2: mean_dist=2.49, base_reward=-0.2436, violation=2, comm_penalty=0.2000, reward=-0.4436
  Client 3: mean_dist=3.23, base_reward=-0.6129, violation=4, comm_penalty=0.4000, reward=-1.0129
  Client 4: mean_dist=3.19, base_reward=-0.5942, violation=2, comm_penalty=0.2000, reward=-0.7942
  Client 5: mean_dist=2.64, base_reward=-0.3209, violation=0, comm_penalty=0.0000, reward=-0.3209
  Client 6: mean_dist=2.47, base_reward=-0.2342, violation=2, comm_penalty=0.2000, reward=-0.4342
  Client 7: mean_dist=0.45, base_reward=0.7744, violation=0, comm_penalty=0.0000, reward=0.7744
  Client 8: mean_dist=1.68, base_reward=0.1580, violation=0, comm_penalty=0.0000, reward=0.1580
  Client 9: mean_dist=2.97, base_reward=-0.4873, violation=0, comm_penalty=0.0000, reward=-0.4873
  RL policy loss: -0.060481
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9808
  Client 1 model accuracy on test set: 0.9768
  Client 2 model accuracy on test set: 0.9839
  Client 3 model accuracy on test set: 0.9833
  Client 4 model accuracy on test set: 0.9774
  Client 5 model accuracy on test set: 0.9822
  Client 6 model accuracy on test set: 0.9818
  Client 7 model accuracy on test set: 0.9808
  Client 8 model accuracy on test set: 0.9809
  Client 9 model accuracy on test set: 0.9802

=== Global Round 40/100 ===
  Client 0: layers_shared=4, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=5, local_acc=1.0000
  Client 7: layers_shared=4, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=2.16, base_reward=-0.0805, violation=1, comm_penalty=0.1000, reward=-0.1805
  Client 1: mean_dist=0.45, base_reward=0.7768, violation=0, comm_penalty=0.0000, reward=0.7768
  Client 2: mean_dist=0.45, base_reward=0.7725, violation=0, comm_penalty=0.0000, reward=0.7725
  Client 3: mean_dist=1.77, base_reward=0.1157, violation=1, comm_penalty=0.1000, reward=0.0157
  Client 4: mean_dist=2.22, base_reward=-0.1108, violation=1, comm_penalty=0.1000, reward=-0.2108
  Client 5: mean_dist=0.46, base_reward=0.7699, violation=0, comm_penalty=0.0000, reward=0.7699
  Client 6: mean_dist=2.22, base_reward=-0.1113, violation=4, comm_penalty=0.4000, reward=-0.5113
  Client 7: mean_dist=2.10, base_reward=-0.0517, violation=0, comm_penalty=0.0000, reward=-0.0517
  Client 8: mean_dist=1.74, base_reward=0.1285, violation=1, comm_penalty=0.1000, reward=0.0285
  Client 9: mean_dist=0.46, base_reward=0.7693, violation=0, comm_penalty=0.0000, reward=0.7693
  RL policy loss: -0.115238
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9808
  Client 1 model accuracy on test set: 0.9773
  Client 2 model accuracy on test set: 0.9841
  Client 3 model accuracy on test set: 0.9833
  Client 4 model accuracy on test set: 0.9771
  Client 5 model accuracy on test set: 0.9835
  Client 6 model accuracy on test set: 0.9814
  Client 7 model accuracy on test set: 0.9811
  Client 8 model accuracy on test set: 0.9806
  Client 9 model accuracy on test set: 0.9809

=== Global Round 41/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=5, local_acc=1.0000
  Client 2: layers_shared=4, local_acc=1.0000
  Client 3: layers_shared=4, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=5, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=5, local_acc=1.0000
  Client 0: mean_dist=0.45, base_reward=0.7755, violation=0, comm_penalty=0.0000, reward=0.7755
  Client 1: mean_dist=3.17, base_reward=-0.5839, violation=0, comm_penalty=0.0000, reward=-0.5839
  Client 2: mean_dist=2.91, base_reward=-0.4527, violation=3, comm_penalty=0.3000, reward=-0.7527
  Client 3: mean_dist=2.91, base_reward=-0.4543, violation=2, comm_penalty=0.2000, reward=-0.6543
  Client 4: mean_dist=3.22, base_reward=-0.6121, violation=1, comm_penalty=0.1000, reward=-0.7121
  Client 5: mean_dist=2.47, base_reward=-0.2334, violation=0, comm_penalty=0.0000, reward=-0.2334
  Client 6: mean_dist=2.30, base_reward=-0.1487, violation=2, comm_penalty=0.2000, reward=-0.3487
  Client 7: mean_dist=3.16, base_reward=-0.5784, violation=0, comm_penalty=0.0000, reward=-0.5784
  Client 8: mean_dist=0.44, base_reward=0.7810, violation=0, comm_penalty=0.0000, reward=0.7810
  Client 9: mean_dist=3.23, base_reward=-0.6134, violation=0, comm_penalty=0.0000, reward=-0.6134
  RL policy loss: -0.115671
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9806
  Client 1 model accuracy on test set: 0.9772
  Client 2 model accuracy on test set: 0.9841
  Client 3 model accuracy on test set: 0.9827
  Client 4 model accuracy on test set: 0.9753
  Client 5 model accuracy on test set: 0.9830
  Client 6 model accuracy on test set: 0.9803
  Client 7 model accuracy on test set: 0.9809
  Client 8 model accuracy on test set: 0.9806
  Client 9 model accuracy on test set: 0.9804

=== Global Round 42/100 ===
  Client 0: layers_shared=4, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=6, local_acc=1.0000
  Client 4: layers_shared=4, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=5, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=6, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=2.74, base_reward=-0.3712, violation=1, comm_penalty=0.1000, reward=-0.4712
  Client 1: mean_dist=2.18, base_reward=-0.0896, violation=0, comm_penalty=0.0000, reward=-0.0896
  Client 2: mean_dist=1.56, base_reward=0.2184, violation=1, comm_penalty=0.1000, reward=0.1184
  Client 3: mean_dist=2.91, base_reward=-0.4572, violation=4, comm_penalty=0.4000, reward=-0.8572
  Client 4: mean_dist=2.67, base_reward=-0.3340, violation=0, comm_penalty=0.0000, reward=-0.3340
  Client 5: mean_dist=2.35, base_reward=-0.1767, violation=0, comm_penalty=0.0000, reward=-0.1767
  Client 6: mean_dist=2.89, base_reward=-0.4442, violation=4, comm_penalty=0.4000, reward=-0.8442
  Client 7: mean_dist=0.45, base_reward=0.7743, violation=0, comm_penalty=0.0000, reward=0.7743
  Client 8: mean_dist=2.88, base_reward=-0.4424, violation=4, comm_penalty=0.4000, reward=-0.8424
  Client 9: mean_dist=0.46, base_reward=0.7693, violation=0, comm_penalty=0.0000, reward=0.7693
  RL policy loss: -0.127303
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9816
  Client 1 model accuracy on test set: 0.9775
  Client 2 model accuracy on test set: 0.9846
  Client 3 model accuracy on test set: 0.9833
  Client 4 model accuracy on test set: 0.9771
  Client 5 model accuracy on test set: 0.9806
  Client 6 model accuracy on test set: 0.9823
  Client 7 model accuracy on test set: 0.9811
  Client 8 model accuracy on test set: 0.9805
  Client 9 model accuracy on test set: 0.9805

=== Global Round 43/100 ===
  Client 0: layers_shared=6, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=2, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=5, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=2, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=2.12, base_reward=-0.0618, violation=3, comm_penalty=0.3000, reward=-0.3618
  Client 1: mean_dist=0.45, base_reward=0.7767, violation=0, comm_penalty=0.0000, reward=0.7767
  Client 2: mean_dist=0.45, base_reward=0.7726, violation=0, comm_penalty=0.0000, reward=0.7726
  Client 3: mean_dist=0.47, base_reward=0.7660, violation=0, comm_penalty=0.0000, reward=0.7660
  Client 4: mean_dist=1.39, base_reward=0.3039, violation=0, comm_penalty=0.0000, reward=0.3039
  Client 5: mean_dist=1.96, base_reward=0.0196, violation=0, comm_penalty=0.0000, reward=0.0196
  Client 6: mean_dist=2.07, base_reward=-0.0364, violation=4, comm_penalty=0.4000, reward=-0.4364
  Client 7: mean_dist=1.83, base_reward=0.0860, violation=0, comm_penalty=0.0000, reward=0.0860
  Client 8: mean_dist=1.37, base_reward=0.3129, violation=0, comm_penalty=0.0000, reward=0.3129
  Client 9: mean_dist=1.85, base_reward=0.0732, violation=0, comm_penalty=0.0000, reward=0.0732
  RL policy loss: -0.062104
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9817
  Client 1 model accuracy on test set: 0.9772
  Client 2 model accuracy on test set: 0.9845
  Client 3 model accuracy on test set: 0.9831
  Client 4 model accuracy on test set: 0.9767
  Client 5 model accuracy on test set: 0.9833
  Client 6 model accuracy on test set: 0.9816
  Client 7 model accuracy on test set: 0.9808
  Client 8 model accuracy on test set: 0.9809
  Client 9 model accuracy on test set: 0.9803

=== Global Round 44/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=5, local_acc=1.0000
  Client 3: layers_shared=5, local_acc=1.0000
  Client 4: layers_shared=6, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=0.9388
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=4, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=2.38, base_reward=-0.1897, violation=0, comm_penalty=0.0000, reward=-0.1897
  Client 1: mean_dist=0.45, base_reward=0.7764, violation=0, comm_penalty=0.0000, reward=0.7764
  Client 2: mean_dist=2.91, base_reward=-0.4560, violation=4, comm_penalty=0.4000, reward=-0.8560
  Client 3: mean_dist=2.90, base_reward=-0.4486, violation=3, comm_penalty=0.3000, reward=-0.7486
  Client 4: mean_dist=2.91, base_reward=-0.4528, violation=2, comm_penalty=0.2000, reward=-0.6528
  Client 5: mean_dist=2.51, base_reward=-0.3145, violation=0, comm_penalty=0.0000, reward=-0.3145
  Client 6: mean_dist=2.32, base_reward=-0.1607, violation=2, comm_penalty=0.2000, reward=-0.3607
  Client 7: mean_dist=0.45, base_reward=0.7741, violation=0, comm_penalty=0.0000, reward=0.7741
  Client 8: mean_dist=2.65, base_reward=-0.3264, violation=2, comm_penalty=0.2000, reward=-0.5264
  Client 9: mean_dist=2.35, base_reward=-0.1732, violation=0, comm_penalty=0.0000, reward=-0.1732
  RL policy loss: -0.146426
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9816
  Client 1 model accuracy on test set: 0.9768
  Client 2 model accuracy on test set: 0.9843
  Client 3 model accuracy on test set: 0.9831
  Client 4 model accuracy on test set: 0.9762
  Client 5 model accuracy on test set: 0.9204
  Client 6 model accuracy on test set: 0.9811
  Client 7 model accuracy on test set: 0.9806
  Client 8 model accuracy on test set: 0.9806
  Client 9 model accuracy on test set: 0.9810

=== Global Round 45/100 ===
  Client 0: layers_shared=2, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=5, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=0.9968
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=6, local_acc=1.0000
  Client 8: layers_shared=4, local_acc=1.0000
  Client 9: layers_shared=4, local_acc=1.0000
  Client 0: mean_dist=1.43, base_reward=0.2831, violation=0, comm_penalty=0.0000, reward=0.2831
  Client 1: mean_dist=0.45, base_reward=0.7761, violation=0, comm_penalty=0.0000, reward=0.7761
  Client 2: mean_dist=0.46, base_reward=0.7719, violation=0, comm_penalty=0.0000, reward=0.7719
  Client 3: mean_dist=2.62, base_reward=-0.3080, violation=3, comm_penalty=0.3000, reward=-0.6080
  Client 4: mean_dist=2.62, base_reward=-0.3092, violation=1, comm_penalty=0.1000, reward=-0.4092
  Client 5: mean_dist=0.47, base_reward=0.7614, violation=0, comm_penalty=0.0000, reward=0.7614
  Client 6: mean_dist=1.92, base_reward=0.0419, violation=2, comm_penalty=0.2000, reward=-0.1581
  Client 7: mean_dist=2.57, base_reward=-0.2865, violation=0, comm_penalty=0.0000, reward=-0.2865
  Client 8: mean_dist=2.36, base_reward=-0.1801, violation=2, comm_penalty=0.2000, reward=-0.3801
  Client 9: mean_dist=2.41, base_reward=-0.2027, violation=0, comm_penalty=0.0000, reward=-0.2027
  RL policy loss: -0.157523
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9809
  Client 1 model accuracy on test set: 0.9774
  Client 2 model accuracy on test set: 0.9847
  Client 3 model accuracy on test set: 0.9834
  Client 4 model accuracy on test set: 0.9766
  Client 5 model accuracy on test set: 0.9695
  Client 6 model accuracy on test set: 0.9818
  Client 7 model accuracy on test set: 0.9810
  Client 8 model accuracy on test set: 0.9813
  Client 9 model accuracy on test set: 0.9808

=== Global Round 46/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=5, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=4, local_acc=1.0000
  Client 5: layers_shared=6, local_acc=1.0000
  Client 6: layers_shared=6, local_acc=1.0000
  Client 7: layers_shared=5, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=2.11, base_reward=-0.0548, violation=0, comm_penalty=0.0000, reward=-0.0548
  Client 1: mean_dist=2.83, base_reward=-0.4137, violation=0, comm_penalty=0.0000, reward=-0.4137
  Client 2: mean_dist=2.08, base_reward=-0.0393, violation=2, comm_penalty=0.2000, reward=-0.2393
  Client 3: mean_dist=0.47, base_reward=0.7660, violation=0, comm_penalty=0.0000, reward=0.7660
  Client 4: mean_dist=2.54, base_reward=-0.2712, violation=0, comm_penalty=0.0000, reward=-0.2712
  Client 5: mean_dist=3.17, base_reward=-0.5853, violation=0, comm_penalty=0.0000, reward=-0.5853
  Client 6: mean_dist=2.88, base_reward=-0.4379, violation=5, comm_penalty=0.5000, reward=-0.9379
  Client 7: mean_dist=2.85, base_reward=-0.4253, violation=0, comm_penalty=0.0000, reward=-0.4253
  Client 8: mean_dist=0.44, base_reward=0.7801, violation=0, comm_penalty=0.0000, reward=0.7801
  Client 9: mean_dist=0.46, base_reward=0.7695, violation=0, comm_penalty=0.0000, reward=0.7695
  RL policy loss: -0.165010
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9808
  Client 1 model accuracy on test set: 0.9771
  Client 2 model accuracy on test set: 0.9843
  Client 3 model accuracy on test set: 0.9836
  Client 4 model accuracy on test set: 0.9775
  Client 5 model accuracy on test set: 0.9818
  Client 6 model accuracy on test set: 0.9818
  Client 7 model accuracy on test set: 0.9816
  Client 8 model accuracy on test set: 0.9807
  Client 9 model accuracy on test set: 0.9809

=== Global Round 47/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=2, local_acc=1.0000
  Client 2: layers_shared=6, local_acc=1.0000
  Client 3: layers_shared=2, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=4, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=2.13, base_reward=-0.0658, violation=0, comm_penalty=0.0000, reward=-0.0658
  Client 1: mean_dist=1.52, base_reward=0.2388, violation=0, comm_penalty=0.0000, reward=0.2388
  Client 2: mean_dist=2.44, base_reward=-0.2197, violation=5, comm_penalty=0.5000, reward=-0.7197
  Client 3: mean_dist=1.53, base_reward=0.2331, violation=0, comm_penalty=0.0000, reward=0.2331
  Client 4: mean_dist=2.42, base_reward=-0.2092, violation=1, comm_penalty=0.1000, reward=-0.3092
  Client 5: mean_dist=0.47, base_reward=0.7662, violation=0, comm_penalty=0.0000, reward=0.7662
  Client 6: mean_dist=2.31, base_reward=-0.1542, violation=3, comm_penalty=0.3000, reward=-0.4542
  Client 7: mean_dist=2.06, base_reward=-0.0307, violation=0, comm_penalty=0.0000, reward=-0.0307
  Client 8: mean_dist=2.06, base_reward=-0.0300, violation=1, comm_penalty=0.1000, reward=-0.1300
  Client 9: mean_dist=0.46, base_reward=0.7694, violation=0, comm_penalty=0.0000, reward=0.7694
  RL policy loss: -0.097231
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9813
  Client 1 model accuracy on test set: 0.9770
  Client 2 model accuracy on test set: 0.9840
  Client 3 model accuracy on test set: 0.9833
  Client 4 model accuracy on test set: 0.9770
  Client 5 model accuracy on test set: 0.9815
  Client 6 model accuracy on test set: 0.9813
  Client 7 model accuracy on test set: 0.9811
  Client 8 model accuracy on test set: 0.9807
  Client 9 model accuracy on test set: 0.9804

=== Global Round 48/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=6, local_acc=1.0000
  Client 5: layers_shared=2, local_acc=0.9992
  Client 6: layers_shared=2, local_acc=1.0000
  Client 7: layers_shared=4, local_acc=1.0000
  Client 8: layers_shared=6, local_acc=1.0000
  Client 9: layers_shared=6, local_acc=1.0000
  Client 0: mean_dist=0.45, base_reward=0.7748, violation=0, comm_penalty=0.0000, reward=0.7748
  Client 1: mean_dist=0.45, base_reward=0.7765, violation=0, comm_penalty=0.0000, reward=0.7765
  Client 2: mean_dist=0.46, base_reward=0.7719, violation=0, comm_penalty=0.0000, reward=0.7719
  Client 3: mean_dist=1.83, base_reward=0.0872, violation=1, comm_penalty=0.1000, reward=-0.0128
  Client 4: mean_dist=2.47, base_reward=-0.2329, violation=2, comm_penalty=0.2000, reward=-0.4329
  Client 5: mean_dist=1.50, base_reward=0.2467, violation=0, comm_penalty=0.0000, reward=0.2467
  Client 6: mean_dist=1.39, base_reward=0.3028, violation=1, comm_penalty=0.1000, reward=0.2028
  Client 7: mean_dist=2.15, base_reward=-0.0765, violation=0, comm_penalty=0.0000, reward=-0.0765
  Client 8: mean_dist=2.40, base_reward=-0.2005, violation=4, comm_penalty=0.4000, reward=-0.6005
  Client 9: mean_dist=2.45, base_reward=-0.2264, violation=1, comm_penalty=0.1000, reward=-0.3264
  RL policy loss: -0.144381
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9811
  Client 1 model accuracy on test set: 0.9767
  Client 2 model accuracy on test set: 0.9844
  Client 3 model accuracy on test set: 0.9832
  Client 4 model accuracy on test set: 0.9768
  Client 5 model accuracy on test set: 0.9710
  Client 6 model accuracy on test set: 0.9822
  Client 7 model accuracy on test set: 0.9813
  Client 8 model accuracy on test set: 0.9806
  Client 9 model accuracy on test set: 0.9809

=== Global Round 49/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=5, local_acc=1.0000
  Client 4: layers_shared=4, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=6, local_acc=1.0000
  Client 8: layers_shared=6, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=1.80, base_reward=0.0978, violation=0, comm_penalty=0.0000, reward=0.0978
  Client 1: mean_dist=0.45, base_reward=0.7765, violation=0, comm_penalty=0.0000, reward=0.7765
  Client 2: mean_dist=0.46, base_reward=0.7719, violation=0, comm_penalty=0.0000, reward=0.7719
  Client 3: mean_dist=2.33, base_reward=-0.1668, violation=3, comm_penalty=0.3000, reward=-0.4668
  Client 4: mean_dist=2.12, base_reward=-0.0622, violation=0, comm_penalty=0.0000, reward=-0.0622
  Client 5: mean_dist=0.47, base_reward=0.7662, violation=0, comm_penalty=0.0000, reward=0.7662
  Client 6: mean_dist=0.44, base_reward=0.7801, violation=0, comm_penalty=0.0000, reward=0.7801
  Client 7: mean_dist=2.32, base_reward=-0.1599, violation=0, comm_penalty=0.0000, reward=-0.1599
  Client 8: mean_dist=2.31, base_reward=-0.1546, violation=4, comm_penalty=0.4000, reward=-0.5546
  Client 9: mean_dist=1.78, base_reward=0.1106, violation=0, comm_penalty=0.0000, reward=0.1106
  RL policy loss: -0.170058
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9815
  Client 1 model accuracy on test set: 0.9774
  Client 2 model accuracy on test set: 0.9845
  Client 3 model accuracy on test set: 0.9834
  Client 4 model accuracy on test set: 0.9767
  Client 5 model accuracy on test set: 0.9835
  Client 6 model accuracy on test set: 0.9818
  Client 7 model accuracy on test set: 0.9808
  Client 8 model accuracy on test set: 0.9804
  Client 9 model accuracy on test set: 0.9814

=== Global Round 50/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=6, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=1.0000
  Client 5: layers_shared=4, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=6, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=0.45, base_reward=0.7748, violation=0, comm_penalty=0.0000, reward=0.7748
  Client 1: mean_dist=1.77, base_reward=0.1138, violation=1, comm_penalty=0.1000, reward=0.0138
  Client 2: mean_dist=1.09, base_reward=0.4533, violation=1, comm_penalty=0.1000, reward=0.3533
  Client 3: mean_dist=0.47, base_reward=0.7661, violation=0, comm_penalty=0.0000, reward=0.7661
  Client 4: mean_dist=1.41, base_reward=0.2927, violation=0, comm_penalty=0.0000, reward=0.2927
  Client 5: mean_dist=1.80, base_reward=0.0999, violation=0, comm_penalty=0.0000, reward=0.0999
  Client 6: mean_dist=0.44, base_reward=0.7801, violation=0, comm_penalty=0.0000, reward=0.7801
  Client 7: mean_dist=1.79, base_reward=0.1033, violation=0, comm_penalty=0.0000, reward=0.1033
  Client 8: mean_dist=0.44, base_reward=0.7801, violation=0, comm_penalty=0.0000, reward=0.7801
  Client 9: mean_dist=0.46, base_reward=0.7694, violation=0, comm_penalty=0.0000, reward=0.7694
  RL policy loss: -0.121459
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9809
  Client 1 model accuracy on test set: 0.9769
  Client 2 model accuracy on test set: 0.9846
  Client 3 model accuracy on test set: 0.9831
  Client 4 model accuracy on test set: 0.9766
  Client 5 model accuracy on test set: 0.9830
  Client 6 model accuracy on test set: 0.9817
  Client 7 model accuracy on test set: 0.9807
  Client 8 model accuracy on test set: 0.9803
  Client 9 model accuracy on test set: 0.9812

=== Global Round 51/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=5, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=6, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=5, local_acc=0.8989
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=2, local_acc=1.0000
  Client 9: layers_shared=6, local_acc=1.0000
  Client 0: mean_dist=2.01, base_reward=-0.0044, violation=0, comm_penalty=0.0000, reward=-0.0044
  Client 1: mean_dist=2.64, base_reward=-0.3203, violation=0, comm_penalty=0.0000, reward=-0.3203
  Client 2: mean_dist=0.46, base_reward=0.7716, violation=0, comm_penalty=0.0000, reward=0.7716
  Client 3: mean_dist=2.70, base_reward=-0.3515, violation=4, comm_penalty=0.4000, reward=-0.7515
  Client 4: mean_dist=0.45, base_reward=0.7774, violation=0, comm_penalty=0.0000, reward=0.7774
  Client 5: mean_dist=2.92, base_reward=-0.5590, violation=0, comm_penalty=0.0000, reward=-0.5590
  Client 6: mean_dist=1.96, base_reward=0.0199, violation=2, comm_penalty=0.2000, reward=-0.1801
  Client 7: mean_dist=0.45, base_reward=0.7736, violation=0, comm_penalty=0.0000, reward=0.7736
  Client 8: mean_dist=1.38, base_reward=0.3099, violation=0, comm_penalty=0.0000, reward=0.3099
  Client 9: mean_dist=2.70, base_reward=-0.3482, violation=1, comm_penalty=0.1000, reward=-0.4482
  RL policy loss: -0.174885
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9815
  Client 1 model accuracy on test set: 0.9776
  Client 2 model accuracy on test set: 0.9840
  Client 3 model accuracy on test set: 0.9839
  Client 4 model accuracy on test set: 0.9775
  Client 5 model accuracy on test set: 0.8054
  Client 6 model accuracy on test set: 0.9820
  Client 7 model accuracy on test set: 0.9809
  Client 8 model accuracy on test set: 0.9804
  Client 9 model accuracy on test set: 0.9810

=== Global Round 52/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=2, local_acc=1.0000
  Client 0: mean_dist=1.46, base_reward=0.2687, violation=2, comm_penalty=0.2000, reward=0.0687
  Client 1: mean_dist=0.45, base_reward=0.7763, violation=0, comm_penalty=0.0000, reward=0.7763
  Client 2: mean_dist=1.46, base_reward=0.2704, violation=2, comm_penalty=0.2000, reward=0.0704
  Client 3: mean_dist=0.47, base_reward=0.7659, violation=0, comm_penalty=0.0000, reward=0.7659
  Client 4: mean_dist=1.43, base_reward=0.2842, violation=0, comm_penalty=0.0000, reward=0.2842
  Client 5: mean_dist=1.55, base_reward=0.2246, violation=0, comm_penalty=0.0000, reward=0.2246
  Client 6: mean_dist=0.44, base_reward=0.7799, violation=0, comm_penalty=0.0000, reward=0.7799
  Client 7: mean_dist=0.45, base_reward=0.7733, violation=0, comm_penalty=0.0000, reward=0.7733
  Client 8: mean_dist=0.44, base_reward=0.7802, violation=0, comm_penalty=0.0000, reward=0.7802
  Client 9: mean_dist=1.13, base_reward=0.4365, violation=0, comm_penalty=0.0000, reward=0.4365
  RL policy loss: -0.067097
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9812
  Client 1 model accuracy on test set: 0.9772
  Client 2 model accuracy on test set: 0.9840
  Client 3 model accuracy on test set: 0.9830
  Client 4 model accuracy on test set: 0.9766
  Client 5 model accuracy on test set: 0.9808
  Client 6 model accuracy on test set: 0.9818
  Client 7 model accuracy on test set: 0.9813
  Client 8 model accuracy on test set: 0.9811
  Client 9 model accuracy on test set: 0.9805

=== Global Round 53/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=6, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=0.9696
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=4, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=5, local_acc=1.0000
  Client 0: mean_dist=1.71, base_reward=0.1455, violation=0, comm_penalty=0.0000, reward=0.1455
  Client 1: mean_dist=1.98, base_reward=0.0105, violation=1, comm_penalty=0.1000, reward=-0.0895
  Client 2: mean_dist=1.25, base_reward=0.3755, violation=1, comm_penalty=0.1000, reward=0.2755
  Client 3: mean_dist=0.47, base_reward=0.7659, violation=0, comm_penalty=0.0000, reward=0.7659
  Client 4: mean_dist=0.45, base_reward=0.7775, violation=0, comm_penalty=0.0000, reward=0.7775
  Client 5: mean_dist=0.47, base_reward=0.7338, violation=0, comm_penalty=0.0000, reward=0.7338
  Client 6: mean_dist=1.66, base_reward=0.1705, violation=2, comm_penalty=0.2000, reward=-0.0295
  Client 7: mean_dist=1.88, base_reward=0.0582, violation=0, comm_penalty=0.0000, reward=0.0582
  Client 8: mean_dist=0.44, base_reward=0.7802, violation=0, comm_penalty=0.0000, reward=0.7802
  Client 9: mean_dist=2.01, base_reward=-0.0050, violation=0, comm_penalty=0.0000, reward=-0.0050
  RL policy loss: -0.127320
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9803
  Client 1 model accuracy on test set: 0.9766
  Client 2 model accuracy on test set: 0.9845
  Client 3 model accuracy on test set: 0.9826
  Client 4 model accuracy on test set: 0.9776
  Client 5 model accuracy on test set: 0.9229
  Client 6 model accuracy on test set: 0.9817
  Client 7 model accuracy on test set: 0.9813
  Client 8 model accuracy on test set: 0.9812
  Client 9 model accuracy on test set: 0.9805

=== Global Round 54/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=5, local_acc=1.0000
  Client 4: layers_shared=6, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=0.1728
  Client 6: layers_shared=4, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=6, local_acc=1.0000
  Client 9: layers_shared=2, local_acc=1.0000
  Client 0: mean_dist=1.97, base_reward=0.0158, violation=0, comm_penalty=0.0000, reward=0.0158
  Client 1: mean_dist=1.91, base_reward=0.0461, violation=0, comm_penalty=0.0000, reward=0.0461
  Client 2: mean_dist=0.46, base_reward=0.7716, violation=0, comm_penalty=0.0000, reward=0.7716
  Client 3: mean_dist=2.51, base_reward=-0.2562, violation=3, comm_penalty=0.3000, reward=-0.5562
  Client 4: mean_dist=2.53, base_reward=-0.2627, violation=2, comm_penalty=0.2000, reward=-0.4627
  Client 5: mean_dist=0.47, base_reward=-0.0638, violation=0, comm_penalty=0.0000, reward=-0.0638
  Client 6: mean_dist=2.28, base_reward=-0.1396, violation=3, comm_penalty=0.3000, reward=-0.4396
  Client 7: mean_dist=0.45, base_reward=0.7733, violation=0, comm_penalty=0.0000, reward=0.7733
  Client 8: mean_dist=2.50, base_reward=-0.2501, violation=4, comm_penalty=0.4000, reward=-0.6501
  Client 9: mean_dist=1.41, base_reward=0.2956, violation=0, comm_penalty=0.0000, reward=0.2956
  RL policy loss: -0.149110
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9817
  Client 1 model accuracy on test set: 0.9770
  Client 2 model accuracy on test set: 0.9843
  Client 3 model accuracy on test set: 0.9830
  Client 4 model accuracy on test set: 0.9770
  Client 5 model accuracy on test set: 0.1411
  Client 6 model accuracy on test set: 0.9816
  Client 7 model accuracy on test set: 0.9809
  Client 8 model accuracy on test set: 0.9808
  Client 9 model accuracy on test set: 0.9813

=== Global Round 55/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=5, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=0.9563
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=0.46, base_reward=0.7710, violation=0, comm_penalty=0.0000, reward=0.7710
  Client 1: mean_dist=0.45, base_reward=0.7744, violation=0, comm_penalty=0.0000, reward=0.7744
  Client 2: mean_dist=0.97, base_reward=0.5163, violation=4, comm_penalty=0.4000, reward=0.1163
  Client 3: mean_dist=0.47, base_reward=0.7638, violation=0, comm_penalty=0.0000, reward=0.7638
  Client 4: mean_dist=0.96, base_reward=0.5209, violation=1, comm_penalty=0.1000, reward=0.4209
  Client 5: mean_dist=0.52, base_reward=0.6972, violation=0, comm_penalty=0.0000, reward=0.6972
  Client 6: mean_dist=0.45, base_reward=0.7772, violation=0, comm_penalty=0.0000, reward=0.7772
  Client 7: mean_dist=0.46, base_reward=0.7701, violation=0, comm_penalty=0.0000, reward=0.7701
  Client 8: mean_dist=0.44, base_reward=0.7776, violation=0, comm_penalty=0.0000, reward=0.7776
  Client 9: mean_dist=0.47, base_reward=0.7672, violation=0, comm_penalty=0.0000, reward=0.7672
  RL policy loss: -0.070147
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9813
  Client 1 model accuracy on test set: 0.9768
  Client 2 model accuracy on test set: 0.9845
  Client 3 model accuracy on test set: 0.9827
  Client 4 model accuracy on test set: 0.9774
  Client 5 model accuracy on test set: 0.9104
  Client 6 model accuracy on test set: 0.9814
  Client 7 model accuracy on test set: 0.9811
  Client 8 model accuracy on test set: 0.9812
  Client 9 model accuracy on test set: 0.9808

=== Global Round 56/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=6, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=6, local_acc=1.0000
  Client 5: layers_shared=2, local_acc=0.9997
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=4, local_acc=1.0000
  Client 8: layers_shared=6, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=0.46, base_reward=0.7715, violation=0, comm_penalty=0.0000, reward=0.7715
  Client 1: mean_dist=0.45, base_reward=0.7743, violation=0, comm_penalty=0.0000, reward=0.7743
  Client 2: mean_dist=2.31, base_reward=-0.1544, violation=5, comm_penalty=0.5000, reward=-0.6544
  Client 3: mean_dist=1.69, base_reward=0.1557, violation=1, comm_penalty=0.1000, reward=0.0557
  Client 4: mean_dist=2.34, base_reward=-0.1678, violation=2, comm_penalty=0.2000, reward=-0.3678
  Client 5: mean_dist=1.45, base_reward=0.2757, violation=0, comm_penalty=0.0000, reward=0.2757
  Client 6: mean_dist=0.45, base_reward=0.7771, violation=0, comm_penalty=0.0000, reward=0.7771
  Client 7: mean_dist=2.03, base_reward=-0.0140, violation=0, comm_penalty=0.0000, reward=-0.0140
  Client 8: mean_dist=2.28, base_reward=-0.1397, violation=4, comm_penalty=0.4000, reward=-0.5397
  Client 9: mean_dist=0.47, base_reward=0.7674, violation=0, comm_penalty=0.0000, reward=0.7674
  RL policy loss: -0.222790
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9814
  Client 1 model accuracy on test set: 0.9772
  Client 2 model accuracy on test set: 0.9842
  Client 3 model accuracy on test set: 0.9822
  Client 4 model accuracy on test set: 0.9763
  Client 5 model accuracy on test set: 0.9746
  Client 6 model accuracy on test set: 0.9809
  Client 7 model accuracy on test set: 0.9805
  Client 8 model accuracy on test set: 0.9809
  Client 9 model accuracy on test set: 0.9811

=== Global Round 57/100 ===
  Client 0: layers_shared=2, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=5, local_acc=0.9999
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=6, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=1.80, base_reward=0.1009, violation=0, comm_penalty=0.0000, reward=0.1009
  Client 1: mean_dist=2.39, base_reward=-0.1941, violation=0, comm_penalty=0.0000, reward=-0.1941
  Client 2: mean_dist=1.75, base_reward=0.1243, violation=1, comm_penalty=0.1000, reward=0.0243
  Client 3: mean_dist=2.42, base_reward=-0.2098, violation=1, comm_penalty=0.1000, reward=-0.3098
  Client 4: mean_dist=2.92, base_reward=-0.4585, violation=1, comm_penalty=0.1000, reward=-0.5585
  Client 5: mean_dist=3.44, base_reward=-0.7209, violation=0, comm_penalty=0.0000, reward=-0.7209
  Client 6: mean_dist=2.42, base_reward=-0.2081, violation=2, comm_penalty=0.2000, reward=-0.4081
  Client 7: mean_dist=2.91, base_reward=-0.4533, violation=0, comm_penalty=0.0000, reward=-0.4533
  Client 8: mean_dist=0.44, base_reward=0.7778, violation=0, comm_penalty=0.0000, reward=0.7778
  Client 9: mean_dist=2.44, base_reward=-0.2217, violation=0, comm_penalty=0.0000, reward=-0.2217
  RL policy loss: -0.074278
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9815
  Client 1 model accuracy on test set: 0.9774
  Client 2 model accuracy on test set: 0.9844
  Client 3 model accuracy on test set: 0.9830
  Client 4 model accuracy on test set: 0.9766
  Client 5 model accuracy on test set: 0.9764
  Client 6 model accuracy on test set: 0.9812
  Client 7 model accuracy on test set: 0.9809
  Client 8 model accuracy on test set: 0.9810
  Client 9 model accuracy on test set: 0.9809

=== Global Round 58/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=5, local_acc=1.0000
  Client 3: layers_shared=4, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=5, local_acc=1.0000
  Client 6: layers_shared=4, local_acc=1.0000
  Client 7: layers_shared=2, local_acc=1.0000
  Client 8: layers_shared=4, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=0.46, base_reward=0.7716, violation=0, comm_penalty=0.0000, reward=0.7716
  Client 1: mean_dist=0.45, base_reward=0.7743, violation=0, comm_penalty=0.0000, reward=0.7743
  Client 2: mean_dist=2.63, base_reward=-0.3158, violation=4, comm_penalty=0.4000, reward=-0.7158
  Client 3: mean_dist=2.51, base_reward=-0.2560, violation=2, comm_penalty=0.2000, reward=-0.4560
  Client 4: mean_dist=0.45, base_reward=0.7741, violation=0, comm_penalty=0.0000, reward=0.7741
  Client 5: mean_dist=3.12, base_reward=-0.5616, violation=0, comm_penalty=0.0000, reward=-0.5616
  Client 6: mean_dist=2.50, base_reward=-0.2495, violation=3, comm_penalty=0.3000, reward=-0.5495
  Client 7: mean_dist=1.40, base_reward=0.2996, violation=0, comm_penalty=0.0000, reward=0.2996
  Client 8: mean_dist=2.47, base_reward=-0.2362, violation=2, comm_penalty=0.2000, reward=-0.4362
  Client 9: mean_dist=2.01, base_reward=-0.0031, violation=0, comm_penalty=0.0000, reward=-0.0031
  RL policy loss: -0.256764
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9814
  Client 1 model accuracy on test set: 0.9771
  Client 2 model accuracy on test set: 0.9846
  Client 3 model accuracy on test set: 0.9826
  Client 4 model accuracy on test set: 0.9767
  Client 5 model accuracy on test set: 0.9788
  Client 6 model accuracy on test set: 0.9818
  Client 7 model accuracy on test set: 0.9809
  Client 8 model accuracy on test set: 0.9815
  Client 9 model accuracy on test set: 0.9799

=== Global Round 59/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=6, local_acc=1.0000
  Client 2: layers_shared=6, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=0.6396
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=2, local_acc=1.0000
  Client 9: layers_shared=6, local_acc=1.0000
  Client 0: mean_dist=0.46, base_reward=0.7715, violation=0, comm_penalty=0.0000, reward=0.7715
  Client 1: mean_dist=1.61, base_reward=0.1939, violation=1, comm_penalty=0.1000, reward=0.0939
  Client 2: mean_dist=1.63, base_reward=0.1837, violation=5, comm_penalty=0.5000, reward=-0.3163
  Client 3: mean_dist=0.47, base_reward=0.7639, violation=0, comm_penalty=0.0000, reward=0.7639
  Client 4: mean_dist=0.45, base_reward=0.7739, violation=0, comm_penalty=0.0000, reward=0.7739
  Client 5: mean_dist=0.52, base_reward=0.3819, violation=0, comm_penalty=0.0000, reward=0.3819
  Client 6: mean_dist=0.45, base_reward=0.7773, violation=0, comm_penalty=0.0000, reward=0.7773
  Client 7: mean_dist=0.46, base_reward=0.7702, violation=0, comm_penalty=0.0000, reward=0.7702
  Client 8: mean_dist=0.91, base_reward=0.5468, violation=0, comm_penalty=0.0000, reward=0.5468
  Client 9: mean_dist=1.62, base_reward=0.1898, violation=1, comm_penalty=0.1000, reward=0.0898
  RL policy loss: -0.150590
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9810
  Client 1 model accuracy on test set: 0.9768
  Client 2 model accuracy on test set: 0.9842
  Client 3 model accuracy on test set: 0.9824
  Client 4 model accuracy on test set: 0.9775
  Client 5 model accuracy on test set: 0.5553
  Client 6 model accuracy on test set: 0.9817
  Client 7 model accuracy on test set: 0.9811
  Client 8 model accuracy on test set: 0.9805
  Client 9 model accuracy on test set: 0.9807

=== Global Round 60/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=6, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=2, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=6, local_acc=1.0000
  Client 9: layers_shared=5, local_acc=1.0000
  Client 0: mean_dist=2.26, base_reward=-0.1286, violation=0, comm_penalty=0.0000, reward=-0.1286
  Client 1: mean_dist=2.62, base_reward=-0.3116, violation=1, comm_penalty=0.1000, reward=-0.4116
  Client 2: mean_dist=2.21, base_reward=-0.1073, violation=2, comm_penalty=0.2000, reward=-0.3073
  Client 3: mean_dist=0.47, base_reward=0.7637, violation=0, comm_penalty=0.0000, reward=0.7637
  Client 4: mean_dist=1.54, base_reward=0.2285, violation=0, comm_penalty=0.0000, reward=0.2285
  Client 5: mean_dist=0.52, base_reward=0.7414, violation=0, comm_penalty=0.0000, reward=0.7414
  Client 6: mean_dist=2.19, base_reward=-0.0951, violation=2, comm_penalty=0.2000, reward=-0.2951
  Client 7: mean_dist=2.18, base_reward=-0.0898, violation=0, comm_penalty=0.0000, reward=-0.0898
  Client 8: mean_dist=2.63, base_reward=-0.3148, violation=4, comm_penalty=0.4000, reward=-0.7148
  Client 9: mean_dist=2.64, base_reward=-0.3224, violation=0, comm_penalty=0.0000, reward=-0.3224
  RL policy loss: -0.138483
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9816
  Client 1 model accuracy on test set: 0.9766
  Client 2 model accuracy on test set: 0.9841
  Client 3 model accuracy on test set: 0.9829
  Client 4 model accuracy on test set: 0.9765
  Client 5 model accuracy on test set: 0.9827
  Client 6 model accuracy on test set: 0.9816
  Client 7 model accuracy on test set: 0.9805
  Client 8 model accuracy on test set: 0.9811
  Client 9 model accuracy on test set: 0.9805

=== Global Round 61/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=5, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=2, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=5, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=2.47, base_reward=-0.2345, violation=2, comm_penalty=0.2000, reward=-0.4345
  Client 1: mean_dist=1.92, base_reward=0.0405, violation=0, comm_penalty=0.0000, reward=0.0405
  Client 2: mean_dist=2.41, base_reward=-0.2027, violation=4, comm_penalty=0.4000, reward=-0.6027
  Client 3: mean_dist=0.47, base_reward=0.7637, violation=0, comm_penalty=0.0000, reward=0.7637
  Client 4: mean_dist=0.45, base_reward=0.7737, violation=0, comm_penalty=0.0000, reward=0.7737
  Client 5: mean_dist=0.52, base_reward=0.7416, violation=0, comm_penalty=0.0000, reward=0.7416
  Client 6: mean_dist=1.40, base_reward=0.3019, violation=1, comm_penalty=0.1000, reward=0.2019
  Client 7: mean_dist=1.92, base_reward=0.0406, violation=0, comm_penalty=0.0000, reward=0.0406
  Client 8: mean_dist=2.37, base_reward=-0.1827, violation=3, comm_penalty=0.3000, reward=-0.4827
  Client 9: mean_dist=1.94, base_reward=0.0283, violation=0, comm_penalty=0.0000, reward=0.0283
  RL policy loss: -0.196320
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9819
  Client 1 model accuracy on test set: 0.9768
  Client 2 model accuracy on test set: 0.9837
  Client 3 model accuracy on test set: 0.9834
  Client 4 model accuracy on test set: 0.9773
  Client 5 model accuracy on test set: 0.9822
  Client 6 model accuracy on test set: 0.9819
  Client 7 model accuracy on test set: 0.9811
  Client 8 model accuracy on test set: 0.9805
  Client 9 model accuracy on test set: 0.9809

=== Global Round 62/100 ===
  Client 0: layers_shared=4, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=4, local_acc=1.0000
  Client 3: layers_shared=2, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=4, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=2.51, base_reward=-0.2534, violation=1, comm_penalty=0.1000, reward=-0.3534
  Client 1: mean_dist=0.45, base_reward=0.7737, violation=0, comm_penalty=0.0000, reward=0.7737
  Client 2: mean_dist=2.46, base_reward=-0.2275, violation=3, comm_penalty=0.3000, reward=-0.5275
  Client 3: mean_dist=1.55, base_reward=0.2275, violation=0, comm_penalty=0.0000, reward=0.2275
  Client 4: mean_dist=2.20, base_reward=-0.0991, violation=0, comm_penalty=0.0000, reward=-0.0991
  Client 5: mean_dist=0.52, base_reward=0.7401, violation=0, comm_penalty=0.0000, reward=0.7401
  Client 6: mean_dist=2.19, base_reward=-0.0965, violation=2, comm_penalty=0.2000, reward=-0.2965
  Client 7: mean_dist=2.18, base_reward=-0.0892, violation=0, comm_penalty=0.0000, reward=-0.0892
  Client 8: mean_dist=2.41, base_reward=-0.2059, violation=2, comm_penalty=0.2000, reward=-0.4059
  Client 9: mean_dist=2.21, base_reward=-0.1053, violation=0, comm_penalty=0.0000, reward=-0.1053
  RL policy loss: -0.158148
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9808
  Client 1 model accuracy on test set: 0.9768
  Client 2 model accuracy on test set: 0.9843
  Client 3 model accuracy on test set: 0.9832
  Client 4 model accuracy on test set: 0.9771
  Client 5 model accuracy on test set: 0.9798
  Client 6 model accuracy on test set: 0.9819
  Client 7 model accuracy on test set: 0.9812
  Client 8 model accuracy on test set: 0.9805
  Client 9 model accuracy on test set: 0.9804

=== Global Round 63/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=5, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=1.87, base_reward=0.0639, violation=0, comm_penalty=0.0000, reward=0.0639
  Client 1: mean_dist=1.83, base_reward=0.0871, violation=0, comm_penalty=0.0000, reward=0.0871
  Client 2: mean_dist=0.46, base_reward=0.7687, violation=0, comm_penalty=0.0000, reward=0.7687
  Client 3: mean_dist=1.86, base_reward=0.0684, violation=1, comm_penalty=0.1000, reward=-0.0316
  Client 4: mean_dist=2.12, base_reward=-0.0607, violation=1, comm_penalty=0.1000, reward=-0.1607
  Client 5: mean_dist=2.47, base_reward=-0.2374, violation=0, comm_penalty=0.0000, reward=-0.2374
  Client 6: mean_dist=0.45, base_reward=0.7770, violation=0, comm_penalty=0.0000, reward=0.7770
  Client 7: mean_dist=0.46, base_reward=0.7701, violation=0, comm_penalty=0.0000, reward=0.7701
  Client 8: mean_dist=0.45, base_reward=0.7772, violation=0, comm_penalty=0.0000, reward=0.7772
  Client 9: mean_dist=1.87, base_reward=0.0629, violation=0, comm_penalty=0.0000, reward=0.0629
  RL policy loss: -0.158563
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9808
  Client 1 model accuracy on test set: 0.9774
  Client 2 model accuracy on test set: 0.9849
  Client 3 model accuracy on test set: 0.9839
  Client 4 model accuracy on test set: 0.9776
  Client 5 model accuracy on test set: 0.9788
  Client 6 model accuracy on test set: 0.9823
  Client 7 model accuracy on test set: 0.9811
  Client 8 model accuracy on test set: 0.9810
  Client 9 model accuracy on test set: 0.9809

=== Global Round 64/100 ===
  Client 0: layers_shared=2, local_acc=1.0000
  Client 1: layers_shared=2, local_acc=1.0000
  Client 2: layers_shared=4, local_acc=1.0000
  Client 3: layers_shared=2, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=6, local_acc=1.0000
  Client 6: layers_shared=6, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=6, local_acc=1.0000
  Client 9: layers_shared=2, local_acc=1.0000
  Client 0: mean_dist=1.64, base_reward=0.1794, violation=0, comm_penalty=0.0000, reward=0.1794
  Client 1: mean_dist=1.58, base_reward=0.2114, violation=0, comm_penalty=0.0000, reward=0.2114
  Client 2: mean_dist=2.35, base_reward=-0.1745, violation=3, comm_penalty=0.3000, reward=-0.4745
  Client 3: mean_dist=1.58, base_reward=0.2076, violation=0, comm_penalty=0.0000, reward=0.2076
  Client 4: mean_dist=0.45, base_reward=0.7736, violation=0, comm_penalty=0.0000, reward=0.7736
  Client 5: mean_dist=3.05, base_reward=-0.5274, violation=0, comm_penalty=0.0000, reward=-0.5274
  Client 6: mean_dist=2.60, base_reward=-0.3024, violation=5, comm_penalty=0.5000, reward=-0.8024
  Client 7: mean_dist=0.46, base_reward=0.7702, violation=0, comm_penalty=0.0000, reward=0.7702
  Client 8: mean_dist=2.58, base_reward=-0.2900, violation=4, comm_penalty=0.4000, reward=-0.6900
  Client 9: mean_dist=1.61, base_reward=0.1940, violation=0, comm_penalty=0.0000, reward=0.1940
  RL policy loss: -0.208822
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9812
  Client 1 model accuracy on test set: 0.9771
  Client 2 model accuracy on test set: 0.9839
  Client 3 model accuracy on test set: 0.9831
  Client 4 model accuracy on test set: 0.9770
  Client 5 model accuracy on test set: 0.9817
  Client 6 model accuracy on test set: 0.9819
  Client 7 model accuracy on test set: 0.9809
  Client 8 model accuracy on test set: 0.9809
  Client 9 model accuracy on test set: 0.9808

=== Global Round 65/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=4, local_acc=1.0000
  Client 2: layers_shared=6, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=6, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=6, local_acc=1.0000
  Client 0: mean_dist=0.46, base_reward=0.7712, violation=0, comm_penalty=0.0000, reward=0.7712
  Client 1: mean_dist=2.81, base_reward=-0.4045, violation=0, comm_penalty=0.0000, reward=-0.4045
  Client 2: mean_dist=3.21, base_reward=-0.6044, violation=5, comm_penalty=0.5000, reward=-1.1044
  Client 3: mean_dist=0.47, base_reward=0.7636, violation=0, comm_penalty=0.0000, reward=0.7636
  Client 4: mean_dist=3.19, base_reward=-0.5939, violation=1, comm_penalty=0.1000, reward=-0.6939
  Client 5: mean_dist=2.84, base_reward=-0.4208, violation=0, comm_penalty=0.0000, reward=-0.4208
  Client 6: mean_dist=2.36, base_reward=-0.1782, violation=2, comm_penalty=0.2000, reward=-0.3782
  Client 7: mean_dist=3.14, base_reward=-0.5712, violation=0, comm_penalty=0.0000, reward=-0.5712
  Client 8: mean_dist=2.35, base_reward=-0.1736, violation=1, comm_penalty=0.1000, reward=-0.2736
  Client 9: mean_dist=3.21, base_reward=-0.6030, violation=1, comm_penalty=0.1000, reward=-0.7030
  RL policy loss: -0.242167
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9815
  Client 1 model accuracy on test set: 0.9766
  Client 2 model accuracy on test set: 0.9843
  Client 3 model accuracy on test set: 0.9834
  Client 4 model accuracy on test set: 0.9767
  Client 5 model accuracy on test set: 0.9811
  Client 6 model accuracy on test set: 0.9821
  Client 7 model accuracy on test set: 0.9810
  Client 8 model accuracy on test set: 0.9813
  Client 9 model accuracy on test set: 0.9812

=== Global Round 66/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=6, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=4, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=2.17, base_reward=-0.0874, violation=2, comm_penalty=0.2000, reward=-0.2874
  Client 1: mean_dist=0.45, base_reward=0.7737, violation=0, comm_penalty=0.0000, reward=0.7737
  Client 2: mean_dist=1.81, base_reward=0.0972, violation=2, comm_penalty=0.2000, reward=-0.1028
  Client 3: mean_dist=0.47, base_reward=0.7636, violation=0, comm_penalty=0.0000, reward=0.7636
  Client 4: mean_dist=2.13, base_reward=-0.0666, violation=2, comm_penalty=0.2000, reward=-0.2666
  Client 5: mean_dist=0.52, base_reward=0.7410, violation=0, comm_penalty=0.0000, reward=0.7410
  Client 6: mean_dist=1.78, base_reward=0.1108, violation=2, comm_penalty=0.2000, reward=-0.0892
  Client 7: mean_dist=0.46, base_reward=0.7701, violation=0, comm_penalty=0.0000, reward=0.7701
  Client 8: mean_dist=2.02, base_reward=-0.0075, violation=2, comm_penalty=0.2000, reward=-0.2075
  Client 9: mean_dist=1.80, base_reward=0.1015, violation=0, comm_penalty=0.0000, reward=0.1015
  RL policy loss: -0.242167
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9816
  Client 1 model accuracy on test set: 0.9769
  Client 2 model accuracy on test set: 0.9845
  Client 3 model accuracy on test set: 0.9836
  Client 4 model accuracy on test set: 0.9767
  Client 5 model accuracy on test set: 0.9819
  Client 6 model accuracy on test set: 0.9811
  Client 7 model accuracy on test set: 0.9816
  Client 8 model accuracy on test set: 0.9811
  Client 9 model accuracy on test set: 0.9810

=== Global Round 67/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=2, local_acc=1.0000
  Client 2: layers_shared=4, local_acc=1.0000
  Client 3: layers_shared=2, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=5, local_acc=1.0000
  Client 7: layers_shared=4, local_acc=1.0000
  Client 8: layers_shared=4, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=0.46, base_reward=0.7712, violation=0, comm_penalty=0.0000, reward=0.7712
  Client 1: mean_dist=1.37, base_reward=0.3140, violation=0, comm_penalty=0.0000, reward=0.3140
  Client 2: mean_dist=2.17, base_reward=-0.0872, violation=3, comm_penalty=0.3000, reward=-0.3872
  Client 3: mean_dist=1.38, base_reward=0.3094, violation=0, comm_penalty=0.0000, reward=0.3094
  Client 4: mean_dist=1.81, base_reward=0.0928, violation=0, comm_penalty=0.0000, reward=0.0928
  Client 5: mean_dist=0.52, base_reward=0.7412, violation=0, comm_penalty=0.0000, reward=0.7412
  Client 6: mean_dist=2.15, base_reward=-0.0775, violation=4, comm_penalty=0.4000, reward=-0.4775
  Client 7: mean_dist=2.14, base_reward=-0.0724, violation=0, comm_penalty=0.0000, reward=-0.0724
  Client 8: mean_dist=2.15, base_reward=-0.0737, violation=2, comm_penalty=0.2000, reward=-0.2737
  Client 9: mean_dist=0.47, base_reward=0.7672, violation=0, comm_penalty=0.0000, reward=0.7672
  RL policy loss: -0.234828
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9813
  Client 1 model accuracy on test set: 0.9764
  Client 2 model accuracy on test set: 0.9847
  Client 3 model accuracy on test set: 0.9831
  Client 4 model accuracy on test set: 0.9773
  Client 5 model accuracy on test set: 0.9823
  Client 6 model accuracy on test set: 0.9820
  Client 7 model accuracy on test set: 0.9810
  Client 8 model accuracy on test set: 0.9806
  Client 9 model accuracy on test set: 0.9812

=== Global Round 68/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=2, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=5, local_acc=1.0000
  Client 0: mean_dist=2.27, base_reward=-0.1360, violation=2, comm_penalty=0.2000, reward=-0.3360
  Client 1: mean_dist=0.45, base_reward=0.7737, violation=0, comm_penalty=0.0000, reward=0.7737
  Client 2: mean_dist=1.99, base_reward=0.0075, violation=2, comm_penalty=0.2000, reward=-0.1925
  Client 3: mean_dist=0.47, base_reward=0.7635, violation=0, comm_penalty=0.0000, reward=0.7635
  Client 4: mean_dist=0.45, base_reward=0.7736, violation=0, comm_penalty=0.0000, reward=0.7736
  Client 5: mean_dist=1.67, base_reward=0.1650, violation=0, comm_penalty=0.0000, reward=0.1650
  Client 6: mean_dist=1.97, base_reward=0.0142, violation=2, comm_penalty=0.2000, reward=-0.1858
  Client 7: mean_dist=1.96, base_reward=0.0219, violation=0, comm_penalty=0.0000, reward=0.0219
  Client 8: mean_dist=1.95, base_reward=0.0264, violation=1, comm_penalty=0.1000, reward=-0.0736
  Client 9: mean_dist=2.22, base_reward=-0.1121, violation=0, comm_penalty=0.0000, reward=-0.1121
  RL policy loss: -0.164592
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9812
  Client 1 model accuracy on test set: 0.9767
  Client 2 model accuracy on test set: 0.9842
  Client 3 model accuracy on test set: 0.9832
  Client 4 model accuracy on test set: 0.9766
  Client 5 model accuracy on test set: 0.9820
  Client 6 model accuracy on test set: 0.9815
  Client 7 model accuracy on test set: 0.9807
  Client 8 model accuracy on test set: 0.9813
  Client 9 model accuracy on test set: 0.9814

=== Global Round 69/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=6, local_acc=0.9997
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=4, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=6, local_acc=1.0000
  Client 0: mean_dist=0.46, base_reward=0.7709, violation=0, comm_penalty=0.0000, reward=0.7709
  Client 1: mean_dist=0.45, base_reward=0.7733, violation=0, comm_penalty=0.0000, reward=0.7733
  Client 2: mean_dist=0.46, base_reward=0.7683, violation=0, comm_penalty=0.0000, reward=0.7683
  Client 3: mean_dist=0.47, base_reward=0.7634, violation=0, comm_penalty=0.0000, reward=0.7634
  Client 4: mean_dist=0.45, base_reward=0.7734, violation=0, comm_penalty=0.0000, reward=0.7734
  Client 5: mean_dist=2.00, base_reward=-0.0002, violation=0, comm_penalty=0.0000, reward=-0.0002
  Client 6: mean_dist=1.31, base_reward=0.3463, violation=2, comm_penalty=0.2000, reward=0.1463
  Client 7: mean_dist=1.59, base_reward=0.2072, violation=0, comm_penalty=0.0000, reward=0.2072
  Client 8: mean_dist=0.45, base_reward=0.7767, violation=0, comm_penalty=0.0000, reward=0.7767
  Client 9: mean_dist=1.75, base_reward=0.1244, violation=1, comm_penalty=0.1000, reward=0.0244
  RL policy loss: -0.212753
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9817
  Client 1 model accuracy on test set: 0.9776
  Client 2 model accuracy on test set: 0.9843
  Client 3 model accuracy on test set: 0.9828
  Client 4 model accuracy on test set: 0.9765
  Client 5 model accuracy on test set: 0.9709
  Client 6 model accuracy on test set: 0.9819
  Client 7 model accuracy on test set: 0.9810
  Client 8 model accuracy on test set: 0.9816
  Client 9 model accuracy on test set: 0.9808

=== Global Round 70/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=2, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=0.46, base_reward=0.7710, violation=0, comm_penalty=0.0000, reward=0.7710
  Client 1: mean_dist=0.92, base_reward=0.5410, violation=0, comm_penalty=0.0000, reward=0.5410
  Client 2: mean_dist=0.92, base_reward=0.5378, violation=1, comm_penalty=0.1000, reward=0.4378
  Client 3: mean_dist=1.03, base_reward=0.4836, violation=1, comm_penalty=0.1000, reward=0.3836
  Client 4: mean_dist=0.45, base_reward=0.7735, violation=0, comm_penalty=0.0000, reward=0.7735
  Client 5: mean_dist=0.52, base_reward=0.7400, violation=0, comm_penalty=0.0000, reward=0.7400
  Client 6: mean_dist=0.45, base_reward=0.7769, violation=0, comm_penalty=0.0000, reward=0.7769
  Client 7: mean_dist=0.46, base_reward=0.7702, violation=0, comm_penalty=0.0000, reward=0.7702
  Client 8: mean_dist=1.01, base_reward=0.4930, violation=1, comm_penalty=0.1000, reward=0.3930
  Client 9: mean_dist=0.47, base_reward=0.7671, violation=0, comm_penalty=0.0000, reward=0.7671
  RL policy loss: -0.067904
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9811
  Client 1 model accuracy on test set: 0.9774
  Client 2 model accuracy on test set: 0.9846
  Client 3 model accuracy on test set: 0.9827
  Client 4 model accuracy on test set: 0.9774
  Client 5 model accuracy on test set: 0.9796
  Client 6 model accuracy on test set: 0.9813
  Client 7 model accuracy on test set: 0.9813
  Client 8 model accuracy on test set: 0.9809
  Client 9 model accuracy on test set: 0.9810

=== Global Round 71/100 ===
  Client 0: layers_shared=6, local_acc=1.0000
  Client 1: layers_shared=4, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=5, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=1.63, base_reward=0.1855, violation=3, comm_penalty=0.3000, reward=-0.1145
  Client 1: mean_dist=1.48, base_reward=0.2593, violation=0, comm_penalty=0.0000, reward=0.2593
  Client 2: mean_dist=0.46, base_reward=0.7684, violation=0, comm_penalty=0.0000, reward=0.7684
  Client 3: mean_dist=1.26, base_reward=0.3677, violation=1, comm_penalty=0.1000, reward=0.2677
  Client 4: mean_dist=0.45, base_reward=0.7735, violation=0, comm_penalty=0.0000, reward=0.7735
  Client 5: mean_dist=0.52, base_reward=0.7401, violation=0, comm_penalty=0.0000, reward=0.7401
  Client 6: mean_dist=0.45, base_reward=0.7769, violation=0, comm_penalty=0.0000, reward=0.7769
  Client 7: mean_dist=0.46, base_reward=0.7702, violation=0, comm_penalty=0.0000, reward=0.7702
  Client 8: mean_dist=1.59, base_reward=0.2041, violation=3, comm_penalty=0.3000, reward=-0.0959
  Client 9: mean_dist=0.47, base_reward=0.7670, violation=0, comm_penalty=0.0000, reward=0.7670
  RL policy loss: -0.211209
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9803
  Client 1 model accuracy on test set: 0.9773
  Client 2 model accuracy on test set: 0.9848
  Client 3 model accuracy on test set: 0.9834
  Client 4 model accuracy on test set: 0.9766
  Client 5 model accuracy on test set: 0.9796
  Client 6 model accuracy on test set: 0.9820
  Client 7 model accuracy on test set: 0.9809
  Client 8 model accuracy on test set: 0.9806
  Client 9 model accuracy on test set: 0.9806

=== Global Round 72/100 ===
  Client 0: layers_shared=2, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=4, local_acc=1.0000
  Client 5: layers_shared=6, local_acc=1.0000
  Client 6: layers_shared=2, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=1.31, base_reward=0.3475, violation=0, comm_penalty=0.0000, reward=0.3475
  Client 1: mean_dist=1.61, base_reward=0.1938, violation=0, comm_penalty=0.0000, reward=0.1938
  Client 2: mean_dist=0.46, base_reward=0.7684, violation=0, comm_penalty=0.0000, reward=0.7684
  Client 3: mean_dist=0.47, base_reward=0.7635, violation=0, comm_penalty=0.0000, reward=0.7635
  Client 4: mean_dist=1.78, base_reward=0.1078, violation=0, comm_penalty=0.0000, reward=0.1078
  Client 5: mean_dist=2.07, base_reward=-0.0342, violation=0, comm_penalty=0.0000, reward=-0.0342
  Client 6: mean_dist=1.28, base_reward=0.3603, violation=1, comm_penalty=0.1000, reward=0.2603
  Client 7: mean_dist=0.46, base_reward=0.7702, violation=0, comm_penalty=0.0000, reward=0.7702
  Client 8: mean_dist=1.63, base_reward=0.1852, violation=1, comm_penalty=0.1000, reward=0.0852
  Client 9: mean_dist=0.47, base_reward=0.7670, violation=0, comm_penalty=0.0000, reward=0.7670
  RL policy loss: -0.179969
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9813
  Client 1 model accuracy on test set: 0.9772
  Client 2 model accuracy on test set: 0.9844
  Client 3 model accuracy on test set: 0.9832
  Client 4 model accuracy on test set: 0.9777
  Client 5 model accuracy on test set: 0.9813
  Client 6 model accuracy on test set: 0.9819
  Client 7 model accuracy on test set: 0.9818
  Client 8 model accuracy on test set: 0.9810
  Client 9 model accuracy on test set: 0.9807

=== Global Round 73/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=2, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=1.44, base_reward=0.2800, violation=2, comm_penalty=0.2000, reward=0.0800
  Client 1: mean_dist=0.45, base_reward=0.7736, violation=0, comm_penalty=0.0000, reward=0.7736
  Client 2: mean_dist=1.42, base_reward=0.2898, violation=2, comm_penalty=0.2000, reward=0.0898
  Client 3: mean_dist=1.42, base_reward=0.2918, violation=1, comm_penalty=0.1000, reward=0.1918
  Client 4: mean_dist=1.08, base_reward=0.4615, violation=0, comm_penalty=0.0000, reward=0.4615
  Client 5: mean_dist=0.52, base_reward=0.7406, violation=0, comm_penalty=0.0000, reward=0.7406
  Client 6: mean_dist=0.45, base_reward=0.7769, violation=0, comm_penalty=0.0000, reward=0.7769
  Client 7: mean_dist=1.41, base_reward=0.2957, violation=0, comm_penalty=0.0000, reward=0.2957
  Client 8: mean_dist=0.45, base_reward=0.7770, violation=0, comm_penalty=0.0000, reward=0.7770
  Client 9: mean_dist=0.47, base_reward=0.7671, violation=0, comm_penalty=0.0000, reward=0.7671
  RL policy loss: -0.137615
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9819
  Client 1 model accuracy on test set: 0.9775
  Client 2 model accuracy on test set: 0.9840
  Client 3 model accuracy on test set: 0.9828
  Client 4 model accuracy on test set: 0.9773
  Client 5 model accuracy on test set: 0.9805
  Client 6 model accuracy on test set: 0.9815
  Client 7 model accuracy on test set: 0.9810
  Client 8 model accuracy on test set: 0.9807
  Client 9 model accuracy on test set: 0.9817

=== Global Round 74/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=4, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=2, local_acc=1.0000
  Client 8: layers_shared=6, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=0.46, base_reward=0.7711, violation=0, comm_penalty=0.0000, reward=0.7711
  Client 1: mean_dist=0.45, base_reward=0.7737, violation=0, comm_penalty=0.0000, reward=0.7737
  Client 2: mean_dist=1.08, base_reward=0.4576, violation=1, comm_penalty=0.1000, reward=0.3576
  Client 3: mean_dist=1.41, base_reward=0.2938, violation=2, comm_penalty=0.2000, reward=0.0938
  Client 4: mean_dist=0.45, base_reward=0.7736, violation=0, comm_penalty=0.0000, reward=0.7736
  Client 5: mean_dist=0.52, base_reward=0.7407, violation=0, comm_penalty=0.0000, reward=0.7407
  Client 6: mean_dist=0.45, base_reward=0.7769, violation=0, comm_penalty=0.0000, reward=0.7769
  Client 7: mean_dist=1.06, base_reward=0.4693, violation=0, comm_penalty=0.0000, reward=0.4693
  Client 8: mean_dist=1.38, base_reward=0.3086, violation=4, comm_penalty=0.4000, reward=-0.0914
  Client 9: mean_dist=1.30, base_reward=0.3483, violation=0, comm_penalty=0.0000, reward=0.3483
  RL policy loss: -0.179863
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9818
  Client 1 model accuracy on test set: 0.9773
  Client 2 model accuracy on test set: 0.9840
  Client 3 model accuracy on test set: 0.9830
  Client 4 model accuracy on test set: 0.9774
  Client 5 model accuracy on test set: 0.9814
  Client 6 model accuracy on test set: 0.9825
  Client 7 model accuracy on test set: 0.9815
  Client 8 model accuracy on test set: 0.9815
  Client 9 model accuracy on test set: 0.9806

=== Global Round 75/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=6, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=1.0000
  Client 5: layers_shared=6, local_acc=1.0000
  Client 6: layers_shared=5, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=5, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=0.46, base_reward=0.7711, violation=0, comm_penalty=0.0000, reward=0.7711
  Client 1: mean_dist=0.45, base_reward=0.7737, violation=0, comm_penalty=0.0000, reward=0.7737
  Client 2: mean_dist=2.87, base_reward=-0.4329, violation=5, comm_penalty=0.5000, reward=-0.9329
  Client 3: mean_dist=2.11, base_reward=-0.0551, violation=1, comm_penalty=0.1000, reward=-0.1551
  Client 4: mean_dist=2.11, base_reward=-0.0563, violation=0, comm_penalty=0.0000, reward=-0.0563
  Client 5: mean_dist=3.40, base_reward=-0.7001, violation=0, comm_penalty=0.0000, reward=-0.7001
  Client 6: mean_dist=2.83, base_reward=-0.4152, violation=4, comm_penalty=0.4000, reward=-0.8152
  Client 7: mean_dist=0.46, base_reward=0.7703, violation=0, comm_penalty=0.0000, reward=0.7703
  Client 8: mean_dist=2.82, base_reward=-0.4082, violation=3, comm_penalty=0.3000, reward=-0.7082
  Client 9: mean_dist=2.13, base_reward=-0.0650, violation=0, comm_penalty=0.0000, reward=-0.0650
  RL policy loss: -0.400282
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9807
  Client 1 model accuracy on test set: 0.9767
  Client 2 model accuracy on test set: 0.9842
  Client 3 model accuracy on test set: 0.9832
  Client 4 model accuracy on test set: 0.9761
  Client 5 model accuracy on test set: 0.9812
  Client 6 model accuracy on test set: 0.9827
  Client 7 model accuracy on test set: 0.9808
  Client 8 model accuracy on test set: 0.9814
  Client 9 model accuracy on test set: 0.9811

=== Global Round 76/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=4, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=4, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=4, local_acc=1.0000
  Client 9: layers_shared=6, local_acc=1.0000
  Client 0: mean_dist=0.46, base_reward=0.7710, violation=0, comm_penalty=0.0000, reward=0.7710
  Client 1: mean_dist=2.11, base_reward=-0.0551, violation=0, comm_penalty=0.0000, reward=-0.0551
  Client 2: mean_dist=0.46, base_reward=0.7685, violation=0, comm_penalty=0.0000, reward=0.7685
  Client 3: mean_dist=1.78, base_reward=0.1102, violation=1, comm_penalty=0.1000, reward=0.0102
  Client 4: mean_dist=2.13, base_reward=-0.0675, violation=0, comm_penalty=0.0000, reward=-0.0675
  Client 5: mean_dist=0.52, base_reward=0.7410, violation=0, comm_penalty=0.0000, reward=0.7410
  Client 6: mean_dist=0.45, base_reward=0.7769, violation=0, comm_penalty=0.0000, reward=0.7769
  Client 7: mean_dist=1.76, base_reward=0.1211, violation=0, comm_penalty=0.0000, reward=0.1211
  Client 8: mean_dist=2.10, base_reward=-0.0516, violation=2, comm_penalty=0.2000, reward=-0.2516
  Client 9: mean_dist=2.14, base_reward=-0.0702, violation=1, comm_penalty=0.1000, reward=-0.1702
  RL policy loss: -0.295944
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9817
  Client 1 model accuracy on test set: 0.9774
  Client 2 model accuracy on test set: 0.9840
  Client 3 model accuracy on test set: 0.9826
  Client 4 model accuracy on test set: 0.9765
  Client 5 model accuracy on test set: 0.9814
  Client 6 model accuracy on test set: 0.9822
  Client 7 model accuracy on test set: 0.9811
  Client 8 model accuracy on test set: 0.9808
  Client 9 model accuracy on test set: 0.9809

=== Global Round 77/100 ===
  Client 0: layers_shared=6, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=4, local_acc=1.0000
  Client 3: layers_shared=6, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=2, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=1.84, base_reward=0.0784, violation=3, comm_penalty=0.3000, reward=-0.2216
  Client 1: mean_dist=0.45, base_reward=0.7737, violation=0, comm_penalty=0.0000, reward=0.7737
  Client 2: mean_dist=1.67, base_reward=0.1648, violation=3, comm_penalty=0.3000, reward=-0.1352
  Client 3: mean_dist=1.80, base_reward=0.0979, violation=4, comm_penalty=0.4000, reward=-0.3021
  Client 4: mean_dist=0.45, base_reward=0.7736, violation=0, comm_penalty=0.0000, reward=0.7736
  Client 5: mean_dist=0.52, base_reward=0.7410, violation=0, comm_penalty=0.0000, reward=0.7410
  Client 6: mean_dist=1.09, base_reward=0.4565, violation=1, comm_penalty=0.1000, reward=0.3565
  Client 7: mean_dist=0.46, base_reward=0.7703, violation=0, comm_penalty=0.0000, reward=0.7703
  Client 8: mean_dist=1.39, base_reward=0.3027, violation=1, comm_penalty=0.1000, reward=0.2027
  Client 9: mean_dist=0.47, base_reward=0.7670, violation=0, comm_penalty=0.0000, reward=0.7670
  RL policy loss: -0.297662
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9813
  Client 1 model accuracy on test set: 0.9772
  Client 2 model accuracy on test set: 0.9840
  Client 3 model accuracy on test set: 0.9839
  Client 4 model accuracy on test set: 0.9774
  Client 5 model accuracy on test set: 0.9806
  Client 6 model accuracy on test set: 0.9826
  Client 7 model accuracy on test set: 0.9812
  Client 8 model accuracy on test set: 0.9810
  Client 9 model accuracy on test set: 0.9807

=== Global Round 78/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=2, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=2, local_acc=1.0000
  Client 9: layers_shared=6, local_acc=1.0000
  Client 0: mean_dist=0.46, base_reward=0.7711, violation=0, comm_penalty=0.0000, reward=0.7711
  Client 1: mean_dist=1.18, base_reward=0.4091, violation=0, comm_penalty=0.0000, reward=0.4091
  Client 2: mean_dist=1.09, base_reward=0.4569, violation=1, comm_penalty=0.1000, reward=0.3569
  Client 3: mean_dist=1.08, base_reward=0.4581, violation=0, comm_penalty=0.0000, reward=0.4581
  Client 4: mean_dist=0.45, base_reward=0.7736, violation=0, comm_penalty=0.0000, reward=0.7736
  Client 5: mean_dist=0.52, base_reward=0.7411, violation=0, comm_penalty=0.0000, reward=0.7411
  Client 6: mean_dist=0.45, base_reward=0.7769, violation=0, comm_penalty=0.0000, reward=0.7769
  Client 7: mean_dist=0.46, base_reward=0.7703, violation=0, comm_penalty=0.0000, reward=0.7703
  Client 8: mean_dist=1.06, base_reward=0.4715, violation=0, comm_penalty=0.0000, reward=0.4715
  Client 9: mean_dist=1.20, base_reward=0.4008, violation=1, comm_penalty=0.1000, reward=0.3008
  RL policy loss: -0.129856
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9814
  Client 1 model accuracy on test set: 0.9769
  Client 2 model accuracy on test set: 0.9847
  Client 3 model accuracy on test set: 0.9836
  Client 4 model accuracy on test set: 0.9769
  Client 5 model accuracy on test set: 0.9813
  Client 6 model accuracy on test set: 0.9825
  Client 7 model accuracy on test set: 0.9807
  Client 8 model accuracy on test set: 0.9806
  Client 9 model accuracy on test set: 0.9812

=== Global Round 79/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=4, local_acc=1.0000
  Client 2: layers_shared=5, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=6, local_acc=1.0000
  Client 5: layers_shared=4, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=2, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=0.46, base_reward=0.7711, violation=0, comm_penalty=0.0000, reward=0.7711
  Client 1: mean_dist=2.38, base_reward=-0.1904, violation=0, comm_penalty=0.0000, reward=-0.1904
  Client 2: mean_dist=2.53, base_reward=-0.2634, violation=4, comm_penalty=0.4000, reward=-0.6634
  Client 3: mean_dist=2.00, base_reward=0.0016, violation=1, comm_penalty=0.1000, reward=-0.0984
  Client 4: mean_dist=2.52, base_reward=-0.2577, violation=2, comm_penalty=0.2000, reward=-0.4577
  Client 5: mean_dist=2.85, base_reward=-0.4245, violation=0, comm_penalty=0.0000, reward=-0.4245
  Client 6: mean_dist=0.45, base_reward=0.7769, violation=0, comm_penalty=0.0000, reward=0.7769
  Client 7: mean_dist=1.98, base_reward=0.0080, violation=0, comm_penalty=0.0000, reward=0.0080
  Client 8: mean_dist=1.40, base_reward=0.2985, violation=0, comm_penalty=0.0000, reward=0.2985
  Client 9: mean_dist=0.47, base_reward=0.7670, violation=0, comm_penalty=0.0000, reward=0.7670
  RL policy loss: -0.332914
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9810
  Client 1 model accuracy on test set: 0.9775
  Client 2 model accuracy on test set: 0.9848
  Client 3 model accuracy on test set: 0.9841
  Client 4 model accuracy on test set: 0.9776
  Client 5 model accuracy on test set: 0.9803
  Client 6 model accuracy on test set: 0.9826
  Client 7 model accuracy on test set: 0.9812
  Client 8 model accuracy on test set: 0.9810
  Client 9 model accuracy on test set: 0.9810

=== Global Round 80/100 ===
  Client 0: layers_shared=2, local_acc=1.0000
  Client 1: layers_shared=2, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=0.9742
  Client 6: layers_shared=5, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=5, local_acc=1.0000
  Client 9: layers_shared=6, local_acc=1.0000
  Client 0: mean_dist=1.12, base_reward=0.4402, violation=0, comm_penalty=0.0000, reward=0.4402
  Client 1: mean_dist=1.08, base_reward=0.4578, violation=0, comm_penalty=0.0000, reward=0.4578
  Client 2: mean_dist=0.46, base_reward=0.7684, violation=0, comm_penalty=0.0000, reward=0.7684
  Client 3: mean_dist=0.47, base_reward=0.7633, violation=0, comm_penalty=0.0000, reward=0.7633
  Client 4: mean_dist=0.45, base_reward=0.7733, violation=0, comm_penalty=0.0000, reward=0.7733
  Client 5: mean_dist=0.52, base_reward=0.7129, violation=0, comm_penalty=0.0000, reward=0.7129
  Client 6: mean_dist=1.74, base_reward=0.1311, violation=4, comm_penalty=0.4000, reward=-0.2689
  Client 7: mean_dist=0.46, base_reward=0.7699, violation=0, comm_penalty=0.0000, reward=0.7699
  Client 8: mean_dist=1.73, base_reward=0.1356, violation=3, comm_penalty=0.3000, reward=-0.1644
  Client 9: mean_dist=1.75, base_reward=0.1237, violation=1, comm_penalty=0.1000, reward=0.0237
  RL policy loss: -0.263599
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9813
  Client 1 model accuracy on test set: 0.9765
  Client 2 model accuracy on test set: 0.9849
  Client 3 model accuracy on test set: 0.9837
  Client 4 model accuracy on test set: 0.9777
  Client 5 model accuracy on test set: 0.9461
  Client 6 model accuracy on test set: 0.9812
  Client 7 model accuracy on test set: 0.9811
  Client 8 model accuracy on test set: 0.9810
  Client 9 model accuracy on test set: 0.9811

=== Global Round 81/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=5, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=6, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=0.46, base_reward=0.7706, violation=0, comm_penalty=0.0000, reward=0.7706
  Client 1: mean_dist=0.45, base_reward=0.7732, violation=0, comm_penalty=0.0000, reward=0.7732
  Client 2: mean_dist=1.21, base_reward=0.3964, violation=4, comm_penalty=0.4000, reward=-0.0036
  Client 3: mean_dist=0.47, base_reward=0.7635, violation=0, comm_penalty=0.0000, reward=0.7635
  Client 4: mean_dist=0.45, base_reward=0.7733, violation=0, comm_penalty=0.0000, reward=0.7733
  Client 5: mean_dist=0.52, base_reward=0.7386, violation=0, comm_penalty=0.0000, reward=0.7386
  Client 6: mean_dist=0.45, base_reward=0.7764, violation=0, comm_penalty=0.0000, reward=0.7764
  Client 7: mean_dist=0.98, base_reward=0.5113, violation=0, comm_penalty=0.0000, reward=0.5113
  Client 8: mean_dist=1.19, base_reward=0.4066, violation=4, comm_penalty=0.4000, reward=0.0066
  Client 9: mean_dist=0.47, base_reward=0.7670, violation=0, comm_penalty=0.0000, reward=0.7670
  RL policy loss: -0.194267
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9815
  Client 1 model accuracy on test set: 0.9772
  Client 2 model accuracy on test set: 0.9843
  Client 3 model accuracy on test set: 0.9826
  Client 4 model accuracy on test set: 0.9773
  Client 5 model accuracy on test set: 0.9815
  Client 6 model accuracy on test set: 0.9815
  Client 7 model accuracy on test set: 0.9809
  Client 8 model accuracy on test set: 0.9814
  Client 9 model accuracy on test set: 0.9810

=== Global Round 82/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=4, local_acc=1.0000
  Client 4: layers_shared=4, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=6, local_acc=1.0000
  Client 7: layers_shared=2, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=5, local_acc=1.0000
  Client 0: mean_dist=2.45, base_reward=-0.2228, violation=2, comm_penalty=0.2000, reward=-0.4228
  Client 1: mean_dist=0.45, base_reward=0.7734, violation=0, comm_penalty=0.0000, reward=0.7734
  Client 2: mean_dist=0.46, base_reward=0.7686, violation=0, comm_penalty=0.0000, reward=0.7686
  Client 3: mean_dist=2.18, base_reward=-0.0910, violation=2, comm_penalty=0.2000, reward=-0.2910
  Client 4: mean_dist=2.16, base_reward=-0.0787, violation=0, comm_penalty=0.0000, reward=-0.0787
  Client 5: mean_dist=0.52, base_reward=0.7405, violation=0, comm_penalty=0.0000, reward=0.7405
  Client 6: mean_dist=2.37, base_reward=-0.1862, violation=5, comm_penalty=0.5000, reward=-0.6862
  Client 7: mean_dist=1.24, base_reward=0.3821, violation=0, comm_penalty=0.0000, reward=0.3821
  Client 8: mean_dist=0.45, base_reward=0.7768, violation=0, comm_penalty=0.0000, reward=0.7768
  Client 9: mean_dist=2.40, base_reward=-0.1998, violation=0, comm_penalty=0.0000, reward=-0.1998
  RL policy loss: -0.394270
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9817
  Client 1 model accuracy on test set: 0.9772
  Client 2 model accuracy on test set: 0.9851
  Client 3 model accuracy on test set: 0.9831
  Client 4 model accuracy on test set: 0.9776
  Client 5 model accuracy on test set: 0.9796
  Client 6 model accuracy on test set: 0.9820
  Client 7 model accuracy on test set: 0.9811
  Client 8 model accuracy on test set: 0.9815
  Client 9 model accuracy on test set: 0.9816

=== Global Round 83/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=4, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=2, local_acc=1.0000
  Client 9: layers_shared=4, local_acc=1.0000
  Client 0: mean_dist=0.46, base_reward=0.7709, violation=0, comm_penalty=0.0000, reward=0.7709
  Client 1: mean_dist=0.45, base_reward=0.7735, violation=0, comm_penalty=0.0000, reward=0.7735
  Client 2: mean_dist=1.09, base_reward=0.4546, violation=1, comm_penalty=0.1000, reward=0.3546
  Client 3: mean_dist=1.30, base_reward=0.3486, violation=1, comm_penalty=0.1000, reward=0.2486
  Client 4: mean_dist=0.45, base_reward=0.7734, violation=0, comm_penalty=0.0000, reward=0.7734
  Client 5: mean_dist=0.52, base_reward=0.7407, violation=0, comm_penalty=0.0000, reward=0.7407
  Client 6: mean_dist=1.41, base_reward=0.2965, violation=3, comm_penalty=0.3000, reward=-0.0035
  Client 7: mean_dist=0.46, base_reward=0.7698, violation=0, comm_penalty=0.0000, reward=0.7698
  Client 8: mean_dist=1.06, base_reward=0.4719, violation=0, comm_penalty=0.0000, reward=0.4719
  Client 9: mean_dist=1.43, base_reward=0.2875, violation=0, comm_penalty=0.0000, reward=0.2875
  RL policy loss: -0.206755
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9814
  Client 1 model accuracy on test set: 0.9770
  Client 2 model accuracy on test set: 0.9845
  Client 3 model accuracy on test set: 0.9826
  Client 4 model accuracy on test set: 0.9769
  Client 5 model accuracy on test set: 0.9813
  Client 6 model accuracy on test set: 0.9819
  Client 7 model accuracy on test set: 0.9807
  Client 8 model accuracy on test set: 0.9810
  Client 9 model accuracy on test set: 0.9814

=== Global Round 84/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=4, local_acc=1.0000
  Client 4: layers_shared=6, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=0.9739
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=2, local_acc=1.0000
  Client 8: layers_shared=6, local_acc=1.0000
  Client 9: layers_shared=2, local_acc=1.0000
  Client 0: mean_dist=0.46, base_reward=0.7704, violation=0, comm_penalty=0.0000, reward=0.7704
  Client 1: mean_dist=0.45, base_reward=0.7729, violation=0, comm_penalty=0.0000, reward=0.7729
  Client 2: mean_dist=0.46, base_reward=0.7680, violation=0, comm_penalty=0.0000, reward=0.7680
  Client 3: mean_dist=1.54, base_reward=0.2298, violation=2, comm_penalty=0.2000, reward=0.0298
  Client 4: mean_dist=1.69, base_reward=0.1561, violation=2, comm_penalty=0.2000, reward=-0.0439
  Client 5: mean_dist=0.52, base_reward=0.7118, violation=0, comm_penalty=0.0000, reward=0.7118
  Client 6: mean_dist=0.45, base_reward=0.7763, violation=0, comm_penalty=0.0000, reward=0.7763
  Client 7: mean_dist=1.07, base_reward=0.4671, violation=0, comm_penalty=0.0000, reward=0.4671
  Client 8: mean_dist=1.65, base_reward=0.1736, violation=4, comm_penalty=0.4000, reward=-0.2264
  Client 9: mean_dist=1.08, base_reward=0.4575, violation=0, comm_penalty=0.0000, reward=0.4575
  RL policy loss: -0.270994
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9812
  Client 1 model accuracy on test set: 0.9773
  Client 2 model accuracy on test set: 0.9843
  Client 3 model accuracy on test set: 0.9833
  Client 4 model accuracy on test set: 0.9770
  Client 5 model accuracy on test set: 0.9367
  Client 6 model accuracy on test set: 0.9817
  Client 7 model accuracy on test set: 0.9816
  Client 8 model accuracy on test set: 0.9810
  Client 9 model accuracy on test set: 0.9809

=== Global Round 85/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=2, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=2, local_acc=1.0000
  Client 4: layers_shared=4, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=5, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=2, local_acc=1.0000
  Client 0: mean_dist=0.46, base_reward=0.7707, violation=0, comm_penalty=0.0000, reward=0.7707
  Client 1: mean_dist=1.38, base_reward=0.3099, violation=0, comm_penalty=0.0000, reward=0.3099
  Client 2: mean_dist=1.73, base_reward=0.1344, violation=2, comm_penalty=0.2000, reward=-0.0656
  Client 3: mean_dist=1.39, base_reward=0.3038, violation=0, comm_penalty=0.0000, reward=0.3038
  Client 4: mean_dist=1.84, base_reward=0.0820, violation=0, comm_penalty=0.0000, reward=0.0820
  Client 5: mean_dist=0.52, base_reward=0.7383, violation=0, comm_penalty=0.0000, reward=0.7383
  Client 6: mean_dist=1.83, base_reward=0.0836, violation=4, comm_penalty=0.4000, reward=-0.3164
  Client 7: mean_dist=0.46, base_reward=0.7695, violation=0, comm_penalty=0.0000, reward=0.7695
  Client 8: mean_dist=1.70, base_reward=0.1509, violation=1, comm_penalty=0.1000, reward=0.0509
  Client 9: mean_dist=1.41, base_reward=0.2942, violation=0, comm_penalty=0.0000, reward=0.2942
  RL policy loss: -0.210578
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9812
  Client 1 model accuracy on test set: 0.9777
  Client 2 model accuracy on test set: 0.9838
  Client 3 model accuracy on test set: 0.9823
  Client 4 model accuracy on test set: 0.9768
  Client 5 model accuracy on test set: 0.9785
  Client 6 model accuracy on test set: 0.9814
  Client 7 model accuracy on test set: 0.9812
  Client 8 model accuracy on test set: 0.9814
  Client 9 model accuracy on test set: 0.9814

=== Global Round 86/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=6, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=1.45, base_reward=0.2771, violation=0, comm_penalty=0.0000, reward=0.2771
  Client 1: mean_dist=0.45, base_reward=0.7731, violation=0, comm_penalty=0.0000, reward=0.7731
  Client 2: mean_dist=1.11, base_reward=0.4442, violation=1, comm_penalty=0.1000, reward=0.3442
  Client 3: mean_dist=0.47, base_reward=0.7635, violation=0, comm_penalty=0.0000, reward=0.7635
  Client 4: mean_dist=1.41, base_reward=0.2945, violation=2, comm_penalty=0.2000, reward=0.0945
  Client 5: mean_dist=0.52, base_reward=0.7376, violation=0, comm_penalty=0.0000, reward=0.7376
  Client 6: mean_dist=1.41, base_reward=0.2925, violation=2, comm_penalty=0.2000, reward=0.0925
  Client 7: mean_dist=0.46, base_reward=0.7694, violation=0, comm_penalty=0.0000, reward=0.7694
  Client 8: mean_dist=0.45, base_reward=0.7765, violation=0, comm_penalty=0.0000, reward=0.7765
  Client 9: mean_dist=1.44, base_reward=0.2817, violation=0, comm_penalty=0.0000, reward=0.2817
  RL policy loss: -0.194303
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9813
  Client 1 model accuracy on test set: 0.9772
  Client 2 model accuracy on test set: 0.9843
  Client 3 model accuracy on test set: 0.9833
  Client 4 model accuracy on test set: 0.9766
  Client 5 model accuracy on test set: 0.9809
  Client 6 model accuracy on test set: 0.9819
  Client 7 model accuracy on test set: 0.9812
  Client 8 model accuracy on test set: 0.9815
  Client 9 model accuracy on test set: 0.9813

=== Global Round 87/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=2, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=2, local_acc=1.0000
  Client 0: mean_dist=0.46, base_reward=0.7706, violation=0, comm_penalty=0.0000, reward=0.7706
  Client 1: mean_dist=0.45, base_reward=0.7731, violation=0, comm_penalty=0.0000, reward=0.7731
  Client 2: mean_dist=0.46, base_reward=0.7682, violation=0, comm_penalty=0.0000, reward=0.7682
  Client 3: mean_dist=0.78, base_reward=0.6087, violation=0, comm_penalty=0.0000, reward=0.6087
  Client 4: mean_dist=0.77, base_reward=0.6173, violation=0, comm_penalty=0.0000, reward=0.6173
  Client 5: mean_dist=0.52, base_reward=0.7379, violation=0, comm_penalty=0.0000, reward=0.7379
  Client 6: mean_dist=0.45, base_reward=0.7760, violation=0, comm_penalty=0.0000, reward=0.7760
  Client 7: mean_dist=0.46, base_reward=0.7695, violation=0, comm_penalty=0.0000, reward=0.7695
  Client 8: mean_dist=0.45, base_reward=0.7765, violation=0, comm_penalty=0.0000, reward=0.7765
  Client 9: mean_dist=0.78, base_reward=0.6081, violation=0, comm_penalty=0.0000, reward=0.6081
  RL policy loss: -0.044933
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9815
  Client 1 model accuracy on test set: 0.9776
  Client 2 model accuracy on test set: 0.9842
  Client 3 model accuracy on test set: 0.9832
  Client 4 model accuracy on test set: 0.9776
  Client 5 model accuracy on test set: 0.9811
  Client 6 model accuracy on test set: 0.9816
  Client 7 model accuracy on test set: 0.9811
  Client 8 model accuracy on test set: 0.9815
  Client 9 model accuracy on test set: 0.9813

=== Global Round 88/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=5, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=6, local_acc=1.0000
  Client 6: layers_shared=2, local_acc=1.0000
  Client 7: layers_shared=4, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=2, local_acc=1.0000
  Client 0: mean_dist=2.37, base_reward=-0.1832, violation=2, comm_penalty=0.2000, reward=-0.3832
  Client 1: mean_dist=0.45, base_reward=0.7731, violation=0, comm_penalty=0.0000, reward=0.7731
  Client 2: mean_dist=0.46, base_reward=0.7683, violation=0, comm_penalty=0.0000, reward=0.7683
  Client 3: mean_dist=2.32, base_reward=-0.1592, violation=3, comm_penalty=0.3000, reward=-0.4592
  Client 4: mean_dist=0.45, base_reward=0.7730, violation=0, comm_penalty=0.0000, reward=0.7730
  Client 5: mean_dist=2.71, base_reward=-0.3563, violation=0, comm_penalty=0.0000, reward=-0.3563
  Client 6: mean_dist=1.29, base_reward=0.3571, violation=1, comm_penalty=0.1000, reward=0.2571
  Client 7: mean_dist=2.04, base_reward=-0.0225, violation=0, comm_penalty=0.0000, reward=-0.0225
  Client 8: mean_dist=0.45, base_reward=0.7765, violation=0, comm_penalty=0.0000, reward=0.7765
  Client 9: mean_dist=1.30, base_reward=0.3493, violation=0, comm_penalty=0.0000, reward=0.3493
  RL policy loss: -0.407995
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9811
  Client 1 model accuracy on test set: 0.9773
  Client 2 model accuracy on test set: 0.9845
  Client 3 model accuracy on test set: 0.9829
  Client 4 model accuracy on test set: 0.9777
  Client 5 model accuracy on test set: 0.9813
  Client 6 model accuracy on test set: 0.9815
  Client 7 model accuracy on test set: 0.9808
  Client 8 model accuracy on test set: 0.9810
  Client 9 model accuracy on test set: 0.9814

=== Global Round 89/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=5, local_acc=1.0000
  Client 2: layers_shared=4, local_acc=1.0000
  Client 3: layers_shared=4, local_acc=1.0000
  Client 4: layers_shared=6, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=4, local_acc=1.0000
  Client 8: layers_shared=6, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=2.44, base_reward=-0.2178, violation=0, comm_penalty=0.0000, reward=-0.2178
  Client 1: mean_dist=3.17, base_reward=-0.5853, violation=0, comm_penalty=0.0000, reward=-0.5853
  Client 2: mean_dist=3.00, base_reward=-0.4984, violation=3, comm_penalty=0.3000, reward=-0.7984
  Client 3: mean_dist=2.99, base_reward=-0.4948, violation=2, comm_penalty=0.2000, reward=-0.6948
  Client 4: mean_dist=3.24, base_reward=-0.6198, violation=2, comm_penalty=0.2000, reward=-0.8198
  Client 5: mean_dist=2.88, base_reward=-0.4403, violation=0, comm_penalty=0.0000, reward=-0.4403
  Client 6: mean_dist=0.45, base_reward=0.7760, violation=0, comm_penalty=0.0000, reward=0.7760
  Client 7: mean_dist=2.96, base_reward=-0.4806, violation=0, comm_penalty=0.0000, reward=-0.4806
  Client 8: mean_dist=3.21, base_reward=-0.6041, violation=4, comm_penalty=0.4000, reward=-1.0041
  Client 9: mean_dist=0.47, base_reward=0.7669, violation=0, comm_penalty=0.0000, reward=0.7669
  RL policy loss: -0.431023
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9810
  Client 1 model accuracy on test set: 0.9772
  Client 2 model accuracy on test set: 0.9845
  Client 3 model accuracy on test set: 0.9830
  Client 4 model accuracy on test set: 0.9775
  Client 5 model accuracy on test set: 0.9809
  Client 6 model accuracy on test set: 0.9817
  Client 7 model accuracy on test set: 0.9814
  Client 8 model accuracy on test set: 0.9811
  Client 9 model accuracy on test set: 0.9807

=== Global Round 90/100 ===
  Client 0: layers_shared=2, local_acc=1.0000
  Client 1: layers_shared=4, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=2, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=0.9766
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=1.44, base_reward=0.2778, violation=0, comm_penalty=0.0000, reward=0.2778
  Client 1: mean_dist=1.70, base_reward=0.1483, violation=0, comm_penalty=0.0000, reward=0.1483
  Client 2: mean_dist=1.42, base_reward=0.2911, violation=1, comm_penalty=0.1000, reward=0.1911
  Client 3: mean_dist=1.41, base_reward=0.2967, violation=0, comm_penalty=0.0000, reward=0.2967
  Client 4: mean_dist=1.71, base_reward=0.1446, violation=0, comm_penalty=0.0000, reward=0.1446
  Client 5: mean_dist=0.53, base_reward=0.7127, violation=0, comm_penalty=0.0000, reward=0.7127
  Client 6: mean_dist=1.73, base_reward=0.1374, violation=2, comm_penalty=0.2000, reward=-0.0626
  Client 7: mean_dist=0.46, base_reward=0.7695, violation=0, comm_penalty=0.0000, reward=0.7695
  Client 8: mean_dist=0.45, base_reward=0.7761, violation=0, comm_penalty=0.0000, reward=0.7761
  Client 9: mean_dist=1.75, base_reward=0.1245, violation=0, comm_penalty=0.0000, reward=0.1245
  RL policy loss: -0.185757
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9811
  Client 1 model accuracy on test set: 0.9777
  Client 2 model accuracy on test set: 0.9848
  Client 3 model accuracy on test set: 0.9833
  Client 4 model accuracy on test set: 0.9773
  Client 5 model accuracy on test set: 0.9563
  Client 6 model accuracy on test set: 0.9826
  Client 7 model accuracy on test set: 0.9810
  Client 8 model accuracy on test set: 0.9805
  Client 9 model accuracy on test set: 0.9808

=== Global Round 91/100 ===
  Client 0: layers_shared=6, local_acc=1.0000
  Client 1: layers_shared=2, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=6, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=5, local_acc=0.9941
  Client 6: layers_shared=6, local_acc=1.0000
  Client 7: layers_shared=6, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=2.89, base_reward=-0.4471, violation=3, comm_penalty=0.3000, reward=-0.7471
  Client 1: mean_dist=1.27, base_reward=0.3649, violation=0, comm_penalty=0.0000, reward=0.3649
  Client 2: mean_dist=0.47, base_reward=0.7672, violation=0, comm_penalty=0.0000, reward=0.7672
  Client 3: mean_dist=2.83, base_reward=-0.4141, violation=4, comm_penalty=0.4000, reward=-0.8141
  Client 4: mean_dist=0.46, base_reward=0.7719, violation=0, comm_penalty=0.0000, reward=0.7719
  Client 5: mean_dist=3.30, base_reward=-0.6542, violation=0, comm_penalty=0.0000, reward=-0.6542
  Client 6: mean_dist=2.80, base_reward=-0.3985, violation=5, comm_penalty=0.5000, reward=-0.8985
  Client 7: mean_dist=2.77, base_reward=-0.3868, violation=0, comm_penalty=0.0000, reward=-0.3868
  Client 8: mean_dist=0.45, base_reward=0.7761, violation=0, comm_penalty=0.0000, reward=0.7761
  Client 9: mean_dist=0.47, base_reward=0.7663, violation=0, comm_penalty=0.0000, reward=0.7663
  RL policy loss: -0.617638
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9813
  Client 1 model accuracy on test set: 0.9774
  Client 2 model accuracy on test set: 0.9851
  Client 3 model accuracy on test set: 0.9831
  Client 4 model accuracy on test set: 0.9774
  Client 5 model accuracy on test set: 0.9709
  Client 6 model accuracy on test set: 0.9823
  Client 7 model accuracy on test set: 0.9810
  Client 8 model accuracy on test set: 0.9808
  Client 9 model accuracy on test set: 0.9810

=== Global Round 92/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=1.23, base_reward=0.3847, violation=2, comm_penalty=0.2000, reward=0.1847
  Client 1: mean_dist=0.45, base_reward=0.7728, violation=0, comm_penalty=0.0000, reward=0.7728
  Client 2: mean_dist=0.46, base_reward=0.7677, violation=0, comm_penalty=0.0000, reward=0.7677
  Client 3: mean_dist=0.47, base_reward=0.7634, violation=0, comm_penalty=0.0000, reward=0.7634
  Client 4: mean_dist=1.22, base_reward=0.3924, violation=1, comm_penalty=0.1000, reward=0.2924
  Client 5: mean_dist=0.53, base_reward=0.7353, violation=0, comm_penalty=0.0000, reward=0.7353
  Client 6: mean_dist=0.45, base_reward=0.7755, violation=0, comm_penalty=0.0000, reward=0.7755
  Client 7: mean_dist=1.00, base_reward=0.4985, violation=0, comm_penalty=0.0000, reward=0.4985
  Client 8: mean_dist=0.45, base_reward=0.7765, violation=0, comm_penalty=0.0000, reward=0.7765
  Client 9: mean_dist=0.47, base_reward=0.7664, violation=0, comm_penalty=0.0000, reward=0.7664
  RL policy loss: -0.171223
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9810
  Client 1 model accuracy on test set: 0.9772
  Client 2 model accuracy on test set: 0.9842
  Client 3 model accuracy on test set: 0.9829
  Client 4 model accuracy on test set: 0.9775
  Client 5 model accuracy on test set: 0.9796
  Client 6 model accuracy on test set: 0.9813
  Client 7 model accuracy on test set: 0.9815
  Client 8 model accuracy on test set: 0.9809
  Client 9 model accuracy on test set: 0.9810

=== Global Round 93/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=6, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=4, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=0.9909
  Client 6: layers_shared=6, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=2.37, base_reward=-0.1861, violation=0, comm_penalty=0.0000, reward=-0.1861
  Client 1: mean_dist=2.65, base_reward=-0.3243, violation=1, comm_penalty=0.1000, reward=-0.4243
  Client 2: mean_dist=0.47, base_reward=0.7674, violation=0, comm_penalty=0.0000, reward=0.7674
  Client 3: mean_dist=2.57, base_reward=-0.2825, violation=2, comm_penalty=0.2000, reward=-0.4825
  Client 4: mean_dist=2.30, base_reward=-0.1520, violation=0, comm_penalty=0.0000, reward=-0.1520
  Client 5: mean_dist=0.54, base_reward=0.7233, violation=0, comm_penalty=0.0000, reward=0.7233
  Client 6: mean_dist=2.67, base_reward=-0.3339, violation=5, comm_penalty=0.5000, reward=-0.8339
  Client 7: mean_dist=2.30, base_reward=-0.1509, violation=0, comm_penalty=0.0000, reward=-0.1509
  Client 8: mean_dist=2.29, base_reward=-0.1448, violation=1, comm_penalty=0.1000, reward=-0.2448
  Client 9: mean_dist=2.33, base_reward=-0.1631, violation=0, comm_penalty=0.0000, reward=-0.1631
  RL policy loss: -0.317929
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9812
  Client 1 model accuracy on test set: 0.9770
  Client 2 model accuracy on test set: 0.9846
  Client 3 model accuracy on test set: 0.9835
  Client 4 model accuracy on test set: 0.9768
  Client 5 model accuracy on test set: 0.9625
  Client 6 model accuracy on test set: 0.9818
  Client 7 model accuracy on test set: 0.9812
  Client 8 model accuracy on test set: 0.9809
  Client 9 model accuracy on test set: 0.9813

=== Global Round 94/100 ===
  Client 0: layers_shared=2, local_acc=1.0000
  Client 1: layers_shared=4, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=1.28, base_reward=0.3584, violation=0, comm_penalty=0.0000, reward=0.3584
  Client 1: mean_dist=1.67, base_reward=0.1665, violation=0, comm_penalty=0.0000, reward=0.1665
  Client 2: mean_dist=0.47, base_reward=0.7674, violation=0, comm_penalty=0.0000, reward=0.7674
  Client 3: mean_dist=1.68, base_reward=0.1591, violation=1, comm_penalty=0.1000, reward=0.0591
  Client 4: mean_dist=0.46, base_reward=0.7720, violation=0, comm_penalty=0.0000, reward=0.7720
  Client 5: mean_dist=0.54, base_reward=0.7324, violation=0, comm_penalty=0.0000, reward=0.7324
  Client 6: mean_dist=1.67, base_reward=0.1642, violation=2, comm_penalty=0.2000, reward=-0.0358
  Client 7: mean_dist=1.67, base_reward=0.1662, violation=0, comm_penalty=0.0000, reward=0.1662
  Client 8: mean_dist=1.65, base_reward=0.1741, violation=1, comm_penalty=0.1000, reward=0.0741
  Client 9: mean_dist=0.47, base_reward=0.7658, violation=0, comm_penalty=0.0000, reward=0.7658
  RL policy loss: -0.226902
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9812
  Client 1 model accuracy on test set: 0.9778
  Client 2 model accuracy on test set: 0.9845
  Client 3 model accuracy on test set: 0.9832
  Client 4 model accuracy on test set: 0.9771
  Client 5 model accuracy on test set: 0.9814
  Client 6 model accuracy on test set: 0.9825
  Client 7 model accuracy on test set: 0.9815
  Client 8 model accuracy on test set: 0.9816
  Client 9 model accuracy on test set: 0.9813

=== Global Round 95/100 ===
  Client 0: layers_shared=2, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=1.0000
  Client 5: layers_shared=6, local_acc=1.0000
  Client 6: layers_shared=2, local_acc=1.0000
  Client 7: layers_shared=5, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=1.49, base_reward=0.2569, violation=0, comm_penalty=0.0000, reward=0.2569
  Client 1: mean_dist=0.46, base_reward=0.7722, violation=0, comm_penalty=0.0000, reward=0.7722
  Client 2: mean_dist=1.93, base_reward=0.0361, violation=2, comm_penalty=0.2000, reward=-0.1639
  Client 3: mean_dist=0.47, base_reward=0.7631, violation=0, comm_penalty=0.0000, reward=0.7631
  Client 4: mean_dist=1.91, base_reward=0.0435, violation=0, comm_penalty=0.0000, reward=0.0435
  Client 5: mean_dist=2.59, base_reward=-0.2939, violation=0, comm_penalty=0.0000, reward=-0.2939
  Client 6: mean_dist=1.45, base_reward=0.2772, violation=1, comm_penalty=0.1000, reward=0.1772
  Client 7: mean_dist=2.20, base_reward=-0.0998, violation=0, comm_penalty=0.0000, reward=-0.0998
  Client 8: mean_dist=1.90, base_reward=0.0490, violation=1, comm_penalty=0.1000, reward=-0.0510
  Client 9: mean_dist=0.47, base_reward=0.7658, violation=0, comm_penalty=0.0000, reward=0.7658
  RL policy loss: -0.314911
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9806
  Client 1 model accuracy on test set: 0.9776
  Client 2 model accuracy on test set: 0.9847
  Client 3 model accuracy on test set: 0.9834
  Client 4 model accuracy on test set: 0.9771
  Client 5 model accuracy on test set: 0.9830
  Client 6 model accuracy on test set: 0.9828
  Client 7 model accuracy on test set: 0.9812
  Client 8 model accuracy on test set: 0.9813
  Client 9 model accuracy on test set: 0.9812

=== Global Round 96/100 ===
  Client 0: layers_shared=2, local_acc=1.0000
  Client 1: layers_shared=5, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=1.11, base_reward=0.4433, violation=0, comm_penalty=0.0000, reward=0.4433
  Client 1: mean_dist=1.39, base_reward=0.3026, violation=0, comm_penalty=0.0000, reward=0.3026
  Client 2: mean_dist=0.46, base_reward=0.7675, violation=0, comm_penalty=0.0000, reward=0.7675
  Client 3: mean_dist=0.47, base_reward=0.7632, violation=0, comm_penalty=0.0000, reward=0.7632
  Client 4: mean_dist=1.40, base_reward=0.2991, violation=0, comm_penalty=0.0000, reward=0.2991
  Client 5: mean_dist=0.53, base_reward=0.7332, violation=0, comm_penalty=0.0000, reward=0.7332
  Client 6: mean_dist=1.41, base_reward=0.2953, violation=2, comm_penalty=0.2000, reward=0.0953
  Client 7: mean_dist=0.46, base_reward=0.7689, violation=0, comm_penalty=0.0000, reward=0.7689
  Client 8: mean_dist=1.41, base_reward=0.2959, violation=1, comm_penalty=0.1000, reward=0.1959
  Client 9: mean_dist=0.47, base_reward=0.7658, violation=0, comm_penalty=0.0000, reward=0.7658
  RL policy loss: -0.190773
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9819
  Client 1 model accuracy on test set: 0.9772
  Client 2 model accuracy on test set: 0.9843
  Client 3 model accuracy on test set: 0.9836
  Client 4 model accuracy on test set: 0.9770
  Client 5 model accuracy on test set: 0.9821
  Client 6 model accuracy on test set: 0.9819
  Client 7 model accuracy on test set: 0.9815
  Client 8 model accuracy on test set: 0.9806
  Client 9 model accuracy on test set: 0.9816

=== Global Round 97/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=4, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=2, local_acc=1.0000
  Client 7: layers_shared=5, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=1.18, base_reward=0.4076, violation=0, comm_penalty=0.0000, reward=0.4076
  Client 1: mean_dist=0.46, base_reward=0.7722, violation=0, comm_penalty=0.0000, reward=0.7722
  Client 2: mean_dist=1.28, base_reward=0.3602, violation=3, comm_penalty=0.3000, reward=0.0602
  Client 3: mean_dist=0.47, base_reward=0.7632, violation=0, comm_penalty=0.0000, reward=0.7632
  Client 4: mean_dist=0.46, base_reward=0.7720, violation=0, comm_penalty=0.0000, reward=0.7720
  Client 5: mean_dist=0.53, base_reward=0.7334, violation=0, comm_penalty=0.0000, reward=0.7334
  Client 6: mean_dist=0.93, base_reward=0.5333, violation=1, comm_penalty=0.1000, reward=0.4333
  Client 7: mean_dist=1.27, base_reward=0.3650, violation=0, comm_penalty=0.0000, reward=0.3650
  Client 8: mean_dist=0.45, base_reward=0.7759, violation=0, comm_penalty=0.0000, reward=0.7759
  Client 9: mean_dist=0.47, base_reward=0.7658, violation=0, comm_penalty=0.0000, reward=0.7658
  RL policy loss: -0.208954
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9820
  Client 1 model accuracy on test set: 0.9777
  Client 2 model accuracy on test set: 0.9843
  Client 3 model accuracy on test set: 0.9837
  Client 4 model accuracy on test set: 0.9774
  Client 5 model accuracy on test set: 0.9819
  Client 6 model accuracy on test set: 0.9823
  Client 7 model accuracy on test set: 0.9807
  Client 8 model accuracy on test set: 0.9814
  Client 9 model accuracy on test set: 0.9815

=== Global Round 98/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=2, local_acc=1.0000
  Client 5: layers_shared=5, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=0.46, base_reward=0.7700, violation=0, comm_penalty=0.0000, reward=0.7700
  Client 1: mean_dist=0.46, base_reward=0.7722, violation=0, comm_penalty=0.0000, reward=0.7722
  Client 2: mean_dist=0.97, base_reward=0.5174, violation=2, comm_penalty=0.2000, reward=0.3174
  Client 3: mean_dist=0.47, base_reward=0.7632, violation=0, comm_penalty=0.0000, reward=0.7632
  Client 4: mean_dist=0.81, base_reward=0.5963, violation=0, comm_penalty=0.0000, reward=0.5963
  Client 5: mean_dist=1.06, base_reward=0.4677, violation=0, comm_penalty=0.0000, reward=0.4677
  Client 6: mean_dist=0.45, base_reward=0.7755, violation=0, comm_penalty=0.0000, reward=0.7755
  Client 7: mean_dist=0.46, base_reward=0.7689, violation=0, comm_penalty=0.0000, reward=0.7689
  Client 8: mean_dist=0.45, base_reward=0.7759, violation=0, comm_penalty=0.0000, reward=0.7759
  Client 9: mean_dist=0.47, base_reward=0.7658, violation=0, comm_penalty=0.0000, reward=0.7658
  RL policy loss: -0.114721
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9811
  Client 1 model accuracy on test set: 0.9772
  Client 2 model accuracy on test set: 0.9844
  Client 3 model accuracy on test set: 0.9833
  Client 4 model accuracy on test set: 0.9772
  Client 5 model accuracy on test set: 0.9810
  Client 6 model accuracy on test set: 0.9824
  Client 7 model accuracy on test set: 0.9812
  Client 8 model accuracy on test set: 0.9816
  Client 9 model accuracy on test set: 0.9810

=== Global Round 99/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=6, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=0.73, base_reward=0.6325, violation=0, comm_penalty=0.0000, reward=0.6325
  Client 1: mean_dist=0.46, base_reward=0.7722, violation=0, comm_penalty=0.0000, reward=0.7722
  Client 2: mean_dist=0.46, base_reward=0.7676, violation=0, comm_penalty=0.0000, reward=0.7676
  Client 3: mean_dist=0.47, base_reward=0.7632, violation=0, comm_penalty=0.0000, reward=0.7632
  Client 4: mean_dist=0.46, base_reward=0.7719, violation=0, comm_penalty=0.0000, reward=0.7719
  Client 5: mean_dist=0.53, base_reward=0.7333, violation=0, comm_penalty=0.0000, reward=0.7333
  Client 6: mean_dist=0.45, base_reward=0.7754, violation=0, comm_penalty=0.0000, reward=0.7754
  Client 7: mean_dist=0.46, base_reward=0.7689, violation=0, comm_penalty=0.0000, reward=0.7689
  Client 8: mean_dist=0.72, base_reward=0.6384, violation=4, comm_penalty=0.4000, reward=0.2384
  Client 9: mean_dist=0.47, base_reward=0.7659, violation=0, comm_penalty=0.0000, reward=0.7659
  RL policy loss: -0.113134
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9822
  Client 1 model accuracy on test set: 0.9771
  Client 2 model accuracy on test set: 0.9840
  Client 3 model accuracy on test set: 0.9831
  Client 4 model accuracy on test set: 0.9774
  Client 5 model accuracy on test set: 0.9828
  Client 6 model accuracy on test set: 0.9817
  Client 7 model accuracy on test set: 0.9816
  Client 8 model accuracy on test set: 0.9809
  Client 9 model accuracy on test set: 0.9813

=== Global Round 100/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=5, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=0.46, base_reward=0.7699, violation=0, comm_penalty=0.0000, reward=0.7699
  Client 1: mean_dist=0.46, base_reward=0.7722, violation=0, comm_penalty=0.0000, reward=0.7722
  Client 2: mean_dist=0.46, base_reward=0.7675, violation=0, comm_penalty=0.0000, reward=0.7675
  Client 3: mean_dist=0.47, base_reward=0.7632, violation=0, comm_penalty=0.0000, reward=0.7632
  Client 4: mean_dist=0.46, base_reward=0.7719, violation=0, comm_penalty=0.0000, reward=0.7719
  Client 5: mean_dist=0.53, base_reward=0.7335, violation=0, comm_penalty=0.0000, reward=0.7335
  Client 6: mean_dist=0.45, base_reward=0.7754, violation=0, comm_penalty=0.0000, reward=0.7754
  Client 7: mean_dist=0.46, base_reward=0.7689, violation=0, comm_penalty=0.0000, reward=0.7689
  Client 8: mean_dist=0.45, base_reward=0.7759, violation=3, comm_penalty=0.3000, reward=0.4759
  Client 9: mean_dist=0.47, base_reward=0.7658, violation=0, comm_penalty=0.0000, reward=0.7658
  RL policy loss: -0.053780
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9819
  Client 1 model accuracy on test set: 0.9766
  Client 2 model accuracy on test set: 0.9846
  Client 3 model accuracy on test set: 0.9829
  Client 4 model accuracy on test set: 0.9768
  Client 5 model accuracy on test set: 0.9836
  Client 6 model accuracy on test set: 0.9825
  Client 7 model accuracy on test set: 0.9813
  Client 8 model accuracy on test set: 0.9807
  Client 9 model accuracy on test set: 0.9806

Training finished.
Saved global model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/global_model.pt
Saved client 0 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_0_model.pt
Saved client 1 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_1_model.pt
Saved client 2 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_2_model.pt
Saved client 3 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_3_model.pt
Saved client 4 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_4_model.pt
Saved client 5 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_5_model.pt
Saved client 6 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_6_model.pt
Saved client 7 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_7_model.pt
Saved client 8 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_8_model.pt
Saved client 9 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_9_model.pt
Saved RL policy network  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/policy_net.pt