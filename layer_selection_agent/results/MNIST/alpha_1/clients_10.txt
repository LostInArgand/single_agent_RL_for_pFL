RL will choose number of shared layers in [1, 6] for each client.

=== Global Round 1/100 ===
  Client 0: layers_shared=2, local_acc=0.8846
  Client 1: layers_shared=3, local_acc=0.9768
  Client 2: layers_shared=3, local_acc=0.9397
  Client 3: layers_shared=3, local_acc=0.9330
  Client 4: layers_shared=2, local_acc=0.9383
  Client 5: layers_shared=4, local_acc=0.9453
  Client 6: layers_shared=6, local_acc=0.9276
  Client 7: layers_shared=5, local_acc=0.9440
  Client 8: layers_shared=3, local_acc=0.9561
  Client 9: layers_shared=3, local_acc=0.9002
  Client 0: mean_dist=1.57, base_reward=0.1009, violation=0, comm_penalty=0.0000, reward=0.1009
  Client 1: mean_dist=2.23, base_reward=-0.1394, violation=0, comm_penalty=0.0000, reward=-0.1394
  Client 2: mean_dist=2.23, base_reward=-0.1756, violation=2, comm_penalty=0.2000, reward=-0.3756
  Client 3: mean_dist=2.20, base_reward=-0.1693, violation=1, comm_penalty=0.1000, reward=-0.2693
  Client 4: mean_dist=1.53, base_reward=0.1725, violation=0, comm_penalty=0.0000, reward=0.1725
  Client 5: mean_dist=2.22, base_reward=-0.1661, violation=0, comm_penalty=0.0000, reward=-0.1661
  Client 6: mean_dist=2.31, base_reward=-0.2287, violation=5, comm_penalty=0.5000, reward=-0.7287
  Client 7: mean_dist=2.41, base_reward=-0.2626, violation=0, comm_penalty=0.0000, reward=-0.2626
  Client 8: mean_dist=2.29, base_reward=-0.1888, violation=1, comm_penalty=0.1000, reward=-0.2888
  Client 9: mean_dist=2.12, base_reward=-0.1600, violation=0, comm_penalty=0.0000, reward=-0.1600
  RL policy loss: 0.024907
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.7803
  Client 1 model accuracy on test set: 0.9215
  Client 2 model accuracy on test set: 0.8848
  Client 3 model accuracy on test set: 0.8888
  Client 4 model accuracy on test set: 0.7185
  Client 5 model accuracy on test set: 0.6974
  Client 6 model accuracy on test set: 0.7416
  Client 7 model accuracy on test set: 0.8628
  Client 8 model accuracy on test set: 0.8445
  Client 9 model accuracy on test set: 0.8303

=== Global Round 2/100 ===
  Client 0: layers_shared=4, local_acc=0.9908
  Client 1: layers_shared=5, local_acc=0.9905
  Client 2: layers_shared=1, local_acc=0.9564
  Client 3: layers_shared=5, local_acc=0.9788
  Client 4: layers_shared=5, local_acc=0.9515
  Client 5: layers_shared=3, local_acc=0.9807
  Client 6: layers_shared=2, local_acc=0.8453
  Client 7: layers_shared=2, local_acc=0.9917
  Client 8: layers_shared=3, local_acc=0.9747
  Client 9: layers_shared=4, local_acc=0.9845
  Client 0: mean_dist=2.54, base_reward=-0.2797, violation=1, comm_penalty=0.1000, reward=-0.3797
  Client 1: mean_dist=2.83, base_reward=-0.4244, violation=0, comm_penalty=0.0000, reward=-0.4244
  Client 2: mean_dist=0.43, base_reward=0.7403, violation=0, comm_penalty=0.0000, reward=0.7403
  Client 3: mean_dist=2.76, base_reward=-0.4011, violation=3, comm_penalty=0.3000, reward=-0.7011
  Client 4: mean_dist=2.63, base_reward=-0.3657, violation=1, comm_penalty=0.1000, reward=-0.4657
  Client 5: mean_dist=2.06, base_reward=-0.0471, violation=0, comm_penalty=0.0000, reward=-0.0471
  Client 6: mean_dist=1.53, base_reward=0.0819, violation=1, comm_penalty=0.1000, reward=-0.0181
  Client 7: mean_dist=1.61, base_reward=0.1853, violation=0, comm_penalty=0.0000, reward=0.1853
  Client 8: mean_dist=2.29, base_reward=-0.1691, violation=1, comm_penalty=0.1000, reward=-0.2691
  Client 9: mean_dist=2.53, base_reward=-0.2818, violation=0, comm_penalty=0.0000, reward=-0.2818
  RL policy loss: 0.068457
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9485
  Client 1 model accuracy on test set: 0.9401
  Client 2 model accuracy on test set: 0.8807
  Client 3 model accuracy on test set: 0.9479
  Client 4 model accuracy on test set: 0.7802
  Client 5 model accuracy on test set: 0.7713
  Client 6 model accuracy on test set: 0.7551
  Client 7 model accuracy on test set: 0.9680
  Client 8 model accuracy on test set: 0.9157
  Client 9 model accuracy on test set: 0.9061

=== Global Round 3/100 ===
  Client 0: layers_shared=1, local_acc=0.9990
  Client 1: layers_shared=6, local_acc=0.9998
  Client 2: layers_shared=2, local_acc=0.9937
  Client 3: layers_shared=6, local_acc=0.9964
  Client 4: layers_shared=5, local_acc=0.9972
  Client 5: layers_shared=5, local_acc=0.9970
  Client 6: layers_shared=6, local_acc=0.9980
  Client 7: layers_shared=4, local_acc=0.9964
  Client 8: layers_shared=1, local_acc=0.9849
  Client 9: layers_shared=6, local_acc=0.9984
  Client 0: mean_dist=0.44, base_reward=0.7795, violation=0, comm_penalty=0.0000, reward=0.7795
  Client 1: mean_dist=3.40, base_reward=-0.7010, violation=1, comm_penalty=0.1000, reward=-0.8010
  Client 2: mean_dist=1.52, base_reward=0.2315, violation=1, comm_penalty=0.1000, reward=0.1315
  Client 3: mean_dist=3.34, base_reward=-0.6737, violation=4, comm_penalty=0.4000, reward=-1.0737
  Client 4: mean_dist=3.09, base_reward=-0.5466, violation=1, comm_penalty=0.1000, reward=-0.6466
  Client 5: mean_dist=3.05, base_reward=-0.5265, violation=0, comm_penalty=0.0000, reward=-0.5265
  Client 6: mean_dist=3.15, base_reward=-0.5794, violation=5, comm_penalty=0.5000, reward=-1.0794
  Client 7: mean_dist=2.77, base_reward=-0.3902, violation=0, comm_penalty=0.0000, reward=-0.3902
  Client 8: mean_dist=0.47, base_reward=0.7516, violation=0, comm_penalty=0.0000, reward=0.7516
  Client 9: mean_dist=3.19, base_reward=-0.5975, violation=1, comm_penalty=0.1000, reward=-0.6975
  RL policy loss: 0.079821
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9676
  Client 1 model accuracy on test set: 0.9635
  Client 2 model accuracy on test set: 0.9415
  Client 3 model accuracy on test set: 0.9581
  Client 4 model accuracy on test set: 0.8803
  Client 5 model accuracy on test set: 0.8359
  Client 6 model accuracy on test set: 0.9140
  Client 7 model accuracy on test set: 0.9559
  Client 8 model accuracy on test set: 0.9441
  Client 9 model accuracy on test set: 0.9612

=== Global Round 4/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=0.9994
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=0.9993
  Client 5: layers_shared=1, local_acc=0.9978
  Client 6: layers_shared=5, local_acc=0.9980
  Client 7: layers_shared=4, local_acc=0.9992
  Client 8: layers_shared=1, local_acc=0.9997
  Client 9: layers_shared=2, local_acc=1.0000
  Client 0: mean_dist=1.34, base_reward=0.3303, violation=0, comm_penalty=0.0000, reward=0.3303
  Client 1: mean_dist=0.48, base_reward=0.7578, violation=0, comm_penalty=0.0000, reward=0.7578
  Client 2: mean_dist=0.44, base_reward=0.7802, violation=0, comm_penalty=0.0000, reward=0.7802
  Client 3: mean_dist=0.44, base_reward=0.7795, violation=0, comm_penalty=0.0000, reward=0.7795
  Client 4: mean_dist=1.61, base_reward=0.1942, violation=1, comm_penalty=0.1000, reward=0.0942
  Client 5: mean_dist=0.43, base_reward=0.7804, violation=0, comm_penalty=0.0000, reward=0.7804
  Client 6: mean_dist=1.61, base_reward=0.1931, violation=4, comm_penalty=0.4000, reward=-0.2069
  Client 7: mean_dist=1.60, base_reward=0.2015, violation=0, comm_penalty=0.0000, reward=0.2015
  Client 8: mean_dist=0.47, base_reward=0.7661, violation=0, comm_penalty=0.0000, reward=0.7661
  Client 9: mean_dist=1.04, base_reward=0.4783, violation=0, comm_penalty=0.0000, reward=0.4783
  RL policy loss: 0.020048
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9657
  Client 1 model accuracy on test set: 0.9660
  Client 2 model accuracy on test set: 0.9639
  Client 3 model accuracy on test set: 0.9743
  Client 4 model accuracy on test set: 0.8931
  Client 5 model accuracy on test set: 0.8549
  Client 6 model accuracy on test set: 0.9219
  Client 7 model accuracy on test set: 0.9696
  Client 8 model accuracy on test set: 0.9587
  Client 9 model accuracy on test set: 0.9715

=== Global Round 5/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=2, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=0.9996
  Client 5: layers_shared=2, local_acc=0.9998
  Client 6: layers_shared=4, local_acc=1.0000
  Client 7: layers_shared=5, local_acc=0.9999
  Client 8: layers_shared=4, local_acc=1.0000
  Client 9: layers_shared=6, local_acc=1.0000
  Client 0: mean_dist=3.13, base_reward=-0.5646, violation=2, comm_penalty=0.2000, reward=-0.7646
  Client 1: mean_dist=2.36, base_reward=-0.1813, violation=0, comm_penalty=0.0000, reward=-0.1813
  Client 2: mean_dist=0.44, base_reward=0.7806, violation=0, comm_penalty=0.0000, reward=0.7806
  Client 3: mean_dist=1.70, base_reward=0.1523, violation=0, comm_penalty=0.0000, reward=0.1523
  Client 4: mean_dist=3.06, base_reward=-0.5292, violation=1, comm_penalty=0.1000, reward=-0.6292
  Client 5: mean_dist=1.59, base_reward=0.2048, violation=0, comm_penalty=0.0000, reward=0.2048
  Client 6: mean_dist=2.73, base_reward=-0.3658, violation=3, comm_penalty=0.3000, reward=-0.6658
  Client 7: mean_dist=3.24, base_reward=-0.6194, violation=0, comm_penalty=0.0000, reward=-0.6194
  Client 8: mean_dist=2.97, base_reward=-0.4874, violation=2, comm_penalty=0.2000, reward=-0.6874
  Client 9: mean_dist=3.09, base_reward=-0.5442, violation=1, comm_penalty=0.1000, reward=-0.6442
  RL policy loss: 0.097017
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9704
  Client 1 model accuracy on test set: 0.9731
  Client 2 model accuracy on test set: 0.9659
  Client 3 model accuracy on test set: 0.9766
  Client 4 model accuracy on test set: 0.9113
  Client 5 model accuracy on test set: 0.8474
  Client 6 model accuracy on test set: 0.9517
  Client 7 model accuracy on test set: 0.9768
  Client 8 model accuracy on test set: 0.9711
  Client 9 model accuracy on test set: 0.9740

=== Global Round 6/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=6, local_acc=1.0000
  Client 2: layers_shared=4, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=0.9998
  Client 6: layers_shared=5, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=6, local_acc=1.0000
  Client 0: mean_dist=3.19, base_reward=-0.5926, violation=2, comm_penalty=0.2000, reward=-0.7926
  Client 1: mean_dist=3.35, base_reward=-0.6760, violation=1, comm_penalty=0.1000, reward=-0.7760
  Client 2: mean_dist=2.84, base_reward=-0.4218, violation=3, comm_penalty=0.3000, reward=-0.7218
  Client 3: mean_dist=0.44, base_reward=0.7779, violation=0, comm_penalty=0.0000, reward=0.7779
  Client 4: mean_dist=3.12, base_reward=-0.5601, violation=1, comm_penalty=0.1000, reward=-0.6601
  Client 5: mean_dist=2.12, base_reward=-0.0595, violation=0, comm_penalty=0.0000, reward=-0.0595
  Client 6: mean_dist=3.10, base_reward=-0.5494, violation=4, comm_penalty=0.4000, reward=-0.9494
  Client 7: mean_dist=0.45, base_reward=0.7749, violation=0, comm_penalty=0.0000, reward=0.7749
  Client 8: mean_dist=2.36, base_reward=-0.1804, violation=1, comm_penalty=0.1000, reward=-0.2804
  Client 9: mean_dist=3.15, base_reward=-0.5743, violation=1, comm_penalty=0.1000, reward=-0.6743
  RL policy loss: 0.020296
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9717
  Client 1 model accuracy on test set: 0.9731
  Client 2 model accuracy on test set: 0.9697
  Client 3 model accuracy on test set: 0.9765
  Client 4 model accuracy on test set: 0.9326
  Client 5 model accuracy on test set: 0.8663
  Client 6 model accuracy on test set: 0.9532
  Client 7 model accuracy on test set: 0.9728
  Client 8 model accuracy on test set: 0.9715
  Client 9 model accuracy on test set: 0.9737

=== Global Round 7/100 ===
  Client 0: layers_shared=4, local_acc=1.0000
  Client 1: layers_shared=6, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=2, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=0.9710
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=6, local_acc=1.0000
  Client 7: layers_shared=6, local_acc=1.0000
  Client 8: layers_shared=2, local_acc=1.0000
  Client 9: layers_shared=5, local_acc=1.0000
  Client 0: mean_dist=2.99, base_reward=-0.4969, violation=1, comm_penalty=0.1000, reward=-0.5969
  Client 1: mean_dist=3.49, base_reward=-0.7443, violation=1, comm_penalty=0.1000, reward=-0.8443
  Client 2: mean_dist=2.61, base_reward=-0.3052, violation=2, comm_penalty=0.2000, reward=-0.5052
  Client 3: mean_dist=1.87, base_reward=0.0642, violation=0, comm_penalty=0.0000, reward=0.0642
  Client 4: mean_dist=2.48, base_reward=-0.2698, violation=0, comm_penalty=0.0000, reward=-0.2698
  Client 5: mean_dist=2.43, base_reward=-0.2161, violation=0, comm_penalty=0.0000, reward=-0.2161
  Client 6: mean_dist=3.26, base_reward=-0.6299, violation=5, comm_penalty=0.5000, reward=-1.1299
  Client 7: mean_dist=3.46, base_reward=-0.7282, violation=0, comm_penalty=0.0000, reward=-0.7282
  Client 8: mean_dist=1.94, base_reward=0.0320, violation=0, comm_penalty=0.0000, reward=0.0320
  Client 9: mean_dist=3.26, base_reward=-0.6301, violation=0, comm_penalty=0.0000, reward=-0.6301
  RL policy loss: 0.085995
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9736
  Client 1 model accuracy on test set: 0.9721
  Client 2 model accuracy on test set: 0.9698
  Client 3 model accuracy on test set: 0.9764
  Client 4 model accuracy on test set: 0.8681
  Client 5 model accuracy on test set: 0.8677
  Client 6 model accuracy on test set: 0.9586
  Client 7 model accuracy on test set: 0.9759
  Client 8 model accuracy on test set: 0.9695
  Client 9 model accuracy on test set: 0.9735

=== Global Round 8/100 ===
  Client 0: layers_shared=6, local_acc=1.0000
  Client 1: layers_shared=2, local_acc=1.0000
  Client 2: layers_shared=5, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=5, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=3.03, base_reward=-0.5140, violation=3, comm_penalty=0.3000, reward=-0.8140
  Client 1: mean_dist=1.72, base_reward=0.1409, violation=0, comm_penalty=0.0000, reward=0.1409
  Client 2: mean_dist=3.09, base_reward=-0.5454, violation=4, comm_penalty=0.4000, reward=-0.9454
  Client 3: mean_dist=2.45, base_reward=-0.2235, violation=1, comm_penalty=0.1000, reward=-0.3235
  Client 4: mean_dist=2.97, base_reward=-0.4873, violation=1, comm_penalty=0.1000, reward=-0.5873
  Client 5: mean_dist=2.92, base_reward=-0.4579, violation=0, comm_penalty=0.0000, reward=-0.4579
  Client 6: mean_dist=2.31, base_reward=-0.1544, violation=2, comm_penalty=0.2000, reward=-0.3544
  Client 7: mean_dist=2.44, base_reward=-0.2215, violation=0, comm_penalty=0.0000, reward=-0.2215
  Client 8: mean_dist=0.47, base_reward=0.7651, violation=0, comm_penalty=0.0000, reward=0.7651
  Client 9: mean_dist=2.36, base_reward=-0.1806, violation=0, comm_penalty=0.0000, reward=-0.1806
  RL policy loss: 0.053134
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9744
  Client 1 model accuracy on test set: 0.9729
  Client 2 model accuracy on test set: 0.9700
  Client 3 model accuracy on test set: 0.9781
  Client 4 model accuracy on test set: 0.9266
  Client 5 model accuracy on test set: 0.8766
  Client 6 model accuracy on test set: 0.9590
  Client 7 model accuracy on test set: 0.9763
  Client 8 model accuracy on test set: 0.9719
  Client 9 model accuracy on test set: 0.9753

=== Global Round 9/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=5, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=4, local_acc=0.9998
  Client 4: layers_shared=6, local_acc=1.0000
  Client 5: layers_shared=6, local_acc=1.0000
  Client 6: layers_shared=6, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=2, local_acc=1.0000
  Client 9: layers_shared=4, local_acc=1.0000
  Client 0: mean_dist=0.44, base_reward=0.7802, violation=0, comm_penalty=0.0000, reward=0.7802
  Client 1: mean_dist=3.43, base_reward=-0.7157, violation=0, comm_penalty=0.0000, reward=-0.7157
  Client 2: mean_dist=2.47, base_reward=-0.2327, violation=2, comm_penalty=0.2000, reward=-0.4327
  Client 3: mean_dist=3.04, base_reward=-0.5184, violation=2, comm_penalty=0.2000, reward=-0.7184
  Client 4: mean_dist=3.28, base_reward=-0.6411, violation=2, comm_penalty=0.2000, reward=-0.8411
  Client 5: mean_dist=3.20, base_reward=-0.5988, violation=0, comm_penalty=0.0000, reward=-0.5988
  Client 6: mean_dist=3.24, base_reward=-0.6205, violation=5, comm_penalty=0.5000, reward=-1.1205
  Client 7: mean_dist=2.46, base_reward=-0.2313, violation=0, comm_penalty=0.0000, reward=-0.2313
  Client 8: mean_dist=1.78, base_reward=0.1122, violation=0, comm_penalty=0.0000, reward=0.1122
  Client 9: mean_dist=2.92, base_reward=-0.4604, violation=0, comm_penalty=0.0000, reward=-0.4604
  RL policy loss: 0.041769
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9734
  Client 1 model accuracy on test set: 0.9717
  Client 2 model accuracy on test set: 0.9691
  Client 3 model accuracy on test set: 0.9790
  Client 4 model accuracy on test set: 0.9359
  Client 5 model accuracy on test set: 0.8752
  Client 6 model accuracy on test set: 0.9553
  Client 7 model accuracy on test set: 0.9754
  Client 8 model accuracy on test set: 0.9727
  Client 9 model accuracy on test set: 0.9756

=== Global Round 10/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=4, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=4, local_acc=1.0000
  Client 4: layers_shared=4, local_acc=1.0000
  Client 5: layers_shared=5, local_acc=1.0000
  Client 6: layers_shared=5, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=6, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=3.27, base_reward=-0.6328, violation=2, comm_penalty=0.2000, reward=-0.8328
  Client 1: mean_dist=3.08, base_reward=-0.5403, violation=0, comm_penalty=0.0000, reward=-0.5403
  Client 2: mean_dist=2.32, base_reward=-0.1608, violation=2, comm_penalty=0.2000, reward=-0.3608
  Client 3: mean_dist=3.00, base_reward=-0.4977, violation=2, comm_penalty=0.2000, reward=-0.6977
  Client 4: mean_dist=2.87, base_reward=-0.4352, violation=0, comm_penalty=0.0000, reward=-0.4352
  Client 5: mean_dist=3.11, base_reward=-0.5557, violation=0, comm_penalty=0.0000, reward=-0.5557
  Client 6: mean_dist=3.16, base_reward=-0.5782, violation=4, comm_penalty=0.4000, reward=-0.9782
  Client 7: mean_dist=0.45, base_reward=0.7746, violation=0, comm_penalty=0.0000, reward=0.7746
  Client 8: mean_dist=3.39, base_reward=-0.6943, violation=4, comm_penalty=0.4000, reward=-1.0943
  Client 9: mean_dist=0.45, base_reward=0.7743, violation=0, comm_penalty=0.0000, reward=0.7743
  RL policy loss: -0.000152
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9731
  Client 1 model accuracy on test set: 0.9733
  Client 2 model accuracy on test set: 0.9704
  Client 3 model accuracy on test set: 0.9781
  Client 4 model accuracy on test set: 0.9350
  Client 5 model accuracy on test set: 0.8774
  Client 6 model accuracy on test set: 0.9588
  Client 7 model accuracy on test set: 0.9775
  Client 8 model accuracy on test set: 0.9707
  Client 9 model accuracy on test set: 0.9755

=== Global Round 11/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=2, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=0.8807
  Client 4: layers_shared=2, local_acc=1.0000
  Client 5: layers_shared=4, local_acc=1.0000
  Client 6: layers_shared=2, local_acc=1.0000
  Client 7: layers_shared=5, local_acc=1.0000
  Client 8: layers_shared=5, local_acc=1.0000
  Client 9: layers_shared=4, local_acc=1.0000
  Client 0: mean_dist=2.88, base_reward=-0.4379, violation=2, comm_penalty=0.2000, reward=-0.6379
  Client 1: mean_dist=1.73, base_reward=0.1350, violation=0, comm_penalty=0.0000, reward=0.1350
  Client 2: mean_dist=0.44, base_reward=0.7796, violation=0, comm_penalty=0.0000, reward=0.7796
  Client 3: mean_dist=2.25, base_reward=-0.2437, violation=1, comm_penalty=0.1000, reward=-0.3437
  Client 4: mean_dist=1.63, base_reward=0.1850, violation=0, comm_penalty=0.0000, reward=0.1850
  Client 5: mean_dist=2.55, base_reward=-0.2750, violation=0, comm_penalty=0.0000, reward=-0.2750
  Client 6: mean_dist=1.61, base_reward=0.1965, violation=1, comm_penalty=0.1000, reward=0.0965
  Client 7: mean_dist=2.96, base_reward=-0.4797, violation=0, comm_penalty=0.0000, reward=-0.4797
  Client 8: mean_dist=3.01, base_reward=-0.5065, violation=3, comm_penalty=0.3000, reward=-0.8065
  Client 9: mean_dist=2.62, base_reward=-0.3105, violation=0, comm_penalty=0.0000, reward=-0.3105
  RL policy loss: 0.080969
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9738
  Client 1 model accuracy on test set: 0.9736
  Client 2 model accuracy on test set: 0.9701
  Client 3 model accuracy on test set: 0.8614
  Client 4 model accuracy on test set: 0.9290
  Client 5 model accuracy on test set: 0.8827
  Client 6 model accuracy on test set: 0.9572
  Client 7 model accuracy on test set: 0.9770
  Client 8 model accuracy on test set: 0.9726
  Client 9 model accuracy on test set: 0.9757

=== Global Round 12/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=6, local_acc=1.0000
  Client 2: layers_shared=5, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=0.7708
  Client 5: layers_shared=5, local_acc=1.0000
  Client 6: layers_shared=6, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=4, local_acc=1.0000
  Client 9: layers_shared=6, local_acc=1.0000
  Client 0: mean_dist=3.74, base_reward=-0.8675, violation=2, comm_penalty=0.2000, reward=-1.0675
  Client 1: mean_dist=3.97, base_reward=-0.9855, violation=1, comm_penalty=0.1000, reward=-1.0855
  Client 2: mean_dist=3.81, base_reward=-0.9059, violation=4, comm_penalty=0.4000, reward=-1.3059
  Client 3: mean_dist=2.58, base_reward=-0.2911, violation=1, comm_penalty=0.1000, reward=-0.3911
  Client 4: mean_dist=2.49, base_reward=-0.4724, violation=0, comm_penalty=0.0000, reward=-0.4724
  Client 5: mean_dist=3.59, base_reward=-0.7975, violation=0, comm_penalty=0.0000, reward=-0.7975
  Client 6: mean_dist=3.67, base_reward=-0.8349, violation=5, comm_penalty=0.5000, reward=-1.3349
  Client 7: mean_dist=0.45, base_reward=0.7738, violation=0, comm_penalty=0.0000, reward=0.7738
  Client 8: mean_dist=3.36, base_reward=-0.6777, violation=2, comm_penalty=0.2000, reward=-0.8777
  Client 9: mean_dist=3.68, base_reward=-0.8422, violation=1, comm_penalty=0.1000, reward=-0.9422
  RL policy loss: -0.023310
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9731
  Client 1 model accuracy on test set: 0.9750
  Client 2 model accuracy on test set: 0.9703
  Client 3 model accuracy on test set: 0.9757
  Client 4 model accuracy on test set: 0.6737
  Client 5 model accuracy on test set: 0.8788
  Client 6 model accuracy on test set: 0.9580
  Client 7 model accuracy on test set: 0.9789
  Client 8 model accuracy on test set: 0.9700
  Client 9 model accuracy on test set: 0.9753

=== Global Round 13/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=6, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=6, local_acc=1.0000
  Client 7: layers_shared=2, local_acc=1.0000
  Client 8: layers_shared=5, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=0.44, base_reward=0.7797, violation=0, comm_penalty=0.0000, reward=0.7797
  Client 1: mean_dist=1.99, base_reward=0.0070, violation=0, comm_penalty=0.0000, reward=0.0070
  Client 2: mean_dist=2.66, base_reward=-0.3315, violation=5, comm_penalty=0.5000, reward=-0.8315
  Client 3: mean_dist=0.45, base_reward=0.7772, violation=0, comm_penalty=0.0000, reward=0.7772
  Client 4: mean_dist=2.60, base_reward=-0.2977, violation=1, comm_penalty=0.1000, reward=-0.3977
  Client 5: mean_dist=1.83, base_reward=0.0860, violation=0, comm_penalty=0.0000, reward=0.0860
  Client 6: mean_dist=2.53, base_reward=-0.2635, violation=5, comm_penalty=0.5000, reward=-0.7635
  Client 7: mean_dist=1.39, base_reward=0.3045, violation=0, comm_penalty=0.0000, reward=0.3045
  Client 8: mean_dist=2.69, base_reward=-0.3436, violation=3, comm_penalty=0.3000, reward=-0.6436
  Client 9: mean_dist=0.45, base_reward=0.7727, violation=0, comm_penalty=0.0000, reward=0.7727
  RL policy loss: 0.020912
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9741
  Client 1 model accuracy on test set: 0.9732
  Client 2 model accuracy on test set: 0.9700
  Client 3 model accuracy on test set: 0.9772
  Client 4 model accuracy on test set: 0.9468
  Client 5 model accuracy on test set: 0.8887
  Client 6 model accuracy on test set: 0.9572
  Client 7 model accuracy on test set: 0.9777
  Client 8 model accuracy on test set: 0.9734
  Client 9 model accuracy on test set: 0.9755

=== Global Round 14/100 ===
  Client 0: layers_shared=6, local_acc=1.0000
  Client 1: layers_shared=6, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=0.9998
  Client 5: layers_shared=5, local_acc=0.5376
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=5, local_acc=1.0000
  Client 8: layers_shared=2, local_acc=1.0000
  Client 9: layers_shared=2, local_acc=1.0000
  Client 0: mean_dist=2.99, base_reward=-0.4975, violation=3, comm_penalty=0.3000, reward=-0.7975
  Client 1: mean_dist=3.12, base_reward=-0.5588, violation=1, comm_penalty=0.1000, reward=-0.6588
  Client 2: mean_dist=0.44, base_reward=0.7792, violation=0, comm_penalty=0.0000, reward=0.7792
  Client 3: mean_dist=2.10, base_reward=-0.0516, violation=1, comm_penalty=0.1000, reward=-0.1516
  Client 4: mean_dist=2.97, base_reward=-0.4838, violation=1, comm_penalty=0.1000, reward=-0.5838
  Client 5: mean_dist=2.92, base_reward=-0.9204, violation=0, comm_penalty=0.0000, reward=-0.9204
  Client 6: mean_dist=0.42, base_reward=0.7894, violation=0, comm_penalty=0.0000, reward=0.7894
  Client 7: mean_dist=3.08, base_reward=-0.5394, violation=0, comm_penalty=0.0000, reward=-0.5394
  Client 8: mean_dist=1.63, base_reward=0.1872, violation=0, comm_penalty=0.0000, reward=0.1872
  Client 9: mean_dist=1.53, base_reward=0.2332, violation=0, comm_penalty=0.0000, reward=0.2332
  RL policy loss: 0.068616
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9742
  Client 1 model accuracy on test set: 0.9745
  Client 2 model accuracy on test set: 0.9710
  Client 3 model accuracy on test set: 0.9773
  Client 4 model accuracy on test set: 0.9336
  Client 5 model accuracy on test set: 0.4470
  Client 6 model accuracy on test set: 0.9607
  Client 7 model accuracy on test set: 0.9763
  Client 8 model accuracy on test set: 0.9723
  Client 9 model accuracy on test set: 0.9762

=== Global Round 15/100 ===
  Client 0: layers_shared=6, local_acc=1.0000
  Client 1: layers_shared=5, local_acc=1.0000
  Client 2: layers_shared=4, local_acc=1.0000
  Client 3: layers_shared=5, local_acc=1.0000
  Client 4: layers_shared=4, local_acc=1.0000
  Client 5: layers_shared=6, local_acc=1.0000
  Client 6: layers_shared=5, local_acc=1.0000
  Client 7: layers_shared=5, local_acc=1.0000
  Client 8: layers_shared=5, local_acc=1.0000
  Client 9: layers_shared=2, local_acc=1.0000
  Client 0: mean_dist=4.32, base_reward=-1.1604, violation=3, comm_penalty=0.3000, reward=-1.4604
  Client 1: mean_dist=4.50, base_reward=-1.2477, violation=0, comm_penalty=0.0000, reward=-1.2477
  Client 2: mean_dist=3.71, base_reward=-0.8572, violation=3, comm_penalty=0.3000, reward=-1.1572
  Client 3: mean_dist=4.39, base_reward=-1.1933, violation=3, comm_penalty=0.3000, reward=-1.4933
  Client 4: mean_dist=3.64, base_reward=-0.8214, violation=0, comm_penalty=0.0000, reward=-0.8214
  Client 5: mean_dist=4.20, base_reward=-1.0980, violation=0, comm_penalty=0.0000, reward=-1.0980
  Client 6: mean_dist=4.17, base_reward=-1.0870, violation=4, comm_penalty=0.4000, reward=-1.4870
  Client 7: mean_dist=4.45, base_reward=-1.2232, violation=0, comm_penalty=0.0000, reward=-1.2232
  Client 8: mean_dist=4.48, base_reward=-1.2409, violation=3, comm_penalty=0.3000, reward=-1.5409
  Client 9: mean_dist=1.83, base_reward=0.0835, violation=0, comm_penalty=0.0000, reward=0.0835
  RL policy loss: 0.103529
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9740
  Client 1 model accuracy on test set: 0.9740
  Client 2 model accuracy on test set: 0.9709
  Client 3 model accuracy on test set: 0.9786
  Client 4 model accuracy on test set: 0.9422
  Client 5 model accuracy on test set: 0.8863
  Client 6 model accuracy on test set: 0.9575
  Client 7 model accuracy on test set: 0.9774
  Client 8 model accuracy on test set: 0.9726
  Client 9 model accuracy on test set: 0.9749

=== Global Round 16/100 ===
  Client 0: layers_shared=6, local_acc=1.0000
  Client 1: layers_shared=5, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=5, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=4, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=5, local_acc=1.0000
  Client 9: layers_shared=4, local_acc=1.0000
  Client 0: mean_dist=3.56, base_reward=-0.7820, violation=3, comm_penalty=0.3000, reward=-1.0820
  Client 1: mean_dist=3.74, base_reward=-0.8689, violation=0, comm_penalty=0.0000, reward=-0.8689
  Client 2: mean_dist=1.73, base_reward=0.1355, violation=1, comm_penalty=0.1000, reward=0.0355
  Client 3: mean_dist=3.64, base_reward=-0.8177, violation=3, comm_penalty=0.3000, reward=-1.1177
  Client 4: mean_dist=3.58, base_reward=-0.7896, violation=1, comm_penalty=0.1000, reward=-0.8896
  Client 5: mean_dist=3.02, base_reward=-0.5117, violation=0, comm_penalty=0.0000, reward=-0.5117
  Client 6: mean_dist=0.42, base_reward=0.7897, violation=0, comm_penalty=0.0000, reward=0.7897
  Client 7: mean_dist=2.50, base_reward=-0.2520, violation=0, comm_penalty=0.0000, reward=-0.2520
  Client 8: mean_dist=3.76, base_reward=-0.8806, violation=3, comm_penalty=0.3000, reward=-1.1806
  Client 9: mean_dist=3.09, base_reward=-0.5470, violation=0, comm_penalty=0.0000, reward=-0.5470
  RL policy loss: 0.035141
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9744
  Client 1 model accuracy on test set: 0.9737
  Client 2 model accuracy on test set: 0.9702
  Client 3 model accuracy on test set: 0.9776
  Client 4 model accuracy on test set: 0.9414
  Client 5 model accuracy on test set: 0.8867
  Client 6 model accuracy on test set: 0.9576
  Client 7 model accuracy on test set: 0.9775
  Client 8 model accuracy on test set: 0.9720
  Client 9 model accuracy on test set: 0.9768

=== Global Round 17/100 ===
  Client 0: layers_shared=4, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=0.9953
  Client 4: layers_shared=1, local_acc=0.8481
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=6, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=5, local_acc=1.0000
  Client 9: layers_shared=2, local_acc=1.0000
  Client 0: mean_dist=2.14, base_reward=-0.0688, violation=1, comm_penalty=0.1000, reward=-0.1688
  Client 1: mean_dist=0.49, base_reward=0.7555, violation=0, comm_penalty=0.0000, reward=0.7555
  Client 2: mean_dist=0.44, base_reward=0.7785, violation=0, comm_penalty=0.0000, reward=0.7785
  Client 3: mean_dist=1.95, base_reward=0.0193, violation=1, comm_penalty=0.1000, reward=-0.0807
  Client 4: mean_dist=0.43, base_reward=0.6349, violation=0, comm_penalty=0.0000, reward=0.6349
  Client 5: mean_dist=1.84, base_reward=0.0797, violation=0, comm_penalty=0.0000, reward=0.0797
  Client 6: mean_dist=2.17, base_reward=-0.0850, violation=5, comm_penalty=0.5000, reward=-0.5850
  Client 7: mean_dist=1.96, base_reward=0.0188, violation=0, comm_penalty=0.0000, reward=0.0188
  Client 8: mean_dist=2.34, base_reward=-0.1720, violation=3, comm_penalty=0.3000, reward=-0.4720
  Client 9: mean_dist=1.38, base_reward=0.3121, violation=0, comm_penalty=0.0000, reward=0.3121
  RL policy loss: 0.003228
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9745
  Client 1 model accuracy on test set: 0.9734
  Client 2 model accuracy on test set: 0.9714
  Client 3 model accuracy on test set: 0.9648
  Client 4 model accuracy on test set: 0.7052
  Client 5 model accuracy on test set: 0.8832
  Client 6 model accuracy on test set: 0.9571
  Client 7 model accuracy on test set: 0.9775
  Client 8 model accuracy on test set: 0.9728
  Client 9 model accuracy on test set: 0.9759

=== Global Round 18/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=2, local_acc=1.0000
  Client 2: layers_shared=6, local_acc=1.0000
  Client 3: layers_shared=5, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=0.9998
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=5, local_acc=1.0000
  Client 7: layers_shared=5, local_acc=1.0000
  Client 8: layers_shared=4, local_acc=1.0000
  Client 9: layers_shared=6, local_acc=1.0000
  Client 0: mean_dist=4.15, base_reward=-1.0761, violation=2, comm_penalty=0.2000, reward=-1.2761
  Client 1: mean_dist=1.91, base_reward=0.0469, violation=0, comm_penalty=0.0000, reward=0.0469
  Client 2: mean_dist=4.27, base_reward=-1.1346, violation=5, comm_penalty=0.5000, reward=-1.6346
  Client 3: mean_dist=4.27, base_reward=-1.1333, violation=3, comm_penalty=0.3000, reward=-1.4333
  Client 4: mean_dist=4.26, base_reward=-1.1295, violation=1, comm_penalty=0.1000, reward=-1.2295
  Client 5: mean_dist=2.60, base_reward=-0.2992, violation=0, comm_penalty=0.0000, reward=-0.2992
  Client 6: mean_dist=4.08, base_reward=-1.0380, violation=4, comm_penalty=0.4000, reward=-1.4380
  Client 7: mean_dist=4.32, base_reward=-1.1591, violation=0, comm_penalty=0.0000, reward=-1.1591
  Client 8: mean_dist=3.69, base_reward=-0.8449, violation=2, comm_penalty=0.2000, reward=-1.0449
  Client 9: mean_dist=4.11, base_reward=-1.0558, violation=1, comm_penalty=0.1000, reward=-1.1558
  RL policy loss: 0.053388
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9745
  Client 1 model accuracy on test set: 0.9743
  Client 2 model accuracy on test set: 0.9714
  Client 3 model accuracy on test set: 0.9783
  Client 4 model accuracy on test set: 0.9161
  Client 5 model accuracy on test set: 0.8843
  Client 6 model accuracy on test set: 0.9595
  Client 7 model accuracy on test set: 0.9773
  Client 8 model accuracy on test set: 0.9720
  Client 9 model accuracy on test set: 0.9754

=== Global Round 19/100 ===
  Client 0: layers_shared=4, local_acc=1.0000
  Client 1: layers_shared=5, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=0.9710
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=2, local_acc=1.0000
  Client 8: layers_shared=2, local_acc=1.0000
  Client 9: layers_shared=4, local_acc=1.0000
  Client 0: mean_dist=1.79, base_reward=0.1066, violation=1, comm_penalty=0.1000, reward=0.0066
  Client 1: mean_dist=1.85, base_reward=0.0753, violation=0, comm_penalty=0.0000, reward=0.0753
  Client 2: mean_dist=0.44, base_reward=0.7786, violation=0, comm_penalty=0.0000, reward=0.7786
  Client 3: mean_dist=0.45, base_reward=0.7764, violation=0, comm_penalty=0.0000, reward=0.7764
  Client 4: mean_dist=1.57, base_reward=0.1881, violation=0, comm_penalty=0.0000, reward=0.1881
  Client 5: mean_dist=0.44, base_reward=0.7817, violation=0, comm_penalty=0.0000, reward=0.7817
  Client 6: mean_dist=0.42, base_reward=0.7887, violation=0, comm_penalty=0.0000, reward=0.7887
  Client 7: mean_dist=1.26, base_reward=0.3711, violation=0, comm_penalty=0.0000, reward=0.3711
  Client 8: mean_dist=1.31, base_reward=0.3451, violation=0, comm_penalty=0.0000, reward=0.3451
  Client 9: mean_dist=1.79, base_reward=0.1067, violation=0, comm_penalty=0.0000, reward=0.1067
  RL policy loss: -0.028802
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9739
  Client 1 model accuracy on test set: 0.9743
  Client 2 model accuracy on test set: 0.9708
  Client 3 model accuracy on test set: 0.9782
  Client 4 model accuracy on test set: 0.8579
  Client 5 model accuracy on test set: 0.8845
  Client 6 model accuracy on test set: 0.9595
  Client 7 model accuracy on test set: 0.9767
  Client 8 model accuracy on test set: 0.9722
  Client 9 model accuracy on test set: 0.9751

=== Global Round 20/100 ===
  Client 0: layers_shared=4, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=6, local_acc=1.0000
  Client 3: layers_shared=6, local_acc=1.0000
  Client 4: layers_shared=2, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=4, local_acc=1.0000
  Client 8: layers_shared=5, local_acc=1.0000
  Client 9: layers_shared=5, local_acc=1.0000
  Client 0: mean_dist=2.77, base_reward=-0.3838, violation=1, comm_penalty=0.1000, reward=-0.4838
  Client 1: mean_dist=0.49, base_reward=0.7555, violation=0, comm_penalty=0.0000, reward=0.7555
  Client 2: mean_dist=3.17, base_reward=-0.5851, violation=5, comm_penalty=0.5000, reward=-1.0851
  Client 3: mean_dist=3.20, base_reward=-0.5975, violation=4, comm_penalty=0.4000, reward=-0.9975
  Client 4: mean_dist=1.56, base_reward=0.2206, violation=0, comm_penalty=0.0000, reward=0.2206
  Client 5: mean_dist=2.11, base_reward=-0.0563, violation=0, comm_penalty=0.0000, reward=-0.0563
  Client 6: mean_dist=0.42, base_reward=0.7886, violation=0, comm_penalty=0.0000, reward=0.7886
  Client 7: mean_dist=2.86, base_reward=-0.4323, violation=0, comm_penalty=0.0000, reward=-0.4323
  Client 8: mean_dist=3.24, base_reward=-0.6177, violation=3, comm_penalty=0.3000, reward=-0.9177
  Client 9: mean_dist=3.04, base_reward=-0.5224, violation=0, comm_penalty=0.0000, reward=-0.5224
  RL policy loss: -0.007812
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9748
  Client 1 model accuracy on test set: 0.9734
  Client 2 model accuracy on test set: 0.9712
  Client 3 model accuracy on test set: 0.9793
  Client 4 model accuracy on test set: 0.9250
  Client 5 model accuracy on test set: 0.8845
  Client 6 model accuracy on test set: 0.9575
  Client 7 model accuracy on test set: 0.9781
  Client 8 model accuracy on test set: 0.9727
  Client 9 model accuracy on test set: 0.9750

=== Global Round 21/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=0.9998
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=4, local_acc=1.0000
  Client 7: layers_shared=4, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=5, local_acc=1.0000
  Client 0: mean_dist=0.44, base_reward=0.7789, violation=0, comm_penalty=0.0000, reward=0.7789
  Client 1: mean_dist=2.37, base_reward=-0.1864, violation=0, comm_penalty=0.0000, reward=-0.1864
  Client 2: mean_dist=0.44, base_reward=0.7785, violation=0, comm_penalty=0.0000, reward=0.7785
  Client 3: mean_dist=2.35, base_reward=-0.1750, violation=1, comm_penalty=0.1000, reward=-0.2750
  Client 4: mean_dist=2.80, base_reward=-0.3985, violation=1, comm_penalty=0.1000, reward=-0.4985
  Client 5: mean_dist=2.21, base_reward=-0.1028, violation=0, comm_penalty=0.0000, reward=-0.1028
  Client 6: mean_dist=2.56, base_reward=-0.2777, violation=3, comm_penalty=0.3000, reward=-0.5777
  Client 7: mean_dist=2.72, base_reward=-0.3576, violation=0, comm_penalty=0.0000, reward=-0.3576
  Client 8: mean_dist=2.42, base_reward=-0.2079, violation=1, comm_penalty=0.1000, reward=-0.3079
  Client 9: mean_dist=2.73, base_reward=-0.3637, violation=0, comm_penalty=0.0000, reward=-0.3637
  RL policy loss: -0.022997
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9750
  Client 1 model accuracy on test set: 0.9748
  Client 2 model accuracy on test set: 0.9705
  Client 3 model accuracy on test set: 0.9784
  Client 4 model accuracy on test set: 0.9361
  Client 5 model accuracy on test set: 0.8883
  Client 6 model accuracy on test set: 0.9601
  Client 7 model accuracy on test set: 0.9775
  Client 8 model accuracy on test set: 0.9734
  Client 9 model accuracy on test set: 0.9747

=== Global Round 22/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=5, local_acc=1.0000
  Client 4: layers_shared=4, local_acc=1.0000
  Client 5: layers_shared=6, local_acc=1.0000
  Client 6: layers_shared=4, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=2, local_acc=1.0000
  Client 9: layers_shared=2, local_acc=1.0000
  Client 0: mean_dist=0.44, base_reward=0.7787, violation=0, comm_penalty=0.0000, reward=0.7787
  Client 1: mean_dist=0.49, base_reward=0.7552, violation=0, comm_penalty=0.0000, reward=0.7552
  Client 2: mean_dist=1.58, base_reward=0.2122, violation=1, comm_penalty=0.1000, reward=0.1122
  Client 3: mean_dist=2.49, base_reward=-0.2450, violation=3, comm_penalty=0.3000, reward=-0.5450
  Client 4: mean_dist=2.35, base_reward=-0.1755, violation=0, comm_penalty=0.0000, reward=-0.1755
  Client 5: mean_dist=2.34, base_reward=-0.1709, violation=0, comm_penalty=0.0000, reward=-0.1709
  Client 6: mean_dist=2.25, base_reward=-0.1242, violation=3, comm_penalty=0.3000, reward=-0.4242
  Client 7: mean_dist=2.01, base_reward=-0.0056, violation=0, comm_penalty=0.0000, reward=-0.0056
  Client 8: mean_dist=1.63, base_reward=0.1874, violation=0, comm_penalty=0.0000, reward=0.1874
  Client 9: mean_dist=1.54, base_reward=0.2293, violation=0, comm_penalty=0.0000, reward=0.2293
  RL policy loss: -0.023550
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9753
  Client 1 model accuracy on test set: 0.9743
  Client 2 model accuracy on test set: 0.9704
  Client 3 model accuracy on test set: 0.9787
  Client 4 model accuracy on test set: 0.9365
  Client 5 model accuracy on test set: 0.8854
  Client 6 model accuracy on test set: 0.9590
  Client 7 model accuracy on test set: 0.9776
  Client 8 model accuracy on test set: 0.9734
  Client 9 model accuracy on test set: 0.9760

=== Global Round 23/100 ===
  Client 0: layers_shared=4, local_acc=1.0000
  Client 1: layers_shared=5, local_acc=1.0000
  Client 2: layers_shared=6, local_acc=1.0000
  Client 3: layers_shared=6, local_acc=1.0000
  Client 4: layers_shared=6, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=4, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=4, local_acc=1.0000
  Client 9: layers_shared=2, local_acc=1.0000
  Client 0: mean_dist=3.15, base_reward=-0.5741, violation=1, comm_penalty=0.1000, reward=-0.6741
  Client 1: mean_dist=3.66, base_reward=-0.8284, violation=0, comm_penalty=0.0000, reward=-0.8284
  Client 2: mean_dist=3.65, base_reward=-0.8250, violation=5, comm_penalty=0.5000, reward=-1.3250
  Client 3: mean_dist=3.62, base_reward=-0.8083, violation=4, comm_penalty=0.4000, reward=-1.2083
  Client 4: mean_dist=3.62, base_reward=-0.8113, violation=2, comm_penalty=0.2000, reward=-1.0113
  Client 5: mean_dist=2.36, base_reward=-0.1787, violation=0, comm_penalty=0.0000, reward=-0.1787
  Client 6: mean_dist=3.08, base_reward=-0.5387, violation=3, comm_penalty=0.3000, reward=-0.8387
  Client 7: mean_dist=0.45, base_reward=0.7729, violation=0, comm_penalty=0.0000, reward=0.7729
  Client 8: mean_dist=3.32, base_reward=-0.6601, violation=2, comm_penalty=0.2000, reward=-0.8601
  Client 9: mean_dist=1.68, base_reward=0.1578, violation=0, comm_penalty=0.0000, reward=0.1578
  RL policy loss: -0.017356
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9744
  Client 1 model accuracy on test set: 0.9740
  Client 2 model accuracy on test set: 0.9702
  Client 3 model accuracy on test set: 0.9775
  Client 4 model accuracy on test set: 0.9435
  Client 5 model accuracy on test set: 0.8901
  Client 6 model accuracy on test set: 0.9592
  Client 7 model accuracy on test set: 0.9774
  Client 8 model accuracy on test set: 0.9726
  Client 9 model accuracy on test set: 0.9755

=== Global Round 24/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=5, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=6, local_acc=1.0000
  Client 4: layers_shared=4, local_acc=1.0000
  Client 5: layers_shared=2, local_acc=1.0000
  Client 6: layers_shared=4, local_acc=1.0000
  Client 7: layers_shared=6, local_acc=1.0000
  Client 8: layers_shared=4, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=2.34, base_reward=-0.1725, violation=0, comm_penalty=0.0000, reward=-0.1725
  Client 1: mean_dist=3.32, base_reward=-0.6585, violation=0, comm_penalty=0.0000, reward=-0.6585
  Client 2: mean_dist=1.74, base_reward=0.1292, violation=1, comm_penalty=0.1000, reward=0.0292
  Client 3: mean_dist=3.30, base_reward=-0.6499, violation=4, comm_penalty=0.4000, reward=-1.0499
  Client 4: mean_dist=3.02, base_reward=-0.5080, violation=0, comm_penalty=0.0000, reward=-0.5080
  Client 5: mean_dist=1.65, base_reward=0.1770, violation=0, comm_penalty=0.0000, reward=0.1770
  Client 6: mean_dist=2.88, base_reward=-0.4394, violation=3, comm_penalty=0.3000, reward=-0.7394
  Client 7: mean_dist=3.31, base_reward=-0.6528, violation=0, comm_penalty=0.0000, reward=-0.6528
  Client 8: mean_dist=3.11, base_reward=-0.5551, violation=2, comm_penalty=0.2000, reward=-0.7551
  Client 9: mean_dist=0.46, base_reward=0.7717, violation=0, comm_penalty=0.0000, reward=0.7717
  RL policy loss: -0.001948
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9747
  Client 1 model accuracy on test set: 0.9744
  Client 2 model accuracy on test set: 0.9705
  Client 3 model accuracy on test set: 0.9795
  Client 4 model accuracy on test set: 0.9416
  Client 5 model accuracy on test set: 0.8900
  Client 6 model accuracy on test set: 0.9594
  Client 7 model accuracy on test set: 0.9768
  Client 8 model accuracy on test set: 0.9732
  Client 9 model accuracy on test set: 0.9755

=== Global Round 25/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=5, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=4, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=0.9703
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=5, local_acc=1.0000
  Client 7: layers_shared=2, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=5, local_acc=1.0000
  Client 0: mean_dist=0.44, base_reward=0.7783, violation=0, comm_penalty=0.0000, reward=0.7783
  Client 1: mean_dist=3.02, base_reward=-0.5123, violation=0, comm_penalty=0.0000, reward=-0.5123
  Client 2: mean_dist=1.74, base_reward=0.1297, violation=1, comm_penalty=0.1000, reward=0.0297
  Client 3: mean_dist=2.78, base_reward=-0.3890, violation=2, comm_penalty=0.2000, reward=-0.5890
  Client 4: mean_dist=2.40, base_reward=-0.2294, violation=0, comm_penalty=0.0000, reward=-0.2294
  Client 5: mean_dist=2.26, base_reward=-0.1294, violation=0, comm_penalty=0.0000, reward=-0.1294
  Client 6: mean_dist=2.83, base_reward=-0.4172, violation=4, comm_penalty=0.4000, reward=-0.8172
  Client 7: mean_dist=1.73, base_reward=0.1367, violation=0, comm_penalty=0.0000, reward=0.1367
  Client 8: mean_dist=2.47, base_reward=-0.2372, violation=1, comm_penalty=0.1000, reward=-0.3372
  Client 9: mean_dist=2.88, base_reward=-0.4407, violation=0, comm_penalty=0.0000, reward=-0.4407
  RL policy loss: 0.007130
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9736
  Client 1 model accuracy on test set: 0.9750
  Client 2 model accuracy on test set: 0.9712
  Client 3 model accuracy on test set: 0.9792
  Client 4 model accuracy on test set: 0.8756
  Client 5 model accuracy on test set: 0.8869
  Client 6 model accuracy on test set: 0.9598
  Client 7 model accuracy on test set: 0.9780
  Client 8 model accuracy on test set: 0.9735
  Client 9 model accuracy on test set: 0.9753

=== Global Round 26/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=4, local_acc=1.0000
  Client 2: layers_shared=5, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=2, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=6, local_acc=1.0000
  Client 8: layers_shared=5, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=0.44, base_reward=0.7784, violation=0, comm_penalty=0.0000, reward=0.7784
  Client 1: mean_dist=2.93, base_reward=-0.4666, violation=0, comm_penalty=0.0000, reward=-0.4666
  Client 2: mean_dist=3.12, base_reward=-0.5605, violation=4, comm_penalty=0.4000, reward=-0.9605
  Client 3: mean_dist=2.53, base_reward=-0.2633, violation=1, comm_penalty=0.1000, reward=-0.3633
  Client 4: mean_dist=1.73, base_reward=0.1333, violation=0, comm_penalty=0.0000, reward=0.1333
  Client 5: mean_dist=2.37, base_reward=-0.1842, violation=0, comm_penalty=0.0000, reward=-0.1842
  Client 6: mean_dist=2.37, base_reward=-0.1872, violation=2, comm_penalty=0.2000, reward=-0.3872
  Client 7: mean_dist=3.13, base_reward=-0.5656, violation=0, comm_penalty=0.0000, reward=-0.5656
  Client 8: mean_dist=3.21, base_reward=-0.6049, violation=3, comm_penalty=0.3000, reward=-0.9049
  Client 9: mean_dist=2.43, base_reward=-0.2139, violation=0, comm_penalty=0.0000, reward=-0.2139
  RL policy loss: -0.012825
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9732
  Client 1 model accuracy on test set: 0.9734
  Client 2 model accuracy on test set: 0.9710
  Client 3 model accuracy on test set: 0.9796
  Client 4 model accuracy on test set: 0.9418
  Client 5 model accuracy on test set: 0.8859
  Client 6 model accuracy on test set: 0.9597
  Client 7 model accuracy on test set: 0.9777
  Client 8 model accuracy on test set: 0.9729
  Client 9 model accuracy on test set: 0.9758

=== Global Round 27/100 ===
  Client 0: layers_shared=4, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=6, local_acc=0.8964
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=6, local_acc=1.0000
  Client 8: layers_shared=6, local_acc=1.0000
  Client 9: layers_shared=4, local_acc=1.0000
  Client 0: mean_dist=2.51, base_reward=-0.2557, violation=1, comm_penalty=0.1000, reward=-0.3557
  Client 1: mean_dist=2.11, base_reward=-0.0555, violation=0, comm_penalty=0.0000, reward=-0.0555
  Client 2: mean_dist=0.45, base_reward=0.7774, violation=0, comm_penalty=0.0000, reward=0.7774
  Client 3: mean_dist=2.87, base_reward=-0.5406, violation=4, comm_penalty=0.4000, reward=-0.9406
  Client 4: mean_dist=0.44, base_reward=0.7825, violation=0, comm_penalty=0.0000, reward=0.7825
  Client 5: mean_dist=0.44, base_reward=0.7813, violation=0, comm_penalty=0.0000, reward=0.7813
  Client 6: mean_dist=1.98, base_reward=0.0125, violation=2, comm_penalty=0.2000, reward=-0.1875
  Client 7: mean_dist=2.89, base_reward=-0.4442, violation=0, comm_penalty=0.0000, reward=-0.4442
  Client 8: mean_dist=2.94, base_reward=-0.4680, violation=4, comm_penalty=0.4000, reward=-0.8680
  Client 9: mean_dist=2.49, base_reward=-0.2441, violation=0, comm_penalty=0.0000, reward=-0.2441
  RL policy loss: -0.084313
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9746
  Client 1 model accuracy on test set: 0.9744
  Client 2 model accuracy on test set: 0.9712
  Client 3 model accuracy on test set: 0.8432
  Client 4 model accuracy on test set: 0.9433
  Client 5 model accuracy on test set: 0.8900
  Client 6 model accuracy on test set: 0.9606
  Client 7 model accuracy on test set: 0.9790
  Client 8 model accuracy on test set: 0.9725
  Client 9 model accuracy on test set: 0.9757

=== Global Round 28/100 ===
  Client 0: layers_shared=6, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=6, local_acc=1.0000
  Client 5: layers_shared=6, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=0.9993
  Client 7: layers_shared=5, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=4, local_acc=1.0000
  Client 0: mean_dist=3.18, base_reward=-0.5896, violation=3, comm_penalty=0.3000, reward=-0.8896
  Client 1: mean_dist=2.37, base_reward=-0.1850, violation=0, comm_penalty=0.0000, reward=-0.1850
  Client 2: mean_dist=0.44, base_reward=0.7775, violation=0, comm_penalty=0.0000, reward=0.7775
  Client 3: mean_dist=0.45, base_reward=0.7735, violation=0, comm_penalty=0.0000, reward=0.7735
  Client 4: mean_dist=3.22, base_reward=-0.6110, violation=2, comm_penalty=0.2000, reward=-0.8110
  Client 5: mean_dist=3.08, base_reward=-0.5411, violation=0, comm_penalty=0.0000, reward=-0.5411
  Client 6: mean_dist=2.21, base_reward=-0.1056, violation=2, comm_penalty=0.2000, reward=-0.3056
  Client 7: mean_dist=3.21, base_reward=-0.6044, violation=0, comm_penalty=0.0000, reward=-0.6044
  Client 8: mean_dist=2.42, base_reward=-0.2114, violation=1, comm_penalty=0.1000, reward=-0.3114
  Client 9: mean_dist=2.73, base_reward=-0.3647, violation=0, comm_penalty=0.0000, reward=-0.3647
  RL policy loss: -0.056084
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9747
  Client 1 model accuracy on test set: 0.9747
  Client 2 model accuracy on test set: 0.9724
  Client 3 model accuracy on test set: 0.9790
  Client 4 model accuracy on test set: 0.9462
  Client 5 model accuracy on test set: 0.8854
  Client 6 model accuracy on test set: 0.9152
  Client 7 model accuracy on test set: 0.9776
  Client 8 model accuracy on test set: 0.9727
  Client 9 model accuracy on test set: 0.9752

=== Global Round 29/100 ===
  Client 0: layers_shared=6, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=2, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=5, local_acc=1.0000
  Client 0: mean_dist=3.17, base_reward=-0.5842, violation=3, comm_penalty=0.3000, reward=-0.8842
  Client 1: mean_dist=2.81, base_reward=-0.4064, violation=0, comm_penalty=0.0000, reward=-0.4064
  Client 2: mean_dist=2.79, base_reward=-0.3929, violation=2, comm_penalty=0.2000, reward=-0.5929
  Client 3: mean_dist=2.82, base_reward=-0.4106, violation=1, comm_penalty=0.1000, reward=-0.5106
  Client 4: mean_dist=3.25, base_reward=-0.6275, violation=1, comm_penalty=0.1000, reward=-0.7275
  Client 5: mean_dist=2.62, base_reward=-0.3097, violation=0, comm_penalty=0.0000, reward=-0.3097
  Client 6: mean_dist=2.64, base_reward=-0.3189, violation=2, comm_penalty=0.2000, reward=-0.5189
  Client 7: mean_dist=1.89, base_reward=0.0547, violation=0, comm_penalty=0.0000, reward=0.0547
  Client 8: mean_dist=2.88, base_reward=-0.4393, violation=1, comm_penalty=0.1000, reward=-0.5393
  Client 9: mean_dist=3.15, base_reward=-0.5736, violation=0, comm_penalty=0.0000, reward=-0.5736
  RL policy loss: 0.021209
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9736
  Client 1 model accuracy on test set: 0.9744
  Client 2 model accuracy on test set: 0.9718
  Client 3 model accuracy on test set: 0.9770
  Client 4 model accuracy on test set: 0.9460
  Client 5 model accuracy on test set: 0.8879
  Client 6 model accuracy on test set: 0.9606
  Client 7 model accuracy on test set: 0.9779
  Client 8 model accuracy on test set: 0.9720
  Client 9 model accuracy on test set: 0.9762

=== Global Round 30/100 ===
  Client 0: layers_shared=4, local_acc=1.0000
  Client 1: layers_shared=2, local_acc=1.0000
  Client 2: layers_shared=5, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=0.9927
  Client 5: layers_shared=2, local_acc=1.0000
  Client 6: layers_shared=5, local_acc=1.0000
  Client 7: layers_shared=6, local_acc=1.0000
  Client 8: layers_shared=5, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=3.09, base_reward=-0.5453, violation=1, comm_penalty=0.1000, reward=-0.6453
  Client 1: mean_dist=1.92, base_reward=0.0417, violation=0, comm_penalty=0.0000, reward=0.0417
  Client 2: mean_dist=3.51, base_reward=-0.7561, violation=4, comm_penalty=0.4000, reward=-1.1561
  Client 3: mean_dist=2.72, base_reward=-0.3592, violation=1, comm_penalty=0.1000, reward=-0.4592
  Client 4: mean_dist=2.69, base_reward=-0.3530, violation=0, comm_penalty=0.0000, reward=-0.3530
  Client 5: mean_dist=1.80, base_reward=0.1016, violation=0, comm_penalty=0.0000, reward=0.1016
  Client 6: mean_dist=3.34, base_reward=-0.6706, violation=4, comm_penalty=0.4000, reward=-1.0706
  Client 7: mean_dist=3.53, base_reward=-0.7663, violation=0, comm_penalty=0.0000, reward=-0.7663
  Client 8: mean_dist=3.60, base_reward=-0.8015, violation=3, comm_penalty=0.3000, reward=-1.1015
  Client 9: mean_dist=2.60, base_reward=-0.2987, violation=0, comm_penalty=0.0000, reward=-0.2987
  RL policy loss: 0.031698
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9742
  Client 1 model accuracy on test set: 0.9751
  Client 2 model accuracy on test set: 0.9708
  Client 3 model accuracy on test set: 0.9780
  Client 4 model accuracy on test set: 0.8819
  Client 5 model accuracy on test set: 0.8905
  Client 6 model accuracy on test set: 0.9578
  Client 7 model accuracy on test set: 0.9776
  Client 8 model accuracy on test set: 0.9721
  Client 9 model accuracy on test set: 0.9770

=== Global Round 31/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=4, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=5, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=2, local_acc=1.0000
  Client 0: mean_dist=0.44, base_reward=0.7783, violation=0, comm_penalty=0.0000, reward=0.7783
  Client 1: mean_dist=2.28, base_reward=-0.1381, violation=0, comm_penalty=0.0000, reward=-0.1381
  Client 2: mean_dist=2.00, base_reward=-0.0012, violation=2, comm_penalty=0.2000, reward=-0.2012
  Client 3: mean_dist=2.02, base_reward=-0.0087, violation=1, comm_penalty=0.1000, reward=-0.1087
  Client 4: mean_dist=2.36, base_reward=-0.1820, violation=1, comm_penalty=0.1000, reward=-0.2820
  Client 5: mean_dist=0.44, base_reward=0.7813, violation=0, comm_penalty=0.0000, reward=0.7813
  Client 6: mean_dist=2.26, base_reward=-0.1293, violation=4, comm_penalty=0.4000, reward=-0.5293
  Client 7: mean_dist=0.46, base_reward=0.7719, violation=0, comm_penalty=0.0000, reward=0.7719
  Client 8: mean_dist=2.06, base_reward=-0.0283, violation=1, comm_penalty=0.1000, reward=-0.1283
  Client 9: mean_dist=1.39, base_reward=0.3029, violation=0, comm_penalty=0.0000, reward=0.3029
  RL policy loss: -0.044891
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9751
  Client 1 model accuracy on test set: 0.9746
  Client 2 model accuracy on test set: 0.9715
  Client 3 model accuracy on test set: 0.9793
  Client 4 model accuracy on test set: 0.9462
  Client 5 model accuracy on test set: 0.8868
  Client 6 model accuracy on test set: 0.9570
  Client 7 model accuracy on test set: 0.9776
  Client 8 model accuracy on test set: 0.9735
  Client 9 model accuracy on test set: 0.9764

=== Global Round 32/100 ===
  Client 0: layers_shared=2, local_acc=1.0000
  Client 1: layers_shared=5, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=6, local_acc=1.0000
  Client 7: layers_shared=4, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=1.84, base_reward=0.0776, violation=0, comm_penalty=0.0000, reward=0.0776
  Client 1: mean_dist=3.08, base_reward=-0.5386, violation=0, comm_penalty=0.0000, reward=-0.5386
  Client 2: mean_dist=1.90, base_reward=0.0488, violation=1, comm_penalty=0.1000, reward=-0.0512
  Client 3: mean_dist=2.72, base_reward=-0.3591, violation=1, comm_penalty=0.1000, reward=-0.4591
  Client 4: mean_dist=2.68, base_reward=-0.3419, violation=0, comm_penalty=0.0000, reward=-0.3419
  Client 5: mean_dist=2.52, base_reward=-0.2611, violation=0, comm_penalty=0.0000, reward=-0.2611
  Client 6: mean_dist=2.90, base_reward=-0.4478, violation=5, comm_penalty=0.5000, reward=-0.9478
  Client 7: mean_dist=2.93, base_reward=-0.4664, violation=0, comm_penalty=0.0000, reward=-0.4664
  Client 8: mean_dist=2.77, base_reward=-0.3836, violation=1, comm_penalty=0.1000, reward=-0.4836
  Client 9: mean_dist=2.59, base_reward=-0.2972, violation=0, comm_penalty=0.0000, reward=-0.2972
  RL policy loss: 0.022713
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9747
  Client 1 model accuracy on test set: 0.9742
  Client 2 model accuracy on test set: 0.9713
  Client 3 model accuracy on test set: 0.9794
  Client 4 model accuracy on test set: 0.9470
  Client 5 model accuracy on test set: 0.8876
  Client 6 model accuracy on test set: 0.9586
  Client 7 model accuracy on test set: 0.9770
  Client 8 model accuracy on test set: 0.9719
  Client 9 model accuracy on test set: 0.9765

=== Global Round 33/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=6, local_acc=1.0000
  Client 4: layers_shared=4, local_acc=1.0000
  Client 5: layers_shared=4, local_acc=1.0000
  Client 6: layers_shared=4, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=6, local_acc=1.0000
  Client 0: mean_dist=3.23, base_reward=-0.6164, violation=2, comm_penalty=0.2000, reward=-0.8164
  Client 1: mean_dist=2.53, base_reward=-0.2640, violation=0, comm_penalty=0.0000, reward=-0.2640
  Client 2: mean_dist=1.73, base_reward=0.1335, violation=1, comm_penalty=0.1000, reward=0.0335
  Client 3: mean_dist=3.38, base_reward=-0.6887, violation=4, comm_penalty=0.4000, reward=-1.0887
  Client 4: mean_dist=3.11, base_reward=-0.5539, violation=0, comm_penalty=0.0000, reward=-0.5539
  Client 5: mean_dist=2.93, base_reward=-0.4630, violation=0, comm_penalty=0.0000, reward=-0.4630
  Client 6: mean_dist=2.95, base_reward=-0.4742, violation=3, comm_penalty=0.3000, reward=-0.7742
  Client 7: mean_dist=2.50, base_reward=-0.2522, violation=0, comm_penalty=0.0000, reward=-0.2522
  Client 8: mean_dist=0.47, base_reward=0.7639, violation=0, comm_penalty=0.0000, reward=0.7639
  Client 9: mean_dist=3.24, base_reward=-0.6190, violation=1, comm_penalty=0.1000, reward=-0.7190
  RL policy loss: -0.045991
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9738
  Client 1 model accuracy on test set: 0.9734
  Client 2 model accuracy on test set: 0.9714
  Client 3 model accuracy on test set: 0.9788
  Client 4 model accuracy on test set: 0.9430
  Client 5 model accuracy on test set: 0.8861
  Client 6 model accuracy on test set: 0.9605
  Client 7 model accuracy on test set: 0.9774
  Client 8 model accuracy on test set: 0.9740
  Client 9 model accuracy on test set: 0.9767

=== Global Round 34/100 ===
  Client 0: layers_shared=4, local_acc=1.0000
  Client 1: layers_shared=5, local_acc=1.0000
  Client 2: layers_shared=5, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=6, local_acc=1.0000
  Client 7: layers_shared=4, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=2, local_acc=1.0000
  Client 0: mean_dist=3.08, base_reward=-0.5401, violation=1, comm_penalty=0.1000, reward=-0.6401
  Client 1: mean_dist=3.56, base_reward=-0.7824, violation=0, comm_penalty=0.0000, reward=-0.7824
  Client 2: mean_dist=3.52, base_reward=-0.7617, violation=4, comm_penalty=0.4000, reward=-1.1617
  Client 3: mean_dist=2.57, base_reward=-0.2839, violation=1, comm_penalty=0.1000, reward=-0.3839
  Client 4: mean_dist=3.54, base_reward=-0.7676, violation=1, comm_penalty=0.1000, reward=-0.8676
  Client 5: mean_dist=0.44, base_reward=0.7811, violation=0, comm_penalty=0.0000, reward=0.7811
  Client 6: mean_dist=3.36, base_reward=-0.6797, violation=5, comm_penalty=0.5000, reward=-1.1797
  Client 7: mean_dist=3.17, base_reward=-0.5865, violation=0, comm_penalty=0.0000, reward=-0.5865
  Client 8: mean_dist=2.63, base_reward=-0.3151, violation=1, comm_penalty=0.1000, reward=-0.4151
  Client 9: mean_dist=1.71, base_reward=0.1469, violation=0, comm_penalty=0.0000, reward=0.1469
  RL policy loss: -0.058373
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9739
  Client 1 model accuracy on test set: 0.9741
  Client 2 model accuracy on test set: 0.9713
  Client 3 model accuracy on test set: 0.9780
  Client 4 model accuracy on test set: 0.9415
  Client 5 model accuracy on test set: 0.8895
  Client 6 model accuracy on test set: 0.9612
  Client 7 model accuracy on test set: 0.9777
  Client 8 model accuracy on test set: 0.9735
  Client 9 model accuracy on test set: 0.9761

=== Global Round 35/100 ===
  Client 0: layers_shared=6, local_acc=1.0000
  Client 1: layers_shared=6, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=5, local_acc=1.0000
  Client 4: layers_shared=6, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=4, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=5, local_acc=1.0000
  Client 0: mean_dist=3.12, base_reward=-0.5577, violation=3, comm_penalty=0.3000, reward=-0.8577
  Client 1: mean_dist=3.25, base_reward=-0.6267, violation=1, comm_penalty=0.1000, reward=-0.7267
  Client 2: mean_dist=0.45, base_reward=0.7774, violation=0, comm_penalty=0.0000, reward=0.7774
  Client 3: mean_dist=3.16, base_reward=-0.5819, violation=3, comm_penalty=0.3000, reward=-0.8819
  Client 4: mean_dist=3.21, base_reward=-0.6037, violation=2, comm_penalty=0.2000, reward=-0.8037
  Client 5: mean_dist=0.44, base_reward=0.7811, violation=0, comm_penalty=0.0000, reward=0.7811
  Client 6: mean_dist=2.57, base_reward=-0.2862, violation=3, comm_penalty=0.3000, reward=-0.5862
  Client 7: mean_dist=2.09, base_reward=-0.0435, violation=0, comm_penalty=0.0000, reward=-0.0435
  Client 8: mean_dist=0.47, base_reward=0.7638, violation=0, comm_penalty=0.0000, reward=0.7638
  Client 9: mean_dist=3.06, base_reward=-0.5321, violation=0, comm_penalty=0.0000, reward=-0.5321
  RL policy loss: -0.143859
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9743
  Client 1 model accuracy on test set: 0.9740
  Client 2 model accuracy on test set: 0.9717
  Client 3 model accuracy on test set: 0.9799
  Client 4 model accuracy on test set: 0.9478
  Client 5 model accuracy on test set: 0.8934
  Client 6 model accuracy on test set: 0.9578
  Client 7 model accuracy on test set: 0.9786
  Client 8 model accuracy on test set: 0.9733
  Client 9 model accuracy on test set: 0.9770

=== Global Round 36/100 ===
  Client 0: layers_shared=6, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=0.9735
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=6, local_acc=1.0000
  Client 8: layers_shared=2, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=1.93, base_reward=0.0374, violation=3, comm_penalty=0.3000, reward=-0.2626
  Client 1: mean_dist=1.72, base_reward=0.1411, violation=0, comm_penalty=0.0000, reward=0.1411
  Client 2: mean_dist=0.45, base_reward=0.7772, violation=0, comm_penalty=0.0000, reward=0.7772
  Client 3: mean_dist=0.45, base_reward=0.7467, violation=0, comm_penalty=0.0000, reward=0.7467
  Client 4: mean_dist=0.43, base_reward=0.7832, violation=0, comm_penalty=0.0000, reward=0.7832
  Client 5: mean_dist=0.44, base_reward=0.7809, violation=0, comm_penalty=0.0000, reward=0.7809
  Client 6: mean_dist=1.60, base_reward=0.1980, violation=2, comm_penalty=0.2000, reward=-0.0020
  Client 7: mean_dist=1.96, base_reward=0.0182, violation=0, comm_penalty=0.0000, reward=0.0182
  Client 8: mean_dist=1.30, base_reward=0.3492, violation=0, comm_penalty=0.0000, reward=0.3492
  Client 9: mean_dist=1.65, base_reward=0.1748, violation=0, comm_penalty=0.0000, reward=0.1748
  RL policy loss: -0.046841
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9753
  Client 1 model accuracy on test set: 0.9747
  Client 2 model accuracy on test set: 0.9705
  Client 3 model accuracy on test set: 0.9466
  Client 4 model accuracy on test set: 0.9472
  Client 5 model accuracy on test set: 0.8913
  Client 6 model accuracy on test set: 0.9585
  Client 7 model accuracy on test set: 0.9777
  Client 8 model accuracy on test set: 0.9741
  Client 9 model accuracy on test set: 0.9767

=== Global Round 37/100 ===
  Client 0: layers_shared=4, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=4, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=0.9965
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=5, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=2.03, base_reward=-0.0150, violation=1, comm_penalty=0.1000, reward=-0.1150
  Client 1: mean_dist=1.87, base_reward=0.0674, violation=0, comm_penalty=0.0000, reward=0.0674
  Client 2: mean_dist=2.07, base_reward=-0.0367, violation=3, comm_penalty=0.3000, reward=-0.3367
  Client 3: mean_dist=0.46, base_reward=0.7722, violation=0, comm_penalty=0.0000, reward=0.7722
  Client 4: mean_dist=1.84, base_reward=0.0753, violation=0, comm_penalty=0.0000, reward=0.0753
  Client 5: mean_dist=0.44, base_reward=0.7807, violation=0, comm_penalty=0.0000, reward=0.7807
  Client 6: mean_dist=0.43, base_reward=0.7868, violation=0, comm_penalty=0.0000, reward=0.7868
  Client 7: mean_dist=0.46, base_reward=0.7716, violation=0, comm_penalty=0.0000, reward=0.7716
  Client 8: mean_dist=2.15, base_reward=-0.0732, violation=3, comm_penalty=0.3000, reward=-0.3732
  Client 9: mean_dist=1.78, base_reward=0.1093, violation=0, comm_penalty=0.0000, reward=0.1093
  RL policy loss: -0.076670
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9749
  Client 1 model accuracy on test set: 0.9749
  Client 2 model accuracy on test set: 0.9716
  Client 3 model accuracy on test set: 0.9782
  Client 4 model accuracy on test set: 0.8752
  Client 5 model accuracy on test set: 0.8928
  Client 6 model accuracy on test set: 0.9582
  Client 7 model accuracy on test set: 0.9786
  Client 8 model accuracy on test set: 0.9745
  Client 9 model accuracy on test set: 0.9762

=== Global Round 38/100 ===
  Client 0: layers_shared=4, local_acc=1.0000
  Client 1: layers_shared=4, local_acc=1.0000
  Client 2: layers_shared=6, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=0.9670
  Client 4: layers_shared=1, local_acc=0.9954
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=4, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=2.67, base_reward=-0.3327, violation=1, comm_penalty=0.1000, reward=-0.4327
  Client 1: mean_dist=2.77, base_reward=-0.3838, violation=0, comm_penalty=0.0000, reward=-0.3838
  Client 2: mean_dist=2.71, base_reward=-0.3568, violation=5, comm_penalty=0.5000, reward=-0.8568
  Client 3: mean_dist=0.46, base_reward=0.7392, violation=0, comm_penalty=0.0000, reward=0.7392
  Client 4: mean_dist=0.44, base_reward=0.7743, violation=0, comm_penalty=0.0000, reward=0.7743
  Client 5: mean_dist=2.22, base_reward=-0.1084, violation=0, comm_penalty=0.0000, reward=-0.1084
  Client 6: mean_dist=2.22, base_reward=-0.1095, violation=2, comm_penalty=0.2000, reward=-0.3095
  Client 7: mean_dist=2.74, base_reward=-0.3679, violation=0, comm_penalty=0.0000, reward=-0.3679
  Client 8: mean_dist=2.43, base_reward=-0.2151, violation=1, comm_penalty=0.1000, reward=-0.3151
  Client 9: mean_dist=2.27, base_reward=-0.1329, violation=0, comm_penalty=0.0000, reward=-0.1329
  RL policy loss: -0.078529
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9744
  Client 1 model accuracy on test set: 0.9751
  Client 2 model accuracy on test set: 0.9716
  Client 3 model accuracy on test set: 0.9233
  Client 4 model accuracy on test set: 0.9258
  Client 5 model accuracy on test set: 0.8915
  Client 6 model accuracy on test set: 0.9611
  Client 7 model accuracy on test set: 0.9770
  Client 8 model accuracy on test set: 0.9733
  Client 9 model accuracy on test set: 0.9758

=== Global Round 39/100 ===
  Client 0: layers_shared=6, local_acc=1.0000
  Client 1: layers_shared=4, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=6, local_acc=1.0000
  Client 4: layers_shared=6, local_acc=0.9926
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=2, local_acc=1.0000
  Client 9: layers_shared=4, local_acc=1.0000
  Client 0: mean_dist=3.20, base_reward=-0.6024, violation=3, comm_penalty=0.3000, reward=-0.9024
  Client 1: mean_dist=3.06, base_reward=-0.5317, violation=0, comm_penalty=0.0000, reward=-0.5317
  Client 2: mean_dist=2.53, base_reward=-0.2645, violation=2, comm_penalty=0.2000, reward=-0.4645
  Client 3: mean_dist=3.33, base_reward=-0.6658, violation=4, comm_penalty=0.4000, reward=-1.0658
  Client 4: mean_dist=3.33, base_reward=-0.6745, violation=2, comm_penalty=0.2000, reward=-0.8745
  Client 5: mean_dist=2.38, base_reward=-0.1878, violation=0, comm_penalty=0.0000, reward=-0.1878
  Client 6: mean_dist=2.39, base_reward=-0.1966, violation=2, comm_penalty=0.2000, reward=-0.3966
  Client 7: mean_dist=0.46, base_reward=0.7712, violation=0, comm_penalty=0.0000, reward=0.7712
  Client 8: mean_dist=1.80, base_reward=0.0985, violation=0, comm_penalty=0.0000, reward=0.0985
  Client 9: mean_dist=2.92, base_reward=-0.4624, violation=0, comm_penalty=0.0000, reward=-0.4624
  RL policy loss: -0.071383
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9747
  Client 1 model accuracy on test set: 0.9746
  Client 2 model accuracy on test set: 0.9713
  Client 3 model accuracy on test set: 0.9784
  Client 4 model accuracy on test set: 0.8723
  Client 5 model accuracy on test set: 0.8896
  Client 6 model accuracy on test set: 0.9612
  Client 7 model accuracy on test set: 0.9776
  Client 8 model accuracy on test set: 0.9731
  Client 9 model accuracy on test set: 0.9755

=== Global Round 40/100 ===
  Client 0: layers_shared=4, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=2, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=5, local_acc=1.0000
  Client 7: layers_shared=4, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=1.93, base_reward=0.0372, violation=1, comm_penalty=0.1000, reward=-0.0628
  Client 1: mean_dist=0.49, base_reward=0.7537, violation=0, comm_penalty=0.0000, reward=0.7537
  Client 2: mean_dist=0.45, base_reward=0.7770, violation=0, comm_penalty=0.0000, reward=0.7770
  Client 3: mean_dist=1.75, base_reward=0.1268, violation=1, comm_penalty=0.1000, reward=0.0268
  Client 4: mean_dist=1.26, base_reward=0.3694, violation=0, comm_penalty=0.0000, reward=0.3694
  Client 5: mean_dist=0.44, base_reward=0.7803, violation=0, comm_penalty=0.0000, reward=0.7803
  Client 6: mean_dist=1.88, base_reward=0.0613, violation=4, comm_penalty=0.4000, reward=-0.3387
  Client 7: mean_dist=1.97, base_reward=0.0133, violation=0, comm_penalty=0.0000, reward=0.0133
  Client 8: mean_dist=1.78, base_reward=0.1094, violation=1, comm_penalty=0.1000, reward=0.0094
  Client 9: mean_dist=0.46, base_reward=0.7711, violation=0, comm_penalty=0.0000, reward=0.7711
  RL policy loss: -0.081011
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9746
  Client 1 model accuracy on test set: 0.9748
  Client 2 model accuracy on test set: 0.9717
  Client 3 model accuracy on test set: 0.9799
  Client 4 model accuracy on test set: 0.9229
  Client 5 model accuracy on test set: 0.8914
  Client 6 model accuracy on test set: 0.9585
  Client 7 model accuracy on test set: 0.9778
  Client 8 model accuracy on test set: 0.9727
  Client 9 model accuracy on test set: 0.9763

=== Global Round 41/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=5, local_acc=1.0000
  Client 2: layers_shared=4, local_acc=1.0000
  Client 3: layers_shared=4, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=5, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=5, local_acc=1.0000
  Client 0: mean_dist=0.44, base_reward=0.7781, violation=0, comm_penalty=0.0000, reward=0.7781
  Client 1: mean_dist=3.40, base_reward=-0.6993, violation=0, comm_penalty=0.0000, reward=-0.6993
  Client 2: mean_dist=2.99, base_reward=-0.4949, violation=3, comm_penalty=0.3000, reward=-0.7949
  Client 3: mean_dist=3.06, base_reward=-0.5296, violation=2, comm_penalty=0.2000, reward=-0.7296
  Client 4: mean_dist=3.40, base_reward=-0.7000, violation=1, comm_penalty=0.1000, reward=-0.8000
  Client 5: mean_dist=2.23, base_reward=-0.1165, violation=0, comm_penalty=0.0000, reward=-0.1165
  Client 6: mean_dist=2.24, base_reward=-0.1209, violation=2, comm_penalty=0.2000, reward=-0.3209
  Client 7: mean_dist=3.37, base_reward=-0.6858, violation=0, comm_penalty=0.0000, reward=-0.6858
  Client 8: mean_dist=0.48, base_reward=0.7624, violation=0, comm_penalty=0.0000, reward=0.7624
  Client 9: mean_dist=3.24, base_reward=-0.6211, violation=0, comm_penalty=0.0000, reward=-0.6211
  RL policy loss: -0.130809
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9746
  Client 1 model accuracy on test set: 0.9748
  Client 2 model accuracy on test set: 0.9714
  Client 3 model accuracy on test set: 0.9796
  Client 4 model accuracy on test set: 0.9423
  Client 5 model accuracy on test set: 0.8867
  Client 6 model accuracy on test set: 0.9599
  Client 7 model accuracy on test set: 0.9782
  Client 8 model accuracy on test set: 0.9734
  Client 9 model accuracy on test set: 0.9762

=== Global Round 42/100 ===
  Client 0: layers_shared=4, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=6, local_acc=1.0000
  Client 4: layers_shared=4, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=5, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=6, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=2.69, base_reward=-0.3437, violation=1, comm_penalty=0.1000, reward=-0.4437
  Client 1: mean_dist=2.30, base_reward=-0.1504, violation=0, comm_penalty=0.0000, reward=-0.1504
  Client 2: mean_dist=1.60, base_reward=0.2015, violation=1, comm_penalty=0.1000, reward=0.1015
  Client 3: mean_dist=3.08, base_reward=-0.5390, violation=4, comm_penalty=0.4000, reward=-0.9390
  Client 4: mean_dist=2.78, base_reward=-0.3919, violation=0, comm_penalty=0.0000, reward=-0.3919
  Client 5: mean_dist=2.14, base_reward=-0.0681, violation=0, comm_penalty=0.0000, reward=-0.0681
  Client 6: mean_dist=2.86, base_reward=-0.4312, violation=4, comm_penalty=0.4000, reward=-0.8312
  Client 7: mean_dist=0.46, base_reward=0.7717, violation=0, comm_penalty=0.0000, reward=0.7717
  Client 8: mean_dist=3.09, base_reward=-0.5426, violation=4, comm_penalty=0.4000, reward=-0.9426
  Client 9: mean_dist=0.46, base_reward=0.7707, violation=0, comm_penalty=0.0000, reward=0.7707
  RL policy loss: -0.135289
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9753
  Client 1 model accuracy on test set: 0.9749
  Client 2 model accuracy on test set: 0.9715
  Client 3 model accuracy on test set: 0.9803
  Client 4 model accuracy on test set: 0.9447
  Client 5 model accuracy on test set: 0.8888
  Client 6 model accuracy on test set: 0.9601
  Client 7 model accuracy on test set: 0.9780
  Client 8 model accuracy on test set: 0.9731
  Client 9 model accuracy on test set: 0.9761

=== Global Round 43/100 ===
  Client 0: layers_shared=6, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=2, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=5, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=2, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=2.04, base_reward=-0.0199, violation=3, comm_penalty=0.3000, reward=-0.3199
  Client 1: mean_dist=0.49, base_reward=0.7536, violation=0, comm_penalty=0.0000, reward=0.7536
  Client 2: mean_dist=0.45, base_reward=0.7771, violation=0, comm_penalty=0.0000, reward=0.7771
  Client 3: mean_dist=0.45, base_reward=0.7726, violation=0, comm_penalty=0.0000, reward=0.7726
  Client 4: mean_dist=1.41, base_reward=0.2948, violation=0, comm_penalty=0.0000, reward=0.2948
  Client 5: mean_dist=1.75, base_reward=0.1267, violation=0, comm_penalty=0.0000, reward=0.1267
  Client 6: mean_dist=1.98, base_reward=0.0112, violation=4, comm_penalty=0.4000, reward=-0.3888
  Client 7: mean_dist=1.85, base_reward=0.0731, violation=0, comm_penalty=0.0000, reward=0.0731
  Client 8: mean_dist=1.46, base_reward=0.2680, violation=0, comm_penalty=0.0000, reward=0.2680
  Client 9: mean_dist=1.80, base_reward=0.0992, violation=0, comm_penalty=0.0000, reward=0.0992
  RL policy loss: -0.066111
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9749
  Client 1 model accuracy on test set: 0.9747
  Client 2 model accuracy on test set: 0.9713
  Client 3 model accuracy on test set: 0.9796
  Client 4 model accuracy on test set: 0.9450
  Client 5 model accuracy on test set: 0.8916
  Client 6 model accuracy on test set: 0.9583
  Client 7 model accuracy on test set: 0.9779
  Client 8 model accuracy on test set: 0.9738
  Client 9 model accuracy on test set: 0.9760

=== Global Round 44/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=5, local_acc=1.0000
  Client 3: layers_shared=5, local_acc=1.0000
  Client 4: layers_shared=6, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=4, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=2.31, base_reward=-0.1526, violation=0, comm_penalty=0.0000, reward=-0.1526
  Client 1: mean_dist=0.49, base_reward=0.7537, violation=0, comm_penalty=0.0000, reward=0.7537
  Client 2: mean_dist=2.99, base_reward=-0.4938, violation=4, comm_penalty=0.4000, reward=-0.8938
  Client 3: mean_dist=3.02, base_reward=-0.5109, violation=3, comm_penalty=0.3000, reward=-0.8109
  Client 4: mean_dist=3.01, base_reward=-0.5059, violation=2, comm_penalty=0.2000, reward=-0.7059
  Client 5: mean_dist=2.22, base_reward=-0.1120, violation=0, comm_penalty=0.0000, reward=-0.1120
  Client 6: mean_dist=2.25, base_reward=-0.1235, violation=2, comm_penalty=0.2000, reward=-0.3235
  Client 7: mean_dist=0.46, base_reward=0.7718, violation=0, comm_penalty=0.0000, reward=0.7718
  Client 8: mean_dist=2.82, base_reward=-0.4084, violation=2, comm_penalty=0.2000, reward=-0.6084
  Client 9: mean_dist=2.30, base_reward=-0.1483, violation=0, comm_penalty=0.0000, reward=-0.1483
  RL policy loss: -0.161969
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9744
  Client 1 model accuracy on test set: 0.9736
  Client 2 model accuracy on test set: 0.9716
  Client 3 model accuracy on test set: 0.9790
  Client 4 model accuracy on test set: 0.9347
  Client 5 model accuracy on test set: 0.8892
  Client 6 model accuracy on test set: 0.9592
  Client 7 model accuracy on test set: 0.9773
  Client 8 model accuracy on test set: 0.9740
  Client 9 model accuracy on test set: 0.9769

=== Global Round 45/100 ===
  Client 0: layers_shared=2, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=4, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=6, local_acc=1.0000
  Client 8: layers_shared=4, local_acc=1.0000
  Client 9: layers_shared=4, local_acc=1.0000
  Client 0: mean_dist=1.39, base_reward=0.3038, violation=0, comm_penalty=0.0000, reward=0.3038
  Client 1: mean_dist=0.49, base_reward=0.7537, violation=0, comm_penalty=0.0000, reward=0.7537
  Client 2: mean_dist=0.45, base_reward=0.7769, violation=0, comm_penalty=0.0000, reward=0.7769
  Client 3: mean_dist=2.54, base_reward=-0.2715, violation=2, comm_penalty=0.2000, reward=-0.4715
  Client 4: mean_dist=2.65, base_reward=-0.3248, violation=1, comm_penalty=0.1000, reward=-0.4248
  Client 5: mean_dist=0.44, base_reward=0.7800, violation=0, comm_penalty=0.0000, reward=0.7800
  Client 6: mean_dist=1.90, base_reward=0.0519, violation=2, comm_penalty=0.2000, reward=-0.1481
  Client 7: mean_dist=2.65, base_reward=-0.3252, violation=0, comm_penalty=0.0000, reward=-0.3252
  Client 8: mean_dist=2.56, base_reward=-0.2795, violation=2, comm_penalty=0.2000, reward=-0.4795
  Client 9: mean_dist=2.44, base_reward=-0.2177, violation=0, comm_penalty=0.0000, reward=-0.2177
  RL policy loss: -0.162782
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9751
  Client 1 model accuracy on test set: 0.9740
  Client 2 model accuracy on test set: 0.9717
  Client 3 model accuracy on test set: 0.9787
  Client 4 model accuracy on test set: 0.9438
  Client 5 model accuracy on test set: 0.8917
  Client 6 model accuracy on test set: 0.9606
  Client 7 model accuracy on test set: 0.9783
  Client 8 model accuracy on test set: 0.9686
  Client 9 model accuracy on test set: 0.9761

=== Global Round 46/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=5, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=0.9991
  Client 4: layers_shared=4, local_acc=1.0000
  Client 5: layers_shared=6, local_acc=1.0000
  Client 6: layers_shared=6, local_acc=1.0000
  Client 7: layers_shared=5, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=2.03, base_reward=-0.0162, violation=0, comm_penalty=0.0000, reward=-0.0162
  Client 1: mean_dist=3.00, base_reward=-0.5013, violation=0, comm_penalty=0.0000, reward=-0.5013
  Client 2: mean_dist=2.08, base_reward=-0.0417, violation=2, comm_penalty=0.2000, reward=-0.2417
  Client 3: mean_dist=0.46, base_reward=0.7713, violation=0, comm_penalty=0.0000, reward=0.7713
  Client 4: mean_dist=2.61, base_reward=-0.3038, violation=0, comm_penalty=0.0000, reward=-0.3038
  Client 5: mean_dist=2.84, base_reward=-0.4196, violation=0, comm_penalty=0.0000, reward=-0.4196
  Client 6: mean_dist=2.82, base_reward=-0.4113, violation=5, comm_penalty=0.5000, reward=-0.9113
  Client 7: mean_dist=2.96, base_reward=-0.4784, violation=0, comm_penalty=0.0000, reward=-0.4784
  Client 8: mean_dist=0.48, base_reward=0.7623, violation=0, comm_penalty=0.0000, reward=0.7623
  Client 9: mean_dist=0.46, base_reward=0.7709, violation=0, comm_penalty=0.0000, reward=0.7709
  RL policy loss: -0.165612
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9756
  Client 1 model accuracy on test set: 0.9746
  Client 2 model accuracy on test set: 0.9716
  Client 3 model accuracy on test set: 0.9732
  Client 4 model accuracy on test set: 0.9427
  Client 5 model accuracy on test set: 0.8910
  Client 6 model accuracy on test set: 0.9610
  Client 7 model accuracy on test set: 0.9777
  Client 8 model accuracy on test set: 0.9735
  Client 9 model accuracy on test set: 0.9760

=== Global Round 47/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=2, local_acc=1.0000
  Client 2: layers_shared=6, local_acc=1.0000
  Client 3: layers_shared=2, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=4, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=2.11, base_reward=-0.0573, violation=0, comm_penalty=0.0000, reward=-0.0573
  Client 1: mean_dist=1.62, base_reward=0.1895, violation=0, comm_penalty=0.0000, reward=0.1895
  Client 2: mean_dist=2.54, base_reward=-0.2716, violation=5, comm_penalty=0.5000, reward=-0.7716
  Client 3: mean_dist=1.63, base_reward=0.1868, violation=0, comm_penalty=0.0000, reward=0.1868
  Client 4: mean_dist=2.56, base_reward=-0.2813, violation=1, comm_penalty=0.1000, reward=-0.3813
  Client 5: mean_dist=0.44, base_reward=0.7800, violation=0, comm_penalty=0.0000, reward=0.7800
  Client 6: mean_dist=2.30, base_reward=-0.1507, violation=3, comm_penalty=0.3000, reward=-0.4507
  Client 7: mean_dist=2.16, base_reward=-0.0796, violation=0, comm_penalty=0.0000, reward=-0.0796
  Client 8: mean_dist=2.24, base_reward=-0.1205, violation=1, comm_penalty=0.1000, reward=-0.2205
  Client 9: mean_dist=0.46, base_reward=0.7710, violation=0, comm_penalty=0.0000, reward=0.7710
  RL policy loss: -0.101183
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9749
  Client 1 model accuracy on test set: 0.9759
  Client 2 model accuracy on test set: 0.9708
  Client 3 model accuracy on test set: 0.9789
  Client 4 model accuracy on test set: 0.9449
  Client 5 model accuracy on test set: 0.8915
  Client 6 model accuracy on test set: 0.9599
  Client 7 model accuracy on test set: 0.9776
  Client 8 model accuracy on test set: 0.9733
  Client 9 model accuracy on test set: 0.9761

=== Global Round 48/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=0.9726
  Client 4: layers_shared=6, local_acc=1.0000
  Client 5: layers_shared=2, local_acc=1.0000
  Client 6: layers_shared=2, local_acc=1.0000
  Client 7: layers_shared=4, local_acc=1.0000
  Client 8: layers_shared=6, local_acc=1.0000
  Client 9: layers_shared=6, local_acc=1.0000
  Client 0: mean_dist=0.44, base_reward=0.7781, violation=0, comm_penalty=0.0000, reward=0.7781
  Client 1: mean_dist=0.49, base_reward=0.7534, violation=0, comm_penalty=0.0000, reward=0.7534
  Client 2: mean_dist=0.45, base_reward=0.7763, violation=0, comm_penalty=0.0000, reward=0.7763
  Client 3: mean_dist=1.93, base_reward=0.0094, violation=1, comm_penalty=0.1000, reward=-0.0906
  Client 4: mean_dist=2.59, base_reward=-0.2929, violation=2, comm_penalty=0.2000, reward=-0.4929
  Client 5: mean_dist=1.35, base_reward=0.3238, violation=0, comm_penalty=0.0000, reward=0.3238
  Client 6: mean_dist=1.35, base_reward=0.3265, violation=1, comm_penalty=0.1000, reward=0.2265
  Client 7: mean_dist=2.28, base_reward=-0.1394, violation=0, comm_penalty=0.0000, reward=-0.1394
  Client 8: mean_dist=2.58, base_reward=-0.2923, violation=4, comm_penalty=0.4000, reward=-0.6923
  Client 9: mean_dist=2.48, base_reward=-0.2380, violation=1, comm_penalty=0.1000, reward=-0.3380
  RL policy loss: -0.143326
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9748
  Client 1 model accuracy on test set: 0.9745
  Client 2 model accuracy on test set: 0.9717
  Client 3 model accuracy on test set: 0.9388
  Client 4 model accuracy on test set: 0.9472
  Client 5 model accuracy on test set: 0.8890
  Client 6 model accuracy on test set: 0.9592
  Client 7 model accuracy on test set: 0.9782
  Client 8 model accuracy on test set: 0.9738
  Client 9 model accuracy on test set: 0.9764

=== Global Round 49/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=5, local_acc=1.0000
  Client 4: layers_shared=4, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=6, local_acc=1.0000
  Client 8: layers_shared=6, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=1.81, base_reward=0.0965, violation=0, comm_penalty=0.0000, reward=0.0965
  Client 1: mean_dist=0.49, base_reward=0.7533, violation=0, comm_penalty=0.0000, reward=0.7533
  Client 2: mean_dist=0.45, base_reward=0.7762, violation=0, comm_penalty=0.0000, reward=0.7762
  Client 3: mean_dist=2.52, base_reward=-0.2610, violation=3, comm_penalty=0.3000, reward=-0.5610
  Client 4: mean_dist=2.25, base_reward=-0.1233, violation=0, comm_penalty=0.0000, reward=-0.1233
  Client 5: mean_dist=0.44, base_reward=0.7797, violation=0, comm_penalty=0.0000, reward=0.7797
  Client 6: mean_dist=0.43, base_reward=0.7859, violation=0, comm_penalty=0.0000, reward=0.7859
  Client 7: mean_dist=2.54, base_reward=-0.2689, violation=0, comm_penalty=0.0000, reward=-0.2689
  Client 8: mean_dist=2.58, base_reward=-0.2885, violation=4, comm_penalty=0.4000, reward=-0.6885
  Client 9: mean_dist=1.81, base_reward=0.0928, violation=0, comm_penalty=0.0000, reward=0.0928
  RL policy loss: -0.187556
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9751
  Client 1 model accuracy on test set: 0.9742
  Client 2 model accuracy on test set: 0.9714
  Client 3 model accuracy on test set: 0.9718
  Client 4 model accuracy on test set: 0.9477
  Client 5 model accuracy on test set: 0.8944
  Client 6 model accuracy on test set: 0.9586
  Client 7 model accuracy on test set: 0.9780
  Client 8 model accuracy on test set: 0.9745
  Client 9 model accuracy on test set: 0.9765

=== Global Round 50/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=6, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=1.0000
  Client 5: layers_shared=4, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=6, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=0.44, base_reward=0.7777, violation=0, comm_penalty=0.0000, reward=0.7777
  Client 1: mean_dist=1.88, base_reward=0.0586, violation=1, comm_penalty=0.1000, reward=-0.0414
  Client 2: mean_dist=1.10, base_reward=0.4520, violation=1, comm_penalty=0.1000, reward=0.3520
  Client 3: mean_dist=0.46, base_reward=0.7700, violation=0, comm_penalty=0.0000, reward=0.7700
  Client 4: mean_dist=1.44, base_reward=0.2798, violation=0, comm_penalty=0.0000, reward=0.2798
  Client 5: mean_dist=1.63, base_reward=0.1855, violation=0, comm_penalty=0.0000, reward=0.1855
  Client 6: mean_dist=0.43, base_reward=0.7860, violation=0, comm_penalty=0.0000, reward=0.7860
  Client 7: mean_dist=1.84, base_reward=0.0807, violation=0, comm_penalty=0.0000, reward=0.0807
  Client 8: mean_dist=0.48, base_reward=0.7622, violation=0, comm_penalty=0.0000, reward=0.7622
  Client 9: mean_dist=0.46, base_reward=0.7706, violation=0, comm_penalty=0.0000, reward=0.7706
  RL policy loss: -0.118504
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9749
  Client 1 model accuracy on test set: 0.9746
  Client 2 model accuracy on test set: 0.9711
  Client 3 model accuracy on test set: 0.9783
  Client 4 model accuracy on test set: 0.9441
  Client 5 model accuracy on test set: 0.8906
  Client 6 model accuracy on test set: 0.9592
  Client 7 model accuracy on test set: 0.9767
  Client 8 model accuracy on test set: 0.9733
  Client 9 model accuracy on test set: 0.9761

=== Global Round 51/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=5, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=6, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=5, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=2, local_acc=1.0000
  Client 9: layers_shared=6, local_acc=1.0000
  Client 0: mean_dist=1.92, base_reward=0.0403, violation=0, comm_penalty=0.0000, reward=0.0403
  Client 1: mean_dist=2.76, base_reward=-0.3787, violation=0, comm_penalty=0.0000, reward=-0.3787
  Client 2: mean_dist=0.45, base_reward=0.7763, violation=0, comm_penalty=0.0000, reward=0.7763
  Client 3: mean_dist=2.78, base_reward=-0.3908, violation=4, comm_penalty=0.4000, reward=-0.7908
  Client 4: mean_dist=0.44, base_reward=0.7792, violation=0, comm_penalty=0.0000, reward=0.7792
  Client 5: mean_dist=2.58, base_reward=-0.2894, violation=0, comm_penalty=0.0000, reward=-0.2894
  Client 6: mean_dist=1.87, base_reward=0.0665, violation=2, comm_penalty=0.2000, reward=-0.1335
  Client 7: mean_dist=0.46, base_reward=0.7714, violation=0, comm_penalty=0.0000, reward=0.7714
  Client 8: mean_dist=1.46, base_reward=0.2694, violation=0, comm_penalty=0.0000, reward=0.2694
  Client 9: mean_dist=2.63, base_reward=-0.3150, violation=1, comm_penalty=0.1000, reward=-0.4150
  RL policy loss: -0.172035
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9761
  Client 1 model accuracy on test set: 0.9741
  Client 2 model accuracy on test set: 0.9714
  Client 3 model accuracy on test set: 0.9793
  Client 4 model accuracy on test set: 0.9487
  Client 5 model accuracy on test set: 0.8901
  Client 6 model accuracy on test set: 0.9595
  Client 7 model accuracy on test set: 0.9781
  Client 8 model accuracy on test set: 0.9728
  Client 9 model accuracy on test set: 0.9757

=== Global Round 52/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=2, local_acc=1.0000
  Client 0: mean_dist=1.39, base_reward=0.3042, violation=2, comm_penalty=0.2000, reward=0.1042
  Client 1: mean_dist=0.49, base_reward=0.7531, violation=0, comm_penalty=0.0000, reward=0.7531
  Client 2: mean_dist=1.42, base_reward=0.2882, violation=2, comm_penalty=0.2000, reward=0.0882
  Client 3: mean_dist=0.46, base_reward=0.7702, violation=0, comm_penalty=0.0000, reward=0.7702
  Client 4: mean_dist=1.43, base_reward=0.2847, violation=0, comm_penalty=0.0000, reward=0.2847
  Client 5: mean_dist=1.36, base_reward=0.3207, violation=0, comm_penalty=0.0000, reward=0.3207
  Client 6: mean_dist=0.43, base_reward=0.7860, violation=0, comm_penalty=0.0000, reward=0.7860
  Client 7: mean_dist=0.46, base_reward=0.7713, violation=0, comm_penalty=0.0000, reward=0.7713
  Client 8: mean_dist=0.48, base_reward=0.7622, violation=0, comm_penalty=0.0000, reward=0.7622
  Client 9: mean_dist=1.08, base_reward=0.4622, violation=0, comm_penalty=0.0000, reward=0.4622
  RL policy loss: -0.061846
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9752
  Client 1 model accuracy on test set: 0.9751
  Client 2 model accuracy on test set: 0.9710
  Client 3 model accuracy on test set: 0.9802
  Client 4 model accuracy on test set: 0.9495
  Client 5 model accuracy on test set: 0.8890
  Client 6 model accuracy on test set: 0.9611
  Client 7 model accuracy on test set: 0.9786
  Client 8 model accuracy on test set: 0.9740
  Client 9 model accuracy on test set: 0.9763

=== Global Round 53/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=6, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=4, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=5, local_acc=1.0000
  Client 0: mean_dist=1.66, base_reward=0.1710, violation=0, comm_penalty=0.0000, reward=0.1710
  Client 1: mean_dist=2.09, base_reward=-0.0451, violation=1, comm_penalty=0.1000, reward=-0.1451
  Client 2: mean_dist=1.24, base_reward=0.3800, violation=1, comm_penalty=0.1000, reward=0.2800
  Client 3: mean_dist=0.46, base_reward=0.7703, violation=0, comm_penalty=0.0000, reward=0.7703
  Client 4: mean_dist=0.44, base_reward=0.7788, violation=0, comm_penalty=0.0000, reward=0.7788
  Client 5: mean_dist=0.44, base_reward=0.7797, violation=0, comm_penalty=0.0000, reward=0.7797
  Client 6: mean_dist=1.61, base_reward=0.1939, violation=2, comm_penalty=0.2000, reward=-0.0061
  Client 7: mean_dist=1.95, base_reward=0.0274, violation=0, comm_penalty=0.0000, reward=0.0274
  Client 8: mean_dist=0.48, base_reward=0.7623, violation=0, comm_penalty=0.0000, reward=0.7623
  Client 9: mean_dist=2.01, base_reward=-0.0065, violation=0, comm_penalty=0.0000, reward=-0.0065
  RL policy loss: -0.134675
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9752
  Client 1 model accuracy on test set: 0.9752
  Client 2 model accuracy on test set: 0.9713
  Client 3 model accuracy on test set: 0.9808
  Client 4 model accuracy on test set: 0.9422
  Client 5 model accuracy on test set: 0.8912
  Client 6 model accuracy on test set: 0.9569
  Client 7 model accuracy on test set: 0.9789
  Client 8 model accuracy on test set: 0.9736
  Client 9 model accuracy on test set: 0.9761

=== Global Round 54/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=5, local_acc=1.0000
  Client 4: layers_shared=6, local_acc=0.9926
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=4, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=6, local_acc=1.0000
  Client 9: layers_shared=2, local_acc=1.0000
  Client 0: mean_dist=1.95, base_reward=0.0228, violation=0, comm_penalty=0.0000, reward=0.0228
  Client 1: mean_dist=2.03, base_reward=-0.0167, violation=0, comm_penalty=0.0000, reward=-0.0167
  Client 2: mean_dist=0.45, base_reward=0.7758, violation=0, comm_penalty=0.0000, reward=0.7758
  Client 3: mean_dist=2.67, base_reward=-0.3336, violation=3, comm_penalty=0.3000, reward=-0.6336
  Client 4: mean_dist=2.68, base_reward=-0.3458, violation=2, comm_penalty=0.2000, reward=-0.5458
  Client 5: mean_dist=0.44, base_reward=0.7795, violation=0, comm_penalty=0.0000, reward=0.7795
  Client 6: mean_dist=2.28, base_reward=-0.1390, violation=3, comm_penalty=0.3000, reward=-0.4390
  Client 7: mean_dist=0.46, base_reward=0.7706, violation=0, comm_penalty=0.0000, reward=0.7706
  Client 8: mean_dist=2.73, base_reward=-0.3640, violation=4, comm_penalty=0.4000, reward=-0.7640
  Client 9: mean_dist=1.40, base_reward=0.2984, violation=0, comm_penalty=0.0000, reward=0.2984
  RL policy loss: -0.215093
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9752
  Client 1 model accuracy on test set: 0.9755
  Client 2 model accuracy on test set: 0.9718
  Client 3 model accuracy on test set: 0.9783
  Client 4 model accuracy on test set: 0.8846
  Client 5 model accuracy on test set: 0.8896
  Client 6 model accuracy on test set: 0.9609
  Client 7 model accuracy on test set: 0.9771
  Client 8 model accuracy on test set: 0.9739
  Client 9 model accuracy on test set: 0.9763

=== Global Round 55/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=5, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=0.45, base_reward=0.7772, violation=0, comm_penalty=0.0000, reward=0.7772
  Client 1: mean_dist=0.49, base_reward=0.7526, violation=0, comm_penalty=0.0000, reward=0.7526
  Client 2: mean_dist=1.00, base_reward=0.5009, violation=4, comm_penalty=0.4000, reward=0.1009
  Client 3: mean_dist=0.46, base_reward=0.7701, violation=0, comm_penalty=0.0000, reward=0.7701
  Client 4: mean_dist=1.00, base_reward=0.4997, violation=1, comm_penalty=0.1000, reward=0.3997
  Client 5: mean_dist=0.44, base_reward=0.7791, violation=0, comm_penalty=0.0000, reward=0.7791
  Client 6: mean_dist=0.43, base_reward=0.7852, violation=0, comm_penalty=0.0000, reward=0.7852
  Client 7: mean_dist=0.46, base_reward=0.7704, violation=0, comm_penalty=0.0000, reward=0.7704
  Client 8: mean_dist=0.48, base_reward=0.7614, violation=0, comm_penalty=0.0000, reward=0.7614
  Client 9: mean_dist=0.46, base_reward=0.7699, violation=0, comm_penalty=0.0000, reward=0.7699
  RL policy loss: -0.076142
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9751
  Client 1 model accuracy on test set: 0.9743
  Client 2 model accuracy on test set: 0.9714
  Client 3 model accuracy on test set: 0.9779
  Client 4 model accuracy on test set: 0.9401
  Client 5 model accuracy on test set: 0.8898
  Client 6 model accuracy on test set: 0.9583
  Client 7 model accuracy on test set: 0.9779
  Client 8 model accuracy on test set: 0.9752
  Client 9 model accuracy on test set: 0.9761

=== Global Round 56/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=6, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=6, local_acc=1.0000
  Client 5: layers_shared=2, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=4, local_acc=1.0000
  Client 8: layers_shared=6, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=0.45, base_reward=0.7771, violation=0, comm_penalty=0.0000, reward=0.7771
  Client 1: mean_dist=0.49, base_reward=0.7525, violation=0, comm_penalty=0.0000, reward=0.7525
  Client 2: mean_dist=2.44, base_reward=-0.2223, violation=5, comm_penalty=0.5000, reward=-0.7223
  Client 3: mean_dist=1.78, base_reward=0.1077, violation=1, comm_penalty=0.1000, reward=0.0077
  Client 4: mean_dist=2.48, base_reward=-0.2401, violation=2, comm_penalty=0.2000, reward=-0.4401
  Client 5: mean_dist=1.22, base_reward=0.3891, violation=0, comm_penalty=0.0000, reward=0.3891
  Client 6: mean_dist=0.43, base_reward=0.7851, violation=0, comm_penalty=0.0000, reward=0.7851
  Client 7: mean_dist=2.14, base_reward=-0.0720, violation=0, comm_penalty=0.0000, reward=-0.0720
  Client 8: mean_dist=2.49, base_reward=-0.2460, violation=4, comm_penalty=0.4000, reward=-0.6460
  Client 9: mean_dist=0.46, base_reward=0.7699, violation=0, comm_penalty=0.0000, reward=0.7699
  RL policy loss: -0.230186
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9748
  Client 1 model accuracy on test set: 0.9753
  Client 2 model accuracy on test set: 0.9710
  Client 3 model accuracy on test set: 0.9732
  Client 4 model accuracy on test set: 0.9427
  Client 5 model accuracy on test set: 0.8860
  Client 6 model accuracy on test set: 0.9579
  Client 7 model accuracy on test set: 0.9790
  Client 8 model accuracy on test set: 0.9745
  Client 9 model accuracy on test set: 0.9760

=== Global Round 57/100 ===
  Client 0: layers_shared=2, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=4, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=6, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=1.69, base_reward=0.1541, violation=0, comm_penalty=0.0000, reward=0.1541
  Client 1: mean_dist=2.44, base_reward=-0.2207, violation=0, comm_penalty=0.0000, reward=-0.2207
  Client 2: mean_dist=1.74, base_reward=0.1277, violation=1, comm_penalty=0.1000, reward=0.0277
  Client 3: mean_dist=2.49, base_reward=-0.2453, violation=1, comm_penalty=0.1000, reward=-0.3453
  Client 4: mean_dist=2.84, base_reward=-0.4184, violation=1, comm_penalty=0.1000, reward=-0.5184
  Client 5: mean_dist=2.53, base_reward=-0.2642, violation=0, comm_penalty=0.0000, reward=-0.2642
  Client 6: mean_dist=2.30, base_reward=-0.1477, violation=2, comm_penalty=0.2000, reward=-0.3477
  Client 7: mean_dist=2.80, base_reward=-0.4021, violation=0, comm_penalty=0.0000, reward=-0.4021
  Client 8: mean_dist=0.48, base_reward=0.7617, violation=0, comm_penalty=0.0000, reward=0.7617
  Client 9: mean_dist=2.35, base_reward=-0.1742, violation=0, comm_penalty=0.0000, reward=-0.1742
  RL policy loss: -0.056356
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9755
  Client 1 model accuracy on test set: 0.9745
  Client 2 model accuracy on test set: 0.9718
  Client 3 model accuracy on test set: 0.9788
  Client 4 model accuracy on test set: 0.9293
  Client 5 model accuracy on test set: 0.8911
  Client 6 model accuracy on test set: 0.9593
  Client 7 model accuracy on test set: 0.9771
  Client 8 model accuracy on test set: 0.9746
  Client 9 model accuracy on test set: 0.9760

=== Global Round 58/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=5, local_acc=1.0000
  Client 3: layers_shared=4, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=5, local_acc=1.0000
  Client 6: layers_shared=4, local_acc=1.0000
  Client 7: layers_shared=2, local_acc=1.0000
  Client 8: layers_shared=4, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=0.45, base_reward=0.7772, violation=0, comm_penalty=0.0000, reward=0.7772
  Client 1: mean_dist=0.50, base_reward=0.7525, violation=0, comm_penalty=0.0000, reward=0.7525
  Client 2: mean_dist=2.58, base_reward=-0.2887, violation=4, comm_penalty=0.4000, reward=-0.6887
  Client 3: mean_dist=2.55, base_reward=-0.2748, violation=2, comm_penalty=0.2000, reward=-0.4748
  Client 4: mean_dist=0.45, base_reward=0.7748, violation=0, comm_penalty=0.0000, reward=0.7748
  Client 5: mean_dist=2.45, base_reward=-0.2242, violation=0, comm_penalty=0.0000, reward=-0.2242
  Client 6: mean_dist=2.35, base_reward=-0.1763, violation=3, comm_penalty=0.3000, reward=-0.4763
  Client 7: mean_dist=1.42, base_reward=0.2882, violation=0, comm_penalty=0.0000, reward=0.2882
  Client 8: mean_dist=2.52, base_reward=-0.2617, violation=2, comm_penalty=0.2000, reward=-0.4617
  Client 9: mean_dist=1.93, base_reward=0.0343, violation=0, comm_penalty=0.0000, reward=0.0343
  RL policy loss: -0.240113
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9745
  Client 1 model accuracy on test set: 0.9748
  Client 2 model accuracy on test set: 0.9720
  Client 3 model accuracy on test set: 0.9793
  Client 4 model accuracy on test set: 0.9410
  Client 5 model accuracy on test set: 0.8914
  Client 6 model accuracy on test set: 0.9604
  Client 7 model accuracy on test set: 0.9773
  Client 8 model accuracy on test set: 0.9753
  Client 9 model accuracy on test set: 0.9754

=== Global Round 59/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=6, local_acc=1.0000
  Client 2: layers_shared=6, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=0.9509
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=2, local_acc=1.0000
  Client 9: layers_shared=6, local_acc=1.0000
  Client 0: mean_dist=0.45, base_reward=0.7770, violation=0, comm_penalty=0.0000, reward=0.7770
  Client 1: mean_dist=1.77, base_reward=0.1158, violation=1, comm_penalty=0.1000, reward=0.0158
  Client 2: mean_dist=1.70, base_reward=0.1500, violation=5, comm_penalty=0.5000, reward=-0.3500
  Client 3: mean_dist=0.46, base_reward=0.7696, violation=0, comm_penalty=0.0000, reward=0.7696
  Client 4: mean_dist=0.46, base_reward=0.7219, violation=0, comm_penalty=0.0000, reward=0.7219
  Client 5: mean_dist=0.44, base_reward=0.7782, violation=0, comm_penalty=0.0000, reward=0.7782
  Client 6: mean_dist=0.43, base_reward=0.7843, violation=0, comm_penalty=0.0000, reward=0.7843
  Client 7: mean_dist=0.46, base_reward=0.7699, violation=0, comm_penalty=0.0000, reward=0.7699
  Client 8: mean_dist=0.98, base_reward=0.5086, violation=0, comm_penalty=0.0000, reward=0.5086
  Client 9: mean_dist=1.66, base_reward=0.1696, violation=1, comm_penalty=0.1000, reward=0.0696
  RL policy loss: -0.182772
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9747
  Client 1 model accuracy on test set: 0.9759
  Client 2 model accuracy on test set: 0.9714
  Client 3 model accuracy on test set: 0.9801
  Client 4 model accuracy on test set: 0.8788
  Client 5 model accuracy on test set: 0.8883
  Client 6 model accuracy on test set: 0.9607
  Client 7 model accuracy on test set: 0.9776
  Client 8 model accuracy on test set: 0.9742
  Client 9 model accuracy on test set: 0.9760

=== Global Round 60/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=6, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=2, local_acc=0.9894
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=6, local_acc=1.0000
  Client 9: layers_shared=5, local_acc=1.0000
  Client 0: mean_dist=2.22, base_reward=-0.1117, violation=0, comm_penalty=0.0000, reward=-0.1117
  Client 1: mean_dist=2.84, base_reward=-0.4225, violation=1, comm_penalty=0.1000, reward=-0.5225
  Client 2: mean_dist=2.27, base_reward=-0.1346, violation=2, comm_penalty=0.2000, reward=-0.3346
  Client 3: mean_dist=0.46, base_reward=0.7687, violation=0, comm_penalty=0.0000, reward=0.7687
  Client 4: mean_dist=1.66, base_reward=0.1608, violation=0, comm_penalty=0.0000, reward=0.1608
  Client 5: mean_dist=0.44, base_reward=0.7783, violation=0, comm_penalty=0.0000, reward=0.7783
  Client 6: mean_dist=2.16, base_reward=-0.0784, violation=2, comm_penalty=0.2000, reward=-0.2784
  Client 7: mean_dist=2.27, base_reward=-0.1351, violation=0, comm_penalty=0.0000, reward=-0.1351
  Client 8: mean_dist=2.87, base_reward=-0.4371, violation=4, comm_penalty=0.4000, reward=-0.8371
  Client 9: mean_dist=2.66, base_reward=-0.3300, violation=0, comm_penalty=0.0000, reward=-0.3300
  RL policy loss: -0.160092
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9746
  Client 1 model accuracy on test set: 0.9751
  Client 2 model accuracy on test set: 0.9716
  Client 3 model accuracy on test set: 0.9789
  Client 4 model accuracy on test set: 0.9276
  Client 5 model accuracy on test set: 0.8889
  Client 6 model accuracy on test set: 0.9600
  Client 7 model accuracy on test set: 0.9796
  Client 8 model accuracy on test set: 0.9737
  Client 9 model accuracy on test set: 0.9761

=== Global Round 61/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=5, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=0.9998
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=2, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=5, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=2.43, base_reward=-0.2144, violation=2, comm_penalty=0.2000, reward=-0.4144
  Client 1: mean_dist=2.02, base_reward=-0.0099, violation=0, comm_penalty=0.0000, reward=-0.0099
  Client 2: mean_dist=2.46, base_reward=-0.2305, violation=4, comm_penalty=0.4000, reward=-0.6305
  Client 3: mean_dist=0.46, base_reward=0.7685, violation=0, comm_penalty=0.0000, reward=0.7685
  Client 4: mean_dist=0.46, base_reward=0.7682, violation=0, comm_penalty=0.0000, reward=0.7682
  Client 5: mean_dist=0.44, base_reward=0.7782, violation=0, comm_penalty=0.0000, reward=0.7782
  Client 6: mean_dist=1.35, base_reward=0.3261, violation=1, comm_penalty=0.1000, reward=0.2261
  Client 7: mean_dist=1.99, base_reward=0.0027, violation=0, comm_penalty=0.0000, reward=0.0027
  Client 8: mean_dist=2.56, base_reward=-0.2786, violation=3, comm_penalty=0.3000, reward=-0.5786
  Client 9: mean_dist=1.94, base_reward=0.0321, violation=0, comm_penalty=0.0000, reward=0.0321
  RL policy loss: -0.203039
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9752
  Client 1 model accuracy on test set: 0.9752
  Client 2 model accuracy on test set: 0.9717
  Client 3 model accuracy on test set: 0.9790
  Client 4 model accuracy on test set: 0.9352
  Client 5 model accuracy on test set: 0.8890
  Client 6 model accuracy on test set: 0.9582
  Client 7 model accuracy on test set: 0.9782
  Client 8 model accuracy on test set: 0.9743
  Client 9 model accuracy on test set: 0.9768

=== Global Round 62/100 ===
  Client 0: layers_shared=4, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=4, local_acc=1.0000
  Client 3: layers_shared=2, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=4, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=2.48, base_reward=-0.2420, violation=1, comm_penalty=0.1000, reward=-0.3420
  Client 1: mean_dist=0.49, base_reward=0.7525, violation=0, comm_penalty=0.0000, reward=0.7525
  Client 2: mean_dist=2.54, base_reward=-0.2679, violation=3, comm_penalty=0.3000, reward=-0.5679
  Client 3: mean_dist=1.64, base_reward=0.1790, violation=0, comm_penalty=0.0000, reward=0.1790
  Client 4: mean_dist=2.40, base_reward=-0.1997, violation=0, comm_penalty=0.0000, reward=-0.1997
  Client 5: mean_dist=0.44, base_reward=0.7782, violation=0, comm_penalty=0.0000, reward=0.7782
  Client 6: mean_dist=2.18, base_reward=-0.0903, violation=2, comm_penalty=0.2000, reward=-0.2903
  Client 7: mean_dist=2.29, base_reward=-0.1462, violation=0, comm_penalty=0.0000, reward=-0.1462
  Client 8: mean_dist=2.61, base_reward=-0.3063, violation=2, comm_penalty=0.2000, reward=-0.5063
  Client 9: mean_dist=2.23, base_reward=-0.1157, violation=0, comm_penalty=0.0000, reward=-0.1157
  RL policy loss: -0.166017
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9750
  Client 1 model accuracy on test set: 0.9751
  Client 2 model accuracy on test set: 0.9714
  Client 3 model accuracy on test set: 0.9792
  Client 4 model accuracy on test set: 0.9484
  Client 5 model accuracy on test set: 0.8951
  Client 6 model accuracy on test set: 0.9574
  Client 7 model accuracy on test set: 0.9782
  Client 8 model accuracy on test set: 0.9745
  Client 9 model accuracy on test set: 0.9762

=== Global Round 63/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=5, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=1.79, base_reward=0.1055, violation=0, comm_penalty=0.0000, reward=0.1055
  Client 1: mean_dist=1.87, base_reward=0.0658, violation=0, comm_penalty=0.0000, reward=0.0658
  Client 2: mean_dist=0.45, base_reward=0.7750, violation=0, comm_penalty=0.0000, reward=0.7750
  Client 3: mean_dist=1.87, base_reward=0.0626, violation=1, comm_penalty=0.1000, reward=-0.0374
  Client 4: mean_dist=2.14, base_reward=-0.0717, violation=1, comm_penalty=0.1000, reward=-0.1717
  Client 5: mean_dist=1.99, base_reward=0.0059, violation=0, comm_penalty=0.0000, reward=0.0059
  Client 6: mean_dist=0.43, base_reward=0.7843, violation=0, comm_penalty=0.0000, reward=0.7843
  Client 7: mean_dist=0.46, base_reward=0.7695, violation=0, comm_penalty=0.0000, reward=0.7695
  Client 8: mean_dist=0.47, base_reward=0.7625, violation=0, comm_penalty=0.0000, reward=0.7625
  Client 9: mean_dist=1.80, base_reward=0.1023, violation=0, comm_penalty=0.0000, reward=0.1023
  RL policy loss: -0.140855
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9755
  Client 1 model accuracy on test set: 0.9743
  Client 2 model accuracy on test set: 0.9719
  Client 3 model accuracy on test set: 0.9804
  Client 4 model accuracy on test set: 0.9440
  Client 5 model accuracy on test set: 0.8915
  Client 6 model accuracy on test set: 0.9606
  Client 7 model accuracy on test set: 0.9777
  Client 8 model accuracy on test set: 0.9733
  Client 9 model accuracy on test set: 0.9772

=== Global Round 64/100 ===
  Client 0: layers_shared=2, local_acc=1.0000
  Client 1: layers_shared=2, local_acc=1.0000
  Client 2: layers_shared=4, local_acc=1.0000
  Client 3: layers_shared=2, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=6, local_acc=1.0000
  Client 6: layers_shared=6, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=6, local_acc=1.0000
  Client 9: layers_shared=2, local_acc=1.0000
  Client 0: mean_dist=1.54, base_reward=0.2305, violation=0, comm_penalty=0.0000, reward=0.2305
  Client 1: mean_dist=1.61, base_reward=0.1944, violation=0, comm_penalty=0.0000, reward=0.1944
  Client 2: mean_dist=2.28, base_reward=-0.1395, violation=3, comm_penalty=0.3000, reward=-0.4395
  Client 3: mean_dist=1.63, base_reward=0.1861, violation=0, comm_penalty=0.0000, reward=0.1861
  Client 4: mean_dist=0.46, base_reward=0.7702, violation=0, comm_penalty=0.0000, reward=0.7702
  Client 5: mean_dist=2.42, base_reward=-0.2110, violation=0, comm_penalty=0.0000, reward=-0.2110
  Client 6: mean_dist=2.43, base_reward=-0.2173, violation=5, comm_penalty=0.5000, reward=-0.7173
  Client 7: mean_dist=0.46, base_reward=0.7695, violation=0, comm_penalty=0.0000, reward=0.7695
  Client 8: mean_dist=2.59, base_reward=-0.2972, violation=4, comm_penalty=0.4000, reward=-0.6972
  Client 9: mean_dist=1.55, base_reward=0.2271, violation=0, comm_penalty=0.0000, reward=0.2271
  RL policy loss: -0.190919
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9761
  Client 1 model accuracy on test set: 0.9752
  Client 2 model accuracy on test set: 0.9717
  Client 3 model accuracy on test set: 0.9790
  Client 4 model accuracy on test set: 0.9489
  Client 5 model accuracy on test set: 0.8880
  Client 6 model accuracy on test set: 0.9590
  Client 7 model accuracy on test set: 0.9784
  Client 8 model accuracy on test set: 0.9733
  Client 9 model accuracy on test set: 0.9760

=== Global Round 65/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=4, local_acc=1.0000
  Client 2: layers_shared=6, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=0.9388
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=6, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=6, local_acc=1.0000
  Client 0: mean_dist=0.45, base_reward=0.7761, violation=0, comm_penalty=0.0000, reward=0.7761
  Client 1: mean_dist=2.95, base_reward=-0.4751, violation=0, comm_penalty=0.0000, reward=-0.4751
  Client 2: mean_dist=3.31, base_reward=-0.6528, violation=5, comm_penalty=0.5000, reward=-1.1528
  Client 3: mean_dist=0.47, base_reward=0.7034, violation=0, comm_penalty=0.0000, reward=0.7034
  Client 4: mean_dist=3.43, base_reward=-0.7160, violation=1, comm_penalty=0.1000, reward=-0.8160
  Client 5: mean_dist=2.26, base_reward=-0.1276, violation=0, comm_penalty=0.0000, reward=-0.1276
  Client 6: mean_dist=2.26, base_reward=-0.1318, violation=2, comm_penalty=0.2000, reward=-0.3318
  Client 7: mean_dist=3.34, base_reward=-0.6683, violation=0, comm_penalty=0.0000, reward=-0.6683
  Client 8: mean_dist=2.47, base_reward=-0.2329, violation=1, comm_penalty=0.1000, reward=-0.3329
  Client 9: mean_dist=3.20, base_reward=-0.6015, violation=1, comm_penalty=0.1000, reward=-0.7015
  RL policy loss: -0.259208
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9751
  Client 1 model accuracy on test set: 0.9750
  Client 2 model accuracy on test set: 0.9718
  Client 3 model accuracy on test set: 0.8688
  Client 4 model accuracy on test set: 0.9491
  Client 5 model accuracy on test set: 0.8909
  Client 6 model accuracy on test set: 0.9598
  Client 7 model accuracy on test set: 0.9797
  Client 8 model accuracy on test set: 0.9729
  Client 9 model accuracy on test set: 0.9759

=== Global Round 66/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=6, local_acc=0.9985
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=4, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=2.18, base_reward=-0.0908, violation=2, comm_penalty=0.2000, reward=-0.2908
  Client 1: mean_dist=0.50, base_reward=0.7523, violation=0, comm_penalty=0.0000, reward=0.7523
  Client 2: mean_dist=1.84, base_reward=0.0782, violation=2, comm_penalty=0.2000, reward=-0.1218
  Client 3: mean_dist=0.47, base_reward=0.7663, violation=0, comm_penalty=0.0000, reward=0.7663
  Client 4: mean_dist=2.32, base_reward=-0.1623, violation=2, comm_penalty=0.2000, reward=-0.3623
  Client 5: mean_dist=0.44, base_reward=0.7781, violation=0, comm_penalty=0.0000, reward=0.7781
  Client 6: mean_dist=1.76, base_reward=0.1204, violation=2, comm_penalty=0.2000, reward=-0.0796
  Client 7: mean_dist=0.46, base_reward=0.7691, violation=0, comm_penalty=0.0000, reward=0.7691
  Client 8: mean_dist=2.16, base_reward=-0.0807, violation=2, comm_penalty=0.2000, reward=-0.2807
  Client 9: mean_dist=1.80, base_reward=0.1000, violation=0, comm_penalty=0.0000, reward=0.1000
  RL policy loss: -0.256338
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9755
  Client 1 model accuracy on test set: 0.9747
  Client 2 model accuracy on test set: 0.9718
  Client 3 model accuracy on test set: 0.9794
  Client 4 model accuracy on test set: 0.9422
  Client 5 model accuracy on test set: 0.8908
  Client 6 model accuracy on test set: 0.9570
  Client 7 model accuracy on test set: 0.9778
  Client 8 model accuracy on test set: 0.9742
  Client 9 model accuracy on test set: 0.9763

=== Global Round 67/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=2, local_acc=1.0000
  Client 2: layers_shared=4, local_acc=1.0000
  Client 3: layers_shared=2, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=5, local_acc=1.0000
  Client 7: layers_shared=4, local_acc=1.0000
  Client 8: layers_shared=4, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=0.45, base_reward=0.7765, violation=0, comm_penalty=0.0000, reward=0.7765
  Client 1: mean_dist=1.48, base_reward=0.2603, violation=0, comm_penalty=0.0000, reward=0.2603
  Client 2: mean_dist=2.30, base_reward=-0.1496, violation=3, comm_penalty=0.3000, reward=-0.4496
  Client 3: mean_dist=1.49, base_reward=0.2547, violation=0, comm_penalty=0.0000, reward=0.2547
  Client 4: mean_dist=2.00, base_reward=-0.0020, violation=0, comm_penalty=0.0000, reward=-0.0020
  Client 5: mean_dist=0.44, base_reward=0.7783, violation=0, comm_penalty=0.0000, reward=0.7783
  Client 6: mean_dist=2.19, base_reward=-0.0938, violation=4, comm_penalty=0.4000, reward=-0.4938
  Client 7: mean_dist=2.29, base_reward=-0.1458, violation=0, comm_penalty=0.0000, reward=-0.1458
  Client 8: mean_dist=2.35, base_reward=-0.1755, violation=2, comm_penalty=0.2000, reward=-0.3755
  Client 9: mean_dist=0.46, base_reward=0.7686, violation=0, comm_penalty=0.0000, reward=0.7686
  RL policy loss: -0.254428
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9753
  Client 1 model accuracy on test set: 0.9736
  Client 2 model accuracy on test set: 0.9718
  Client 3 model accuracy on test set: 0.9795
  Client 4 model accuracy on test set: 0.9443
  Client 5 model accuracy on test set: 0.8919
  Client 6 model accuracy on test set: 0.9601
  Client 7 model accuracy on test set: 0.9785
  Client 8 model accuracy on test set: 0.9747
  Client 9 model accuracy on test set: 0.9764

=== Global Round 68/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=2, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=5, local_acc=1.0000
  Client 0: mean_dist=2.16, base_reward=-0.0824, violation=2, comm_penalty=0.2000, reward=-0.2824
  Client 1: mean_dist=0.50, base_reward=0.7523, violation=0, comm_penalty=0.0000, reward=0.7523
  Client 2: mean_dist=1.97, base_reward=0.0168, violation=2, comm_penalty=0.2000, reward=-0.1832
  Client 3: mean_dist=0.47, base_reward=0.7667, violation=0, comm_penalty=0.0000, reward=0.7667
  Client 4: mean_dist=0.46, base_reward=0.7710, violation=0, comm_penalty=0.0000, reward=0.7710
  Client 5: mean_dist=1.34, base_reward=0.3277, violation=0, comm_penalty=0.0000, reward=0.3277
  Client 6: mean_dist=1.88, base_reward=0.0607, violation=2, comm_penalty=0.2000, reward=-0.1393
  Client 7: mean_dist=1.99, base_reward=0.0072, violation=0, comm_penalty=0.0000, reward=0.0072
  Client 8: mean_dist=2.04, base_reward=-0.0209, violation=1, comm_penalty=0.1000, reward=-0.1209
  Client 9: mean_dist=2.15, base_reward=-0.0760, violation=0, comm_penalty=0.0000, reward=-0.0760
  RL policy loss: -0.147526
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9762
  Client 1 model accuracy on test set: 0.9743
  Client 2 model accuracy on test set: 0.9713
  Client 3 model accuracy on test set: 0.9811
  Client 4 model accuracy on test set: 0.9456
  Client 5 model accuracy on test set: 0.8928
  Client 6 model accuracy on test set: 0.9592
  Client 7 model accuracy on test set: 0.9784
  Client 8 model accuracy on test set: 0.9737
  Client 9 model accuracy on test set: 0.9755

=== Global Round 69/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=6, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=4, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=6, local_acc=1.0000
  Client 0: mean_dist=0.45, base_reward=0.7765, violation=0, comm_penalty=0.0000, reward=0.7765
  Client 1: mean_dist=0.50, base_reward=0.7524, violation=0, comm_penalty=0.0000, reward=0.7524
  Client 2: mean_dist=0.45, base_reward=0.7749, violation=0, comm_penalty=0.0000, reward=0.7749
  Client 3: mean_dist=0.47, base_reward=0.7669, violation=0, comm_penalty=0.0000, reward=0.7669
  Client 4: mean_dist=0.46, base_reward=0.7711, violation=0, comm_penalty=0.0000, reward=0.7711
  Client 5: mean_dist=1.56, base_reward=0.2195, violation=0, comm_penalty=0.0000, reward=0.2195
  Client 6: mean_dist=1.18, base_reward=0.4082, violation=2, comm_penalty=0.2000, reward=0.2082
  Client 7: mean_dist=1.50, base_reward=0.2483, violation=0, comm_penalty=0.0000, reward=0.2483
  Client 8: mean_dist=0.48, base_reward=0.7622, violation=0, comm_penalty=0.0000, reward=0.7622
  Client 9: mean_dist=1.60, base_reward=0.2025, violation=1, comm_penalty=0.1000, reward=0.1025
  RL policy loss: -0.177579
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9754
  Client 1 model accuracy on test set: 0.9747
  Client 2 model accuracy on test set: 0.9722
  Client 3 model accuracy on test set: 0.9796
  Client 4 model accuracy on test set: 0.9462
  Client 5 model accuracy on test set: 0.8931
  Client 6 model accuracy on test set: 0.9612
  Client 7 model accuracy on test set: 0.9777
  Client 8 model accuracy on test set: 0.9733
  Client 9 model accuracy on test set: 0.9762

=== Global Round 70/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=2, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=0.45, base_reward=0.7766, violation=0, comm_penalty=0.0000, reward=0.7766
  Client 1: mean_dist=1.00, base_reward=0.5004, violation=0, comm_penalty=0.0000, reward=0.5004
  Client 2: mean_dist=0.96, base_reward=0.5198, violation=1, comm_penalty=0.1000, reward=0.4198
  Client 3: mean_dist=1.10, base_reward=0.4479, violation=1, comm_penalty=0.1000, reward=0.3479
  Client 4: mean_dist=0.46, base_reward=0.7713, violation=0, comm_penalty=0.0000, reward=0.7713
  Client 5: mean_dist=0.44, base_reward=0.7784, violation=0, comm_penalty=0.0000, reward=0.7784
  Client 6: mean_dist=0.43, base_reward=0.7839, violation=0, comm_penalty=0.0000, reward=0.7839
  Client 7: mean_dist=0.46, base_reward=0.7694, violation=0, comm_penalty=0.0000, reward=0.7694
  Client 8: mean_dist=1.11, base_reward=0.4439, violation=1, comm_penalty=0.1000, reward=0.3439
  Client 9: mean_dist=0.46, base_reward=0.7686, violation=0, comm_penalty=0.0000, reward=0.7686
  RL policy loss: -0.076899
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9754
  Client 1 model accuracy on test set: 0.9752
  Client 2 model accuracy on test set: 0.9709
  Client 3 model accuracy on test set: 0.9792
  Client 4 model accuracy on test set: 0.9475
  Client 5 model accuracy on test set: 0.8916
  Client 6 model accuracy on test set: 0.9589
  Client 7 model accuracy on test set: 0.9778
  Client 8 model accuracy on test set: 0.9733
  Client 9 model accuracy on test set: 0.9752

=== Global Round 71/100 ===
  Client 0: layers_shared=6, local_acc=1.0000
  Client 1: layers_shared=4, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=5, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=1.65, base_reward=0.1745, violation=3, comm_penalty=0.3000, reward=-0.1255
  Client 1: mean_dist=1.60, base_reward=0.1978, violation=0, comm_penalty=0.0000, reward=0.1978
  Client 2: mean_dist=0.45, base_reward=0.7749, violation=0, comm_penalty=0.0000, reward=0.7749
  Client 3: mean_dist=1.32, base_reward=0.3378, violation=1, comm_penalty=0.1000, reward=0.2378
  Client 4: mean_dist=0.46, base_reward=0.7714, violation=0, comm_penalty=0.0000, reward=0.7714
  Client 5: mean_dist=0.44, base_reward=0.7785, violation=0, comm_penalty=0.0000, reward=0.7785
  Client 6: mean_dist=0.43, base_reward=0.7839, violation=0, comm_penalty=0.0000, reward=0.7839
  Client 7: mean_dist=0.46, base_reward=0.7694, violation=0, comm_penalty=0.0000, reward=0.7694
  Client 8: mean_dist=1.73, base_reward=0.1355, violation=3, comm_penalty=0.3000, reward=-0.1645
  Client 9: mean_dist=0.46, base_reward=0.7687, violation=0, comm_penalty=0.0000, reward=0.7687
  RL policy loss: -0.227080
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9750
  Client 1 model accuracy on test set: 0.9750
  Client 2 model accuracy on test set: 0.9708
  Client 3 model accuracy on test set: 0.9792
  Client 4 model accuracy on test set: 0.9435
  Client 5 model accuracy on test set: 0.8917
  Client 6 model accuracy on test set: 0.9586
  Client 7 model accuracy on test set: 0.9773
  Client 8 model accuracy on test set: 0.9737
  Client 9 model accuracy on test set: 0.9762

=== Global Round 72/100 ===
  Client 0: layers_shared=2, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=4, local_acc=1.0000
  Client 5: layers_shared=6, local_acc=1.0000
  Client 6: layers_shared=2, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=1.23, base_reward=0.3836, violation=0, comm_penalty=0.0000, reward=0.3836
  Client 1: mean_dist=1.66, base_reward=0.1720, violation=0, comm_penalty=0.0000, reward=0.1720
  Client 2: mean_dist=0.45, base_reward=0.7749, violation=0, comm_penalty=0.0000, reward=0.7749
  Client 3: mean_dist=0.47, base_reward=0.7674, violation=0, comm_penalty=0.0000, reward=0.7674
  Client 4: mean_dist=1.80, base_reward=0.1016, violation=0, comm_penalty=0.0000, reward=0.1016
  Client 5: mean_dist=1.66, base_reward=0.1695, violation=0, comm_penalty=0.0000, reward=0.1695
  Client 6: mean_dist=1.20, base_reward=0.4009, violation=1, comm_penalty=0.1000, reward=0.3009
  Client 7: mean_dist=0.46, base_reward=0.7694, violation=0, comm_penalty=0.0000, reward=0.7694
  Client 8: mean_dist=1.67, base_reward=0.1662, violation=1, comm_penalty=0.1000, reward=0.0662
  Client 9: mean_dist=0.46, base_reward=0.7686, violation=0, comm_penalty=0.0000, reward=0.7686
  RL policy loss: -0.158366
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9759
  Client 1 model accuracy on test set: 0.9748
  Client 2 model accuracy on test set: 0.9718
  Client 3 model accuracy on test set: 0.9814
  Client 4 model accuracy on test set: 0.9420
  Client 5 model accuracy on test set: 0.8929
  Client 6 model accuracy on test set: 0.9601
  Client 7 model accuracy on test set: 0.9787
  Client 8 model accuracy on test set: 0.9737
  Client 9 model accuracy on test set: 0.9766

=== Global Round 73/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=2, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=1.43, base_reward=0.2826, violation=2, comm_penalty=0.2000, reward=0.0826
  Client 1: mean_dist=0.50, base_reward=0.7523, violation=0, comm_penalty=0.0000, reward=0.7523
  Client 2: mean_dist=1.47, base_reward=0.2655, violation=2, comm_penalty=0.2000, reward=0.0655
  Client 3: mean_dist=1.51, base_reward=0.2475, violation=1, comm_penalty=0.1000, reward=0.1475
  Client 4: mean_dist=1.15, base_reward=0.4242, violation=0, comm_penalty=0.0000, reward=0.4242
  Client 5: mean_dist=0.44, base_reward=0.7781, violation=0, comm_penalty=0.0000, reward=0.7781
  Client 6: mean_dist=0.43, base_reward=0.7836, violation=0, comm_penalty=0.0000, reward=0.7836
  Client 7: mean_dist=1.47, base_reward=0.2652, violation=0, comm_penalty=0.0000, reward=0.2652
  Client 8: mean_dist=0.48, base_reward=0.7621, violation=0, comm_penalty=0.0000, reward=0.7621
  Client 9: mean_dist=0.46, base_reward=0.7684, violation=0, comm_penalty=0.0000, reward=0.7684
  RL policy loss: -0.143080
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9756
  Client 1 model accuracy on test set: 0.9751
  Client 2 model accuracy on test set: 0.9714
  Client 3 model accuracy on test set: 0.9763
  Client 4 model accuracy on test set: 0.9460
  Client 5 model accuracy on test set: 0.8941
  Client 6 model accuracy on test set: 0.9605
  Client 7 model accuracy on test set: 0.9786
  Client 8 model accuracy on test set: 0.9736
  Client 9 model accuracy on test set: 0.9765

=== Global Round 74/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=4, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=2, local_acc=1.0000
  Client 8: layers_shared=6, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=0.45, base_reward=0.7764, violation=0, comm_penalty=0.0000, reward=0.7764
  Client 1: mean_dist=0.50, base_reward=0.7524, violation=0, comm_penalty=0.0000, reward=0.7524
  Client 2: mean_dist=1.11, base_reward=0.4449, violation=1, comm_penalty=0.1000, reward=0.3449
  Client 3: mean_dist=1.52, base_reward=0.2393, violation=2, comm_penalty=0.2000, reward=0.0393
  Client 4: mean_dist=0.46, base_reward=0.7712, violation=0, comm_penalty=0.0000, reward=0.7712
  Client 5: mean_dist=0.44, base_reward=0.7782, violation=0, comm_penalty=0.0000, reward=0.7782
  Client 6: mean_dist=0.43, base_reward=0.7837, violation=0, comm_penalty=0.0000, reward=0.7837
  Client 7: mean_dist=1.12, base_reward=0.4399, violation=0, comm_penalty=0.0000, reward=0.4399
  Client 8: mean_dist=1.52, base_reward=0.2394, violation=4, comm_penalty=0.4000, reward=-0.1606
  Client 9: mean_dist=1.34, base_reward=0.3320, violation=0, comm_penalty=0.0000, reward=0.3320
  RL policy loss: -0.194550
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9749
  Client 1 model accuracy on test set: 0.9750
  Client 2 model accuracy on test set: 0.9718
  Client 3 model accuracy on test set: 0.9808
  Client 4 model accuracy on test set: 0.9453
  Client 5 model accuracy on test set: 0.8874
  Client 6 model accuracy on test set: 0.9604
  Client 7 model accuracy on test set: 0.9777
  Client 8 model accuracy on test set: 0.9736
  Client 9 model accuracy on test set: 0.9765

=== Global Round 75/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=6, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=0.9905
  Client 4: layers_shared=3, local_acc=1.0000
  Client 5: layers_shared=6, local_acc=1.0000
  Client 6: layers_shared=5, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=5, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=0.45, base_reward=0.7765, violation=0, comm_penalty=0.0000, reward=0.7765
  Client 1: mean_dist=0.50, base_reward=0.7524, violation=0, comm_penalty=0.0000, reward=0.7524
  Client 2: mean_dist=2.88, base_reward=-0.4417, violation=5, comm_penalty=0.5000, reward=-0.9417
  Client 3: mean_dist=2.19, base_reward=-0.1056, violation=1, comm_penalty=0.1000, reward=-0.2056
  Client 4: mean_dist=2.23, base_reward=-0.1133, violation=0, comm_penalty=0.0000, reward=-0.1133
  Client 5: mean_dist=2.71, base_reward=-0.3538, violation=0, comm_penalty=0.0000, reward=-0.3538
  Client 6: mean_dist=2.71, base_reward=-0.3544, violation=4, comm_penalty=0.4000, reward=-0.7544
  Client 7: mean_dist=0.46, base_reward=0.7693, violation=0, comm_penalty=0.0000, reward=0.7693
  Client 8: mean_dist=2.88, base_reward=-0.4381, violation=3, comm_penalty=0.3000, reward=-0.7381
  Client 9: mean_dist=2.07, base_reward=-0.0347, violation=0, comm_penalty=0.0000, reward=-0.0347
  RL policy loss: -0.366902
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9745
  Client 1 model accuracy on test set: 0.9741
  Client 2 model accuracy on test set: 0.9717
  Client 3 model accuracy on test set: 0.9642
  Client 4 model accuracy on test set: 0.9473
  Client 5 model accuracy on test set: 0.8921
  Client 6 model accuracy on test set: 0.9576
  Client 7 model accuracy on test set: 0.9787
  Client 8 model accuracy on test set: 0.9744
  Client 9 model accuracy on test set: 0.9765

=== Global Round 76/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=4, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=4, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=4, local_acc=1.0000
  Client 9: layers_shared=6, local_acc=1.0000
  Client 0: mean_dist=0.45, base_reward=0.7766, violation=0, comm_penalty=0.0000, reward=0.7766
  Client 1: mean_dist=2.31, base_reward=-0.1533, violation=0, comm_penalty=0.0000, reward=-0.1533
  Client 2: mean_dist=0.45, base_reward=0.7750, violation=0, comm_penalty=0.0000, reward=0.7750
  Client 3: mean_dist=1.93, base_reward=0.0374, violation=1, comm_penalty=0.1000, reward=-0.0626
  Client 4: mean_dist=2.36, base_reward=-0.1800, violation=0, comm_penalty=0.0000, reward=-0.1800
  Client 5: mean_dist=0.44, base_reward=0.7781, violation=0, comm_penalty=0.0000, reward=0.7781
  Client 6: mean_dist=0.43, base_reward=0.7840, violation=0, comm_penalty=0.0000, reward=0.7840
  Client 7: mean_dist=1.88, base_reward=0.0582, violation=0, comm_penalty=0.0000, reward=0.0582
  Client 8: mean_dist=2.32, base_reward=-0.1624, violation=2, comm_penalty=0.2000, reward=-0.3624
  Client 9: mean_dist=2.21, base_reward=-0.1057, violation=1, comm_penalty=0.1000, reward=-0.2057
  RL policy loss: -0.328129
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9754
  Client 1 model accuracy on test set: 0.9749
  Client 2 model accuracy on test set: 0.9710
  Client 3 model accuracy on test set: 0.9791
  Client 4 model accuracy on test set: 0.9417
  Client 5 model accuracy on test set: 0.8917
  Client 6 model accuracy on test set: 0.9613
  Client 7 model accuracy on test set: 0.9785
  Client 8 model accuracy on test set: 0.9748
  Client 9 model accuracy on test set: 0.9765

=== Global Round 77/100 ===
  Client 0: layers_shared=6, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=4, local_acc=1.0000
  Client 3: layers_shared=6, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=2, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=1.80, base_reward=0.0986, violation=3, comm_penalty=0.3000, reward=-0.2014
  Client 1: mean_dist=0.49, base_reward=0.7525, violation=0, comm_penalty=0.0000, reward=0.7525
  Client 2: mean_dist=1.71, base_reward=0.1437, violation=3, comm_penalty=0.3000, reward=-0.1563
  Client 3: mean_dist=1.88, base_reward=0.0604, violation=4, comm_penalty=0.4000, reward=-0.3396
  Client 4: mean_dist=0.46, base_reward=0.7713, violation=0, comm_penalty=0.0000, reward=0.7713
  Client 5: mean_dist=0.44, base_reward=0.7778, violation=0, comm_penalty=0.0000, reward=0.7778
  Client 6: mean_dist=1.06, base_reward=0.4688, violation=1, comm_penalty=0.1000, reward=0.3688
  Client 7: mean_dist=0.46, base_reward=0.7692, violation=0, comm_penalty=0.0000, reward=0.7692
  Client 8: mean_dist=1.50, base_reward=0.2481, violation=1, comm_penalty=0.1000, reward=0.1481
  Client 9: mean_dist=0.46, base_reward=0.7684, violation=0, comm_penalty=0.0000, reward=0.7684
  RL policy loss: -0.301339
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9755
  Client 1 model accuracy on test set: 0.9751
  Client 2 model accuracy on test set: 0.9718
  Client 3 model accuracy on test set: 0.9790
  Client 4 model accuracy on test set: 0.9445
  Client 5 model accuracy on test set: 0.8927
  Client 6 model accuracy on test set: 0.9597
  Client 7 model accuracy on test set: 0.9764
  Client 8 model accuracy on test set: 0.9732
  Client 9 model accuracy on test set: 0.9771

=== Global Round 78/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=3, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=2, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=0.9905
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=2, local_acc=1.0000
  Client 9: layers_shared=6, local_acc=1.0000
  Client 0: mean_dist=0.45, base_reward=0.7762, violation=0, comm_penalty=0.0000, reward=0.7762
  Client 1: mean_dist=1.26, base_reward=0.3694, violation=0, comm_penalty=0.0000, reward=0.3694
  Client 2: mean_dist=1.12, base_reward=0.4416, violation=1, comm_penalty=0.1000, reward=0.3416
  Client 3: mean_dist=1.15, base_reward=0.4260, violation=0, comm_penalty=0.0000, reward=0.4260
  Client 4: mean_dist=0.46, base_reward=0.7612, violation=0, comm_penalty=0.0000, reward=0.7612
  Client 5: mean_dist=0.44, base_reward=0.7779, violation=0, comm_penalty=0.0000, reward=0.7779
  Client 6: mean_dist=0.43, base_reward=0.7840, violation=0, comm_penalty=0.0000, reward=0.7840
  Client 7: mean_dist=0.46, base_reward=0.7694, violation=0, comm_penalty=0.0000, reward=0.7694
  Client 8: mean_dist=1.15, base_reward=0.4227, violation=0, comm_penalty=0.0000, reward=0.4227
  Client 9: mean_dist=1.21, base_reward=0.3952, violation=1, comm_penalty=0.1000, reward=0.2952
  RL policy loss: -0.140670
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9743
  Client 1 model accuracy on test set: 0.9756
  Client 2 model accuracy on test set: 0.9710
  Client 3 model accuracy on test set: 0.9798
  Client 4 model accuracy on test set: 0.8752
  Client 5 model accuracy on test set: 0.8941
  Client 6 model accuracy on test set: 0.9607
  Client 7 model accuracy on test set: 0.9780
  Client 8 model accuracy on test set: 0.9731
  Client 9 model accuracy on test set: 0.9762

=== Global Round 79/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=4, local_acc=1.0000
  Client 2: layers_shared=5, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=6, local_acc=0.9697
  Client 5: layers_shared=4, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=2, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=0.45, base_reward=0.7758, violation=0, comm_penalty=0.0000, reward=0.7758
  Client 1: mean_dist=2.48, base_reward=-0.2389, violation=0, comm_penalty=0.0000, reward=-0.2389
  Client 2: mean_dist=2.56, base_reward=-0.2795, violation=4, comm_penalty=0.4000, reward=-0.6795
  Client 3: mean_dist=2.09, base_reward=-0.0453, violation=1, comm_penalty=0.1000, reward=-0.1453
  Client 4: mean_dist=2.68, base_reward=-0.3687, violation=2, comm_penalty=0.2000, reward=-0.5687
  Client 5: mean_dist=2.31, base_reward=-0.1564, violation=0, comm_penalty=0.0000, reward=-0.1564
  Client 6: mean_dist=0.43, base_reward=0.7836, violation=0, comm_penalty=0.0000, reward=0.7836
  Client 7: mean_dist=2.04, base_reward=-0.0188, violation=0, comm_penalty=0.0000, reward=-0.0188
  Client 8: mean_dist=1.50, base_reward=0.2484, violation=0, comm_penalty=0.0000, reward=0.2484
  Client 9: mean_dist=0.46, base_reward=0.7687, violation=0, comm_penalty=0.0000, reward=0.7687
  RL policy loss: -0.320026
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9753
  Client 1 model accuracy on test set: 0.9752
  Client 2 model accuracy on test set: 0.9723
  Client 3 model accuracy on test set: 0.9786
  Client 4 model accuracy on test set: 0.8448
  Client 5 model accuracy on test set: 0.8934
  Client 6 model accuracy on test set: 0.9610
  Client 7 model accuracy on test set: 0.9779
  Client 8 model accuracy on test set: 0.9746
  Client 9 model accuracy on test set: 0.9759

=== Global Round 80/100 ===
  Client 0: layers_shared=2, local_acc=1.0000
  Client 1: layers_shared=2, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=5, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=5, local_acc=1.0000
  Client 9: layers_shared=6, local_acc=1.0000
  Client 0: mean_dist=1.07, base_reward=0.4636, violation=0, comm_penalty=0.0000, reward=0.4636
  Client 1: mean_dist=1.13, base_reward=0.4371, violation=0, comm_penalty=0.0000, reward=0.4371
  Client 2: mean_dist=0.45, base_reward=0.7742, violation=0, comm_penalty=0.0000, reward=0.7742
  Client 3: mean_dist=0.47, base_reward=0.7664, violation=0, comm_penalty=0.0000, reward=0.7664
  Client 4: mean_dist=0.46, base_reward=0.7692, violation=0, comm_penalty=0.0000, reward=0.7692
  Client 5: mean_dist=0.45, base_reward=0.7775, violation=0, comm_penalty=0.0000, reward=0.7775
  Client 6: mean_dist=1.70, base_reward=0.1505, violation=4, comm_penalty=0.4000, reward=-0.2495
  Client 7: mean_dist=0.46, base_reward=0.7699, violation=0, comm_penalty=0.0000, reward=0.7699
  Client 8: mean_dist=1.81, base_reward=0.0975, violation=3, comm_penalty=0.3000, reward=-0.2025
  Client 9: mean_dist=1.73, base_reward=0.1361, violation=1, comm_penalty=0.1000, reward=0.0361
  RL policy loss: -0.269013
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9749
  Client 1 model accuracy on test set: 0.9752
  Client 2 model accuracy on test set: 0.9719
  Client 3 model accuracy on test set: 0.9794
  Client 4 model accuracy on test set: 0.9470
  Client 5 model accuracy on test set: 0.8915
  Client 6 model accuracy on test set: 0.9597
  Client 7 model accuracy on test set: 0.9776
  Client 8 model accuracy on test set: 0.9735
  Client 9 model accuracy on test set: 0.9761

=== Global Round 81/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=5, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=6, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=0.45, base_reward=0.7764, violation=0, comm_penalty=0.0000, reward=0.7764
  Client 1: mean_dist=0.50, base_reward=0.7520, violation=0, comm_penalty=0.0000, reward=0.7520
  Client 2: mean_dist=1.26, base_reward=0.3682, violation=4, comm_penalty=0.4000, reward=-0.0318
  Client 3: mean_dist=0.47, base_reward=0.7662, violation=0, comm_penalty=0.0000, reward=0.7662
  Client 4: mean_dist=0.46, base_reward=0.7694, violation=0, comm_penalty=0.0000, reward=0.7694
  Client 5: mean_dist=0.44, base_reward=0.7775, violation=0, comm_penalty=0.0000, reward=0.7775
  Client 6: mean_dist=0.43, base_reward=0.7833, violation=0, comm_penalty=0.0000, reward=0.7833
  Client 7: mean_dist=1.03, base_reward=0.4868, violation=0, comm_penalty=0.0000, reward=0.4868
  Client 8: mean_dist=1.30, base_reward=0.3476, violation=4, comm_penalty=0.4000, reward=-0.0524
  Client 9: mean_dist=0.46, base_reward=0.7683, violation=0, comm_penalty=0.0000, reward=0.7683
  RL policy loss: -0.207656
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9751
  Client 1 model accuracy on test set: 0.9752
  Client 2 model accuracy on test set: 0.9721
  Client 3 model accuracy on test set: 0.9788
  Client 4 model accuracy on test set: 0.9443
  Client 5 model accuracy on test set: 0.8968
  Client 6 model accuracy on test set: 0.9613
  Client 7 model accuracy on test set: 0.9776
  Client 8 model accuracy on test set: 0.9729
  Client 9 model accuracy on test set: 0.9764

=== Global Round 82/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=4, local_acc=1.0000
  Client 4: layers_shared=4, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=6, local_acc=1.0000
  Client 7: layers_shared=2, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=5, local_acc=1.0000
  Client 0: mean_dist=2.43, base_reward=-0.2126, violation=2, comm_penalty=0.2000, reward=-0.4126
  Client 1: mean_dist=0.50, base_reward=0.7521, violation=0, comm_penalty=0.0000, reward=0.7521
  Client 2: mean_dist=0.45, base_reward=0.7741, violation=0, comm_penalty=0.0000, reward=0.7741
  Client 3: mean_dist=2.30, base_reward=-0.1505, violation=2, comm_penalty=0.2000, reward=-0.3505
  Client 4: mean_dist=2.36, base_reward=-0.1813, violation=0, comm_penalty=0.0000, reward=-0.1813
  Client 5: mean_dist=0.44, base_reward=0.7775, violation=0, comm_penalty=0.0000, reward=0.7775
  Client 6: mean_dist=2.38, base_reward=-0.1915, violation=5, comm_penalty=0.5000, reward=-0.6915
  Client 7: mean_dist=1.28, base_reward=0.3603, violation=0, comm_penalty=0.0000, reward=0.3603
  Client 8: mean_dist=0.48, base_reward=0.7625, violation=0, comm_penalty=0.0000, reward=0.7625
  Client 9: mean_dist=2.42, base_reward=-0.2080, violation=0, comm_penalty=0.0000, reward=-0.2080
  RL policy loss: -0.407978
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9751
  Client 1 model accuracy on test set: 0.9755
  Client 2 model accuracy on test set: 0.9727
  Client 3 model accuracy on test set: 0.9804
  Client 4 model accuracy on test set: 0.9459
  Client 5 model accuracy on test set: 0.8955
  Client 6 model accuracy on test set: 0.9584
  Client 7 model accuracy on test set: 0.9781
  Client 8 model accuracy on test set: 0.9750
  Client 9 model accuracy on test set: 0.9767

=== Global Round 83/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=4, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=4, local_acc=1.0000
  Client 0: mean_dist=0.45, base_reward=0.7765, violation=0, comm_penalty=0.0000, reward=0.7765
  Client 1: mean_dist=0.50, base_reward=0.7520, violation=0, comm_penalty=0.0000, reward=0.7520
  Client 2: mean_dist=1.11, base_reward=0.4431, violation=1, comm_penalty=0.1000, reward=0.3431
  Client 3: mean_dist=1.50, base_reward=0.2500, violation=1, comm_penalty=0.1000, reward=0.1500
  Client 4: mean_dist=0.46, base_reward=0.7692, violation=0, comm_penalty=0.0000, reward=0.7692
  Client 5: mean_dist=0.45, base_reward=0.7773, violation=0, comm_penalty=0.0000, reward=0.7773
  Client 6: mean_dist=1.50, base_reward=0.2478, violation=3, comm_penalty=0.3000, reward=-0.0522
  Client 7: mean_dist=0.46, base_reward=0.7699, violation=0, comm_penalty=0.0000, reward=0.7699
  Client 8: mean_dist=1.49, base_reward=0.2564, violation=1, comm_penalty=0.1000, reward=0.1564
  Client 9: mean_dist=1.54, base_reward=0.2301, violation=0, comm_penalty=0.0000, reward=0.2301
  RL policy loss: -0.232053
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9755
  Client 1 model accuracy on test set: 0.9752
  Client 2 model accuracy on test set: 0.9711
  Client 3 model accuracy on test set: 0.9801
  Client 4 model accuracy on test set: 0.9475
  Client 5 model accuracy on test set: 0.8905
  Client 6 model accuracy on test set: 0.9605
  Client 7 model accuracy on test set: 0.9779
  Client 8 model accuracy on test set: 0.9748
  Client 9 model accuracy on test set: 0.9766

=== Global Round 84/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=4, local_acc=1.0000
  Client 4: layers_shared=6, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=2, local_acc=1.0000
  Client 8: layers_shared=6, local_acc=1.0000
  Client 9: layers_shared=2, local_acc=1.0000
  Client 0: mean_dist=0.45, base_reward=0.7765, violation=0, comm_penalty=0.0000, reward=0.7765
  Client 1: mean_dist=0.50, base_reward=0.7520, violation=0, comm_penalty=0.0000, reward=0.7520
  Client 2: mean_dist=0.45, base_reward=0.7741, violation=0, comm_penalty=0.0000, reward=0.7741
  Client 3: mean_dist=1.68, base_reward=0.1614, violation=2, comm_penalty=0.2000, reward=-0.0386
  Client 4: mean_dist=1.87, base_reward=0.0666, violation=2, comm_penalty=0.2000, reward=-0.1334
  Client 5: mean_dist=0.45, base_reward=0.7774, violation=0, comm_penalty=0.0000, reward=0.7774
  Client 6: mean_dist=0.43, base_reward=0.7833, violation=0, comm_penalty=0.0000, reward=0.7833
  Client 7: mean_dist=1.14, base_reward=0.4318, violation=0, comm_penalty=0.0000, reward=0.4318
  Client 8: mean_dist=1.85, base_reward=0.0727, violation=4, comm_penalty=0.4000, reward=-0.3273
  Client 9: mean_dist=1.13, base_reward=0.4367, violation=0, comm_penalty=0.0000, reward=0.4367
  RL policy loss: -0.303370
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9755
  Client 1 model accuracy on test set: 0.9745
  Client 2 model accuracy on test set: 0.9720
  Client 3 model accuracy on test set: 0.9793
  Client 4 model accuracy on test set: 0.9456
  Client 5 model accuracy on test set: 0.8934
  Client 6 model accuracy on test set: 0.9599
  Client 7 model accuracy on test set: 0.9782
  Client 8 model accuracy on test set: 0.9741
  Client 9 model accuracy on test set: 0.9769

=== Global Round 85/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=2, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=2, local_acc=0.9998
  Client 4: layers_shared=4, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=5, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=2, local_acc=1.0000
  Client 0: mean_dist=0.45, base_reward=0.7764, violation=0, comm_penalty=0.0000, reward=0.7764
  Client 1: mean_dist=1.48, base_reward=0.2607, violation=0, comm_penalty=0.0000, reward=0.2607
  Client 2: mean_dist=1.82, base_reward=0.0923, violation=2, comm_penalty=0.2000, reward=-0.1077
  Client 3: mean_dist=1.50, base_reward=0.2520, violation=0, comm_penalty=0.0000, reward=0.2520
  Client 4: mean_dist=2.04, base_reward=-0.0180, violation=0, comm_penalty=0.0000, reward=-0.0180
  Client 5: mean_dist=0.45, base_reward=0.7771, violation=0, comm_penalty=0.0000, reward=0.7771
  Client 6: mean_dist=1.86, base_reward=0.0706, violation=4, comm_penalty=0.4000, reward=-0.3294
  Client 7: mean_dist=0.46, base_reward=0.7694, violation=0, comm_penalty=0.0000, reward=0.7694
  Client 8: mean_dist=1.86, base_reward=0.0712, violation=1, comm_penalty=0.1000, reward=-0.0288
  Client 9: mean_dist=1.42, base_reward=0.2888, violation=0, comm_penalty=0.0000, reward=0.2888
  RL policy loss: -0.231496
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9756
  Client 1 model accuracy on test set: 0.9745
  Client 2 model accuracy on test set: 0.9711
  Client 3 model accuracy on test set: 0.9705
  Client 4 model accuracy on test set: 0.9449
  Client 5 model accuracy on test set: 0.8893
  Client 6 model accuracy on test set: 0.9602
  Client 7 model accuracy on test set: 0.9776
  Client 8 model accuracy on test set: 0.9755
  Client 9 model accuracy on test set: 0.9772

=== Global Round 86/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=6, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=1.42, base_reward=0.2914, violation=0, comm_penalty=0.0000, reward=0.2914
  Client 1: mean_dist=0.50, base_reward=0.7517, violation=0, comm_penalty=0.0000, reward=0.7517
  Client 2: mean_dist=1.11, base_reward=0.4452, violation=1, comm_penalty=0.1000, reward=0.3452
  Client 3: mean_dist=0.47, base_reward=0.7644, violation=0, comm_penalty=0.0000, reward=0.7644
  Client 4: mean_dist=1.52, base_reward=0.2385, violation=2, comm_penalty=0.2000, reward=0.0385
  Client 5: mean_dist=0.45, base_reward=0.7771, violation=0, comm_penalty=0.0000, reward=0.7771
  Client 6: mean_dist=1.39, base_reward=0.3045, violation=2, comm_penalty=0.2000, reward=0.1045
  Client 7: mean_dist=0.46, base_reward=0.7695, violation=0, comm_penalty=0.0000, reward=0.7695
  Client 8: mean_dist=0.48, base_reward=0.7624, violation=0, comm_penalty=0.0000, reward=0.7624
  Client 9: mean_dist=1.43, base_reward=0.2868, violation=0, comm_penalty=0.0000, reward=0.2868
  RL policy loss: -0.200180
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9763
  Client 1 model accuracy on test set: 0.9749
  Client 2 model accuracy on test set: 0.9719
  Client 3 model accuracy on test set: 0.9806
  Client 4 model accuracy on test set: 0.9435
  Client 5 model accuracy on test set: 0.8912
  Client 6 model accuracy on test set: 0.9595
  Client 7 model accuracy on test set: 0.9772
  Client 8 model accuracy on test set: 0.9745
  Client 9 model accuracy on test set: 0.9773

=== Global Round 87/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=2, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=2, local_acc=1.0000
  Client 0: mean_dist=0.45, base_reward=0.7763, violation=0, comm_penalty=0.0000, reward=0.7763
  Client 1: mean_dist=0.50, base_reward=0.7518, violation=0, comm_penalty=0.0000, reward=0.7518
  Client 2: mean_dist=0.45, base_reward=0.7740, violation=0, comm_penalty=0.0000, reward=0.7740
  Client 3: mean_dist=0.82, base_reward=0.5925, violation=0, comm_penalty=0.0000, reward=0.5925
  Client 4: mean_dist=0.81, base_reward=0.5941, violation=0, comm_penalty=0.0000, reward=0.5941
  Client 5: mean_dist=0.45, base_reward=0.7772, violation=0, comm_penalty=0.0000, reward=0.7772
  Client 6: mean_dist=0.43, base_reward=0.7831, violation=0, comm_penalty=0.0000, reward=0.7831
  Client 7: mean_dist=0.46, base_reward=0.7695, violation=0, comm_penalty=0.0000, reward=0.7695
  Client 8: mean_dist=0.48, base_reward=0.7624, violation=0, comm_penalty=0.0000, reward=0.7624
  Client 9: mean_dist=0.80, base_reward=0.5989, violation=0, comm_penalty=0.0000, reward=0.5989
  RL policy loss: -0.050880
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9751
  Client 1 model accuracy on test set: 0.9751
  Client 2 model accuracy on test set: 0.9726
  Client 3 model accuracy on test set: 0.9813
  Client 4 model accuracy on test set: 0.9488
  Client 5 model accuracy on test set: 0.8896
  Client 6 model accuracy on test set: 0.9593
  Client 7 model accuracy on test set: 0.9764
  Client 8 model accuracy on test set: 0.9733
  Client 9 model accuracy on test set: 0.9768

=== Global Round 88/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=5, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=0.9602
  Client 5: layers_shared=6, local_acc=1.0000
  Client 6: layers_shared=2, local_acc=1.0000
  Client 7: layers_shared=4, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=2, local_acc=1.0000
  Client 0: mean_dist=2.17, base_reward=-0.0851, violation=2, comm_penalty=0.2000, reward=-0.2851
  Client 1: mean_dist=0.50, base_reward=0.7510, violation=0, comm_penalty=0.0000, reward=0.7510
  Client 2: mean_dist=0.45, base_reward=0.7735, violation=0, comm_penalty=0.0000, reward=0.7735
  Client 3: mean_dist=2.26, base_reward=-0.1311, violation=3, comm_penalty=0.3000, reward=-0.4311
  Client 4: mean_dist=0.47, base_reward=0.7236, violation=0, comm_penalty=0.0000, reward=0.7236
  Client 5: mean_dist=2.15, base_reward=-0.0758, violation=0, comm_penalty=0.0000, reward=-0.0758
  Client 6: mean_dist=1.19, base_reward=0.4040, violation=1, comm_penalty=0.1000, reward=0.3040
  Client 7: mean_dist=1.99, base_reward=0.0032, violation=0, comm_penalty=0.0000, reward=0.0032
  Client 8: mean_dist=0.48, base_reward=0.7618, violation=0, comm_penalty=0.0000, reward=0.7618
  Client 9: mean_dist=1.24, base_reward=0.3797, violation=0, comm_penalty=0.0000, reward=0.3797
  RL policy loss: -0.354117
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9757
  Client 1 model accuracy on test set: 0.9751
  Client 2 model accuracy on test set: 0.9725
  Client 3 model accuracy on test set: 0.9808
  Client 4 model accuracy on test set: 0.8444
  Client 5 model accuracy on test set: 0.8930
  Client 6 model accuracy on test set: 0.9595
  Client 7 model accuracy on test set: 0.9783
  Client 8 model accuracy on test set: 0.9738
  Client 9 model accuracy on test set: 0.9767

=== Global Round 89/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=5, local_acc=1.0000
  Client 2: layers_shared=4, local_acc=1.0000
  Client 3: layers_shared=4, local_acc=1.0000
  Client 4: layers_shared=6, local_acc=1.0000
  Client 5: layers_shared=3, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=4, local_acc=1.0000
  Client 8: layers_shared=6, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=2.38, base_reward=-0.1880, violation=0, comm_penalty=0.0000, reward=-0.1880
  Client 1: mean_dist=3.42, base_reward=-0.7099, violation=0, comm_penalty=0.0000, reward=-0.7099
  Client 2: mean_dist=3.10, base_reward=-0.5491, violation=3, comm_penalty=0.3000, reward=-0.8491
  Client 3: mean_dist=3.18, base_reward=-0.5889, violation=2, comm_penalty=0.2000, reward=-0.7889
  Client 4: mean_dist=3.60, base_reward=-0.7989, violation=2, comm_penalty=0.2000, reward=-0.9989
  Client 5: mean_dist=2.31, base_reward=-0.1563, violation=0, comm_penalty=0.0000, reward=-0.1563
  Client 6: mean_dist=0.44, base_reward=0.7823, violation=0, comm_penalty=0.0000, reward=0.7823
  Client 7: mean_dist=3.12, base_reward=-0.5579, violation=0, comm_penalty=0.0000, reward=-0.5579
  Client 8: mean_dist=3.48, base_reward=-0.7403, violation=4, comm_penalty=0.4000, reward=-1.1403
  Client 9: mean_dist=0.47, base_reward=0.7670, violation=0, comm_penalty=0.0000, reward=0.7670
  RL policy loss: -0.464778
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9757
  Client 1 model accuracy on test set: 0.9751
  Client 2 model accuracy on test set: 0.9725
  Client 3 model accuracy on test set: 0.9807
  Client 4 model accuracy on test set: 0.9436
  Client 5 model accuracy on test set: 0.8906
  Client 6 model accuracy on test set: 0.9588
  Client 7 model accuracy on test set: 0.9790
  Client 8 model accuracy on test set: 0.9758
  Client 9 model accuracy on test set: 0.9769

=== Global Round 90/100 ===
  Client 0: layers_shared=2, local_acc=1.0000
  Client 1: layers_shared=4, local_acc=1.0000
  Client 2: layers_shared=2, local_acc=1.0000
  Client 3: layers_shared=2, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=1.40, base_reward=0.2991, violation=0, comm_penalty=0.0000, reward=0.2991
  Client 1: mean_dist=1.81, base_reward=0.0929, violation=0, comm_penalty=0.0000, reward=0.0929
  Client 2: mean_dist=1.45, base_reward=0.2736, violation=1, comm_penalty=0.1000, reward=0.1736
  Client 3: mean_dist=1.49, base_reward=0.2558, violation=0, comm_penalty=0.0000, reward=0.2558
  Client 4: mean_dist=1.90, base_reward=0.0484, violation=0, comm_penalty=0.0000, reward=0.0484
  Client 5: mean_dist=0.45, base_reward=0.7760, violation=0, comm_penalty=0.0000, reward=0.7760
  Client 6: mean_dist=1.71, base_reward=0.1441, violation=2, comm_penalty=0.2000, reward=-0.0559
  Client 7: mean_dist=0.46, base_reward=0.7688, violation=0, comm_penalty=0.0000, reward=0.7688
  Client 8: mean_dist=0.48, base_reward=0.7617, violation=0, comm_penalty=0.0000, reward=0.7617
  Client 9: mean_dist=1.75, base_reward=0.1250, violation=0, comm_penalty=0.0000, reward=0.1250
  RL policy loss: -0.202686
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9748
  Client 1 model accuracy on test set: 0.9755
  Client 2 model accuracy on test set: 0.9720
  Client 3 model accuracy on test set: 0.9800
  Client 4 model accuracy on test set: 0.9472
  Client 5 model accuracy on test set: 0.8966
  Client 6 model accuracy on test set: 0.9592
  Client 7 model accuracy on test set: 0.9764
  Client 8 model accuracy on test set: 0.9730
  Client 9 model accuracy on test set: 0.9765

=== Global Round 91/100 ===
  Client 0: layers_shared=6, local_acc=1.0000
  Client 1: layers_shared=2, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=6, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=5, local_acc=1.0000
  Client 6: layers_shared=6, local_acc=1.0000
  Client 7: layers_shared=6, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=2.72, base_reward=-0.3611, violation=3, comm_penalty=0.3000, reward=-0.6611
  Client 1: mean_dist=1.29, base_reward=0.3570, violation=0, comm_penalty=0.0000, reward=0.3570
  Client 2: mean_dist=0.45, base_reward=0.7731, violation=0, comm_penalty=0.0000, reward=0.7731
  Client 3: mean_dist=2.85, base_reward=-0.4259, violation=4, comm_penalty=0.4000, reward=-0.8259
  Client 4: mean_dist=0.47, base_reward=0.7625, violation=0, comm_penalty=0.0000, reward=0.7625
  Client 5: mean_dist=2.61, base_reward=-0.3046, violation=0, comm_penalty=0.0000, reward=-0.3046
  Client 6: mean_dist=2.68, base_reward=-0.3421, violation=5, comm_penalty=0.5000, reward=-0.8421
  Client 7: mean_dist=2.81, base_reward=-0.4040, violation=0, comm_penalty=0.0000, reward=-0.4040
  Client 8: mean_dist=0.48, base_reward=0.7618, violation=0, comm_penalty=0.0000, reward=0.7618
  Client 9: mean_dist=0.47, base_reward=0.7671, violation=0, comm_penalty=0.0000, reward=0.7671
  RL policy loss: -0.573934
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9745
  Client 1 model accuracy on test set: 0.9751
  Client 2 model accuracy on test set: 0.9721
  Client 3 model accuracy on test set: 0.9814
  Client 4 model accuracy on test set: 0.9487
  Client 5 model accuracy on test set: 0.8945
  Client 6 model accuracy on test set: 0.9611
  Client 7 model accuracy on test set: 0.9766
  Client 8 model accuracy on test set: 0.9732
  Client 9 model accuracy on test set: 0.9773

=== Global Round 92/100 ===
  Client 0: layers_shared=5, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=5, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=1.28, base_reward=0.3599, violation=2, comm_penalty=0.2000, reward=0.1599
  Client 1: mean_dist=0.50, base_reward=0.7512, violation=0, comm_penalty=0.0000, reward=0.7512
  Client 2: mean_dist=0.45, base_reward=0.7732, violation=0, comm_penalty=0.0000, reward=0.7732
  Client 3: mean_dist=0.47, base_reward=0.7648, violation=0, comm_penalty=0.0000, reward=0.7648
  Client 4: mean_dist=1.34, base_reward=0.3322, violation=1, comm_penalty=0.1000, reward=0.2322
  Client 5: mean_dist=0.45, base_reward=0.7760, violation=0, comm_penalty=0.0000, reward=0.7760
  Client 6: mean_dist=0.44, base_reward=0.7824, violation=0, comm_penalty=0.0000, reward=0.7824
  Client 7: mean_dist=1.04, base_reward=0.4791, violation=0, comm_penalty=0.0000, reward=0.4791
  Client 8: mean_dist=0.48, base_reward=0.7617, violation=0, comm_penalty=0.0000, reward=0.7617
  Client 9: mean_dist=0.47, base_reward=0.7672, violation=0, comm_penalty=0.0000, reward=0.7672
  RL policy loss: -0.186578
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9747
  Client 1 model accuracy on test set: 0.9747
  Client 2 model accuracy on test set: 0.9719
  Client 3 model accuracy on test set: 0.9815
  Client 4 model accuracy on test set: 0.9468
  Client 5 model accuracy on test set: 0.8958
  Client 6 model accuracy on test set: 0.9594
  Client 7 model accuracy on test set: 0.9784
  Client 8 model accuracy on test set: 0.9750
  Client 9 model accuracy on test set: 0.9769

=== Global Round 93/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=6, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=4, local_acc=0.8305
  Client 4: layers_shared=3, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=6, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=3, local_acc=1.0000
  Client 0: mean_dist=2.37, base_reward=-0.1855, violation=0, comm_penalty=0.0000, reward=-0.1855
  Client 1: mean_dist=2.87, base_reward=-0.4346, violation=1, comm_penalty=0.1000, reward=-0.5346
  Client 2: mean_dist=0.45, base_reward=0.7732, violation=0, comm_penalty=0.0000, reward=0.7732
  Client 3: mean_dist=2.77, base_reward=-0.5537, violation=2, comm_penalty=0.2000, reward=-0.7537
  Client 4: mean_dist=2.59, base_reward=-0.2971, violation=0, comm_penalty=0.0000, reward=-0.2971
  Client 5: mean_dist=0.45, base_reward=0.7759, violation=0, comm_penalty=0.0000, reward=0.7759
  Client 6: mean_dist=2.72, base_reward=-0.3603, violation=5, comm_penalty=0.5000, reward=-0.8603
  Client 7: mean_dist=2.43, base_reward=-0.2165, violation=0, comm_penalty=0.0000, reward=-0.2165
  Client 8: mean_dist=2.51, base_reward=-0.2542, violation=1, comm_penalty=0.1000, reward=-0.3542
  Client 9: mean_dist=2.36, base_reward=-0.1818, violation=0, comm_penalty=0.0000, reward=-0.1818
  RL policy loss: -0.356652
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9751
  Client 1 model accuracy on test set: 0.9752
  Client 2 model accuracy on test set: 0.9716
  Client 3 model accuracy on test set: 0.7833
  Client 4 model accuracy on test set: 0.9496
  Client 5 model accuracy on test set: 0.8915
  Client 6 model accuracy on test set: 0.9596
  Client 7 model accuracy on test set: 0.9773
  Client 8 model accuracy on test set: 0.9737
  Client 9 model accuracy on test set: 0.9764

=== Global Round 94/100 ===
  Client 0: layers_shared=2, local_acc=1.0000
  Client 1: layers_shared=4, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=3, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=3, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=1.25, base_reward=0.3760, violation=0, comm_penalty=0.0000, reward=0.3760
  Client 1: mean_dist=1.78, base_reward=0.1125, violation=0, comm_penalty=0.0000, reward=0.1125
  Client 2: mean_dist=0.45, base_reward=0.7732, violation=0, comm_penalty=0.0000, reward=0.7732
  Client 3: mean_dist=1.79, base_reward=0.1033, violation=1, comm_penalty=0.1000, reward=0.0033
  Client 4: mean_dist=0.47, base_reward=0.7632, violation=0, comm_penalty=0.0000, reward=0.7632
  Client 5: mean_dist=0.45, base_reward=0.7761, violation=0, comm_penalty=0.0000, reward=0.7761
  Client 6: mean_dist=1.66, base_reward=0.1703, violation=2, comm_penalty=0.2000, reward=-0.0297
  Client 7: mean_dist=1.75, base_reward=0.1267, violation=0, comm_penalty=0.0000, reward=0.1267
  Client 8: mean_dist=1.80, base_reward=0.1015, violation=1, comm_penalty=0.1000, reward=0.0015
  Client 9: mean_dist=0.47, base_reward=0.7673, violation=0, comm_penalty=0.0000, reward=0.7673
  RL policy loss: -0.243712
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9753
  Client 1 model accuracy on test set: 0.9755
  Client 2 model accuracy on test set: 0.9720
  Client 3 model accuracy on test set: 0.9775
  Client 4 model accuracy on test set: 0.9492
  Client 5 model accuracy on test set: 0.8916
  Client 6 model accuracy on test set: 0.9593
  Client 7 model accuracy on test set: 0.9777
  Client 8 model accuracy on test set: 0.9744
  Client 9 model accuracy on test set: 0.9769

=== Global Round 95/100 ===
  Client 0: layers_shared=2, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=1.0000
  Client 5: layers_shared=6, local_acc=1.0000
  Client 6: layers_shared=2, local_acc=1.0000
  Client 7: layers_shared=5, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=1.41, base_reward=0.2974, violation=0, comm_penalty=0.0000, reward=0.2974
  Client 1: mean_dist=0.50, base_reward=0.7514, violation=0, comm_penalty=0.0000, reward=0.7514
  Client 2: mean_dist=1.91, base_reward=0.0452, violation=2, comm_penalty=0.2000, reward=-0.1548
  Client 3: mean_dist=0.47, base_reward=0.7658, violation=0, comm_penalty=0.0000, reward=0.7658
  Client 4: mean_dist=2.03, base_reward=-0.0155, violation=0, comm_penalty=0.0000, reward=-0.0155
  Client 5: mean_dist=2.07, base_reward=-0.0341, violation=0, comm_penalty=0.0000, reward=-0.0341
  Client 6: mean_dist=1.37, base_reward=0.3162, violation=1, comm_penalty=0.1000, reward=0.2162
  Client 7: mean_dist=2.17, base_reward=-0.0849, violation=0, comm_penalty=0.0000, reward=-0.0849
  Client 8: mean_dist=1.97, base_reward=0.0162, violation=1, comm_penalty=0.1000, reward=-0.0838
  Client 9: mean_dist=0.47, base_reward=0.7673, violation=0, comm_penalty=0.0000, reward=0.7673
  RL policy loss: -0.277199
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9755
  Client 1 model accuracy on test set: 0.9760
  Client 2 model accuracy on test set: 0.9721
  Client 3 model accuracy on test set: 0.9792
  Client 4 model accuracy on test set: 0.9462
  Client 5 model accuracy on test set: 0.8916
  Client 6 model accuracy on test set: 0.9595
  Client 7 model accuracy on test set: 0.9776
  Client 8 model accuracy on test set: 0.9734
  Client 9 model accuracy on test set: 0.9766

=== Global Round 96/100 ===
  Client 0: layers_shared=2, local_acc=1.0000
  Client 1: layers_shared=5, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=3, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=3, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=3, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=1.09, base_reward=0.4531, violation=0, comm_penalty=0.0000, reward=0.4531
  Client 1: mean_dist=1.51, base_reward=0.2432, violation=0, comm_penalty=0.0000, reward=0.2432
  Client 2: mean_dist=0.45, base_reward=0.7734, violation=0, comm_penalty=0.0000, reward=0.7734
  Client 3: mean_dist=0.47, base_reward=0.7659, violation=0, comm_penalty=0.0000, reward=0.7659
  Client 4: mean_dist=1.56, base_reward=0.2210, violation=0, comm_penalty=0.0000, reward=0.2210
  Client 5: mean_dist=0.45, base_reward=0.7762, violation=0, comm_penalty=0.0000, reward=0.7762
  Client 6: mean_dist=1.41, base_reward=0.2956, violation=2, comm_penalty=0.2000, reward=0.0956
  Client 7: mean_dist=0.46, base_reward=0.7690, violation=0, comm_penalty=0.0000, reward=0.7690
  Client 8: mean_dist=1.52, base_reward=0.2377, violation=1, comm_penalty=0.1000, reward=0.1377
  Client 9: mean_dist=0.47, base_reward=0.7674, violation=0, comm_penalty=0.0000, reward=0.7674
  RL policy loss: -0.212232
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9745
  Client 1 model accuracy on test set: 0.9751
  Client 2 model accuracy on test set: 0.9729
  Client 3 model accuracy on test set: 0.9804
  Client 4 model accuracy on test set: 0.9493
  Client 5 model accuracy on test set: 0.8919
  Client 6 model accuracy on test set: 0.9609
  Client 7 model accuracy on test set: 0.9781
  Client 8 model accuracy on test set: 0.9746
  Client 9 model accuracy on test set: 0.9764

=== Global Round 97/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=4, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=1.0000
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=2, local_acc=1.0000
  Client 7: layers_shared=5, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=1.14, base_reward=0.4283, violation=0, comm_penalty=0.0000, reward=0.4283
  Client 1: mean_dist=0.50, base_reward=0.7515, violation=0, comm_penalty=0.0000, reward=0.7515
  Client 2: mean_dist=1.29, base_reward=0.3557, violation=3, comm_penalty=0.3000, reward=0.0557
  Client 3: mean_dist=0.47, base_reward=0.7658, violation=0, comm_penalty=0.0000, reward=0.7658
  Client 4: mean_dist=0.47, base_reward=0.7642, violation=0, comm_penalty=0.0000, reward=0.7642
  Client 5: mean_dist=0.45, base_reward=0.7762, violation=0, comm_penalty=0.0000, reward=0.7762
  Client 6: mean_dist=0.90, base_reward=0.5519, violation=1, comm_penalty=0.1000, reward=0.4519
  Client 7: mean_dist=1.30, base_reward=0.3523, violation=0, comm_penalty=0.0000, reward=0.3523
  Client 8: mean_dist=0.48, base_reward=0.7620, violation=0, comm_penalty=0.0000, reward=0.7620
  Client 9: mean_dist=0.47, base_reward=0.7674, violation=0, comm_penalty=0.0000, reward=0.7674
  RL policy loss: -0.208796
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9757
  Client 1 model accuracy on test set: 0.9751
  Client 2 model accuracy on test set: 0.9723
  Client 3 model accuracy on test set: 0.9787
  Client 4 model accuracy on test set: 0.9506
  Client 5 model accuracy on test set: 0.8946
  Client 6 model accuracy on test set: 0.9594
  Client 7 model accuracy on test set: 0.9777
  Client 8 model accuracy on test set: 0.9753
  Client 9 model accuracy on test set: 0.9767

=== Global Round 98/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=3, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=2, local_acc=1.0000
  Client 5: layers_shared=5, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=0.45, base_reward=0.7756, violation=0, comm_penalty=0.0000, reward=0.7756
  Client 1: mean_dist=0.50, base_reward=0.7515, violation=0, comm_penalty=0.0000, reward=0.7515
  Client 2: mean_dist=0.90, base_reward=0.5502, violation=2, comm_penalty=0.2000, reward=0.3502
  Client 3: mean_dist=0.47, base_reward=0.7658, violation=0, comm_penalty=0.0000, reward=0.7658
  Client 4: mean_dist=0.82, base_reward=0.5884, violation=0, comm_penalty=0.0000, reward=0.5884
  Client 5: mean_dist=0.88, base_reward=0.5622, violation=0, comm_penalty=0.0000, reward=0.5622
  Client 6: mean_dist=0.44, base_reward=0.7825, violation=0, comm_penalty=0.0000, reward=0.7825
  Client 7: mean_dist=0.46, base_reward=0.7689, violation=0, comm_penalty=0.0000, reward=0.7689
  Client 8: mean_dist=0.48, base_reward=0.7620, violation=0, comm_penalty=0.0000, reward=0.7620
  Client 9: mean_dist=0.47, base_reward=0.7674, violation=0, comm_penalty=0.0000, reward=0.7674
  RL policy loss: -0.094370
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9753
  Client 1 model accuracy on test set: 0.9753
  Client 2 model accuracy on test set: 0.9710
  Client 3 model accuracy on test set: 0.9791
  Client 4 model accuracy on test set: 0.9503
  Client 5 model accuracy on test set: 0.8940
  Client 6 model accuracy on test set: 0.9592
  Client 7 model accuracy on test set: 0.9786
  Client 8 model accuracy on test set: 0.9743
  Client 9 model accuracy on test set: 0.9768

=== Global Round 99/100 ===
  Client 0: layers_shared=3, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=0.5767
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=6, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=0.73, base_reward=0.6326, violation=0, comm_penalty=0.0000, reward=0.6326
  Client 1: mean_dist=0.50, base_reward=0.7513, violation=0, comm_penalty=0.0000, reward=0.7513
  Client 2: mean_dist=0.45, base_reward=0.7729, violation=0, comm_penalty=0.0000, reward=0.7729
  Client 3: mean_dist=0.47, base_reward=0.7654, violation=0, comm_penalty=0.0000, reward=0.7654
  Client 4: mean_dist=0.48, base_reward=0.3365, violation=0, comm_penalty=0.0000, reward=0.3365
  Client 5: mean_dist=0.45, base_reward=0.7753, violation=0, comm_penalty=0.0000, reward=0.7753
  Client 6: mean_dist=0.44, base_reward=0.7821, violation=0, comm_penalty=0.0000, reward=0.7821
  Client 7: mean_dist=0.46, base_reward=0.7683, violation=0, comm_penalty=0.0000, reward=0.7683
  Client 8: mean_dist=0.76, base_reward=0.6186, violation=4, comm_penalty=0.4000, reward=0.2186
  Client 9: mean_dist=0.47, base_reward=0.7667, violation=0, comm_penalty=0.0000, reward=0.7667
  RL policy loss: -0.100219
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9752
  Client 1 model accuracy on test set: 0.9747
  Client 2 model accuracy on test set: 0.9720
  Client 3 model accuracy on test set: 0.9799
  Client 4 model accuracy on test set: 0.5556
  Client 5 model accuracy on test set: 0.8968
  Client 6 model accuracy on test set: 0.9601
  Client 7 model accuracy on test set: 0.9782
  Client 8 model accuracy on test set: 0.9742
  Client 9 model accuracy on test set: 0.9763

=== Global Round 100/100 ===
  Client 0: layers_shared=1, local_acc=1.0000
  Client 1: layers_shared=1, local_acc=1.0000
  Client 2: layers_shared=1, local_acc=1.0000
  Client 3: layers_shared=1, local_acc=1.0000
  Client 4: layers_shared=1, local_acc=0.9920
  Client 5: layers_shared=1, local_acc=1.0000
  Client 6: layers_shared=1, local_acc=1.0000
  Client 7: layers_shared=1, local_acc=1.0000
  Client 8: layers_shared=5, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=1.0000
  Client 0: mean_dist=0.45, base_reward=0.7754, violation=0, comm_penalty=0.0000, reward=0.7754
  Client 1: mean_dist=0.50, base_reward=0.7511, violation=0, comm_penalty=0.0000, reward=0.7511
  Client 2: mean_dist=0.45, base_reward=0.7729, violation=0, comm_penalty=0.0000, reward=0.7729
  Client 3: mean_dist=0.47, base_reward=0.7655, violation=0, comm_penalty=0.0000, reward=0.7655
  Client 4: mean_dist=0.48, base_reward=0.7526, violation=0, comm_penalty=0.0000, reward=0.7526
  Client 5: mean_dist=0.45, base_reward=0.7758, violation=0, comm_penalty=0.0000, reward=0.7758
  Client 6: mean_dist=0.44, base_reward=0.7823, violation=0, comm_penalty=0.0000, reward=0.7823
  Client 7: mean_dist=0.46, base_reward=0.7688, violation=0, comm_penalty=0.0000, reward=0.7688
  Client 8: mean_dist=0.48, base_reward=0.7611, violation=3, comm_penalty=0.3000, reward=0.4611
  Client 9: mean_dist=0.47, base_reward=0.7669, violation=0, comm_penalty=0.0000, reward=0.7669
  RL policy loss: -0.056973
Global model accuracy (test set): 0.0868
  Client 0 model accuracy on test set: 0.9753
  Client 1 model accuracy on test set: 0.9753
  Client 2 model accuracy on test set: 0.9725
  Client 3 model accuracy on test set: 0.9798
  Client 4 model accuracy on test set: 0.9361
  Client 5 model accuracy on test set: 0.8905
  Client 6 model accuracy on test set: 0.9599
  Client 7 model accuracy on test set: 0.9793
  Client 8 model accuracy on test set: 0.9753
  Client 9 model accuracy on test set: 0.9769

Training finished.
Saved global model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/global_model.pt
Saved client 0 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_0_model.pt
Saved client 1 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_1_model.pt
Saved client 2 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_2_model.pt
Saved client 3 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_3_model.pt
Saved client 4 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_4_model.pt
Saved client 5 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_5_model.pt
Saved client 6 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_6_model.pt
Saved client 7 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_7_model.pt
Saved client 8 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_8_model.pt
Saved client 9 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_9_model.pt
Saved RL policy network  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/policy_net.pt