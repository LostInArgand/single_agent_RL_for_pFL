Using device: cuda
Files already downloaded and verified
RL will choose number of shared layers in [1, 6] for each client.

=== Global Round 1/100 ===
  Client 0: layers_shared=2, local_acc=0.4933
  Client 1: layers_shared=3, local_acc=0.3413
  Client 2: layers_shared=3, local_acc=0.4546
  Client 3: layers_shared=3, local_acc=0.4171
  Client 4: layers_shared=2, local_acc=0.3880
  Client 5: layers_shared=4, local_acc=0.3632
  Client 6: layers_shared=6, local_acc=0.4512
  Client 7: layers_shared=5, local_acc=0.3610
  Client 8: layers_shared=3, local_acc=0.5943
  Client 9: layers_shared=3, local_acc=0.4306
  Client 0: mean_dist=2.29, base_reward=-0.6505, violation=0, comm_penalty=0.0000, reward=-0.6505
  Client 1: mean_dist=2.96, base_reward=-1.1406, violation=0, comm_penalty=0.0000, reward=-1.1406
  Client 2: mean_dist=2.69, base_reward=-0.8916, violation=2, comm_penalty=2.0000, reward=-2.8916
  Client 3: mean_dist=2.81, base_reward=-0.9880, violation=1, comm_penalty=1.0000, reward=-1.9880
  Client 4: mean_dist=2.26, base_reward=-0.7425, violation=0, comm_penalty=0.0000, reward=-0.7425
  Client 5: mean_dist=2.90, base_reward=-1.0872, violation=0, comm_penalty=0.0000, reward=-1.0872
  Client 6: mean_dist=3.13, base_reward=-1.1116, violation=5, comm_penalty=5.0000, reward=-6.1116
  Client 7: mean_dist=3.22, base_reward=-1.2473, violation=0, comm_penalty=0.0000, reward=-1.2473
  Client 8: mean_dist=2.98, base_reward=-0.8969, violation=1, comm_penalty=1.0000, reward=-1.8969
  Client 9: mean_dist=2.97, base_reward=-1.0566, violation=0, comm_penalty=0.0000, reward=-1.0566
  RL policy loss: 0.029579
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1195
  Client 1 model accuracy on test set: 0.1213
  Client 2 model accuracy on test set: 0.1709
  Client 3 model accuracy on test set: 0.1040
  Client 4 model accuracy on test set: 0.1265
  Client 5 model accuracy on test set: 0.1225
  Client 6 model accuracy on test set: 0.1235
  Client 7 model accuracy on test set: 0.1417
  Client 8 model accuracy on test set: 0.1000
  Client 9 model accuracy on test set: 0.1271

=== Global Round 2/100 ===
  Client 0: layers_shared=4, local_acc=0.4665
  Client 1: layers_shared=5, local_acc=0.4060
  Client 2: layers_shared=1, local_acc=0.4468
  Client 3: layers_shared=5, local_acc=0.5008
  Client 4: layers_shared=5, local_acc=0.4884
  Client 5: layers_shared=3, local_acc=0.3548
  Client 6: layers_shared=2, local_acc=0.5109
  Client 7: layers_shared=2, local_acc=0.4103
  Client 8: layers_shared=3, local_acc=0.6413
  Client 9: layers_shared=4, local_acc=0.5508
  Client 0: mean_dist=3.67, base_reward=-1.3697, violation=1, comm_penalty=1.0000, reward=-2.3697
  Client 1: mean_dist=3.96, base_reward=-1.5740, violation=0, comm_penalty=0.0000, reward=-1.5740
  Client 2: mean_dist=1.01, base_reward=-0.0591, violation=0, comm_penalty=0.0000, reward=-0.0591
  Client 3: mean_dist=3.70, base_reward=-1.3504, violation=3, comm_penalty=3.0000, reward=-4.3504
  Client 4: mean_dist=3.81, base_reward=-1.4152, violation=1, comm_penalty=1.0000, reward=-2.4152
  Client 5: mean_dist=3.17, base_reward=-1.2327, violation=0, comm_penalty=0.0000, reward=-1.2327
  Client 6: mean_dist=2.70, base_reward=-0.8385, violation=1, comm_penalty=1.0000, reward=-1.8385
  Client 7: mean_dist=2.68, base_reward=-0.9289, violation=0, comm_penalty=0.0000, reward=-0.9289
  Client 8: mean_dist=3.35, base_reward=-1.0315, violation=1, comm_penalty=1.0000, reward=-2.0315
  Client 9: mean_dist=3.78, base_reward=-1.3386, violation=0, comm_penalty=0.0000, reward=-1.3386
  RL policy loss: 0.101366
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1001
  Client 1 model accuracy on test set: 0.1365
  Client 2 model accuracy on test set: 0.1350
  Client 3 model accuracy on test set: 0.1534
  Client 4 model accuracy on test set: 0.1375
  Client 5 model accuracy on test set: 0.1799
  Client 6 model accuracy on test set: 0.1000
  Client 7 model accuracy on test set: 0.1154
  Client 8 model accuracy on test set: 0.1883
  Client 9 model accuracy on test set: 0.1700

=== Global Round 3/100 ===
  Client 0: layers_shared=1, local_acc=0.6180
  Client 1: layers_shared=6, local_acc=0.4286
  Client 2: layers_shared=2, local_acc=0.4458
  Client 3: layers_shared=6, local_acc=0.5529
  Client 4: layers_shared=5, local_acc=0.4004
  Client 5: layers_shared=5, local_acc=0.4923
  Client 6: layers_shared=6, local_acc=0.5360
  Client 7: layers_shared=4, local_acc=0.4617
  Client 8: layers_shared=1, local_acc=0.6343
  Client 9: layers_shared=6, local_acc=0.5201
  Client 0: mean_dist=1.11, base_reward=0.0653, violation=0, comm_penalty=0.0000, reward=0.0653
  Client 1: mean_dist=4.92, base_reward=-2.0323, violation=1, comm_penalty=1.0000, reward=-3.0323
  Client 2: mean_dist=2.46, base_reward=-0.7855, violation=1, comm_penalty=1.0000, reward=-1.7855
  Client 3: mean_dist=4.58, base_reward=-1.7349, violation=4, comm_penalty=4.0000, reward=-5.7349
  Client 4: mean_dist=4.66, base_reward=-1.9292, violation=1, comm_penalty=1.0000, reward=-2.9292
  Client 5: mean_dist=4.55, base_reward=-1.7837, violation=0, comm_penalty=0.0000, reward=-1.7837
  Client 6: mean_dist=4.93, base_reward=-1.9302, violation=5, comm_penalty=5.0000, reward=-6.9302
  Client 7: mean_dist=4.40, base_reward=-1.7373, violation=0, comm_penalty=0.0000, reward=-1.7373
  Client 8: mean_dist=1.14, base_reward=0.0645, violation=0, comm_penalty=0.0000, reward=0.0645
  Client 9: mean_dist=4.94, base_reward=-1.9478, violation=1, comm_penalty=1.0000, reward=-2.9478
  RL policy loss: 0.048752
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1051
  Client 1 model accuracy on test set: 0.1114
  Client 2 model accuracy on test set: 0.1271
  Client 3 model accuracy on test set: 0.1646
  Client 4 model accuracy on test set: 0.1252
  Client 5 model accuracy on test set: 0.1485
  Client 6 model accuracy on test set: 0.1150
  Client 7 model accuracy on test set: 0.1520
  Client 8 model accuracy on test set: 0.1125
  Client 9 model accuracy on test set: 0.1873

=== Global Round 4/100 ===
  Client 0: layers_shared=3, local_acc=0.6205
  Client 1: layers_shared=1, local_acc=0.4432
  Client 2: layers_shared=1, local_acc=0.5563
  Client 3: layers_shared=1, local_acc=0.5303
  Client 4: layers_shared=1, local_acc=0.5746
  Client 5: layers_shared=1, local_acc=0.6044
  Client 6: layers_shared=5, local_acc=0.6051
  Client 7: layers_shared=4, local_acc=0.4894
  Client 8: layers_shared=1, local_acc=0.6947
  Client 9: layers_shared=2, local_acc=0.5557
  Client 0: mean_dist=2.28, base_reward=-0.5219, violation=0, comm_penalty=0.0000, reward=-0.5219
  Client 1: mean_dist=1.25, base_reward=-0.1812, violation=0, comm_penalty=0.0000, reward=-0.1812
  Client 2: mean_dist=1.23, base_reward=-0.0571, violation=0, comm_penalty=0.0000, reward=-0.0571
  Client 3: mean_dist=1.15, base_reward=-0.0431, violation=0, comm_penalty=0.0000, reward=-0.0431
  Client 4: mean_dist=1.23, base_reward=-0.0424, violation=0, comm_penalty=0.0000, reward=-0.0424
  Client 5: mean_dist=1.23, base_reward=-0.0130, violation=0, comm_penalty=0.0000, reward=-0.0130
  Client 6: mean_dist=2.60, base_reward=-0.6927, violation=4, comm_penalty=4.0000, reward=-4.6927
  Client 7: mean_dist=2.55, base_reward=-0.7832, violation=0, comm_penalty=0.0000, reward=-0.7832
  Client 8: mean_dist=1.25, base_reward=0.0682, violation=0, comm_penalty=0.0000, reward=0.0682
  Client 9: mean_dist=2.07, base_reward=-0.4775, violation=0, comm_penalty=0.0000, reward=-0.4775
  RL policy loss: 0.054503
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1555
  Client 1 model accuracy on test set: 0.1519
  Client 2 model accuracy on test set: 0.1541
  Client 3 model accuracy on test set: 0.1000
  Client 4 model accuracy on test set: 0.1377
  Client 5 model accuracy on test set: 0.1572
  Client 6 model accuracy on test set: 0.1252
  Client 7 model accuracy on test set: 0.1615
  Client 8 model accuracy on test set: 0.1711
  Client 9 model accuracy on test set: 0.1117

=== Global Round 5/100 ===
  Client 0: layers_shared=5, local_acc=0.6571
  Client 1: layers_shared=3, local_acc=0.4955
  Client 2: layers_shared=1, local_acc=0.5799
  Client 3: layers_shared=2, local_acc=0.5795
  Client 4: layers_shared=5, local_acc=0.5562
  Client 5: layers_shared=2, local_acc=0.6273
  Client 6: layers_shared=4, local_acc=0.6120
  Client 7: layers_shared=5, local_acc=0.5678
  Client 8: layers_shared=4, local_acc=0.7114
  Client 9: layers_shared=6, local_acc=0.5887
  Client 0: mean_dist=5.61, base_reward=-2.1475, violation=2, comm_penalty=2.0000, reward=-4.1475
  Client 1: mean_dist=4.64, base_reward=-1.8243, violation=0, comm_penalty=0.0000, reward=-1.8243
  Client 2: mean_dist=1.32, base_reward=-0.0787, violation=0, comm_penalty=0.0000, reward=-0.0787
  Client 3: mean_dist=3.28, base_reward=-1.0619, violation=0, comm_penalty=0.0000, reward=-1.0619
  Client 4: mean_dist=5.60, base_reward=-2.2423, violation=1, comm_penalty=1.0000, reward=-3.2423
  Client 5: mean_dist=3.41, base_reward=-1.0755, violation=0, comm_penalty=0.0000, reward=-1.0755
  Client 6: mean_dist=5.55, base_reward=-2.1606, violation=3, comm_penalty=3.0000, reward=-5.1606
  Client 7: mean_dist=5.96, base_reward=-2.4137, violation=0, comm_penalty=0.0000, reward=-2.4137
  Client 8: mean_dist=5.37, base_reward=-1.9760, violation=2, comm_penalty=2.0000, reward=-3.9760
  Client 9: mean_dist=6.05, base_reward=-2.4340, violation=1, comm_penalty=1.0000, reward=-3.4340
  RL policy loss: 0.202090
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1107
  Client 1 model accuracy on test set: 0.2139
  Client 2 model accuracy on test set: 0.2179
  Client 3 model accuracy on test set: 0.1351
  Client 4 model accuracy on test set: 0.1322
  Client 5 model accuracy on test set: 0.1666
  Client 6 model accuracy on test set: 0.1121
  Client 7 model accuracy on test set: 0.1813
  Client 8 model accuracy on test set: 0.1034
  Client 9 model accuracy on test set: 0.2205

=== Global Round 6/100 ===
  Client 0: layers_shared=5, local_acc=0.5144
  Client 1: layers_shared=6, local_acc=0.4767
  Client 2: layers_shared=4, local_acc=0.5511
  Client 3: layers_shared=1, local_acc=0.6174
  Client 4: layers_shared=5, local_acc=0.5765
  Client 5: layers_shared=3, local_acc=0.6209
  Client 6: layers_shared=5, local_acc=0.6317
  Client 7: layers_shared=1, local_acc=0.4848
  Client 8: layers_shared=3, local_acc=0.7513
  Client 9: layers_shared=6, local_acc=0.5837
  Client 0: mean_dist=5.98, base_reward=-2.4753, violation=2, comm_penalty=2.0000, reward=-4.4753
  Client 1: mean_dist=6.37, base_reward=-2.7063, violation=1, comm_penalty=1.0000, reward=-3.7063
  Client 2: mean_dist=5.16, base_reward=-2.0266, violation=3, comm_penalty=3.0000, reward=-5.0266
  Client 3: mean_dist=1.32, base_reward=-0.0431, violation=0, comm_penalty=0.0000, reward=-0.0431
  Client 4: mean_dist=5.96, base_reward=-2.4057, violation=1, comm_penalty=1.0000, reward=-3.4057
  Client 5: mean_dist=4.59, base_reward=-1.6749, violation=0, comm_penalty=0.0000, reward=-1.6749
  Client 6: mean_dist=6.33, base_reward=-2.5322, violation=4, comm_penalty=4.0000, reward=-6.5322
  Client 7: mean_dist=1.51, base_reward=-0.2683, violation=0, comm_penalty=0.0000, reward=-0.2683
  Client 8: mean_dist=4.73, base_reward=-1.6129, violation=1, comm_penalty=1.0000, reward=-2.6129
  Client 9: mean_dist=6.54, base_reward=-2.6854, violation=1, comm_penalty=1.0000, reward=-3.6854
  RL policy loss: -0.001747
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.2095
  Client 1 model accuracy on test set: 0.1081
  Client 2 model accuracy on test set: 0.1046
  Client 3 model accuracy on test set: 0.1021
  Client 4 model accuracy on test set: 0.1010
  Client 5 model accuracy on test set: 0.1776
  Client 6 model accuracy on test set: 0.1236
  Client 7 model accuracy on test set: 0.1682
  Client 8 model accuracy on test set: 0.1663
  Client 9 model accuracy on test set: 0.1820

=== Global Round 7/100 ===
  Client 0: layers_shared=4, local_acc=0.6644
  Client 1: layers_shared=6, local_acc=0.4623
  Client 2: layers_shared=3, local_acc=0.4656
  Client 3: layers_shared=2, local_acc=0.5959
  Client 4: layers_shared=3, local_acc=0.5855
  Client 5: layers_shared=3, local_acc=0.6677
  Client 6: layers_shared=4, local_acc=0.5133
  Client 7: layers_shared=6, local_acc=0.5819
  Client 8: layers_shared=2, local_acc=0.7415
  Client 9: layers_shared=5, local_acc=0.5868
  Client 0: mean_dist=6.30, base_reward=-2.4834, violation=1, comm_penalty=1.0000, reward=-3.4834
  Client 1: mean_dist=7.05, base_reward=-3.0650, violation=1, comm_penalty=1.0000, reward=-4.0650
  Client 2: mean_dist=5.24, base_reward=-2.1542, violation=2, comm_penalty=2.0000, reward=-4.1542
  Client 3: mean_dist=4.06, base_reward=-1.4329, violation=0, comm_penalty=0.0000, reward=-1.4329
  Client 4: mean_dist=5.52, base_reward=-2.1741, violation=0, comm_penalty=0.0000, reward=-2.1741
  Client 5: mean_dist=5.55, base_reward=-2.1069, violation=0, comm_penalty=0.0000, reward=-2.1069
  Client 6: mean_dist=6.71, base_reward=-2.8405, violation=3, comm_penalty=3.0000, reward=-5.8405
  Client 7: mean_dist=7.20, base_reward=-3.0165, violation=0, comm_penalty=0.0000, reward=-3.0165
  Client 8: mean_dist=4.27, base_reward=-1.3949, violation=0, comm_penalty=0.0000, reward=-1.3949
  Client 9: mean_dist=7.25, base_reward=-3.0405, violation=0, comm_penalty=0.0000, reward=-3.0405
  RL policy loss: 0.185001
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1060
  Client 1 model accuracy on test set: 0.1020
  Client 2 model accuracy on test set: 0.1431
  Client 3 model accuracy on test set: 0.1000
  Client 4 model accuracy on test set: 0.1022
  Client 5 model accuracy on test set: 0.1502
  Client 6 model accuracy on test set: 0.1903
  Client 7 model accuracy on test set: 0.1104
  Client 8 model accuracy on test set: 0.1676
  Client 9 model accuracy on test set: 0.2202

=== Global Round 8/100 ===
  Client 0: layers_shared=6, local_acc=0.7025
  Client 1: layers_shared=2, local_acc=0.5853
  Client 2: layers_shared=5, local_acc=0.5430
  Client 3: layers_shared=3, local_acc=0.6302
  Client 4: layers_shared=5, local_acc=0.6306
  Client 5: layers_shared=5, local_acc=0.6794
  Client 6: layers_shared=3, local_acc=0.6835
  Client 7: layers_shared=3, local_acc=0.6567
  Client 8: layers_shared=1, local_acc=0.7663
  Client 9: layers_shared=3, local_acc=0.6414
  Client 0: mean_dist=6.51, base_reward=-2.5506, violation=3, comm_penalty=3.0000, reward=-5.5506
  Client 1: mean_dist=4.27, base_reward=-1.5516, violation=0, comm_penalty=0.0000, reward=-1.5516
  Client 2: mean_dist=6.20, base_reward=-2.5564, violation=4, comm_penalty=4.0000, reward=-6.5564
  Client 3: mean_dist=5.45, base_reward=-2.0934, violation=1, comm_penalty=1.0000, reward=-3.0934
  Client 4: mean_dist=6.53, base_reward=-2.6333, violation=1, comm_penalty=1.0000, reward=-3.6333
  Client 5: mean_dist=6.56, base_reward=-2.6026, violation=0, comm_penalty=0.0000, reward=-2.6026
  Client 6: mean_dist=5.92, base_reward=-2.2766, violation=2, comm_penalty=2.0000, reward=-4.2766
  Client 7: mean_dist=6.04, base_reward=-2.3629, violation=0, comm_penalty=0.0000, reward=-2.3629
  Client 8: mean_dist=1.59, base_reward=-0.0290, violation=0, comm_penalty=0.0000, reward=-0.0290
  Client 9: mean_dist=6.08, base_reward=-2.3997, violation=0, comm_penalty=0.0000, reward=-2.3997
  RL policy loss: 0.095375
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1150
  Client 1 model accuracy on test set: 0.1035
  Client 2 model accuracy on test set: 0.2238
  Client 3 model accuracy on test set: 0.1021
  Client 4 model accuracy on test set: 0.1407
  Client 5 model accuracy on test set: 0.1623
  Client 6 model accuracy on test set: 0.1849
  Client 7 model accuracy on test set: 0.1806
  Client 8 model accuracy on test set: 0.1780
  Client 9 model accuracy on test set: 0.1868

=== Global Round 9/100 ===
  Client 0: layers_shared=1, local_acc=0.7149
  Client 1: layers_shared=5, local_acc=0.5489
  Client 2: layers_shared=3, local_acc=0.5755
  Client 3: layers_shared=4, local_acc=0.6561
  Client 4: layers_shared=6, local_acc=0.6373
  Client 5: layers_shared=6, local_acc=0.7159
  Client 6: layers_shared=6, local_acc=0.6961
  Client 7: layers_shared=3, local_acc=0.6424
  Client 8: layers_shared=2, local_acc=0.7695
  Client 9: layers_shared=4, local_acc=0.7245
  Client 0: mean_dist=1.67, base_reward=-0.1221, violation=0, comm_penalty=0.0000, reward=-0.1221
  Client 1: mean_dist=8.02, base_reward=-3.4596, violation=0, comm_penalty=0.0000, reward=-3.4596
  Client 2: mean_dist=5.61, base_reward=-2.2287, violation=2, comm_penalty=2.0000, reward=-4.2287
  Client 3: mean_dist=6.90, base_reward=-2.7920, violation=2, comm_penalty=2.0000, reward=-4.7920
  Client 4: mean_dist=7.54, base_reward=-3.1302, violation=2, comm_penalty=2.0000, reward=-5.1302
  Client 5: mean_dist=7.59, base_reward=-3.0809, violation=0, comm_penalty=0.0000, reward=-3.0809
  Client 6: mean_dist=7.92, base_reward=-3.2636, violation=5, comm_penalty=5.0000, reward=-8.2636
  Client 7: mean_dist=6.45, base_reward=-2.5805, violation=0, comm_penalty=0.0000, reward=-2.5805
  Client 8: mean_dist=4.45, base_reward=-1.4579, violation=0, comm_penalty=0.0000, reward=-1.4579
  Client 9: mean_dist=7.67, base_reward=-3.1104, violation=0, comm_penalty=0.0000, reward=-3.1104
  RL policy loss: 0.115025
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1912
  Client 1 model accuracy on test set: 0.1256
  Client 2 model accuracy on test set: 0.1439
  Client 3 model accuracy on test set: 0.1075
  Client 4 model accuracy on test set: 0.1102
  Client 5 model accuracy on test set: 0.1448
  Client 6 model accuracy on test set: 0.1248
  Client 7 model accuracy on test set: 0.1212
  Client 8 model accuracy on test set: 0.1829
  Client 9 model accuracy on test set: 0.1576

=== Global Round 10/100 ===
  Client 0: layers_shared=5, local_acc=0.7309
  Client 1: layers_shared=4, local_acc=0.5938
  Client 2: layers_shared=3, local_acc=0.6236
  Client 3: layers_shared=4, local_acc=0.6206
  Client 4: layers_shared=4, local_acc=0.6127
  Client 5: layers_shared=5, local_acc=0.7112
  Client 6: layers_shared=5, local_acc=0.7231
  Client 7: layers_shared=1, local_acc=0.6517
  Client 8: layers_shared=6, local_acc=0.7893
  Client 9: layers_shared=1, local_acc=0.6979
  Client 0: mean_dist=7.55, base_reward=-3.0434, violation=2, comm_penalty=2.0000, reward=-5.0434
  Client 1: mean_dist=7.62, base_reward=-3.2178, violation=0, comm_penalty=0.0000, reward=-3.2178
  Client 2: mean_dist=5.45, base_reward=-2.1018, violation=2, comm_penalty=2.0000, reward=-4.1018
  Client 3: mean_dist=7.00, base_reward=-2.8807, violation=2, comm_penalty=2.0000, reward=-4.8807
  Client 4: mean_dist=7.11, base_reward=-2.9405, violation=0, comm_penalty=0.0000, reward=-2.9405
  Client 5: mean_dist=7.69, base_reward=-3.1322, violation=0, comm_penalty=0.0000, reward=-3.1322
  Client 6: mean_dist=7.98, base_reward=-3.2670, violation=4, comm_penalty=4.0000, reward=-7.2670
  Client 7: mean_dist=1.92, base_reward=-0.3059, violation=0, comm_penalty=0.0000, reward=-0.3059
  Client 8: mean_dist=7.79, base_reward=-3.1040, violation=4, comm_penalty=4.0000, reward=-7.1040
  Client 9: mean_dist=1.92, base_reward=-0.2603, violation=0, comm_penalty=0.0000, reward=-0.2603
  RL policy loss: -0.009003
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1788
  Client 1 model accuracy on test set: 0.2107
  Client 2 model accuracy on test set: 0.1936
  Client 3 model accuracy on test set: 0.1034
  Client 4 model accuracy on test set: 0.1383
  Client 5 model accuracy on test set: 0.1765
  Client 6 model accuracy on test set: 0.2061
  Client 7 model accuracy on test set: 0.1538
  Client 8 model accuracy on test set: 0.1688
  Client 9 model accuracy on test set: 0.2291

=== Global Round 11/100 ===
  Client 0: layers_shared=5, local_acc=0.7259
  Client 1: layers_shared=2, local_acc=0.6140
  Client 2: layers_shared=1, local_acc=0.5407
  Client 3: layers_shared=3, local_acc=0.6398
  Client 4: layers_shared=2, local_acc=0.6671
  Client 5: layers_shared=4, local_acc=0.7551
  Client 6: layers_shared=2, local_acc=0.6908
  Client 7: layers_shared=5, local_acc=0.6839
  Client 8: layers_shared=5, local_acc=0.8052
  Client 9: layers_shared=4, local_acc=0.7461
  Client 0: mean_dist=7.37, base_reward=-2.9583, violation=2, comm_penalty=2.0000, reward=-4.9583
  Client 1: mean_dist=5.01, base_reward=-1.8935, violation=0, comm_penalty=0.0000, reward=-1.8935
  Client 2: mean_dist=1.86, base_reward=-0.3916, violation=0, comm_penalty=0.0000, reward=-0.3916
  Client 3: mean_dist=5.94, base_reward=-2.3280, violation=1, comm_penalty=1.0000, reward=-3.3280
  Client 4: mean_dist=4.75, base_reward=-1.7082, violation=0, comm_penalty=0.0000, reward=-1.7082
  Client 5: mean_dist=7.11, base_reward=-2.7984, violation=0, comm_penalty=0.0000, reward=-2.7984
  Client 6: mean_dist=5.10, base_reward=-1.8570, violation=1, comm_penalty=1.0000, reward=-2.8570
  Client 7: mean_dist=8.04, base_reward=-3.3338, violation=0, comm_penalty=0.0000, reward=-3.3338
  Client 8: mean_dist=7.56, base_reward=-2.9724, violation=3, comm_penalty=3.0000, reward=-5.9724
  Client 9: mean_dist=7.70, base_reward=-3.1047, violation=0, comm_penalty=0.0000, reward=-3.1047
  RL policy loss: 0.217300
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1044
  Client 1 model accuracy on test set: 0.1631
  Client 2 model accuracy on test set: 0.1532
  Client 3 model accuracy on test set: 0.1676
  Client 4 model accuracy on test set: 0.1091
  Client 5 model accuracy on test set: 0.1516
  Client 6 model accuracy on test set: 0.1445
  Client 7 model accuracy on test set: 0.1723
  Client 8 model accuracy on test set: 0.1599
  Client 9 model accuracy on test set: 0.1687

=== Global Round 12/100 ===
  Client 0: layers_shared=5, local_acc=0.7154
  Client 1: layers_shared=6, local_acc=0.6542
  Client 2: layers_shared=4, local_acc=0.6545
  Client 3: layers_shared=3, local_acc=0.7034
  Client 4: layers_shared=3, local_acc=0.6798
  Client 5: layers_shared=5, local_acc=0.7262
  Client 6: layers_shared=6, local_acc=0.6698
  Client 7: layers_shared=1, local_acc=0.7022
  Client 8: layers_shared=4, local_acc=0.7534
  Client 9: layers_shared=6, local_acc=0.7532
  Client 0: mean_dist=9.25, base_reward=-3.9082, violation=2, comm_penalty=2.0000, reward=-5.9082
  Client 1: mean_dist=10.06, base_reward=-4.3757, violation=1, comm_penalty=1.0000, reward=-5.3757
  Client 2: mean_dist=8.04, base_reward=-3.3651, violation=3, comm_penalty=3.0000, reward=-6.3651
  Client 3: mean_dist=6.88, base_reward=-2.7357, violation=1, comm_penalty=1.0000, reward=-3.7357
  Client 4: mean_dist=6.95, base_reward=-2.7951, violation=0, comm_penalty=0.0000, reward=-2.7951
  Client 5: mean_dist=9.40, base_reward=-3.9740, violation=0, comm_penalty=0.0000, reward=-3.9740
  Client 6: mean_dist=9.75, base_reward=-4.2047, violation=5, comm_penalty=5.0000, reward=-9.2047
  Client 7: mean_dist=2.09, base_reward=-0.3430, violation=0, comm_penalty=0.0000, reward=-0.3430
  Client 8: mean_dist=8.71, base_reward=-3.5997, violation=2, comm_penalty=2.0000, reward=-5.5997
  Client 9: mean_dist=10.25, base_reward=-4.3713, violation=1, comm_penalty=1.0000, reward=-5.3713
  RL policy loss: -0.169016
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1416
  Client 1 model accuracy on test set: 0.1518
  Client 2 model accuracy on test set: 0.1840
  Client 3 model accuracy on test set: 0.1411
  Client 4 model accuracy on test set: 0.2343
  Client 5 model accuracy on test set: 0.1964
  Client 6 model accuracy on test set: 0.1428
  Client 7 model accuracy on test set: 0.2070
  Client 8 model accuracy on test set: 0.1654
  Client 9 model accuracy on test set: 0.1156

=== Global Round 13/100 ===
  Client 0: layers_shared=1, local_acc=0.7481
  Client 1: layers_shared=3, local_acc=0.6358
  Client 2: layers_shared=6, local_acc=0.6678
  Client 3: layers_shared=1, local_acc=0.6975
  Client 4: layers_shared=5, local_acc=0.6986
  Client 5: layers_shared=3, local_acc=0.7623
  Client 6: layers_shared=6, local_acc=0.7353
  Client 7: layers_shared=2, local_acc=0.7132
  Client 8: layers_shared=5, local_acc=0.8302
  Client 9: layers_shared=1, local_acc=0.7605
  Client 0: mean_dist=1.98, base_reward=-0.2401, violation=0, comm_penalty=0.0000, reward=-0.2401
  Client 1: mean_dist=6.01, base_reward=-2.3698, violation=0, comm_penalty=0.0000, reward=-2.3698
  Client 2: mean_dist=6.77, base_reward=-2.7168, violation=5, comm_penalty=5.0000, reward=-7.7168
  Client 3: mean_dist=1.88, base_reward=-0.2440, violation=0, comm_penalty=0.0000, reward=-0.2440
  Client 4: mean_dist=6.99, base_reward=-2.7983, violation=1, comm_penalty=1.0000, reward=-3.7983
  Client 5: mean_dist=5.78, base_reward=-2.1258, violation=0, comm_penalty=0.0000, reward=-2.1258
  Client 6: mean_dist=7.41, base_reward=-2.9703, violation=5, comm_penalty=5.0000, reward=-7.9703
  Client 7: mean_dist=4.73, base_reward=-1.6535, violation=0, comm_penalty=0.0000, reward=-1.6535
  Client 8: mean_dist=7.18, base_reward=-2.7578, violation=3, comm_penalty=3.0000, reward=-5.7578
  Client 9: mean_dist=2.14, base_reward=-0.3100, violation=0, comm_penalty=0.0000, reward=-0.3100
  RL policy loss: -0.019305
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1533
  Client 1 model accuracy on test set: 0.1684
  Client 2 model accuracy on test set: 0.1772
  Client 3 model accuracy on test set: 0.1166
  Client 4 model accuracy on test set: 0.1681
  Client 5 model accuracy on test set: 0.1726
  Client 6 model accuracy on test set: 0.1607
  Client 7 model accuracy on test set: 0.1766
  Client 8 model accuracy on test set: 0.2173
  Client 9 model accuracy on test set: 0.1822

=== Global Round 14/100 ===
  Client 0: layers_shared=6, local_acc=0.7412
  Client 1: layers_shared=6, local_acc=0.6632
  Client 2: layers_shared=1, local_acc=0.7037
  Client 3: layers_shared=3, local_acc=0.6382
  Client 4: layers_shared=5, local_acc=0.6812
  Client 5: layers_shared=5, local_acc=0.7434
  Client 6: layers_shared=1, local_acc=0.7478
  Client 7: layers_shared=5, local_acc=0.7317
  Client 8: layers_shared=2, local_acc=0.7922
  Client 9: layers_shared=2, local_acc=0.7936
  Client 0: mean_dist=8.40, base_reward=-3.4589, violation=3, comm_penalty=3.0000, reward=-6.4589
  Client 1: mean_dist=9.03, base_reward=-3.8537, violation=1, comm_penalty=1.0000, reward=-4.8537
  Client 2: mean_dist=2.11, base_reward=-0.3494, violation=0, comm_penalty=0.0000, reward=-0.3494
  Client 3: mean_dist=6.29, base_reward=-2.5066, violation=1, comm_penalty=1.0000, reward=-3.5066
  Client 4: mean_dist=8.44, base_reward=-3.5373, violation=1, comm_penalty=1.0000, reward=-4.5373
  Client 5: mean_dist=8.54, base_reward=-3.5251, violation=0, comm_penalty=0.0000, reward=-3.5251
  Client 6: mean_dist=2.31, base_reward=-0.4083, violation=0, comm_penalty=0.0000, reward=-0.4083
  Client 7: mean_dist=9.15, base_reward=-3.8446, violation=0, comm_penalty=0.0000, reward=-3.8446
  Client 8: mean_dist=5.04, base_reward=-1.7254, violation=0, comm_penalty=0.0000, reward=-1.7254
  Client 9: mean_dist=5.42, base_reward=-1.9144, violation=0, comm_penalty=0.0000, reward=-1.9144
  RL policy loss: 0.176735
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1578
  Client 1 model accuracy on test set: 0.1141
  Client 2 model accuracy on test set: 0.1796
  Client 3 model accuracy on test set: 0.1480
  Client 4 model accuracy on test set: 0.1738
  Client 5 model accuracy on test set: 0.1850
  Client 6 model accuracy on test set: 0.2013
  Client 7 model accuracy on test set: 0.2753
  Client 8 model accuracy on test set: 0.1445
  Client 9 model accuracy on test set: 0.2184

=== Global Round 15/100 ===
  Client 0: layers_shared=6, local_acc=0.7578
  Client 1: layers_shared=5, local_acc=0.6843
  Client 2: layers_shared=4, local_acc=0.6940
  Client 3: layers_shared=5, local_acc=0.6869
  Client 4: layers_shared=4, local_acc=0.6626
  Client 5: layers_shared=6, local_acc=0.7568
  Client 6: layers_shared=5, local_acc=0.7743
  Client 7: layers_shared=5, local_acc=0.7416
  Client 8: layers_shared=5, local_acc=0.8391
  Client 9: layers_shared=2, local_acc=0.7725
  Client 0: mean_dist=11.88, base_reward=-5.1810, violation=3, comm_penalty=3.0000, reward=-8.1810
  Client 1: mean_dist=12.93, base_reward=-5.7822, violation=0, comm_penalty=0.0000, reward=-5.7822
  Client 2: mean_dist=10.02, base_reward=-4.3171, violation=3, comm_penalty=3.0000, reward=-7.3171
  Client 3: mean_dist=11.86, base_reward=-5.2425, violation=3, comm_penalty=3.0000, reward=-8.2425
  Client 4: mean_dist=10.60, base_reward=-4.6379, violation=0, comm_penalty=0.0000, reward=-4.6379
  Client 5: mean_dist=12.12, base_reward=-5.3014, violation=0, comm_penalty=0.0000, reward=-5.3014
  Client 6: mean_dist=12.41, base_reward=-5.4303, violation=4, comm_penalty=4.0000, reward=-9.4303
  Client 7: mean_dist=13.09, base_reward=-5.8032, violation=0, comm_penalty=0.0000, reward=-5.8032
  Client 8: mean_dist=12.17, base_reward=-5.2445, violation=3, comm_penalty=3.0000, reward=-8.2445
  Client 9: mean_dist=6.48, base_reward=-2.4680, violation=0, comm_penalty=0.0000, reward=-2.4680
  RL policy loss: 0.330135
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1981
  Client 1 model accuracy on test set: 0.1672
  Client 2 model accuracy on test set: 0.2003
  Client 3 model accuracy on test set: 0.1593
  Client 4 model accuracy on test set: 0.1409
  Client 5 model accuracy on test set: 0.1699
  Client 6 model accuracy on test set: 0.1941
  Client 7 model accuracy on test set: 0.2009
  Client 8 model accuracy on test set: 0.1292
  Client 9 model accuracy on test set: 0.2328

=== Global Round 16/100 ===
  Client 0: layers_shared=6, local_acc=0.7636
  Client 1: layers_shared=5, local_acc=0.6367
  Client 2: layers_shared=2, local_acc=0.6878
  Client 3: layers_shared=5, local_acc=0.6979
  Client 4: layers_shared=5, local_acc=0.7313
  Client 5: layers_shared=4, local_acc=0.7580
  Client 6: layers_shared=1, local_acc=0.8079
  Client 7: layers_shared=3, local_acc=0.7165
  Client 8: layers_shared=5, local_acc=0.8419
  Client 9: layers_shared=4, local_acc=0.7515
  Client 0: mean_dist=10.58, base_reward=-4.5243, violation=3, comm_penalty=3.0000, reward=-7.5243
  Client 1: mean_dist=11.46, base_reward=-5.0955, violation=0, comm_penalty=0.0000, reward=-5.0955
  Client 2: mean_dist=5.46, base_reward=-2.0431, violation=1, comm_penalty=1.0000, reward=-3.0431
  Client 3: mean_dist=10.55, base_reward=-4.5754, violation=3, comm_penalty=3.0000, reward=-7.5754
  Client 4: mean_dist=10.67, base_reward=-4.6049, violation=1, comm_penalty=1.0000, reward=-5.6049
  Client 5: mean_dist=9.83, base_reward=-4.1590, violation=0, comm_penalty=0.0000, reward=-4.1590
  Client 6: mean_dist=2.46, base_reward=-0.4211, violation=0, comm_penalty=0.0000, reward=-0.4211
  Client 7: mean_dist=8.56, base_reward=-3.5659, violation=0, comm_penalty=0.0000, reward=-3.5659
  Client 8: mean_dist=10.84, base_reward=-4.5782, violation=3, comm_penalty=3.0000, reward=-7.5782
  Client 9: mean_dist=10.57, base_reward=-4.5358, violation=0, comm_penalty=0.0000, reward=-4.5358
  RL policy loss: 0.082513
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1471
  Client 1 model accuracy on test set: 0.1859
  Client 2 model accuracy on test set: 0.1607
  Client 3 model accuracy on test set: 0.1362
  Client 4 model accuracy on test set: 0.1438
  Client 5 model accuracy on test set: 0.1890
  Client 6 model accuracy on test set: 0.2196
  Client 7 model accuracy on test set: 0.1988
  Client 8 model accuracy on test set: 0.2176
  Client 9 model accuracy on test set: 0.2052

=== Global Round 17/100 ===
  Client 0: layers_shared=4, local_acc=0.7959
  Client 1: layers_shared=1, local_acc=0.7071
  Client 2: layers_shared=1, local_acc=0.7159
  Client 3: layers_shared=3, local_acc=0.6325
  Client 4: layers_shared=1, local_acc=0.7053
  Client 5: layers_shared=3, local_acc=0.7798
  Client 6: layers_shared=6, local_acc=0.7717
  Client 7: layers_shared=3, local_acc=0.7967
  Client 8: layers_shared=5, local_acc=0.8241
  Client 9: layers_shared=2, local_acc=0.7491
  Client 0: mean_dist=7.17, base_reward=-2.7909, violation=1, comm_penalty=1.0000, reward=-3.7909
  Client 1: mean_dist=2.40, base_reward=-0.4913, violation=0, comm_penalty=0.0000, reward=-0.4913
  Client 2: mean_dist=2.30, base_reward=-0.4321, violation=0, comm_penalty=0.0000, reward=-0.4321
  Client 3: mean_dist=6.47, base_reward=-2.6013, violation=1, comm_penalty=1.0000, reward=-3.6013
  Client 4: mean_dist=2.21, base_reward=-0.4019, violation=0, comm_penalty=0.0000, reward=-0.4019
  Client 5: mean_dist=6.71, base_reward=-2.5762, violation=0, comm_penalty=0.0000, reward=-2.5762
  Client 6: mean_dist=7.82, base_reward=-3.1377, violation=5, comm_penalty=5.0000, reward=-8.1377
  Client 7: mean_dist=7.15, base_reward=-2.7778, violation=0, comm_penalty=0.0000, reward=-2.7778
  Client 8: mean_dist=7.54, base_reward=-2.9460, violation=3, comm_penalty=3.0000, reward=-5.9460
  Client 9: mean_dist=5.40, base_reward=-1.9518, violation=0, comm_penalty=0.0000, reward=-1.9518
  RL policy loss: -0.034791
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1262
  Client 1 model accuracy on test set: 0.2147
  Client 2 model accuracy on test set: 0.1328
  Client 3 model accuracy on test set: 0.2169
  Client 4 model accuracy on test set: 0.1893
  Client 5 model accuracy on test set: 0.1657
  Client 6 model accuracy on test set: 0.1143
  Client 7 model accuracy on test set: 0.2031
  Client 8 model accuracy on test set: 0.1863
  Client 9 model accuracy on test set: 0.2082

=== Global Round 18/100 ===
  Client 0: layers_shared=5, local_acc=0.7930
  Client 1: layers_shared=2, local_acc=0.6753
  Client 2: layers_shared=4, local_acc=0.7000
  Client 3: layers_shared=5, local_acc=0.7812
  Client 4: layers_shared=5, local_acc=0.7263
  Client 5: layers_shared=3, local_acc=0.8151
  Client 6: layers_shared=5, local_acc=0.8285
  Client 7: layers_shared=5, local_acc=0.7769
  Client 8: layers_shared=4, local_acc=0.8621
  Client 9: layers_shared=6, local_acc=0.7914
  Client 0: mean_dist=12.53, base_reward=-5.4700, violation=2, comm_penalty=2.0000, reward=-7.4700
  Client 1: mean_dist=6.81, base_reward=-2.7317, violation=0, comm_penalty=0.0000, reward=-2.7317
  Client 2: mean_dist=10.76, base_reward=-4.6821, violation=3, comm_penalty=3.0000, reward=-7.6821
  Client 3: mean_dist=12.52, base_reward=-5.4776, violation=3, comm_penalty=3.0000, reward=-8.4776
  Client 4: mean_dist=12.64, base_reward=-5.5944, violation=1, comm_penalty=1.0000, reward=-6.5944
  Client 5: mean_dist=9.21, base_reward=-3.7913, violation=0, comm_penalty=0.0000, reward=-3.7913
  Client 6: mean_dist=13.09, base_reward=-5.7163, violation=4, comm_penalty=4.0000, reward=-9.7163
  Client 7: mean_dist=13.75, base_reward=-6.0984, violation=0, comm_penalty=0.0000, reward=-6.0984
  Client 8: mean_dist=11.58, base_reward=-4.9296, violation=2, comm_penalty=2.0000, reward=-6.9296
  Client 9: mean_dist=13.67, base_reward=-6.0425, violation=1, comm_penalty=1.0000, reward=-7.0425
  RL policy loss: 0.134391
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1268
  Client 1 model accuracy on test set: 0.1680
  Client 2 model accuracy on test set: 0.1643
  Client 3 model accuracy on test set: 0.1201
  Client 4 model accuracy on test set: 0.1332
  Client 5 model accuracy on test set: 0.1609
  Client 6 model accuracy on test set: 0.2003
  Client 7 model accuracy on test set: 0.2179
  Client 8 model accuracy on test set: 0.1914
  Client 9 model accuracy on test set: 0.1832

=== Global Round 19/100 ===
  Client 0: layers_shared=4, local_acc=0.8256
  Client 1: layers_shared=5, local_acc=0.6872
  Client 2: layers_shared=1, local_acc=0.7276
  Client 3: layers_shared=1, local_acc=0.7585
  Client 4: layers_shared=3, local_acc=0.7709
  Client 5: layers_shared=1, local_acc=0.8240
  Client 6: layers_shared=1, local_acc=0.8328
  Client 7: layers_shared=2, local_acc=0.7464
  Client 8: layers_shared=2, local_acc=0.8614
  Client 9: layers_shared=4, local_acc=0.7599
  Client 0: mean_dist=6.58, base_reward=-2.4658, violation=1, comm_penalty=1.0000, reward=-3.4658
  Client 1: mean_dist=6.98, base_reward=-2.8011, violation=0, comm_penalty=0.0000, reward=-2.8011
  Client 2: mean_dist=2.42, base_reward=-0.4826, violation=0, comm_penalty=0.0000, reward=-0.4826
  Client 3: mean_dist=2.25, base_reward=-0.3674, violation=0, comm_penalty=0.0000, reward=-0.3674
  Client 4: mean_dist=5.85, base_reward=-2.1555, violation=0, comm_penalty=0.0000, reward=-2.1555
  Client 5: mean_dist=2.46, base_reward=-0.4081, violation=0, comm_penalty=0.0000, reward=-0.4081
  Client 6: mean_dist=2.64, base_reward=-0.4877, violation=0, comm_penalty=0.0000, reward=-0.4877
  Client 7: mean_dist=5.21, base_reward=-1.8596, violation=0, comm_penalty=0.0000, reward=-1.8596
  Client 8: mean_dist=4.84, base_reward=-1.5610, violation=0, comm_penalty=0.0000, reward=-1.5610
  Client 9: mean_dist=7.06, base_reward=-2.7688, violation=0, comm_penalty=0.0000, reward=-2.7688
  RL policy loss: -0.056237
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1244
  Client 1 model accuracy on test set: 0.1565
  Client 2 model accuracy on test set: 0.2040
  Client 3 model accuracy on test set: 0.1669
  Client 4 model accuracy on test set: 0.1548
  Client 5 model accuracy on test set: 0.2081
  Client 6 model accuracy on test set: 0.1994
  Client 7 model accuracy on test set: 0.1390
  Client 8 model accuracy on test set: 0.1994
  Client 9 model accuracy on test set: 0.2504

=== Global Round 20/100 ===
  Client 0: layers_shared=4, local_acc=0.7856
  Client 1: layers_shared=1, local_acc=0.6703
  Client 2: layers_shared=6, local_acc=0.7731
  Client 3: layers_shared=6, local_acc=0.7800
  Client 4: layers_shared=2, local_acc=0.7299
  Client 5: layers_shared=3, local_acc=0.8326
  Client 6: layers_shared=1, local_acc=0.7745
  Client 7: layers_shared=4, local_acc=0.7822
  Client 8: layers_shared=5, local_acc=0.8901
  Client 9: layers_shared=5, local_acc=0.8051
  Client 0: mean_dist=9.60, base_reward=-4.0133, violation=1, comm_penalty=1.0000, reward=-5.0133
  Client 1: mean_dist=2.59, base_reward=-0.6236, violation=0, comm_penalty=0.0000, reward=-0.6236
  Client 2: mean_dist=10.05, base_reward=-4.2508, violation=5, comm_penalty=5.0000, reward=-9.2508
  Client 3: mean_dist=10.36, base_reward=-4.4014, violation=4, comm_penalty=4.0000, reward=-8.4014
  Client 4: mean_dist=5.78, base_reward=-2.1607, violation=0, comm_penalty=0.0000, reward=-2.1607
  Client 5: mean_dist=8.03, base_reward=-3.1821, violation=0, comm_penalty=0.0000, reward=-3.1821
  Client 6: mean_dist=2.70, base_reward=-0.5753, violation=0, comm_penalty=0.0000, reward=-0.5753
  Client 7: mean_dist=10.48, base_reward=-4.4586, violation=0, comm_penalty=0.0000, reward=-4.4586
  Client 8: mean_dist=10.58, base_reward=-4.4015, violation=3, comm_penalty=3.0000, reward=-7.4015
  Client 9: mean_dist=11.25, base_reward=-4.8206, violation=0, comm_penalty=0.0000, reward=-4.8206
  RL policy loss: -0.059259
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1711
  Client 1 model accuracy on test set: 0.1056
  Client 2 model accuracy on test set: 0.1880
  Client 3 model accuracy on test set: 0.1469
  Client 4 model accuracy on test set: 0.1070
  Client 5 model accuracy on test set: 0.1709
  Client 6 model accuracy on test set: 0.1809
  Client 7 model accuracy on test set: 0.2589
  Client 8 model accuracy on test set: 0.1944
  Client 9 model accuracy on test set: 0.1410

=== Global Round 21/100 ===
  Client 0: layers_shared=1, local_acc=0.8339
  Client 1: layers_shared=3, local_acc=0.7451
  Client 2: layers_shared=1, local_acc=0.7268
  Client 3: layers_shared=3, local_acc=0.7581
  Client 4: layers_shared=5, local_acc=0.7872
  Client 5: layers_shared=3, local_acc=0.8054
  Client 6: layers_shared=4, local_acc=0.8405
  Client 7: layers_shared=4, local_acc=0.7344
  Client 8: layers_shared=3, local_acc=0.8964
  Client 9: layers_shared=5, local_acc=0.8241
  Client 0: mean_dist=2.46, base_reward=-0.3938, violation=0, comm_penalty=0.0000, reward=-0.3938
  Client 1: mean_dist=9.17, base_reward=-3.8383, violation=0, comm_penalty=0.0000, reward=-3.8383
  Client 2: mean_dist=2.54, base_reward=-0.5428, violation=0, comm_penalty=0.0000, reward=-0.5428
  Client 3: mean_dist=8.48, base_reward=-3.4825, violation=1, comm_penalty=1.0000, reward=-4.4825
  Client 4: mean_dist=10.01, base_reward=-4.2196, violation=1, comm_penalty=1.0000, reward=-5.2196
  Client 5: mean_dist=8.75, base_reward=-3.5685, violation=0, comm_penalty=0.0000, reward=-3.5685
  Client 6: mean_dist=10.13, base_reward=-4.2262, violation=3, comm_penalty=3.0000, reward=-7.2262
  Client 7: mean_dist=10.54, base_reward=-4.5367, violation=0, comm_penalty=0.0000, reward=-4.5367
  Client 8: mean_dist=8.74, base_reward=-3.4715, violation=1, comm_penalty=1.0000, reward=-4.4715
  Client 9: mean_dist=10.76, base_reward=-4.5558, violation=0, comm_penalty=0.0000, reward=-4.5558
  RL policy loss: -0.077568
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1913
  Client 1 model accuracy on test set: 0.1278
  Client 2 model accuracy on test set: 0.1368
  Client 3 model accuracy on test set: 0.1441
  Client 4 model accuracy on test set: 0.1424
  Client 5 model accuracy on test set: 0.1900
  Client 6 model accuracy on test set: 0.2055
  Client 7 model accuracy on test set: 0.2728
  Client 8 model accuracy on test set: 0.1618
  Client 9 model accuracy on test set: 0.1759

=== Global Round 22/100 ===
  Client 0: layers_shared=1, local_acc=0.7794
  Client 1: layers_shared=1, local_acc=0.7675
  Client 2: layers_shared=2, local_acc=0.7393
  Client 3: layers_shared=5, local_acc=0.7494
  Client 4: layers_shared=4, local_acc=0.7802
  Client 5: layers_shared=6, local_acc=0.7980
  Client 6: layers_shared=4, local_acc=0.8651
  Client 7: layers_shared=3, local_acc=0.8193
  Client 8: layers_shared=2, local_acc=0.8841
  Client 9: layers_shared=2, local_acc=0.8230
  Client 0: mean_dist=2.52, base_reward=-0.4782, violation=0, comm_penalty=0.0000, reward=-0.4782
  Client 1: mean_dist=2.70, base_reward=-0.5810, violation=0, comm_penalty=0.0000, reward=-0.5810
  Client 2: mean_dist=5.91, base_reward=-2.2166, violation=1, comm_penalty=1.0000, reward=-3.2166
  Client 3: mean_dist=8.84, base_reward=-3.6729, violation=3, comm_penalty=3.0000, reward=-6.6729
  Client 4: mean_dist=8.63, base_reward=-3.5347, violation=0, comm_penalty=0.0000, reward=-3.5347
  Client 5: mean_dist=9.10, base_reward=-3.7513, violation=0, comm_penalty=0.0000, reward=-3.7513
  Client 6: mean_dist=9.04, base_reward=-3.6551, violation=3, comm_penalty=3.0000, reward=-6.6551
  Client 7: mean_dist=8.20, base_reward=-3.2817, violation=0, comm_penalty=0.0000, reward=-3.2817
  Client 8: mean_dist=6.13, base_reward=-2.1796, violation=0, comm_penalty=0.0000, reward=-2.1796
  Client 9: mean_dist=6.55, base_reward=-2.4509, violation=0, comm_penalty=0.0000, reward=-2.4509
  RL policy loss: -0.032091
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1638
  Client 1 model accuracy on test set: 0.1037
  Client 2 model accuracy on test set: 0.1644
  Client 3 model accuracy on test set: 0.1312
  Client 4 model accuracy on test set: 0.1660
  Client 5 model accuracy on test set: 0.1360
  Client 6 model accuracy on test set: 0.2070
  Client 7 model accuracy on test set: 0.1990
  Client 8 model accuracy on test set: 0.1946
  Client 9 model accuracy on test set: 0.2678

=== Global Round 23/100 ===
  Client 0: layers_shared=4, local_acc=0.8129
  Client 1: layers_shared=5, local_acc=0.7641
  Client 2: layers_shared=6, local_acc=0.7351
  Client 3: layers_shared=6, local_acc=0.7812
  Client 4: layers_shared=6, local_acc=0.8172
  Client 5: layers_shared=3, local_acc=0.7687
  Client 6: layers_shared=4, local_acc=0.8143
  Client 7: layers_shared=1, local_acc=0.8183
  Client 8: layers_shared=4, local_acc=0.9120
  Client 9: layers_shared=2, local_acc=0.8478
  Client 0: mean_dist=11.55, base_reward=-4.9640, violation=1, comm_penalty=1.0000, reward=-5.9640
  Client 1: mean_dist=13.50, base_reward=-5.9878, violation=0, comm_penalty=0.0000, reward=-5.9878
  Client 2: mean_dist=12.03, base_reward=-5.2783, violation=5, comm_penalty=5.0000, reward=-10.2783
  Client 3: mean_dist=12.47, base_reward=-5.4527, violation=4, comm_penalty=4.0000, reward=-9.4527
  Client 4: mean_dist=12.57, base_reward=-5.4688, violation=2, comm_penalty=2.0000, reward=-7.4688
  Client 5: mean_dist=9.47, base_reward=-3.9675, violation=0, comm_penalty=0.0000, reward=-3.9675
  Client 6: mean_dist=12.03, base_reward=-5.1991, violation=3, comm_penalty=3.0000, reward=-8.1991
  Client 7: mean_dist=2.79, base_reward=-0.5749, violation=0, comm_penalty=0.0000, reward=-0.5749
  Client 8: mean_dist=11.78, base_reward=-4.9772, violation=2, comm_penalty=2.0000, reward=-6.9772
  Client 9: mean_dist=7.20, base_reward=-2.7515, violation=0, comm_penalty=0.0000, reward=-2.7515
  RL policy loss: -0.124506
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1710
  Client 1 model accuracy on test set: 0.1336
  Client 2 model accuracy on test set: 0.1050
  Client 3 model accuracy on test set: 0.1744
  Client 4 model accuracy on test set: 0.1633
  Client 5 model accuracy on test set: 0.1420
  Client 6 model accuracy on test set: 0.1597
  Client 7 model accuracy on test set: 0.1903
  Client 8 model accuracy on test set: 0.1770
  Client 9 model accuracy on test set: 0.2077

=== Global Round 24/100 ===
  Client 0: layers_shared=3, local_acc=0.8212
  Client 1: layers_shared=4, local_acc=0.7608
  Client 2: layers_shared=2, local_acc=0.6901
  Client 3: layers_shared=6, local_acc=0.7999
  Client 4: layers_shared=4, local_acc=0.7857
  Client 5: layers_shared=2, local_acc=0.8407
  Client 6: layers_shared=4, local_acc=0.8345
  Client 7: layers_shared=4, local_acc=0.8562
  Client 8: layers_shared=4, local_acc=0.9163
  Client 9: layers_shared=1, local_acc=0.8301
  Client 0: mean_dist=9.19, base_reward=-3.7714, violation=0, comm_penalty=0.0000, reward=-3.7714
  Client 1: mean_dist=12.09, base_reward=-5.2835, violation=0, comm_penalty=0.0000, reward=-5.2835
  Client 2: mean_dist=6.61, base_reward=-2.6146, violation=1, comm_penalty=1.0000, reward=-3.6146
  Client 3: mean_dist=11.14, base_reward=-4.7681, violation=4, comm_penalty=4.0000, reward=-8.7681
  Client 4: mean_dist=11.23, base_reward=-4.8284, violation=0, comm_penalty=0.0000, reward=-4.8284
  Client 5: mean_dist=6.97, base_reward=-2.6420, violation=0, comm_penalty=0.0000, reward=-2.6420
  Client 6: mean_dist=11.67, base_reward=-5.0016, violation=3, comm_penalty=3.0000, reward=-8.0016
  Client 7: mean_dist=12.16, base_reward=-5.2234, violation=0, comm_penalty=0.0000, reward=-5.2234
  Client 8: mean_dist=11.37, base_reward=-4.7701, violation=2, comm_penalty=2.0000, reward=-6.7701
  Client 9: mean_dist=2.74, base_reward=-0.5381, violation=0, comm_penalty=0.0000, reward=-0.5381
  RL policy loss: -0.035331
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1186
  Client 1 model accuracy on test set: 0.1940
  Client 2 model accuracy on test set: 0.1626
  Client 3 model accuracy on test set: 0.1422
  Client 4 model accuracy on test set: 0.1554
  Client 5 model accuracy on test set: 0.1789
  Client 6 model accuracy on test set: 0.2167
  Client 7 model accuracy on test set: 0.2099
  Client 8 model accuracy on test set: 0.1786
  Client 9 model accuracy on test set: 0.1771

=== Global Round 25/100 ===
  Client 0: layers_shared=1, local_acc=0.8326
  Client 1: layers_shared=5, local_acc=0.8344
  Client 2: layers_shared=2, local_acc=0.7918
  Client 3: layers_shared=4, local_acc=0.8495
  Client 4: layers_shared=3, local_acc=0.7953
  Client 5: layers_shared=3, local_acc=0.8396
  Client 6: layers_shared=5, local_acc=0.8338
  Client 7: layers_shared=2, local_acc=0.8695
  Client 8: layers_shared=3, local_acc=0.9181
  Client 9: layers_shared=5, local_acc=0.8451
  Client 0: mean_dist=2.64, base_reward=-0.4857, violation=0, comm_penalty=0.0000, reward=-0.4857
  Client 1: mean_dist=12.21, base_reward=-5.2689, violation=0, comm_penalty=0.0000, reward=-5.2689
  Client 2: mean_dist=6.77, base_reward=-2.5940, violation=1, comm_penalty=1.0000, reward=-3.5940
  Client 3: mean_dist=10.62, base_reward=-4.4589, violation=2, comm_penalty=2.0000, reward=-6.4589
  Client 4: mean_dist=9.37, base_reward=-3.8891, violation=0, comm_penalty=0.0000, reward=-3.8891
  Client 5: mean_dist=9.59, base_reward=-3.9540, violation=0, comm_penalty=0.0000, reward=-3.9540
  Client 6: mean_dist=11.80, base_reward=-5.0640, violation=4, comm_penalty=4.0000, reward=-9.0640
  Client 7: mean_dist=7.60, base_reward=-2.9312, violation=0, comm_penalty=0.0000, reward=-2.9312
  Client 8: mean_dist=9.56, base_reward=-3.8600, violation=1, comm_penalty=1.0000, reward=-4.8600
  Client 9: mean_dist=12.19, base_reward=-5.2479, violation=0, comm_penalty=0.0000, reward=-5.2479
  RL policy loss: 0.008438
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1087
  Client 1 model accuracy on test set: 0.1549
  Client 2 model accuracy on test set: 0.2031
  Client 3 model accuracy on test set: 0.1694
  Client 4 model accuracy on test set: 0.2006
  Client 5 model accuracy on test set: 0.1795
  Client 6 model accuracy on test set: 0.1649
  Client 7 model accuracy on test set: 0.2189
  Client 8 model accuracy on test set: 0.2841
  Client 9 model accuracy on test set: 0.2101

=== Global Round 26/100 ===
  Client 0: layers_shared=1, local_acc=0.8115
  Client 1: layers_shared=4, local_acc=0.8173
  Client 2: layers_shared=5, local_acc=0.7650
  Client 3: layers_shared=3, local_acc=0.8139
  Client 4: layers_shared=2, local_acc=0.7874
  Client 5: layers_shared=3, local_acc=0.8751
  Client 6: layers_shared=3, local_acc=0.8698
  Client 7: layers_shared=6, local_acc=0.8658
  Client 8: layers_shared=5, local_acc=0.8876
  Client 9: layers_shared=3, local_acc=0.8815
  Client 0: mean_dist=2.69, base_reward=-0.5357, violation=0, comm_penalty=0.0000, reward=-0.5357
  Client 1: mean_dist=12.13, base_reward=-5.2496, violation=0, comm_penalty=0.0000, reward=-5.2496
  Client 2: mean_dist=11.49, base_reward=-4.9808, violation=4, comm_penalty=4.0000, reward=-8.9808
  Client 3: mean_dist=9.90, base_reward=-4.1373, violation=1, comm_penalty=1.0000, reward=-5.1373
  Client 4: mean_dist=7.08, base_reward=-2.7506, violation=0, comm_penalty=0.0000, reward=-2.7506
  Client 5: mean_dist=10.18, base_reward=-4.2141, violation=0, comm_penalty=0.0000, reward=-4.2141
  Client 6: mean_dist=10.40, base_reward=-4.3286, violation=2, comm_penalty=2.0000, reward=-6.3286
  Client 7: mean_dist=12.87, base_reward=-5.5698, violation=0, comm_penalty=0.0000, reward=-5.5698
  Client 8: mean_dist=12.08, base_reward=-5.1547, violation=3, comm_penalty=3.0000, reward=-8.1547
  Client 9: mean_dist=10.73, base_reward=-4.4834, violation=0, comm_penalty=0.0000, reward=-4.4834
  RL policy loss: -0.010765
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1928
  Client 1 model accuracy on test set: 0.1937
  Client 2 model accuracy on test set: 0.2165
  Client 3 model accuracy on test set: 0.1987
  Client 4 model accuracy on test set: 0.1879
  Client 5 model accuracy on test set: 0.2026
  Client 6 model accuracy on test set: 0.2192
  Client 7 model accuracy on test set: 0.1726
  Client 8 model accuracy on test set: 0.1841
  Client 9 model accuracy on test set: 0.1927

=== Global Round 27/100 ===
  Client 0: layers_shared=4, local_acc=0.6880
  Client 1: layers_shared=3, local_acc=0.7938
  Client 2: layers_shared=1, local_acc=0.7156
  Client 3: layers_shared=6, local_acc=0.7709
  Client 4: layers_shared=1, local_acc=0.7402
  Client 5: layers_shared=1, local_acc=0.8402
  Client 6: layers_shared=3, local_acc=0.8805
  Client 7: layers_shared=6, local_acc=0.8285
  Client 8: layers_shared=6, local_acc=0.8913
  Client 9: layers_shared=4, local_acc=0.8402
  Client 0: mean_dist=10.48, base_reward=-4.5545, violation=1, comm_penalty=1.0000, reward=-5.5545
  Client 1: mean_dist=9.35, base_reward=-3.8803, violation=0, comm_penalty=0.0000, reward=-3.8803
  Client 2: mean_dist=2.84, base_reward=-0.7068, violation=0, comm_penalty=0.0000, reward=-0.7068
  Client 3: mean_dist=11.14, base_reward=-4.8010, violation=4, comm_penalty=4.0000, reward=-8.8010
  Client 4: mean_dist=2.70, base_reward=-0.6096, violation=0, comm_penalty=0.0000, reward=-0.6096
  Client 5: mean_dist=2.85, base_reward=-0.5824, violation=0, comm_penalty=0.0000, reward=-0.5824
  Client 6: mean_dist=9.14, base_reward=-3.6878, violation=2, comm_penalty=2.0000, reward=-5.6878
  Client 7: mean_dist=12.05, base_reward=-5.1944, violation=0, comm_penalty=0.0000, reward=-5.1944
  Client 8: mean_dist=11.32, base_reward=-4.7696, violation=4, comm_penalty=4.0000, reward=-8.7696
  Client 9: mean_dist=11.24, base_reward=-4.7792, violation=0, comm_penalty=0.0000, reward=-4.7792
  RL policy loss: -0.355157
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1363
  Client 1 model accuracy on test set: 0.1266
  Client 2 model accuracy on test set: 0.1247
  Client 3 model accuracy on test set: 0.1069
  Client 4 model accuracy on test set: 0.1172
  Client 5 model accuracy on test set: 0.2153
  Client 6 model accuracy on test set: 0.1724
  Client 7 model accuracy on test set: 0.2096
  Client 8 model accuracy on test set: 0.1852
  Client 9 model accuracy on test set: 0.2861

=== Global Round 28/100 ===
  Client 0: layers_shared=6, local_acc=0.8728
  Client 1: layers_shared=3, local_acc=0.7971
  Client 2: layers_shared=1, local_acc=0.7502
  Client 3: layers_shared=1, local_acc=0.7732
  Client 4: layers_shared=6, local_acc=0.8258
  Client 5: layers_shared=6, local_acc=0.8757
  Client 6: layers_shared=3, local_acc=0.9086
  Client 7: layers_shared=5, local_acc=0.8315
  Client 8: layers_shared=3, local_acc=0.9148
  Client 9: layers_shared=4, local_acc=0.8760
  Client 0: mean_dist=12.74, base_reward=-5.4983, violation=3, comm_penalty=3.0000, reward=-8.4983
  Client 1: mean_dist=10.60, base_reward=-4.5015, violation=0, comm_penalty=0.0000, reward=-4.5015
  Client 2: mean_dist=2.90, base_reward=-0.6977, violation=0, comm_penalty=0.0000, reward=-0.6977
  Client 3: mean_dist=2.70, base_reward=-0.5779, violation=0, comm_penalty=0.0000, reward=-0.5779
  Client 4: mean_dist=12.79, base_reward=-5.5689, violation=2, comm_penalty=2.0000, reward=-7.5689
  Client 5: mean_dist=12.98, base_reward=-5.6153, violation=0, comm_penalty=0.0000, reward=-5.6153
  Client 6: mean_dist=10.28, base_reward=-4.2295, violation=2, comm_penalty=2.0000, reward=-6.2295
  Client 7: mean_dist=13.65, base_reward=-5.9929, violation=0, comm_penalty=0.0000, reward=-5.9929
  Client 8: mean_dist=10.04, base_reward=-4.1032, violation=1, comm_penalty=1.0000, reward=-5.1032
  Client 9: mean_dist=12.53, base_reward=-5.3889, violation=0, comm_penalty=0.0000, reward=-5.3889
  RL policy loss: -0.230430
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1304
  Client 1 model accuracy on test set: 0.1439
  Client 2 model accuracy on test set: 0.1380
  Client 3 model accuracy on test set: 0.1523
  Client 4 model accuracy on test set: 0.1626
  Client 5 model accuracy on test set: 0.1953
  Client 6 model accuracy on test set: 0.2129
  Client 7 model accuracy on test set: 0.1867
  Client 8 model accuracy on test set: 0.2493
  Client 9 model accuracy on test set: 0.2497

=== Global Round 29/100 ===
  Client 0: layers_shared=6, local_acc=0.8720
  Client 1: layers_shared=3, local_acc=0.8575
  Client 2: layers_shared=3, local_acc=0.7635
  Client 3: layers_shared=3, local_acc=0.8710
  Client 4: layers_shared=5, local_acc=0.8153
  Client 5: layers_shared=3, local_acc=0.8532
  Client 6: layers_shared=3, local_acc=0.8749
  Client 7: layers_shared=2, local_acc=0.8635
  Client 8: layers_shared=3, local_acc=0.8855
  Client 9: layers_shared=5, local_acc=0.8402
  Client 0: mean_dist=13.15, base_reward=-5.7015, violation=3, comm_penalty=3.0000, reward=-8.7015
  Client 1: mean_dist=12.34, base_reward=-5.3119, violation=0, comm_penalty=0.0000, reward=-5.3119
  Client 2: mean_dist=11.04, base_reward=-4.7589, violation=2, comm_penalty=2.0000, reward=-6.7589
  Client 3: mean_dist=11.43, base_reward=-4.8435, violation=1, comm_penalty=1.0000, reward=-5.8435
  Client 4: mean_dist=13.10, base_reward=-5.7365, violation=1, comm_penalty=1.0000, reward=-6.7365
  Client 5: mean_dist=11.71, base_reward=-5.0024, violation=0, comm_penalty=0.0000, reward=-5.0024
  Client 6: mean_dist=11.92, base_reward=-5.0854, violation=2, comm_penalty=2.0000, reward=-7.0854
  Client 7: mean_dist=8.74, base_reward=-3.5044, violation=0, comm_penalty=0.0000, reward=-3.5044
  Client 8: mean_dist=11.68, base_reward=-4.9531, violation=1, comm_penalty=1.0000, reward=-5.9531
  Client 9: mean_dist=14.06, base_reward=-6.1877, violation=0, comm_penalty=0.0000, reward=-6.1877
  RL policy loss: 0.072199
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.2555
  Client 1 model accuracy on test set: 0.2189
  Client 2 model accuracy on test set: 0.2008
  Client 3 model accuracy on test set: 0.1316
  Client 4 model accuracy on test set: 0.1878
  Client 5 model accuracy on test set: 0.1995
  Client 6 model accuracy on test set: 0.1783
  Client 7 model accuracy on test set: 0.2173
  Client 8 model accuracy on test set: 0.1673
  Client 9 model accuracy on test set: 0.2745

=== Global Round 30/100 ===
  Client 0: layers_shared=4, local_acc=0.9024
  Client 1: layers_shared=2, local_acc=0.7971
  Client 2: layers_shared=5, local_acc=0.8420
  Client 3: layers_shared=3, local_acc=0.8388
  Client 4: layers_shared=3, local_acc=0.8485
  Client 5: layers_shared=2, local_acc=0.8431
  Client 6: layers_shared=5, local_acc=0.9062
  Client 7: layers_shared=6, local_acc=0.8843
  Client 8: layers_shared=5, local_acc=0.9321
  Client 9: layers_shared=3, local_acc=0.8776
  Client 0: mean_dist=13.09, base_reward=-5.6442, violation=1, comm_penalty=1.0000, reward=-6.6442
  Client 1: mean_dist=8.72, base_reward=-3.5652, violation=0, comm_penalty=0.0000, reward=-3.5652
  Client 2: mean_dist=13.61, base_reward=-5.9618, violation=4, comm_penalty=4.0000, reward=-9.9618
  Client 3: mean_dist=11.17, base_reward=-4.7484, violation=1, comm_penalty=1.0000, reward=-5.7484
  Client 4: mean_dist=11.22, base_reward=-4.7623, violation=0, comm_penalty=0.0000, reward=-4.7623
  Client 5: mean_dist=8.36, base_reward=-3.3347, violation=0, comm_penalty=0.0000, reward=-3.3347
  Client 6: mean_dist=14.53, base_reward=-6.3566, violation=4, comm_penalty=4.0000, reward=-10.3566
  Client 7: mean_dist=15.21, base_reward=-6.7184, violation=0, comm_penalty=0.0000, reward=-6.7184
  Client 8: mean_dist=14.22, base_reward=-6.1786, violation=3, comm_penalty=3.0000, reward=-9.1786
  Client 9: mean_dist=12.08, base_reward=-5.1609, violation=0, comm_penalty=0.0000, reward=-5.1609
  RL policy loss: 0.080380
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1556
  Client 1 model accuracy on test set: 0.1251
  Client 2 model accuracy on test set: 0.1747
  Client 3 model accuracy on test set: 0.1059
  Client 4 model accuracy on test set: 0.1389
  Client 5 model accuracy on test set: 0.1579
  Client 6 model accuracy on test set: 0.2034
  Client 7 model accuracy on test set: 0.2600
  Client 8 model accuracy on test set: 0.1435
  Client 9 model accuracy on test set: 0.2100

=== Global Round 31/100 ===
  Client 0: layers_shared=3, local_acc=0.8711
  Client 1: layers_shared=4, local_acc=0.8636
  Client 2: layers_shared=3, local_acc=0.7585
  Client 3: layers_shared=3, local_acc=0.8685
  Client 4: layers_shared=5, local_acc=0.8602
  Client 5: layers_shared=1, local_acc=0.9093
  Client 6: layers_shared=5, local_acc=0.9368
  Client 7: layers_shared=1, local_acc=0.8435
  Client 8: layers_shared=3, local_acc=0.9163
  Client 9: layers_shared=2, local_acc=0.8725
  Client 0: mean_dist=9.77, base_reward=-4.0137, violation=0, comm_penalty=0.0000, reward=-4.0137
  Client 1: mean_dist=11.48, base_reward=-4.8759, violation=0, comm_penalty=0.0000, reward=-4.8759
  Client 2: mean_dist=9.43, base_reward=-3.9580, violation=2, comm_penalty=2.0000, reward=-5.9580
  Client 3: mean_dist=9.66, base_reward=-3.9601, violation=1, comm_penalty=1.0000, reward=-4.9601
  Client 4: mean_dist=11.08, base_reward=-4.6783, violation=1, comm_penalty=1.0000, reward=-5.6783
  Client 5: mean_dist=3.00, base_reward=-0.5928, violation=0, comm_penalty=0.0000, reward=-0.5928
  Client 6: mean_dist=11.47, base_reward=-4.7980, violation=4, comm_penalty=4.0000, reward=-8.7980
  Client 7: mean_dist=3.12, base_reward=-0.7166, violation=0, comm_penalty=0.0000, reward=-0.7166
  Client 8: mean_dist=9.83, base_reward=-3.9981, violation=1, comm_penalty=1.0000, reward=-4.9981
  Client 9: mean_dist=7.53, base_reward=-2.8918, violation=0, comm_penalty=0.0000, reward=-2.8918
  RL policy loss: -0.118615
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.2110
  Client 1 model accuracy on test set: 0.1366
  Client 2 model accuracy on test set: 0.2102
  Client 3 model accuracy on test set: 0.1538
  Client 4 model accuracy on test set: 0.1190
  Client 5 model accuracy on test set: 0.1269
  Client 6 model accuracy on test set: 0.2485
  Client 7 model accuracy on test set: 0.2012
  Client 8 model accuracy on test set: 0.1729
  Client 9 model accuracy on test set: 0.2236

=== Global Round 32/100 ===
  Client 0: layers_shared=2, local_acc=0.8299
  Client 1: layers_shared=5, local_acc=0.8440
  Client 2: layers_shared=2, local_acc=0.8199
  Client 3: layers_shared=3, local_acc=0.8584
  Client 4: layers_shared=3, local_acc=0.8685
  Client 5: layers_shared=3, local_acc=0.8967
  Client 6: layers_shared=6, local_acc=0.9296
  Client 7: layers_shared=4, local_acc=0.8516
  Client 8: layers_shared=3, local_acc=0.9272
  Client 9: layers_shared=3, local_acc=0.8905
  Client 0: mean_dist=8.45, base_reward=-3.3973, violation=0, comm_penalty=0.0000, reward=-3.3973
  Client 1: mean_dist=14.04, base_reward=-6.1741, violation=0, comm_penalty=0.0000, reward=-6.1741
  Client 2: mean_dist=8.19, base_reward=-3.2751, violation=1, comm_penalty=1.0000, reward=-4.2751
  Client 3: mean_dist=11.60, base_reward=-4.9418, violation=1, comm_penalty=1.0000, reward=-5.9418
  Client 4: mean_dist=11.64, base_reward=-4.9491, violation=0, comm_penalty=0.0000, reward=-4.9491
  Client 5: mean_dist=11.88, base_reward=-5.0440, violation=0, comm_penalty=0.0000, reward=-5.0440
  Client 6: mean_dist=13.54, base_reward=-5.8386, violation=5, comm_penalty=5.0000, reward=-10.8386
  Client 7: mean_dist=13.66, base_reward=-5.9771, violation=0, comm_penalty=0.0000, reward=-5.9771
  Client 8: mean_dist=11.82, base_reward=-4.9809, violation=1, comm_penalty=1.0000, reward=-5.9809
  Client 9: mean_dist=12.50, base_reward=-5.3586, violation=0, comm_penalty=0.0000, reward=-5.3586
  RL policy loss: 0.005004
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1528
  Client 1 model accuracy on test set: 0.2064
  Client 2 model accuracy on test set: 0.2082
  Client 3 model accuracy on test set: 0.1657
  Client 4 model accuracy on test set: 0.1678
  Client 5 model accuracy on test set: 0.2143
  Client 6 model accuracy on test set: 0.1795
  Client 7 model accuracy on test set: 0.1707
  Client 8 model accuracy on test set: 0.1524
  Client 9 model accuracy on test set: 0.2208

=== Global Round 33/100 ===
  Client 0: layers_shared=5, local_acc=0.8919
  Client 1: layers_shared=3, local_acc=0.8647
  Client 2: layers_shared=2, local_acc=0.8500
  Client 3: layers_shared=6, local_acc=0.8758
  Client 4: layers_shared=4, local_acc=0.8776
  Client 5: layers_shared=4, local_acc=0.8637
  Client 6: layers_shared=4, local_acc=0.8961
  Client 7: layers_shared=3, local_acc=0.9029
  Client 8: layers_shared=1, local_acc=0.9426
  Client 9: layers_shared=6, local_acc=0.9108
  Client 0: mean_dist=14.42, base_reward=-6.3170, violation=2, comm_penalty=2.0000, reward=-8.3170
  Client 1: mean_dist=12.02, base_reward=-5.1450, violation=0, comm_penalty=0.0000, reward=-5.1450
  Client 2: mean_dist=7.73, base_reward=-3.0169, violation=1, comm_penalty=1.0000, reward=-4.0169
  Client 3: mean_dist=14.36, base_reward=-6.3049, violation=4, comm_penalty=4.0000, reward=-10.3049
  Client 4: mean_dist=13.69, base_reward=-5.9681, violation=0, comm_penalty=0.0000, reward=-5.9681
  Client 5: mean_dist=13.87, base_reward=-6.0710, violation=0, comm_penalty=0.0000, reward=-6.0710
  Client 6: mean_dist=14.08, base_reward=-6.1423, violation=3, comm_penalty=3.0000, reward=-9.1423
  Client 7: mean_dist=12.05, base_reward=-5.1210, violation=0, comm_penalty=0.0000, reward=-5.1210
  Client 8: mean_dist=2.92, base_reward=-0.5188, violation=0, comm_penalty=0.0000, reward=-0.5188
  Client 9: mean_dist=15.40, base_reward=-6.7886, violation=1, comm_penalty=1.0000, reward=-7.7886
  RL policy loss: -0.274214
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1268
  Client 1 model accuracy on test set: 0.1953
  Client 2 model accuracy on test set: 0.2099
  Client 3 model accuracy on test set: 0.1459
  Client 4 model accuracy on test set: 0.1745
  Client 5 model accuracy on test set: 0.2061
  Client 6 model accuracy on test set: 0.1997
  Client 7 model accuracy on test set: 0.2263
  Client 8 model accuracy on test set: 0.1721
  Client 9 model accuracy on test set: 0.2502

=== Global Round 34/100 ===
  Client 0: layers_shared=4, local_acc=0.8266
  Client 1: layers_shared=5, local_acc=0.8952
  Client 2: layers_shared=5, local_acc=0.8308
  Client 3: layers_shared=3, local_acc=0.8765
  Client 4: layers_shared=5, local_acc=0.8642
  Client 5: layers_shared=1, local_acc=0.8887
  Client 6: layers_shared=6, local_acc=0.8730
  Client 7: layers_shared=4, local_acc=0.8988
  Client 8: layers_shared=3, local_acc=0.9256
  Client 9: layers_shared=2, local_acc=0.8629
  Client 0: mean_dist=13.87, base_reward=-6.1060, violation=1, comm_penalty=1.0000, reward=-7.1060
  Client 1: mean_dist=16.23, base_reward=-7.2220, violation=0, comm_penalty=0.0000, reward=-7.2220
  Client 2: mean_dist=14.60, base_reward=-6.4682, violation=4, comm_penalty=4.0000, reward=-10.4682
  Client 3: mean_dist=11.25, base_reward=-4.7498, violation=1, comm_penalty=1.0000, reward=-5.7498
  Client 4: mean_dist=15.09, base_reward=-6.6823, violation=1, comm_penalty=1.0000, reward=-7.6823
  Client 5: mean_dist=3.12, base_reward=-0.6720, violation=0, comm_penalty=0.0000, reward=-0.6720
  Client 6: mean_dist=15.45, base_reward=-6.8498, violation=5, comm_penalty=5.0000, reward=-11.8498
  Client 7: mean_dist=14.89, base_reward=-6.5453, violation=0, comm_penalty=0.0000, reward=-6.5453
  Client 8: mean_dist=11.41, base_reward=-4.7816, violation=1, comm_penalty=1.0000, reward=-5.7816
  Client 9: mean_dist=8.55, base_reward=-3.4120, violation=0, comm_penalty=0.0000, reward=-3.4120
  RL policy loss: -0.297702
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1761
  Client 1 model accuracy on test set: 0.1330
  Client 2 model accuracy on test set: 0.2188
  Client 3 model accuracy on test set: 0.1757
  Client 4 model accuracy on test set: 0.1023
  Client 5 model accuracy on test set: 0.1540
  Client 6 model accuracy on test set: 0.1944
  Client 7 model accuracy on test set: 0.2052
  Client 8 model accuracy on test set: 0.1972
  Client 9 model accuracy on test set: 0.2603

=== Global Round 35/100 ===
  Client 0: layers_shared=4, local_acc=0.8745
  Client 1: layers_shared=3, local_acc=0.8272
  Client 2: layers_shared=1, local_acc=0.7980
  Client 3: layers_shared=5, local_acc=0.8658
  Client 4: layers_shared=6, local_acc=0.8029
  Client 5: layers_shared=1, local_acc=0.9289
  Client 6: layers_shared=4, local_acc=0.8634
  Client 7: layers_shared=3, local_acc=0.9136
  Client 8: layers_shared=1, local_acc=0.9225
  Client 9: layers_shared=5, local_acc=0.9198
  Client 0: mean_dist=11.90, base_reward=-5.0779, violation=1, comm_penalty=1.0000, reward=-6.0779
  Client 1: mean_dist=10.55, base_reward=-4.4458, violation=0, comm_penalty=0.0000, reward=-4.4458
  Client 2: mean_dist=3.18, base_reward=-0.7938, violation=0, comm_penalty=0.0000, reward=-0.7938
  Client 3: mean_dist=12.62, base_reward=-5.4435, violation=3, comm_penalty=3.0000, reward=-8.4435
  Client 4: mean_dist=12.72, base_reward=-5.5559, violation=2, comm_penalty=2.0000, reward=-7.5559
  Client 5: mean_dist=3.16, base_reward=-0.6513, violation=0, comm_penalty=0.0000, reward=-0.6513
  Client 6: mean_dist=12.27, base_reward=-5.2741, violation=3, comm_penalty=3.0000, reward=-8.2741
  Client 7: mean_dist=10.54, base_reward=-4.3555, violation=0, comm_penalty=0.0000, reward=-4.3555
  Client 8: mean_dist=2.98, base_reward=-0.5691, violation=0, comm_penalty=0.0000, reward=-0.5691
  Client 9: mean_dist=13.48, base_reward=-5.8210, violation=0, comm_penalty=0.0000, reward=-5.8210
  RL policy loss: -0.538420
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1059
  Client 1 model accuracy on test set: 0.1413
  Client 2 model accuracy on test set: 0.2021
  Client 3 model accuracy on test set: 0.1587
  Client 4 model accuracy on test set: 0.1392
  Client 5 model accuracy on test set: 0.1951
  Client 6 model accuracy on test set: 0.1965
  Client 7 model accuracy on test set: 0.2121
  Client 8 model accuracy on test set: 0.1957
  Client 9 model accuracy on test set: 0.2343

=== Global Round 36/100 ===
  Client 0: layers_shared=6, local_acc=0.8695
  Client 1: layers_shared=3, local_acc=0.8478
  Client 2: layers_shared=1, local_acc=0.8648
  Client 3: layers_shared=1, local_acc=0.9172
  Client 4: layers_shared=1, local_acc=0.8542
  Client 5: layers_shared=1, local_acc=0.9167
  Client 6: layers_shared=3, local_acc=0.8343
  Client 7: layers_shared=6, local_acc=0.9417
  Client 8: layers_shared=2, local_acc=0.9377
  Client 9: layers_shared=3, local_acc=0.9121
  Client 0: mean_dist=9.40, base_reward=-3.8306, violation=3, comm_penalty=3.0000, reward=-6.8306
  Client 1: mean_dist=8.96, base_reward=-3.6330, violation=0, comm_penalty=0.0000, reward=-3.6330
  Client 2: mean_dist=3.22, base_reward=-0.7450, violation=0, comm_penalty=0.0000, reward=-0.7450
  Client 3: mean_dist=2.99, base_reward=-0.5801, violation=0, comm_penalty=0.0000, reward=-0.5801
  Client 4: mean_dist=3.01, base_reward=-0.6529, violation=0, comm_penalty=0.0000, reward=-0.6529
  Client 5: mean_dist=3.19, base_reward=-0.6777, violation=0, comm_penalty=0.0000, reward=-0.6777
  Client 6: mean_dist=8.76, base_reward=-3.5461, violation=2, comm_penalty=2.0000, reward=-5.5461
  Client 7: mean_dist=9.92, base_reward=-4.0207, violation=0, comm_penalty=0.0000, reward=-4.0207
  Client 8: mean_dist=6.34, base_reward=-2.2317, violation=0, comm_penalty=0.0000, reward=-2.2317
  Client 9: mean_dist=8.89, base_reward=-3.5306, violation=0, comm_penalty=0.0000, reward=-3.5306
  RL policy loss: -0.165358
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.2117
  Client 1 model accuracy on test set: 0.1096
  Client 2 model accuracy on test set: 0.1700
  Client 3 model accuracy on test set: 0.1278
  Client 4 model accuracy on test set: 0.1564
  Client 5 model accuracy on test set: 0.2168
  Client 6 model accuracy on test set: 0.1948
  Client 7 model accuracy on test set: 0.2454
  Client 8 model accuracy on test set: 0.1829
  Client 9 model accuracy on test set: 0.2483

=== Global Round 37/100 ===
  Client 0: layers_shared=4, local_acc=0.9028
  Client 1: layers_shared=3, local_acc=0.8920
  Client 2: layers_shared=4, local_acc=0.8095
  Client 3: layers_shared=1, local_acc=0.8155
  Client 4: layers_shared=3, local_acc=0.8993
  Client 5: layers_shared=1, local_acc=0.8627
  Client 6: layers_shared=1, local_acc=0.9131
  Client 7: layers_shared=1, local_acc=0.9251
  Client 8: layers_shared=5, local_acc=0.9403
  Client 9: layers_shared=3, local_acc=0.9200
  Client 0: mean_dist=9.85, base_reward=-4.0198, violation=1, comm_penalty=1.0000, reward=-5.0198
  Client 1: mean_dist=9.44, base_reward=-3.8283, violation=0, comm_penalty=0.0000, reward=-3.8283
  Client 2: mean_dist=9.63, base_reward=-4.0080, violation=3, comm_penalty=3.0000, reward=-7.0080
  Client 3: mean_dist=3.03, base_reward=-0.6977, violation=0, comm_penalty=0.0000, reward=-0.6977
  Client 4: mean_dist=8.81, base_reward=-3.5052, violation=0, comm_penalty=0.0000, reward=-3.5052
  Client 5: mean_dist=3.23, base_reward=-0.7503, violation=0, comm_penalty=0.0000, reward=-0.7503
  Client 6: mean_dist=3.43, base_reward=-0.8008, violation=0, comm_penalty=0.0000, reward=-0.8008
  Client 7: mean_dist=3.33, base_reward=-0.7414, violation=0, comm_penalty=0.0000, reward=-0.7414
  Client 8: mean_dist=9.87, base_reward=-3.9945, violation=3, comm_penalty=3.0000, reward=-6.9945
  Client 9: mean_dist=9.37, base_reward=-3.7634, violation=0, comm_penalty=0.0000, reward=-3.7634
  RL policy loss: -0.357758
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1818
  Client 1 model accuracy on test set: 0.1645
  Client 2 model accuracy on test set: 0.1757
  Client 3 model accuracy on test set: 0.1389
  Client 4 model accuracy on test set: 0.1158
  Client 5 model accuracy on test set: 0.1943
  Client 6 model accuracy on test set: 0.1571
  Client 7 model accuracy on test set: 0.2514
  Client 8 model accuracy on test set: 0.2265
  Client 9 model accuracy on test set: 0.2303

=== Global Round 38/100 ===
  Client 0: layers_shared=4, local_acc=0.8894
  Client 1: layers_shared=4, local_acc=0.9123
  Client 2: layers_shared=6, local_acc=0.8339
  Client 3: layers_shared=1, local_acc=0.8845
  Client 4: layers_shared=1, local_acc=0.8790
  Client 5: layers_shared=3, local_acc=0.9316
  Client 6: layers_shared=3, local_acc=0.9238
  Client 7: layers_shared=4, local_acc=0.9318
  Client 8: layers_shared=3, local_acc=0.9240
  Client 9: layers_shared=3, local_acc=0.9035
  Client 0: mean_dist=12.99, base_reward=-5.6056, violation=1, comm_penalty=1.0000, reward=-6.6056
  Client 1: mean_dist=13.92, base_reward=-6.0482, violation=0, comm_penalty=0.0000, reward=-6.0482
  Client 2: mean_dist=12.61, base_reward=-5.4690, violation=5, comm_penalty=5.0000, reward=-10.4690
  Client 3: mean_dist=3.05, base_reward=-0.6416, violation=0, comm_penalty=0.0000, reward=-0.6416
  Client 4: mean_dist=3.08, base_reward=-0.6612, violation=0, comm_penalty=0.0000, reward=-0.6612
  Client 5: mean_dist=11.48, base_reward=-4.8077, violation=0, comm_penalty=0.0000, reward=-4.8077
  Client 6: mean_dist=11.69, base_reward=-4.9197, violation=2, comm_penalty=2.0000, reward=-6.9197
  Client 7: mean_dist=13.81, base_reward=-5.9745, violation=0, comm_penalty=0.0000, reward=-5.9745
  Client 8: mean_dist=11.37, base_reward=-4.7600, violation=1, comm_penalty=1.0000, reward=-5.7600
  Client 9: mean_dist=12.02, base_reward=-5.1053, violation=0, comm_penalty=0.0000, reward=-5.1053
  RL policy loss: -0.374072
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1706
  Client 1 model accuracy on test set: 0.2265
  Client 2 model accuracy on test set: 0.1905
  Client 3 model accuracy on test set: 0.1847
  Client 4 model accuracy on test set: 0.1644
  Client 5 model accuracy on test set: 0.2293
  Client 6 model accuracy on test set: 0.1960
  Client 7 model accuracy on test set: 0.2160
  Client 8 model accuracy on test set: 0.2093
  Client 9 model accuracy on test set: 0.2096

=== Global Round 39/100 ===
  Client 0: layers_shared=6, local_acc=0.9312
  Client 1: layers_shared=4, local_acc=0.8842
  Client 2: layers_shared=3, local_acc=0.8482
  Client 3: layers_shared=6, local_acc=0.9170
  Client 4: layers_shared=6, local_acc=0.7301
  Client 5: layers_shared=3, local_acc=0.9336
  Client 6: layers_shared=3, local_acc=0.9518
  Client 7: layers_shared=1, local_acc=0.9251
  Client 8: layers_shared=2, local_acc=0.9391
  Client 9: layers_shared=4, local_acc=0.9000
  Client 0: mean_dist=15.13, base_reward=-6.6358, violation=3, comm_penalty=3.0000, reward=-9.6358
  Client 1: mean_dist=15.35, base_reward=-6.7896, violation=0, comm_penalty=0.0000, reward=-6.7896
  Client 2: mean_dist=11.61, base_reward=-4.9547, violation=2, comm_penalty=2.0000, reward=-6.9547
  Client 3: mean_dist=15.05, base_reward=-6.6059, violation=4, comm_penalty=4.0000, reward=-10.6059
  Client 4: mean_dist=15.13, base_reward=-6.8368, violation=2, comm_penalty=2.0000, reward=-8.8368
  Client 5: mean_dist=12.16, base_reward=-5.1458, violation=0, comm_penalty=0.0000, reward=-5.1458
  Client 6: mean_dist=12.32, base_reward=-5.2064, violation=2, comm_penalty=2.0000, reward=-7.2064
  Client 7: mean_dist=3.38, base_reward=-0.7641, violation=0, comm_penalty=0.0000, reward=-0.7641
  Client 8: mean_dist=8.44, base_reward=-3.2794, violation=0, comm_penalty=0.0000, reward=-3.2794
  Client 9: mean_dist=15.16, base_reward=-6.6821, violation=0, comm_penalty=0.0000, reward=-6.6821
  RL policy loss: -0.345731
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.2353
  Client 1 model accuracy on test set: 0.1973
  Client 2 model accuracy on test set: 0.1410
  Client 3 model accuracy on test set: 0.1259
  Client 4 model accuracy on test set: 0.1251
  Client 5 model accuracy on test set: 0.2523
  Client 6 model accuracy on test set: 0.1500
  Client 7 model accuracy on test set: 0.2066
  Client 8 model accuracy on test set: 0.2197
  Client 9 model accuracy on test set: 0.2568

=== Global Round 40/100 ===
  Client 0: layers_shared=4, local_acc=0.9076
  Client 1: layers_shared=1, local_acc=0.8734
  Client 2: layers_shared=1, local_acc=0.8731
  Client 3: layers_shared=3, local_acc=0.9204
  Client 4: layers_shared=2, local_acc=0.8850
  Client 5: layers_shared=1, local_acc=0.9388
  Client 6: layers_shared=5, local_acc=0.9266
  Client 7: layers_shared=4, local_acc=0.9069
  Client 8: layers_shared=3, local_acc=0.9594
  Client 9: layers_shared=1, local_acc=0.9073
  Client 0: mean_dist=9.73, base_reward=-3.9576, violation=1, comm_penalty=1.0000, reward=-4.9576
  Client 1: mean_dist=3.47, base_reward=-0.8623, violation=0, comm_penalty=0.0000, reward=-0.8623
  Client 2: mean_dist=3.36, base_reward=-0.8073, violation=0, comm_penalty=0.0000, reward=-0.8073
  Client 3: mean_dist=8.53, base_reward=-3.3454, violation=1, comm_penalty=1.0000, reward=-4.3454
  Client 4: mean_dist=6.47, base_reward=-2.3511, violation=0, comm_penalty=0.0000, reward=-2.3511
  Client 5: mean_dist=3.32, base_reward=-0.7215, violation=0, comm_penalty=0.0000, reward=-0.7215
  Client 6: mean_dist=10.05, base_reward=-4.0983, violation=4, comm_penalty=4.0000, reward=-8.0983
  Client 7: mean_dist=10.32, base_reward=-4.2551, violation=0, comm_penalty=0.0000, reward=-4.2551
  Client 8: mean_dist=8.62, base_reward=-3.3515, violation=1, comm_penalty=1.0000, reward=-4.3515
  Client 9: mean_dist=3.31, base_reward=-0.7464, violation=0, comm_penalty=0.0000, reward=-0.7464
  RL policy loss: -0.354775
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1499
  Client 1 model accuracy on test set: 0.1614
  Client 2 model accuracy on test set: 0.2233
  Client 3 model accuracy on test set: 0.1667
  Client 4 model accuracy on test set: 0.1338
  Client 5 model accuracy on test set: 0.2285
  Client 6 model accuracy on test set: 0.1602
  Client 7 model accuracy on test set: 0.2198
  Client 8 model accuracy on test set: 0.1708
  Client 9 model accuracy on test set: 0.1955

=== Global Round 41/100 ===
  Client 0: layers_shared=1, local_acc=0.9304
  Client 1: layers_shared=5, local_acc=0.8936
  Client 2: layers_shared=4, local_acc=0.8214
  Client 3: layers_shared=4, local_acc=0.9090
  Client 4: layers_shared=5, local_acc=0.8788
  Client 5: layers_shared=3, local_acc=0.9184
  Client 6: layers_shared=3, local_acc=0.9375
  Client 7: layers_shared=5, local_acc=0.9271
  Client 8: layers_shared=1, local_acc=0.9711
  Client 9: layers_shared=5, local_acc=0.9193
  Client 0: mean_dist=3.21, base_reward=-0.6733, violation=0, comm_penalty=0.0000, reward=-0.6733
  Client 1: mean_dist=17.25, base_reward=-7.7334, violation=0, comm_penalty=0.0000, reward=-7.7334
  Client 2: mean_dist=14.18, base_reward=-6.2678, violation=3, comm_penalty=3.0000, reward=-9.2678
  Client 3: mean_dist=14.48, base_reward=-6.3328, violation=2, comm_penalty=2.0000, reward=-8.3328
  Client 4: mean_dist=15.99, base_reward=-7.1169, violation=1, comm_penalty=1.0000, reward=-8.1169
  Client 5: mean_dist=11.80, base_reward=-4.9838, violation=0, comm_penalty=0.0000, reward=-4.9838
  Client 6: mean_dist=11.98, base_reward=-5.0515, violation=2, comm_penalty=2.0000, reward=-7.0515
  Client 7: mean_dist=16.97, base_reward=-7.5565, violation=0, comm_penalty=0.0000, reward=-7.5565
  Client 8: mean_dist=3.18, base_reward=-0.6201, violation=0, comm_penalty=0.0000, reward=-0.6201
  Client 9: mean_dist=16.91, base_reward=-7.5373, violation=0, comm_penalty=0.0000, reward=-7.5373
  RL policy loss: -0.554306
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1782
  Client 1 model accuracy on test set: 0.1523
  Client 2 model accuracy on test set: 0.1312
  Client 3 model accuracy on test set: 0.1434
  Client 4 model accuracy on test set: 0.1499
  Client 5 model accuracy on test set: 0.1421
  Client 6 model accuracy on test set: 0.2113
  Client 7 model accuracy on test set: 0.2190
  Client 8 model accuracy on test set: 0.1809
  Client 9 model accuracy on test set: 0.1490

=== Global Round 42/100 ===
  Client 0: layers_shared=4, local_acc=0.9219
  Client 1: layers_shared=3, local_acc=0.9022
  Client 2: layers_shared=2, local_acc=0.9030
  Client 3: layers_shared=6, local_acc=0.8674
  Client 4: layers_shared=4, local_acc=0.9015
  Client 5: layers_shared=3, local_acc=0.9307
  Client 6: layers_shared=5, local_acc=0.9293
  Client 7: layers_shared=1, local_acc=0.9295
  Client 8: layers_shared=3, local_acc=0.9485
  Client 9: layers_shared=1, local_acc=0.9380
  Client 0: mean_dist=12.84, base_reward=-5.4978, violation=1, comm_penalty=1.0000, reward=-6.4978
  Client 1: mean_dist=11.93, base_reward=-5.0633, violation=0, comm_penalty=0.0000, reward=-5.0633
  Client 2: mean_dist=7.83, base_reward=-3.0133, violation=1, comm_penalty=1.0000, reward=-4.0133
  Client 3: mean_dist=13.16, base_reward=-5.7122, violation=4, comm_penalty=4.0000, reward=-9.7122
  Client 4: mean_dist=12.79, base_reward=-5.4930, violation=0, comm_penalty=0.0000, reward=-5.4930
  Client 5: mean_dist=11.28, base_reward=-4.7111, violation=0, comm_penalty=0.0000, reward=-4.7111
  Client 6: mean_dist=13.56, base_reward=-5.8505, violation=4, comm_penalty=4.0000, reward=-9.8505
  Client 7: mean_dist=3.48, base_reward=-0.8080, violation=0, comm_penalty=0.0000, reward=-0.8080
  Client 8: mean_dist=11.18, base_reward=-4.6406, violation=1, comm_penalty=1.0000, reward=-5.6406
  Client 9: mean_dist=3.36, base_reward=-0.7427, violation=0, comm_penalty=0.0000, reward=-0.7427
  RL policy loss: -0.574193
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1084
  Client 1 model accuracy on test set: 0.1888
  Client 2 model accuracy on test set: 0.1634
  Client 3 model accuracy on test set: 0.1789
  Client 4 model accuracy on test set: 0.1626
  Client 5 model accuracy on test set: 0.2153
  Client 6 model accuracy on test set: 0.2102
  Client 7 model accuracy on test set: 0.1299
  Client 8 model accuracy on test set: 0.1926
  Client 9 model accuracy on test set: 0.2367

=== Global Round 43/100 ===
  Client 0: layers_shared=6, local_acc=0.9349
  Client 1: layers_shared=1, local_acc=0.9098
  Client 2: layers_shared=1, local_acc=0.8485
  Client 3: layers_shared=1, local_acc=0.8994
  Client 4: layers_shared=3, local_acc=0.9086
  Client 5: layers_shared=3, local_acc=0.9652
  Client 6: layers_shared=5, local_acc=0.9548
  Client 7: layers_shared=3, local_acc=0.9518
  Client 8: layers_shared=2, local_acc=0.9477
  Client 9: layers_shared=3, local_acc=0.9511
  Client 0: mean_dist=11.16, base_reward=-4.6447, violation=3, comm_penalty=3.0000, reward=-7.6447
  Client 1: mean_dist=3.56, base_reward=-0.8701, violation=0, comm_penalty=0.0000, reward=-0.8701
  Client 2: mean_dist=3.47, base_reward=-0.8841, violation=0, comm_penalty=0.0000, reward=-0.8841
  Client 3: mean_dist=3.20, base_reward=-0.6985, violation=0, comm_penalty=0.0000, reward=-0.6985
  Client 4: mean_dist=10.11, base_reward=-4.1469, violation=0, comm_penalty=0.0000, reward=-4.1469
  Client 5: mean_dist=10.30, base_reward=-4.1871, violation=0, comm_penalty=0.0000, reward=-4.1871
  Client 6: mean_dist=11.42, base_reward=-4.7557, violation=4, comm_penalty=4.0000, reward=-8.7557
  Client 7: mean_dist=10.77, base_reward=-4.4320, violation=0, comm_penalty=0.0000, reward=-4.4320
  Client 8: mean_dist=7.44, base_reward=-2.7720, violation=0, comm_penalty=0.0000, reward=-2.7720
  Client 9: mean_dist=10.79, base_reward=-4.4428, violation=0, comm_penalty=0.0000, reward=-4.4428
  RL policy loss: -0.405756
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1383
  Client 1 model accuracy on test set: 0.1512
  Client 2 model accuracy on test set: 0.2014
  Client 3 model accuracy on test set: 0.1621
  Client 4 model accuracy on test set: 0.1947
  Client 5 model accuracy on test set: 0.2435
  Client 6 model accuracy on test set: 0.2206
  Client 7 model accuracy on test set: 0.1891
  Client 8 model accuracy on test set: 0.1930
  Client 9 model accuracy on test set: 0.2447

=== Global Round 44/100 ===
  Client 0: layers_shared=3, local_acc=0.9329
  Client 1: layers_shared=1, local_acc=0.8813
  Client 2: layers_shared=4, local_acc=0.8669
  Client 3: layers_shared=5, local_acc=0.9179
  Client 4: layers_shared=6, local_acc=0.8812
  Client 5: layers_shared=3, local_acc=0.9417
  Client 6: layers_shared=3, local_acc=0.9437
  Client 7: layers_shared=1, local_acc=0.9451
  Client 8: layers_shared=4, local_acc=0.9718
  Client 9: layers_shared=3, local_acc=0.9306
  Client 0: mean_dist=11.90, base_reward=-5.0184, violation=0, comm_penalty=0.0000, reward=-5.0184
  Client 1: mean_dist=3.59, base_reward=-0.9124, violation=0, comm_penalty=0.0000, reward=-0.9124
  Client 2: mean_dist=13.18, base_reward=-5.7256, violation=3, comm_penalty=3.0000, reward=-8.7256
  Client 3: mean_dist=13.92, base_reward=-6.0419, violation=3, comm_penalty=3.0000, reward=-9.0419
  Client 4: mean_dist=14.02, base_reward=-6.1281, violation=2, comm_penalty=2.0000, reward=-8.1281
  Client 5: mean_dist=11.96, base_reward=-5.0359, violation=0, comm_penalty=0.0000, reward=-5.0359
  Client 6: mean_dist=12.13, base_reward=-5.1238, violation=2, comm_penalty=2.0000, reward=-7.1238
  Client 7: mean_dist=3.52, base_reward=-0.8144, violation=0, comm_penalty=0.0000, reward=-0.8144
  Client 8: mean_dist=13.60, base_reward=-5.8301, violation=2, comm_penalty=2.0000, reward=-7.8301
  Client 9: mean_dist=12.61, base_reward=-5.3769, violation=0, comm_penalty=0.0000, reward=-5.3769
  RL policy loss: -0.761874
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.2125
  Client 1 model accuracy on test set: 0.1322
  Client 2 model accuracy on test set: 0.1920
  Client 3 model accuracy on test set: 0.1388
  Client 4 model accuracy on test set: 0.1801
  Client 5 model accuracy on test set: 0.2098
  Client 6 model accuracy on test set: 0.1800
  Client 7 model accuracy on test set: 0.2162
  Client 8 model accuracy on test set: 0.2497
  Client 9 model accuracy on test set: 0.2927

=== Global Round 45/100 ===
  Client 0: layers_shared=2, local_acc=0.9175
  Client 1: layers_shared=1, local_acc=0.9111
  Client 2: layers_shared=1, local_acc=0.8900
  Client 3: layers_shared=4, local_acc=0.8994
  Client 4: layers_shared=5, local_acc=0.8762
  Client 5: layers_shared=1, local_acc=0.9652
  Client 6: layers_shared=3, local_acc=0.9242
  Client 7: layers_shared=6, local_acc=0.9226
  Client 8: layers_shared=4, local_acc=0.9790
  Client 9: layers_shared=4, local_acc=0.8996
  Client 0: mean_dist=7.61, base_reward=-2.8882, violation=0, comm_penalty=0.0000, reward=-2.8882
  Client 1: mean_dist=3.62, base_reward=-0.9014, violation=0, comm_penalty=0.0000, reward=-0.9014
  Client 2: mean_dist=3.52, base_reward=-0.8696, violation=0, comm_penalty=0.0000, reward=-0.8696
  Client 3: mean_dist=12.67, base_reward=-5.4362, violation=2, comm_penalty=2.0000, reward=-7.4362
  Client 4: mean_dist=13.29, base_reward=-5.7700, violation=1, comm_penalty=1.0000, reward=-6.7700
  Client 5: mean_dist=3.45, base_reward=-0.7618, violation=0, comm_penalty=0.0000, reward=-0.7618
  Client 6: mean_dist=10.63, base_reward=-4.3892, violation=2, comm_penalty=2.0000, reward=-6.3892
  Client 7: mean_dist=14.00, base_reward=-6.0790, violation=0, comm_penalty=0.0000, reward=-6.0790
  Client 8: mean_dist=12.79, base_reward=-5.4139, violation=2, comm_penalty=2.0000, reward=-7.4139
  Client 9: mean_dist=13.54, base_reward=-5.8728, violation=0, comm_penalty=0.0000, reward=-5.8728
  RL policy loss: -0.708966
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1893
  Client 1 model accuracy on test set: 0.1541
  Client 2 model accuracy on test set: 0.1718
  Client 3 model accuracy on test set: 0.1980
  Client 4 model accuracy on test set: 0.1612
  Client 5 model accuracy on test set: 0.1848
  Client 6 model accuracy on test set: 0.2019
  Client 7 model accuracy on test set: 0.1964
  Client 8 model accuracy on test set: 0.2017
  Client 9 model accuracy on test set: 0.2021

=== Global Round 46/100 ===
  Client 0: layers_shared=3, local_acc=0.9420
  Client 1: layers_shared=5, local_acc=0.9309
  Client 2: layers_shared=3, local_acc=0.8295
  Client 3: layers_shared=1, local_acc=0.9168
  Client 4: layers_shared=4, local_acc=0.9232
  Client 5: layers_shared=6, local_acc=0.9612
  Client 6: layers_shared=6, local_acc=0.9578
  Client 7: layers_shared=5, local_acc=0.9497
  Client 8: layers_shared=1, local_acc=0.9718
  Client 9: layers_shared=1, local_acc=0.9383
  Client 0: mean_dist=10.90, base_reward=-4.5084, violation=0, comm_penalty=0.0000, reward=-4.5084
  Client 1: mean_dist=15.98, base_reward=-7.0593, violation=0, comm_penalty=0.0000, reward=-7.0593
  Client 2: mean_dist=10.63, base_reward=-4.4843, violation=2, comm_penalty=2.0000, reward=-6.4843
  Client 3: mean_dist=3.27, base_reward=-0.7194, violation=0, comm_penalty=0.0000, reward=-0.7194
  Client 4: mean_dist=13.38, base_reward=-5.7681, violation=0, comm_penalty=0.0000, reward=-5.7681
  Client 5: mean_dist=14.94, base_reward=-6.5078, violation=0, comm_penalty=0.0000, reward=-6.5078
  Client 6: mean_dist=15.15, base_reward=-6.6184, violation=5, comm_penalty=5.0000, reward=-11.6184
  Client 7: mean_dist=15.64, base_reward=-6.8696, violation=0, comm_penalty=0.0000, reward=-6.8696
  Client 8: mean_dist=3.28, base_reward=-0.6702, violation=0, comm_penalty=0.0000, reward=-0.6702
  Client 9: mean_dist=3.46, base_reward=-0.7928, violation=0, comm_penalty=0.0000, reward=-0.7928
  RL policy loss: -0.866758
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1593
  Client 1 model accuracy on test set: 0.1646
  Client 2 model accuracy on test set: 0.1784
  Client 3 model accuracy on test set: 0.1823
  Client 4 model accuracy on test set: 0.2053
  Client 5 model accuracy on test set: 0.1833
  Client 6 model accuracy on test set: 0.2090
  Client 7 model accuracy on test set: 0.2208
  Client 8 model accuracy on test set: 0.2659
  Client 9 model accuracy on test set: 0.1914

=== Global Round 47/100 ===
  Client 0: layers_shared=3, local_acc=0.9432
  Client 1: layers_shared=2, local_acc=0.9313
  Client 2: layers_shared=6, local_acc=0.9004
  Client 3: layers_shared=2, local_acc=0.9392
  Client 4: layers_shared=5, local_acc=0.9191
  Client 5: layers_shared=1, local_acc=0.9441
  Client 6: layers_shared=4, local_acc=0.9664
  Client 7: layers_shared=3, local_acc=0.9507
  Client 8: layers_shared=3, local_acc=0.9506
  Client 9: layers_shared=1, local_acc=0.9489
  Client 0: mean_dist=11.11, base_reward=-4.6097, violation=0, comm_penalty=0.0000, reward=-4.6097
  Client 1: mean_dist=8.90, base_reward=-3.5190, violation=0, comm_penalty=0.0000, reward=-3.5190
  Client 2: mean_dist=12.48, base_reward=-5.3372, violation=5, comm_penalty=5.0000, reward=-10.3372
  Client 3: mean_dist=8.25, base_reward=-3.1846, violation=0, comm_penalty=0.0000, reward=-3.1846
  Client 4: mean_dist=12.71, base_reward=-5.4364, violation=1, comm_penalty=1.0000, reward=-6.4364
  Client 5: mean_dist=3.49, base_reward=-0.8019, violation=0, comm_penalty=0.0000, reward=-0.8019
  Client 6: mean_dist=12.55, base_reward=-5.3095, violation=3, comm_penalty=3.0000, reward=-8.3095
  Client 7: mean_dist=11.73, base_reward=-4.9138, violation=0, comm_penalty=0.0000, reward=-4.9138
  Client 8: mean_dist=11.06, base_reward=-4.5798, violation=1, comm_penalty=1.0000, reward=-5.5798
  Client 9: mean_dist=3.48, base_reward=-0.7901, violation=0, comm_penalty=0.0000, reward=-0.7901
  RL policy loss: -0.592946
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.2330
  Client 1 model accuracy on test set: 0.1869
  Client 2 model accuracy on test set: 0.1449
  Client 3 model accuracy on test set: 0.1844
  Client 4 model accuracy on test set: 0.1535
  Client 5 model accuracy on test set: 0.1632
  Client 6 model accuracy on test set: 0.2042
  Client 7 model accuracy on test set: 0.1954
  Client 8 model accuracy on test set: 0.1843
  Client 9 model accuracy on test set: 0.2116

=== Global Round 48/100 ===
  Client 0: layers_shared=1, local_acc=0.9387
  Client 1: layers_shared=1, local_acc=0.9093
  Client 2: layers_shared=1, local_acc=0.8937
  Client 3: layers_shared=3, local_acc=0.9227
  Client 4: layers_shared=6, local_acc=0.9308
  Client 5: layers_shared=2, local_acc=0.9565
  Client 6: layers_shared=2, local_acc=0.9343
  Client 7: layers_shared=4, local_acc=0.9488
  Client 8: layers_shared=6, local_acc=0.9781
  Client 9: layers_shared=6, local_acc=0.9707
  Client 0: mean_dist=3.38, base_reward=-0.7533, violation=0, comm_penalty=0.0000, reward=-0.7533
  Client 1: mean_dist=3.68, base_reward=-0.9315, violation=0, comm_penalty=0.0000, reward=-0.9315
  Client 2: mean_dist=3.60, base_reward=-0.9077, violation=0, comm_penalty=0.0000, reward=-0.9077
  Client 3: mean_dist=9.96, base_reward=-4.0573, violation=1, comm_penalty=1.0000, reward=-5.0573
  Client 4: mean_dist=12.96, base_reward=-5.5468, violation=2, comm_penalty=2.0000, reward=-7.5468
  Client 5: mean_dist=7.86, base_reward=-2.9743, violation=0, comm_penalty=0.0000, reward=-2.9743
  Client 6: mean_dist=8.01, base_reward=-3.0700, violation=1, comm_penalty=1.0000, reward=-4.0700
  Client 7: mean_dist=12.61, base_reward=-5.3577, violation=0, comm_penalty=0.0000, reward=-5.3577
  Client 8: mean_dist=12.92, base_reward=-5.4800, violation=4, comm_penalty=4.0000, reward=-9.4800
  Client 9: mean_dist=13.65, base_reward=-5.8565, violation=1, comm_penalty=1.0000, reward=-6.8565
  RL policy loss: -0.836739
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1101
  Client 1 model accuracy on test set: 0.1217
  Client 2 model accuracy on test set: 0.1992
  Client 3 model accuracy on test set: 0.1778
  Client 4 model accuracy on test set: 0.1784
  Client 5 model accuracy on test set: 0.2133
  Client 6 model accuracy on test set: 0.2355
  Client 7 model accuracy on test set: 0.1982
  Client 8 model accuracy on test set: 0.1834
  Client 9 model accuracy on test set: 0.2071

=== Global Round 49/100 ===
  Client 0: layers_shared=3, local_acc=0.9534
  Client 1: layers_shared=1, local_acc=0.9347
  Client 2: layers_shared=1, local_acc=0.9051
  Client 3: layers_shared=5, local_acc=0.8964
  Client 4: layers_shared=4, local_acc=0.8821
  Client 5: layers_shared=1, local_acc=0.9604
  Client 6: layers_shared=1, local_acc=0.9771
  Client 7: layers_shared=6, local_acc=0.9497
  Client 8: layers_shared=6, local_acc=0.9767
  Client 9: layers_shared=3, local_acc=0.9508
  Client 0: mean_dist=9.99, base_reward=-4.0407, violation=0, comm_penalty=0.0000, reward=-4.0407
  Client 1: mean_dist=3.72, base_reward=-0.9236, violation=0, comm_penalty=0.0000, reward=-0.9236
  Client 2: mean_dist=3.61, base_reward=-0.9010, violation=0, comm_penalty=0.0000, reward=-0.9010
  Client 3: mean_dist=12.69, base_reward=-5.4465, violation=3, comm_penalty=3.0000, reward=-8.4465
  Client 4: mean_dist=11.86, base_reward=-5.0487, violation=0, comm_penalty=0.0000, reward=-5.0487
  Client 5: mean_dist=3.53, base_reward=-0.8028, violation=0, comm_penalty=0.0000, reward=-0.8028
  Client 6: mean_dist=3.73, base_reward=-0.8880, violation=0, comm_penalty=0.0000, reward=-0.8880
  Client 7: mean_dist=13.46, base_reward=-5.7814, violation=0, comm_penalty=0.0000, reward=-5.7814
  Client 8: mean_dist=12.76, base_reward=-5.4016, violation=4, comm_penalty=4.0000, reward=-9.4016
  Client 9: mean_dist=10.53, base_reward=-4.3125, violation=0, comm_penalty=0.0000, reward=-4.3125
  RL policy loss: -1.022467
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1507
  Client 1 model accuracy on test set: 0.1681
  Client 2 model accuracy on test set: 0.1378
  Client 3 model accuracy on test set: 0.1589
  Client 4 model accuracy on test set: 0.1928
  Client 5 model accuracy on test set: 0.1493
  Client 6 model accuracy on test set: 0.2372
  Client 7 model accuracy on test set: 0.2136
  Client 8 model accuracy on test set: 0.2215
  Client 9 model accuracy on test set: 0.2750

=== Global Round 50/100 ===
  Client 0: layers_shared=1, local_acc=0.9586
  Client 1: layers_shared=6, local_acc=0.9008
  Client 2: layers_shared=2, local_acc=0.8952
  Client 3: layers_shared=1, local_acc=0.9268
  Client 4: layers_shared=3, local_acc=0.9413
  Client 5: layers_shared=4, local_acc=0.9495
  Client 6: layers_shared=1, local_acc=0.9550
  Client 7: layers_shared=6, local_acc=0.9472
  Client 8: layers_shared=1, local_acc=0.9688
  Client 9: layers_shared=1, local_acc=0.9506
  Client 0: mean_dist=3.43, base_reward=-0.7545, violation=0, comm_penalty=0.0000, reward=-0.7545
  Client 1: mean_dist=10.72, base_reward=-4.4613, violation=1, comm_penalty=1.0000, reward=-5.4613
  Client 2: mean_dist=6.39, base_reward=-2.3007, violation=1, comm_penalty=1.0000, reward=-3.3007
  Client 3: mean_dist=3.36, base_reward=-0.7509, violation=0, comm_penalty=0.0000, reward=-0.7509
  Client 4: mean_dist=8.06, base_reward=-3.0887, violation=0, comm_penalty=0.0000, reward=-3.0887
  Client 5: mean_dist=9.59, base_reward=-3.8479, violation=0, comm_penalty=0.0000, reward=-3.8479
  Client 6: mean_dist=3.75, base_reward=-0.9182, violation=0, comm_penalty=0.0000, reward=-0.9182
  Client 7: mean_dist=10.58, base_reward=-4.3420, violation=0, comm_penalty=0.0000, reward=-4.3420
  Client 8: mean_dist=3.36, base_reward=-0.7098, violation=0, comm_penalty=0.0000, reward=-0.7098
  Client 9: mean_dist=3.54, base_reward=-0.8202, violation=0, comm_penalty=0.0000, reward=-0.8202
  RL policy loss: -0.667125
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1259
  Client 1 model accuracy on test set: 0.1964
  Client 2 model accuracy on test set: 0.1766
  Client 3 model accuracy on test set: 0.1681
  Client 4 model accuracy on test set: 0.1420
  Client 5 model accuracy on test set: 0.2281
  Client 6 model accuracy on test set: 0.2189
  Client 7 model accuracy on test set: 0.2253
  Client 8 model accuracy on test set: 0.2339
  Client 9 model accuracy on test set: 0.2958

=== Global Round 51/100 ===
  Client 0: layers_shared=3, local_acc=0.9457
  Client 1: layers_shared=5, local_acc=0.9623
  Client 2: layers_shared=1, local_acc=0.9498
  Client 3: layers_shared=6, local_acc=0.9641
  Client 4: layers_shared=1, local_acc=0.9372
  Client 5: layers_shared=5, local_acc=0.9668
  Client 6: layers_shared=3, local_acc=0.9484
  Client 7: layers_shared=1, local_acc=0.9631
  Client 8: layers_shared=2, local_acc=0.9629
  Client 9: layers_shared=6, local_acc=0.9660
  Client 0: mean_dist=10.86, base_reward=-4.4852, violation=0, comm_penalty=0.0000, reward=-4.4852
  Client 1: mean_dist=15.39, base_reward=-6.7319, violation=0, comm_penalty=0.0000, reward=-6.7319
  Client 2: mean_dist=3.68, base_reward=-0.8885, violation=0, comm_penalty=0.0000, reward=-0.8885
  Client 3: mean_dist=14.27, base_reward=-6.1730, violation=4, comm_penalty=4.0000, reward=-10.1730
  Client 4: mean_dist=3.40, base_reward=-0.7609, violation=0, comm_penalty=0.0000, reward=-0.7609
  Client 5: mean_dist=14.43, base_reward=-6.2470, violation=0, comm_penalty=0.0000, reward=-6.2470
  Client 6: mean_dist=11.10, base_reward=-4.6000, violation=2, comm_penalty=2.0000, reward=-6.6000
  Client 7: mean_dist=3.67, base_reward=-0.8733, violation=0, comm_penalty=0.0000, reward=-0.8733
  Client 8: mean_dist=7.84, base_reward=-2.9562, violation=0, comm_penalty=0.0000, reward=-2.9562
  Client 9: mean_dist=15.10, base_reward=-6.5846, violation=1, comm_penalty=1.0000, reward=-7.5846
  RL policy loss: -0.937960
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1767
  Client 1 model accuracy on test set: 0.1810
  Client 2 model accuracy on test set: 0.1934
  Client 3 model accuracy on test set: 0.1533
  Client 4 model accuracy on test set: 0.1760
  Client 5 model accuracy on test set: 0.1719
  Client 6 model accuracy on test set: 0.2034
  Client 7 model accuracy on test set: 0.2348
  Client 8 model accuracy on test set: 0.1814
  Client 9 model accuracy on test set: 0.2785

=== Global Round 52/100 ===
  Client 0: layers_shared=5, local_acc=0.9443
  Client 1: layers_shared=1, local_acc=0.9390
  Client 2: layers_shared=3, local_acc=0.9270
  Client 3: layers_shared=1, local_acc=0.9705
  Client 4: layers_shared=3, local_acc=0.9423
  Client 5: layers_shared=3, local_acc=0.9627
  Client 6: layers_shared=1, local_acc=0.9660
  Client 7: layers_shared=1, local_acc=0.9421
  Client 8: layers_shared=1, local_acc=0.9828
  Client 9: layers_shared=2, local_acc=0.9725
  Client 0: mean_dist=8.11, base_reward=-3.1092, violation=2, comm_penalty=2.0000, reward=-5.1092
  Client 1: mean_dist=3.77, base_reward=-0.9449, violation=0, comm_penalty=0.0000, reward=-0.9449
  Client 2: mean_dist=8.04, base_reward=-3.0948, violation=2, comm_penalty=2.0000, reward=-5.0948
  Client 3: mean_dist=3.39, base_reward=-0.7226, violation=0, comm_penalty=0.0000, reward=-0.7226
  Client 4: mean_dist=8.02, base_reward=-3.0661, violation=0, comm_penalty=0.0000, reward=-3.0661
  Client 5: mean_dist=8.16, base_reward=-3.1184, violation=0, comm_penalty=0.0000, reward=-3.1184
  Client 6: mean_dist=3.78, base_reward=-0.9228, violation=0, comm_penalty=0.0000, reward=-0.9228
  Client 7: mean_dist=3.69, base_reward=-0.9018, violation=0, comm_penalty=0.0000, reward=-0.9018
  Client 8: mean_dist=3.40, base_reward=-0.7174, violation=0, comm_penalty=0.0000, reward=-0.7174
  Client 9: mean_dist=6.70, base_reward=-2.3779, violation=0, comm_penalty=0.0000, reward=-2.3779
  RL policy loss: -0.322369
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1201
  Client 1 model accuracy on test set: 0.1763
  Client 2 model accuracy on test set: 0.1499
  Client 3 model accuracy on test set: 0.2005
  Client 4 model accuracy on test set: 0.1418
  Client 5 model accuracy on test set: 0.1720
  Client 6 model accuracy on test set: 0.1873
  Client 7 model accuracy on test set: 0.1531
  Client 8 model accuracy on test set: 0.1866
  Client 9 model accuracy on test set: 0.2258

=== Global Round 53/100 ===
  Client 0: layers_shared=3, local_acc=0.9631
  Client 1: layers_shared=6, local_acc=0.9408
  Client 2: layers_shared=2, local_acc=0.8994
  Client 3: layers_shared=1, local_acc=0.9506
  Client 4: layers_shared=1, local_acc=0.9537
  Client 5: layers_shared=1, local_acc=0.9553
  Client 6: layers_shared=3, local_acc=0.9610
  Client 7: layers_shared=4, local_acc=0.9301
  Client 8: layers_shared=1, local_acc=0.9660
  Client 9: layers_shared=5, local_acc=0.9525
  Client 0: mean_dist=9.72, base_reward=-3.8979, violation=0, comm_penalty=0.0000, reward=-3.8979
  Client 1: mean_dist=12.46, base_reward=-5.2867, violation=1, comm_penalty=1.0000, reward=-6.2867
  Client 2: mean_dist=7.30, base_reward=-2.7495, violation=1, comm_penalty=1.0000, reward=-3.7495
  Client 3: mean_dist=3.41, base_reward=-0.7546, violation=0, comm_penalty=0.0000, reward=-0.7546
  Client 4: mean_dist=3.42, base_reward=-0.7572, violation=0, comm_penalty=0.0000, reward=-0.7572
  Client 5: mean_dist=3.61, base_reward=-0.8490, violation=0, comm_penalty=0.0000, reward=-0.8490
  Client 6: mean_dist=9.98, base_reward=-4.0301, violation=2, comm_penalty=2.0000, reward=-6.0301
  Client 7: mean_dist=11.68, base_reward=-4.9117, violation=0, comm_penalty=0.0000, reward=-4.9117
  Client 8: mean_dist=3.41, base_reward=-0.7397, violation=0, comm_penalty=0.0000, reward=-0.7397
  Client 9: mean_dist=12.25, base_reward=-5.1720, violation=0, comm_penalty=0.0000, reward=-5.1720
  RL policy loss: -0.741587
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1795
  Client 1 model accuracy on test set: 0.1341
  Client 2 model accuracy on test set: 0.1846
  Client 3 model accuracy on test set: 0.1893
  Client 4 model accuracy on test set: 0.1701
  Client 5 model accuracy on test set: 0.2148
  Client 6 model accuracy on test set: 0.1808
  Client 7 model accuracy on test set: 0.2265
  Client 8 model accuracy on test set: 0.1924
  Client 9 model accuracy on test set: 0.2529

=== Global Round 54/100 ===
  Client 0: layers_shared=3, local_acc=0.9451
  Client 1: layers_shared=3, local_acc=0.9455
  Client 2: layers_shared=1, local_acc=0.9327
  Client 3: layers_shared=5, local_acc=0.9522
  Client 4: layers_shared=6, local_acc=0.9640
  Client 5: layers_shared=1, local_acc=0.9701
  Client 6: layers_shared=4, local_acc=0.9563
  Client 7: layers_shared=1, local_acc=0.9440
  Client 8: layers_shared=6, local_acc=0.9690
  Client 9: layers_shared=2, local_acc=0.9658
  Client 0: mean_dist=11.05, base_reward=-4.5786, violation=0, comm_penalty=0.0000, reward=-4.5786
  Client 1: mean_dist=11.75, base_reward=-4.9276, violation=0, comm_penalty=0.0000, reward=-4.9276
  Client 2: mean_dist=3.73, base_reward=-0.9331, violation=0, comm_penalty=0.0000, reward=-0.9331
  Client 3: mean_dist=13.75, base_reward=-5.9251, violation=3, comm_penalty=3.0000, reward=-8.9251
  Client 4: mean_dist=13.90, base_reward=-5.9848, violation=2, comm_penalty=2.0000, reward=-7.9848
  Client 5: mean_dist=3.63, base_reward=-0.8433, violation=0, comm_penalty=0.0000, reward=-0.8433
  Client 6: mean_dist=13.17, base_reward=-5.6294, violation=3, comm_penalty=3.0000, reward=-8.6294
  Client 7: mean_dist=3.72, base_reward=-0.9175, violation=0, comm_penalty=0.0000, reward=-0.9175
  Client 8: mean_dist=13.82, base_reward=-5.9410, violation=4, comm_penalty=4.0000, reward=-9.9410
  Client 9: mean_dist=8.47, base_reward=-3.2708, violation=0, comm_penalty=0.0000, reward=-3.2708
  RL policy loss: -1.313708
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.2103
  Client 1 model accuracy on test set: 0.1647
  Client 2 model accuracy on test set: 0.1999
  Client 3 model accuracy on test set: 0.1564
  Client 4 model accuracy on test set: 0.1817
  Client 5 model accuracy on test set: 0.2208
  Client 6 model accuracy on test set: 0.1676
  Client 7 model accuracy on test set: 0.1918
  Client 8 model accuracy on test set: 0.2611
  Client 9 model accuracy on test set: 0.2185

=== Global Round 55/100 ===
  Client 0: layers_shared=1, local_acc=0.9521
  Client 1: layers_shared=1, local_acc=0.9259
  Client 2: layers_shared=5, local_acc=0.9594
  Client 3: layers_shared=1, local_acc=0.9344
  Client 4: layers_shared=5, local_acc=0.9487
  Client 5: layers_shared=1, local_acc=0.9753
  Client 6: layers_shared=1, local_acc=0.9786
  Client 7: layers_shared=1, local_acc=0.9687
  Client 8: layers_shared=1, local_acc=0.9720
  Client 9: layers_shared=1, local_acc=0.9660
  Client 0: mean_dist=3.51, base_reward=-0.8038, violation=0, comm_penalty=0.0000, reward=-0.8038
  Client 1: mean_dist=3.83, base_reward=-0.9911, violation=0, comm_penalty=0.0000, reward=-0.9911
  Client 2: mean_dist=6.13, base_reward=-2.1060, violation=4, comm_penalty=4.0000, reward=-6.1060
  Client 3: mean_dist=3.45, base_reward=-0.7892, violation=0, comm_penalty=0.0000, reward=-0.7892
  Client 4: mean_dist=5.83, base_reward=-1.9650, violation=1, comm_penalty=1.0000, reward=-2.9650
  Client 5: mean_dist=3.65, base_reward=-0.8482, violation=0, comm_penalty=0.0000, reward=-0.8482
  Client 6: mean_dist=3.85, base_reward=-0.9453, violation=0, comm_penalty=0.0000, reward=-0.9453
  Client 7: mean_dist=3.75, base_reward=-0.9053, violation=0, comm_penalty=0.0000, reward=-0.9053
  Client 8: mean_dist=3.45, base_reward=-0.7528, violation=0, comm_penalty=0.0000, reward=-0.7528
  Client 9: mean_dist=3.64, base_reward=-0.8538, violation=0, comm_penalty=0.0000, reward=-0.8538
  RL policy loss: -0.546265
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.2073
  Client 1 model accuracy on test set: 0.1536
  Client 2 model accuracy on test set: 0.1523
  Client 3 model accuracy on test set: 0.1724
  Client 4 model accuracy on test set: 0.1697
  Client 5 model accuracy on test set: 0.2101
  Client 6 model accuracy on test set: 0.2371
  Client 7 model accuracy on test set: 0.1813
  Client 8 model accuracy on test set: 0.1665
  Client 9 model accuracy on test set: 0.2818

=== Global Round 56/100 ===
  Client 0: layers_shared=1, local_acc=0.9474
  Client 1: layers_shared=1, local_acc=0.9659
  Client 2: layers_shared=6, local_acc=0.9433
  Client 3: layers_shared=3, local_acc=0.9387
  Client 4: layers_shared=6, local_acc=0.9365
  Client 5: layers_shared=2, local_acc=0.9790
  Client 6: layers_shared=1, local_acc=0.9741
  Client 7: layers_shared=4, local_acc=0.9458
  Client 8: layers_shared=6, local_acc=0.9704
  Client 9: layers_shared=1, local_acc=0.9158
  Client 0: mean_dist=3.52, base_reward=-0.8137, violation=0, comm_penalty=0.0000, reward=-0.8137
  Client 1: mean_dist=3.85, base_reward=-0.9575, violation=0, comm_penalty=0.0000, reward=-0.9575
  Client 2: mean_dist=12.48, base_reward=-5.2962, violation=5, comm_penalty=5.0000, reward=-10.2962
  Client 3: mean_dist=9.56, base_reward=-3.8398, violation=1, comm_penalty=1.0000, reward=-4.8398
  Client 4: mean_dist=12.64, base_reward=-5.3824, violation=2, comm_penalty=2.0000, reward=-7.3824
  Client 5: mean_dist=7.36, base_reward=-2.7028, violation=0, comm_penalty=0.0000, reward=-2.7028
  Client 6: mean_dist=3.86, base_reward=-0.9553, violation=0, comm_penalty=0.0000, reward=-0.9553
  Client 7: mean_dist=12.24, base_reward=-5.1724, violation=0, comm_penalty=0.0000, reward=-5.1724
  Client 8: mean_dist=12.54, base_reward=-5.2983, violation=4, comm_penalty=4.0000, reward=-9.2983
  Client 9: mean_dist=3.66, base_reward=-0.9126, violation=0, comm_penalty=0.0000, reward=-0.9126
  RL policy loss: -1.404101
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1536
  Client 1 model accuracy on test set: 0.1068
  Client 2 model accuracy on test set: 0.1606
  Client 3 model accuracy on test set: 0.1652
  Client 4 model accuracy on test set: 0.1807
  Client 5 model accuracy on test set: 0.1987
  Client 6 model accuracy on test set: 0.2151
  Client 7 model accuracy on test set: 0.1909
  Client 8 model accuracy on test set: 0.1654
  Client 9 model accuracy on test set: 0.2247

=== Global Round 57/100 ===
  Client 0: layers_shared=2, local_acc=0.9644
  Client 1: layers_shared=3, local_acc=0.9444
  Client 2: layers_shared=2, local_acc=0.9194
  Client 3: layers_shared=3, local_acc=0.9337
  Client 4: layers_shared=5, local_acc=0.9563
  Client 5: layers_shared=4, local_acc=0.9798
  Client 6: layers_shared=3, local_acc=0.9587
  Client 7: layers_shared=6, local_acc=0.9548
  Client 8: layers_shared=1, local_acc=0.9699
  Client 9: layers_shared=3, local_acc=0.9499
  Client 0: mean_dist=9.73, base_reward=-3.9009, violation=0, comm_penalty=0.0000, reward=-3.9009
  Client 1: mean_dist=14.26, base_reward=-6.1879, violation=0, comm_penalty=0.0000, reward=-6.1879
  Client 2: mean_dist=9.51, base_reward=-3.8379, violation=1, comm_penalty=1.0000, reward=-4.8379
  Client 3: mean_dist=13.26, base_reward=-5.6975, violation=1, comm_penalty=1.0000, reward=-6.6975
  Client 4: mean_dist=15.18, base_reward=-6.6319, violation=1, comm_penalty=1.0000, reward=-7.6319
  Client 5: mean_dist=14.81, base_reward=-6.4262, violation=0, comm_penalty=0.0000, reward=-6.4262
  Client 6: mean_dist=13.57, base_reward=-5.8266, violation=2, comm_penalty=2.0000, reward=-7.8266
  Client 7: mean_dist=16.05, base_reward=-7.0683, violation=0, comm_penalty=0.0000, reward=-7.0683
  Client 8: mean_dist=3.49, base_reward=-0.7735, violation=0, comm_penalty=0.0000, reward=-0.7735
  Client 9: mean_dist=14.12, base_reward=-6.1120, violation=0, comm_penalty=0.0000, reward=-6.1120
  RL policy loss: -0.244502
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1893
  Client 1 model accuracy on test set: 0.1995
  Client 2 model accuracy on test set: 0.1422
  Client 3 model accuracy on test set: 0.1954
  Client 4 model accuracy on test set: 0.1915
  Client 5 model accuracy on test set: 0.1772
  Client 6 model accuracy on test set: 0.2036
  Client 7 model accuracy on test set: 0.1463
  Client 8 model accuracy on test set: 0.2051
  Client 9 model accuracy on test set: 0.2211

=== Global Round 58/100 ===
  Client 0: layers_shared=1, local_acc=0.9584
  Client 1: layers_shared=1, local_acc=0.9470
  Client 2: layers_shared=5, local_acc=0.9257
  Client 3: layers_shared=4, local_acc=0.9552
  Client 4: layers_shared=1, local_acc=0.9556
  Client 5: layers_shared=5, local_acc=0.9755
  Client 6: layers_shared=4, local_acc=0.9653
  Client 7: layers_shared=2, local_acc=0.9726
  Client 8: layers_shared=4, local_acc=0.9856
  Client 9: layers_shared=3, local_acc=0.9718
  Client 0: mean_dist=3.56, base_reward=-0.8227, violation=0, comm_penalty=0.0000, reward=-0.8227
  Client 1: mean_dist=3.88, base_reward=-0.9941, violation=0, comm_penalty=0.0000, reward=-0.9941
  Client 2: mean_dist=13.95, base_reward=-6.0504, violation=4, comm_penalty=4.0000, reward=-10.0504
  Client 3: mean_dist=13.64, base_reward=-5.8646, violation=2, comm_penalty=2.0000, reward=-7.8646
  Client 4: mean_dist=3.51, base_reward=-0.8001, violation=0, comm_penalty=0.0000, reward=-0.8001
  Client 5: mean_dist=14.29, base_reward=-6.1672, violation=0, comm_penalty=0.0000, reward=-6.1672
  Client 6: mean_dist=14.01, base_reward=-6.0418, violation=3, comm_penalty=3.0000, reward=-9.0418
  Client 7: mean_dist=8.64, base_reward=-3.3484, violation=0, comm_penalty=0.0000, reward=-3.3484
  Client 8: mean_dist=13.68, base_reward=-5.8556, violation=2, comm_penalty=2.0000, reward=-7.8556
  Client 9: mean_dist=11.77, base_reward=-4.9126, violation=0, comm_penalty=0.0000, reward=-4.9126
  RL policy loss: -1.398707
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.2253
  Client 1 model accuracy on test set: 0.1755
  Client 2 model accuracy on test set: 0.1564
  Client 3 model accuracy on test set: 0.1777
  Client 4 model accuracy on test set: 0.1769
  Client 5 model accuracy on test set: 0.1972
  Client 6 model accuracy on test set: 0.2201
  Client 7 model accuracy on test set: 0.1943
  Client 8 model accuracy on test set: 0.1987
  Client 9 model accuracy on test set: 0.2892

=== Global Round 59/100 ===
  Client 0: layers_shared=1, local_acc=0.9758
  Client 1: layers_shared=4, local_acc=0.9443
  Client 2: layers_shared=6, local_acc=0.9475
  Client 3: layers_shared=1, local_acc=0.9696
  Client 4: layers_shared=1, local_acc=0.9160
  Client 5: layers_shared=1, local_acc=0.9856
  Client 6: layers_shared=1, local_acc=0.9634
  Client 7: layers_shared=1, local_acc=0.9647
  Client 8: layers_shared=2, local_acc=0.9807
  Client 9: layers_shared=6, local_acc=0.9777
  Client 0: mean_dist=3.57, base_reward=-0.8101, violation=0, comm_penalty=0.0000, reward=-0.8101
  Client 1: mean_dist=9.17, base_reward=-3.6395, violation=0, comm_penalty=0.0000, reward=-3.6395
  Client 2: mean_dist=9.28, base_reward=-3.6916, violation=5, comm_penalty=5.0000, reward=-8.6916
  Client 3: mean_dist=3.51, base_reward=-0.7836, violation=0, comm_penalty=0.0000, reward=-0.7836
  Client 4: mean_dist=3.52, base_reward=-0.8450, violation=0, comm_penalty=0.0000, reward=-0.8450
  Client 5: mean_dist=3.70, base_reward=-0.8661, violation=0, comm_penalty=0.0000, reward=-0.8661
  Client 6: mean_dist=3.90, base_reward=-0.9862, violation=0, comm_penalty=0.0000, reward=-0.9862
  Client 7: mean_dist=3.80, base_reward=-0.9372, violation=0, comm_penalty=0.0000, reward=-0.9372
  Client 8: mean_dist=5.84, base_reward=-1.9406, violation=0, comm_penalty=0.0000, reward=-1.9406
  Client 9: mean_dist=9.55, base_reward=-3.7972, violation=1, comm_penalty=1.0000, reward=-4.7972
  RL policy loss: -1.076657
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1361
  Client 1 model accuracy on test set: 0.1232
  Client 2 model accuracy on test set: 0.1572
  Client 3 model accuracy on test set: 0.1670
  Client 4 model accuracy on test set: 0.1867
  Client 5 model accuracy on test set: 0.2016
  Client 6 model accuracy on test set: 0.2244
  Client 7 model accuracy on test set: 0.2640
  Client 8 model accuracy on test set: 0.1686
  Client 9 model accuracy on test set: 0.2392

=== Global Round 60/100 ===
  Client 0: layers_shared=3, local_acc=0.9312
  Client 1: layers_shared=6, local_acc=0.9708
  Client 2: layers_shared=3, local_acc=0.9758
  Client 3: layers_shared=1, local_acc=0.9714
  Client 4: layers_shared=2, local_acc=0.9678
  Client 5: layers_shared=1, local_acc=0.9777
  Client 6: layers_shared=3, local_acc=0.9764
  Client 7: layers_shared=3, local_acc=0.9776
  Client 8: layers_shared=6, local_acc=0.9786
  Client 9: layers_shared=5, local_acc=0.9750
  Client 0: mean_dist=12.80, base_reward=-5.4685, violation=0, comm_penalty=0.0000, reward=-5.4685
  Client 1: mean_dist=16.38, base_reward=-7.2173, violation=1, comm_penalty=1.0000, reward=-8.2173
  Client 2: mean_dist=12.48, base_reward=-5.2631, violation=2, comm_penalty=2.0000, reward=-7.2631
  Client 3: mean_dist=3.52, base_reward=-0.7889, violation=0, comm_penalty=0.0000, reward=-0.7889
  Client 4: mean_dist=8.93, base_reward=-3.4985, violation=0, comm_penalty=0.0000, reward=-3.4985
  Client 5: mean_dist=3.72, base_reward=-0.8837, violation=0, comm_penalty=0.0000, reward=-0.8837
  Client 6: mean_dist=12.98, base_reward=-5.5139, violation=2, comm_penalty=2.0000, reward=-7.5139
  Client 7: mean_dist=13.42, base_reward=-5.7315, violation=0, comm_penalty=0.0000, reward=-5.7315
  Client 8: mean_dist=15.27, base_reward=-6.6547, violation=4, comm_penalty=4.0000, reward=-10.6547
  Client 9: mean_dist=16.13, base_reward=-7.0878, violation=0, comm_penalty=0.0000, reward=-7.0878
  RL policy loss: -0.964726
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1444
  Client 1 model accuracy on test set: 0.2221
  Client 2 model accuracy on test set: 0.1899
  Client 3 model accuracy on test set: 0.1741
  Client 4 model accuracy on test set: 0.1828
  Client 5 model accuracy on test set: 0.2470
  Client 6 model accuracy on test set: 0.2488
  Client 7 model accuracy on test set: 0.2174
  Client 8 model accuracy on test set: 0.2036
  Client 9 model accuracy on test set: 0.2557

=== Global Round 61/100 ===
  Client 0: layers_shared=5, local_acc=0.9540
  Client 1: layers_shared=3, local_acc=0.9646
  Client 2: layers_shared=3, local_acc=0.9675
  Client 3: layers_shared=1, local_acc=0.9833
  Client 4: layers_shared=1, local_acc=0.9707
  Client 5: layers_shared=3, local_acc=0.9713
  Client 6: layers_shared=2, local_acc=0.9906
  Client 7: layers_shared=3, local_acc=0.9627
  Client 8: layers_shared=5, local_acc=0.9813
  Client 9: layers_shared=3, local_acc=0.9861
  Client 0: mean_dist=13.95, base_reward=-6.0233, violation=2, comm_penalty=2.0000, reward=-8.0233
  Client 1: mean_dist=13.68, base_reward=-5.8774, violation=0, comm_penalty=0.0000, reward=-5.8774
  Client 2: mean_dist=12.53, base_reward=-5.2950, violation=2, comm_penalty=2.0000, reward=-7.2950
  Client 3: mean_dist=3.54, base_reward=-0.7853, violation=0, comm_penalty=0.0000, reward=-0.7853
  Client 4: mean_dist=3.55, base_reward=-0.8036, violation=0, comm_penalty=0.0000, reward=-0.8036
  Client 5: mean_dist=12.89, base_reward=-5.4758, violation=0, comm_penalty=0.0000, reward=-5.4758
  Client 6: mean_dist=9.36, base_reward=-3.6913, violation=1, comm_penalty=1.0000, reward=-4.6913
  Client 7: mean_dist=13.48, base_reward=-5.7787, violation=0, comm_penalty=0.0000, reward=-5.7787
  Client 8: mean_dist=13.87, base_reward=-5.9562, violation=3, comm_penalty=3.0000, reward=-8.9562
  Client 9: mean_dist=13.55, base_reward=-5.7874, violation=0, comm_penalty=0.0000, reward=-5.7874
  RL policy loss: -0.750552
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.2128
  Client 1 model accuracy on test set: 0.1437
  Client 2 model accuracy on test set: 0.1734
  Client 3 model accuracy on test set: 0.1839
  Client 4 model accuracy on test set: 0.1881
  Client 5 model accuracy on test set: 0.1937
  Client 6 model accuracy on test set: 0.2318
  Client 7 model accuracy on test set: 0.1733
  Client 8 model accuracy on test set: 0.2108
  Client 9 model accuracy on test set: 0.2226

=== Global Round 62/100 ===
  Client 0: layers_shared=4, local_acc=0.9683
  Client 1: layers_shared=1, local_acc=0.9390
  Client 2: layers_shared=4, local_acc=0.9543
  Client 3: layers_shared=2, local_acc=0.9799
  Client 4: layers_shared=3, local_acc=0.9344
  Client 5: layers_shared=1, local_acc=0.9800
  Client 6: layers_shared=3, local_acc=0.9814
  Client 7: layers_shared=3, local_acc=0.9763
  Client 8: layers_shared=4, local_acc=0.9813
  Client 9: layers_shared=3, local_acc=0.9826
  Client 0: mean_dist=14.13, base_reward=-6.0978, violation=1, comm_penalty=1.0000, reward=-7.0978
  Client 1: mean_dist=3.95, base_reward=-1.0347, violation=0, comm_penalty=0.0000, reward=-1.0347
  Client 2: mean_dist=13.78, base_reward=-5.9376, violation=3, comm_penalty=3.0000, reward=-8.9376
  Client 3: mean_dist=8.98, base_reward=-3.5101, violation=0, comm_penalty=0.0000, reward=-3.5101
  Client 4: mean_dist=12.69, base_reward=-5.4086, violation=0, comm_penalty=0.0000, reward=-5.4086
  Client 5: mean_dist=3.75, base_reward=-0.8940, violation=0, comm_penalty=0.0000, reward=-0.8940
  Client 6: mean_dist=12.97, base_reward=-5.5048, violation=2, comm_penalty=2.0000, reward=-7.5048
  Client 7: mean_dist=13.43, base_reward=-5.7407, violation=0, comm_penalty=0.0000, reward=-5.7407
  Client 8: mean_dist=14.06, base_reward=-6.0485, violation=2, comm_penalty=2.0000, reward=-8.0485
  Client 9: mean_dist=13.52, base_reward=-5.7764, violation=0, comm_penalty=0.0000, reward=-5.7764
  RL policy loss: -0.874642
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1978
  Client 1 model accuracy on test set: 0.1396
  Client 2 model accuracy on test set: 0.2022
  Client 3 model accuracy on test set: 0.1790
  Client 4 model accuracy on test set: 0.1452
  Client 5 model accuracy on test set: 0.2045
  Client 6 model accuracy on test set: 0.1606
  Client 7 model accuracy on test set: 0.1920
  Client 8 model accuracy on test set: 0.1930
  Client 9 model accuracy on test set: 0.2448

=== Global Round 63/100 ===
  Client 0: layers_shared=3, local_acc=0.9521
  Client 1: layers_shared=3, local_acc=0.9574
  Client 2: layers_shared=1, local_acc=0.9654
  Client 3: layers_shared=3, local_acc=0.9696
  Client 4: layers_shared=5, local_acc=0.9613
  Client 5: layers_shared=5, local_acc=0.9874
  Client 6: layers_shared=1, local_acc=0.9638
  Client 7: layers_shared=1, local_acc=0.9742
  Client 8: layers_shared=1, local_acc=0.9842
  Client 9: layers_shared=3, local_acc=0.9756
  Client 0: mean_dist=10.84, base_reward=-4.4671, violation=0, comm_penalty=0.0000, reward=-4.4671
  Client 1: mean_dist=11.52, base_reward=-4.8022, violation=0, comm_penalty=0.0000, reward=-4.8022
  Client 2: mean_dist=3.89, base_reward=-0.9787, violation=0, comm_penalty=0.0000, reward=-0.9787
  Client 3: mean_dist=10.69, base_reward=-4.3748, violation=1, comm_penalty=1.0000, reward=-5.3748
  Client 4: mean_dist=11.95, base_reward=-5.0118, violation=1, comm_penalty=1.0000, reward=-6.0118
  Client 5: mean_dist=12.10, base_reward=-5.0639, violation=0, comm_penalty=0.0000, reward=-5.0639
  Client 6: mean_dist=3.96, base_reward=-1.0148, violation=0, comm_penalty=0.0000, reward=-1.0148
  Client 7: mean_dist=3.86, base_reward=-0.9560, violation=0, comm_penalty=0.0000, reward=-0.9560
  Client 8: mean_dist=3.56, base_reward=-0.7944, violation=0, comm_penalty=0.0000, reward=-0.7944
  Client 9: mean_dist=11.33, base_reward=-4.6918, violation=0, comm_penalty=0.0000, reward=-4.6918
  RL policy loss: -0.745328
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1310
  Client 1 model accuracy on test set: 0.1686
  Client 2 model accuracy on test set: 0.2261
  Client 3 model accuracy on test set: 0.1261
  Client 4 model accuracy on test set: 0.1654
  Client 5 model accuracy on test set: 0.2399
  Client 6 model accuracy on test set: 0.2320
  Client 7 model accuracy on test set: 0.1932
  Client 8 model accuracy on test set: 0.2076
  Client 9 model accuracy on test set: 0.2370

=== Global Round 64/100 ===
  Client 0: layers_shared=2, local_acc=0.9714
  Client 1: layers_shared=2, local_acc=0.9719
  Client 2: layers_shared=4, local_acc=0.9199
  Client 3: layers_shared=2, local_acc=0.9652
  Client 4: layers_shared=1, local_acc=0.9532
  Client 5: layers_shared=1, local_acc=0.9860
  Client 6: layers_shared=6, local_acc=0.9820
  Client 7: layers_shared=1, local_acc=0.9689
  Client 8: layers_shared=6, local_acc=0.9832
  Client 9: layers_shared=2, local_acc=0.9385
  Client 0: mean_dist=8.42, base_reward=-3.2399, violation=0, comm_penalty=0.0000, reward=-3.2399
  Client 1: mean_dist=8.89, base_reward=-3.4751, violation=0, comm_penalty=0.0000, reward=-3.4751
  Client 2: mean_dist=10.83, base_reward=-4.4938, violation=3, comm_penalty=3.0000, reward=-7.4938
  Client 3: mean_dist=8.27, base_reward=-3.1720, violation=0, comm_penalty=0.0000, reward=-3.1720
  Client 4: mean_dist=3.60, base_reward=-0.8443, violation=0, comm_penalty=0.0000, reward=-0.8443
  Client 5: mean_dist=3.78, base_reward=-0.9020, violation=0, comm_penalty=0.0000, reward=-0.9020
  Client 6: mean_dist=11.67, base_reward=-4.8539, violation=5, comm_penalty=5.0000, reward=-9.8539
  Client 7: mean_dist=3.88, base_reward=-0.9710, violation=0, comm_penalty=0.0000, reward=-0.9710
  Client 8: mean_dist=11.31, base_reward=-4.6719, violation=4, comm_penalty=4.0000, reward=-8.6719
  Client 9: mean_dist=8.80, base_reward=-3.4613, violation=0, comm_penalty=0.0000, reward=-3.4613
  RL policy loss: -1.377543
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1477
  Client 1 model accuracy on test set: 0.1652
  Client 2 model accuracy on test set: 0.1446
  Client 3 model accuracy on test set: 0.2066
  Client 4 model accuracy on test set: 0.1617
  Client 5 model accuracy on test set: 0.2427
  Client 6 model accuracy on test set: 0.2273
  Client 7 model accuracy on test set: 0.2181
  Client 8 model accuracy on test set: 0.2488
  Client 9 model accuracy on test set: 0.2046

=== Global Round 65/100 ===
  Client 0: layers_shared=1, local_acc=0.9731
  Client 1: layers_shared=4, local_acc=0.9742
  Client 2: layers_shared=3, local_acc=0.9454
  Client 3: layers_shared=1, local_acc=0.9696
  Client 4: layers_shared=5, local_acc=0.9752
  Client 5: layers_shared=3, local_acc=0.9670
  Client 6: layers_shared=3, local_acc=0.9857
  Client 7: layers_shared=6, local_acc=0.9795
  Client 8: layers_shared=3, local_acc=0.9776
  Client 9: layers_shared=6, local_acc=0.9454
  Client 0: mean_dist=3.66, base_reward=-0.8563, violation=0, comm_penalty=0.0000, reward=-0.8563
  Client 1: mean_dist=17.09, base_reward=-7.5711, violation=0, comm_penalty=0.0000, reward=-7.5711
  Client 2: mean_dist=13.33, base_reward=-5.7177, violation=2, comm_penalty=2.0000, reward=-7.7177
  Client 3: mean_dist=3.60, base_reward=-0.8282, violation=0, comm_penalty=0.0000, reward=-0.8282
  Client 4: mean_dist=17.04, base_reward=-7.5459, violation=1, comm_penalty=1.0000, reward=-8.5459
  Client 5: mean_dist=13.72, base_reward=-5.8953, violation=0, comm_penalty=0.0000, reward=-5.8953
  Client 6: mean_dist=13.88, base_reward=-5.9522, violation=2, comm_penalty=2.0000, reward=-7.9522
  Client 7: mean_dist=17.93, base_reward=-7.9878, violation=0, comm_penalty=0.0000, reward=-7.9878
  Client 8: mean_dist=13.65, base_reward=-5.8475, violation=1, comm_penalty=1.0000, reward=-6.8475
  Client 9: mean_dist=18.04, base_reward=-8.0757, violation=1, comm_penalty=1.0000, reward=-9.0757
  RL policy loss: -1.200563
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1225
  Client 1 model accuracy on test set: 0.2116
  Client 2 model accuracy on test set: 0.1680
  Client 3 model accuracy on test set: 0.1652
  Client 4 model accuracy on test set: 0.1724
  Client 5 model accuracy on test set: 0.1993
  Client 6 model accuracy on test set: 0.2151
  Client 7 model accuracy on test set: 0.2266
  Client 8 model accuracy on test set: 0.2228
  Client 9 model accuracy on test set: 0.2102

=== Global Round 66/100 ===
  Client 0: layers_shared=5, local_acc=0.9540
  Client 1: layers_shared=1, local_acc=0.9692
  Client 2: layers_shared=3, local_acc=0.9602
  Client 3: layers_shared=1, local_acc=0.9714
  Client 4: layers_shared=6, local_acc=0.9590
  Client 5: layers_shared=1, local_acc=0.9817
  Client 6: layers_shared=3, local_acc=0.9876
  Client 7: layers_shared=1, local_acc=0.9816
  Client 8: layers_shared=4, local_acc=0.9788
  Client 9: layers_shared=3, local_acc=0.9817
  Client 0: mean_dist=12.70, base_reward=-5.3947, violation=2, comm_penalty=2.0000, reward=-7.3947
  Client 1: mean_dist=4.00, base_reward=-1.0284, violation=0, comm_penalty=0.0000, reward=-1.0284
  Client 2: mean_dist=10.61, base_reward=-4.3461, violation=2, comm_penalty=2.0000, reward=-6.3461
  Client 3: mean_dist=3.60, base_reward=-0.8311, violation=0, comm_penalty=0.0000, reward=-0.8311
  Client 4: mean_dist=12.58, base_reward=-5.3318, violation=2, comm_penalty=2.0000, reward=-7.3318
  Client 5: mean_dist=3.79, base_reward=-0.9154, violation=0, comm_penalty=0.0000, reward=-0.9154
  Client 6: mean_dist=10.95, base_reward=-4.4894, violation=2, comm_penalty=2.0000, reward=-6.4894
  Client 7: mean_dist=3.89, base_reward=-0.9650, violation=0, comm_penalty=0.0000, reward=-0.9650
  Client 8: mean_dist=12.08, base_reward=-5.0609, violation=2, comm_penalty=2.0000, reward=-7.0609
  Client 9: mean_dist=11.33, base_reward=-4.6831, violation=0, comm_penalty=0.0000, reward=-4.6831
  RL policy loss: -1.538404
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.2098
  Client 1 model accuracy on test set: 0.1613
  Client 2 model accuracy on test set: 0.1985
  Client 3 model accuracy on test set: 0.1959
  Client 4 model accuracy on test set: 0.1579
  Client 5 model accuracy on test set: 0.2167
  Client 6 model accuracy on test set: 0.2076
  Client 7 model accuracy on test set: 0.2348
  Client 8 model accuracy on test set: 0.2421
  Client 9 model accuracy on test set: 0.2536

=== Global Round 67/100 ===
  Client 0: layers_shared=1, local_acc=0.9524
  Client 1: layers_shared=2, local_acc=0.9751
  Client 2: layers_shared=4, local_acc=0.9517
  Client 3: layers_shared=2, local_acc=0.9485
  Client 4: layers_shared=3, local_acc=0.9497
  Client 5: layers_shared=1, local_acc=0.9687
  Client 6: layers_shared=5, local_acc=0.9824
  Client 7: layers_shared=4, local_acc=0.9785
  Client 8: layers_shared=4, local_acc=0.9904
  Client 9: layers_shared=1, local_acc=0.9866
  Client 0: mean_dist=3.69, base_reward=-0.8918, violation=0, comm_penalty=0.0000, reward=-0.8918
  Client 1: mean_dist=8.99, base_reward=-3.5194, violation=0, comm_penalty=0.0000, reward=-3.5194
  Client 2: mean_dist=12.87, base_reward=-5.4847, violation=3, comm_penalty=3.0000, reward=-8.4847
  Client 3: mean_dist=8.34, base_reward=-3.2207, violation=0, comm_penalty=0.0000, reward=-3.2207
  Client 4: mean_dist=10.83, base_reward=-4.4671, violation=0, comm_penalty=0.0000, reward=-4.4671
  Client 5: mean_dist=3.81, base_reward=-0.9359, violation=0, comm_penalty=0.0000, reward=-0.9359
  Client 6: mean_dist=13.26, base_reward=-5.6475, violation=4, comm_penalty=4.0000, reward=-9.6475
  Client 7: mean_dist=13.72, base_reward=-5.8836, violation=0, comm_penalty=0.0000, reward=-5.8836
  Client 8: mean_dist=12.96, base_reward=-5.4895, violation=2, comm_penalty=2.0000, reward=-7.4895
  Client 9: mean_dist=3.80, base_reward=-0.9125, violation=0, comm_penalty=0.0000, reward=-0.9125
  RL policy loss: -1.523262
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.2456
  Client 1 model accuracy on test set: 0.1175
  Client 2 model accuracy on test set: 0.1536
  Client 3 model accuracy on test set: 0.1910
  Client 4 model accuracy on test set: 0.1631
  Client 5 model accuracy on test set: 0.2180
  Client 6 model accuracy on test set: 0.2330
  Client 7 model accuracy on test set: 0.1755
  Client 8 model accuracy on test set: 0.2133
  Client 9 model accuracy on test set: 0.2257

=== Global Round 68/100 ===
  Client 0: layers_shared=5, local_acc=0.9832
  Client 1: layers_shared=1, local_acc=0.9726
  Client 2: layers_shared=3, local_acc=0.9454
  Client 3: layers_shared=1, local_acc=0.9792
  Client 4: layers_shared=1, local_acc=0.9637
  Client 5: layers_shared=2, local_acc=0.9738
  Client 6: layers_shared=3, local_acc=0.9880
  Client 7: layers_shared=3, local_acc=0.9488
  Client 8: layers_shared=3, local_acc=0.9818
  Client 9: layers_shared=1, local_acc=0.9826
  Client 0: mean_dist=10.19, base_reward=-4.1140, violation=2, comm_penalty=2.0000, reward=-6.1140
  Client 1: mean_dist=4.02, base_reward=-1.0380, violation=0, comm_penalty=0.0000, reward=-1.0380
  Client 2: mean_dist=10.07, base_reward=-4.0904, violation=2, comm_penalty=2.0000, reward=-6.0904
  Client 3: mean_dist=3.63, base_reward=-0.8359, violation=0, comm_penalty=0.0000, reward=-0.8359
  Client 4: mean_dist=3.64, base_reward=-0.8564, violation=0, comm_penalty=0.0000, reward=-0.8564
  Client 5: mean_dist=7.73, base_reward=-2.8908, violation=0, comm_penalty=0.0000, reward=-2.8908
  Client 6: mean_dist=10.41, base_reward=-4.2148, violation=2, comm_penalty=2.0000, reward=-6.2148
  Client 7: mean_dist=10.65, base_reward=-4.3756, violation=0, comm_penalty=0.0000, reward=-4.3756
  Client 8: mean_dist=10.08, base_reward=-4.0574, violation=1, comm_penalty=1.0000, reward=-5.0574
  Client 9: mean_dist=3.81, base_reward=-0.9217, violation=0, comm_penalty=0.0000, reward=-0.9217
  RL policy loss: -0.763110
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.2064
  Client 1 model accuracy on test set: 0.1366
  Client 2 model accuracy on test set: 0.2169
  Client 3 model accuracy on test set: 0.1868
  Client 4 model accuracy on test set: 0.1862
  Client 5 model accuracy on test set: 0.2125
  Client 6 model accuracy on test set: 0.2204
  Client 7 model accuracy on test set: 0.1515
  Client 8 model accuracy on test set: 0.2151
  Client 9 model accuracy on test set: 0.2857

=== Global Round 69/100 ===
  Client 0: layers_shared=1, local_acc=0.9687
  Client 1: layers_shared=1, local_acc=0.9773
  Client 2: layers_shared=1, local_acc=0.9592
  Client 3: layers_shared=1, local_acc=0.9870
  Client 4: layers_shared=1, local_acc=0.9365
  Client 5: layers_shared=6, local_acc=0.9722
  Client 6: layers_shared=3, local_acc=0.9921
  Client 7: layers_shared=4, local_acc=0.9523
  Client 8: layers_shared=1, local_acc=0.9851
  Client 9: layers_shared=1, local_acc=0.9831
  Client 0: mean_dist=3.71, base_reward=-0.8839, violation=0, comm_penalty=0.0000, reward=-0.8839
  Client 1: mean_dist=4.03, base_reward=-1.0360, violation=0, comm_penalty=0.0000, reward=-1.0360
  Client 2: mean_dist=3.96, base_reward=-1.0217, violation=0, comm_penalty=0.0000, reward=-1.0217
  Client 3: mean_dist=3.64, base_reward=-0.8334, violation=0, comm_penalty=0.0000, reward=-0.8334
  Client 4: mean_dist=3.66, base_reward=-0.8926, violation=0, comm_penalty=0.0000, reward=-0.8926
  Client 5: mean_dist=7.48, base_reward=-2.7697, violation=0, comm_penalty=0.0000, reward=-2.7697
  Client 6: mean_dist=6.92, base_reward=-2.4661, violation=2, comm_penalty=2.0000, reward=-4.4661
  Client 7: mean_dist=7.66, base_reward=-2.8778, violation=0, comm_penalty=0.0000, reward=-2.8778
  Client 8: mean_dist=3.63, base_reward=-0.8277, violation=0, comm_penalty=0.0000, reward=-0.8277
  Client 9: mean_dist=3.82, base_reward=-0.9277, violation=0, comm_penalty=0.0000, reward=-0.9277
  RL policy loss: -0.533746
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.2194
  Client 1 model accuracy on test set: 0.1771
  Client 2 model accuracy on test set: 0.1703
  Client 3 model accuracy on test set: 0.2019
  Client 4 model accuracy on test set: 0.1619
  Client 5 model accuracy on test set: 0.2160
  Client 6 model accuracy on test set: 0.1391
  Client 7 model accuracy on test set: 0.1681
  Client 8 model accuracy on test set: 0.1948
  Client 9 model accuracy on test set: 0.2660

=== Global Round 70/100 ===
  Client 0: layers_shared=1, local_acc=0.9834
  Client 1: layers_shared=2, local_acc=0.9784
  Client 2: layers_shared=2, local_acc=0.9589
  Client 3: layers_shared=3, local_acc=0.9794
  Client 4: layers_shared=1, local_acc=0.9535
  Client 5: layers_shared=1, local_acc=0.9588
  Client 6: layers_shared=1, local_acc=0.9790
  Client 7: layers_shared=1, local_acc=0.9848
  Client 8: layers_shared=3, local_acc=0.9930
  Client 9: layers_shared=1, local_acc=0.9824
  Client 0: mean_dist=3.72, base_reward=-0.8744, violation=0, comm_penalty=0.0000, reward=-0.8744
  Client 1: mean_dist=6.51, base_reward=-2.2763, violation=0, comm_penalty=0.0000, reward=-2.2763
  Client 2: mean_dist=6.23, base_reward=-2.1579, violation=1, comm_penalty=1.0000, reward=-3.1579
  Client 3: mean_dist=6.66, base_reward=-2.3498, violation=1, comm_penalty=1.0000, reward=-3.3498
  Client 4: mean_dist=3.67, base_reward=-0.8818, violation=0, comm_penalty=0.0000, reward=-0.8818
  Client 5: mean_dist=3.85, base_reward=-0.9682, violation=0, comm_penalty=0.0000, reward=-0.9682
  Client 6: mean_dist=4.04, base_reward=-1.0409, violation=0, comm_penalty=0.0000, reward=-1.0409
  Client 7: mean_dist=3.94, base_reward=-0.9853, violation=0, comm_penalty=0.0000, reward=-0.9853
  Client 8: mean_dist=6.65, base_reward=-2.3305, violation=1, comm_penalty=1.0000, reward=-3.3305
  Client 9: mean_dist=3.83, base_reward=-0.9329, violation=0, comm_penalty=0.0000, reward=-0.9329
  RL policy loss: -0.416476
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.2362
  Client 1 model accuracy on test set: 0.1914
  Client 2 model accuracy on test set: 0.1987
  Client 3 model accuracy on test set: 0.1771
  Client 4 model accuracy on test set: 0.1966
  Client 5 model accuracy on test set: 0.2247
  Client 6 model accuracy on test set: 0.1872
  Client 7 model accuracy on test set: 0.2238
  Client 8 model accuracy on test set: 0.2300
  Client 9 model accuracy on test set: 0.2390

=== Global Round 71/100 ===
  Client 0: layers_shared=6, local_acc=0.9671
  Client 1: layers_shared=4, local_acc=0.9843
  Client 2: layers_shared=1, local_acc=0.9732
  Client 3: layers_shared=3, local_acc=0.9707
  Client 4: layers_shared=1, local_acc=0.9728
  Client 5: layers_shared=1, local_acc=0.9827
  Client 6: layers_shared=1, local_acc=0.9852
  Client 7: layers_shared=1, local_acc=0.9433
  Client 8: layers_shared=5, local_acc=0.9932
  Client 9: layers_shared=1, local_acc=0.9840
  Client 0: mean_dist=10.14, base_reward=-4.1019, violation=3, comm_penalty=3.0000, reward=-7.1019
  Client 1: mean_dist=10.29, base_reward=-4.1618, violation=0, comm_penalty=0.0000, reward=-4.1618
  Client 2: mean_dist=3.99, base_reward=-1.0194, violation=0, comm_penalty=0.0000, reward=-1.0194
  Client 3: mean_dist=8.08, base_reward=-3.0683, violation=1, comm_penalty=1.0000, reward=-4.0683
  Client 4: mean_dist=3.67, base_reward=-0.8645, violation=0, comm_penalty=0.0000, reward=-0.8645
  Client 5: mean_dist=3.86, base_reward=-0.9474, violation=0, comm_penalty=0.0000, reward=-0.9474
  Client 6: mean_dist=4.05, base_reward=-1.0398, violation=0, comm_penalty=0.0000, reward=-1.0398
  Client 7: mean_dist=3.95, base_reward=-1.0325, violation=0, comm_penalty=0.0000, reward=-1.0325
  Client 8: mean_dist=10.03, base_reward=-4.0220, violation=3, comm_penalty=3.0000, reward=-7.0220
  Client 9: mean_dist=3.84, base_reward=-0.9338, violation=0, comm_penalty=0.0000, reward=-0.9338
  RL policy loss: -1.538950
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1858
  Client 1 model accuracy on test set: 0.1505
  Client 2 model accuracy on test set: 0.1968
  Client 3 model accuracy on test set: 0.2244
  Client 4 model accuracy on test set: 0.1788
  Client 5 model accuracy on test set: 0.2535
  Client 6 model accuracy on test set: 0.2203
  Client 7 model accuracy on test set: 0.1940
  Client 8 model accuracy on test set: 0.2260
  Client 9 model accuracy on test set: 0.2722

=== Global Round 72/100 ===
  Client 0: layers_shared=2, local_acc=0.9753
  Client 1: layers_shared=3, local_acc=0.9726
  Client 2: layers_shared=1, local_acc=0.9452
  Client 3: layers_shared=1, local_acc=0.9858
  Client 4: layers_shared=4, local_acc=0.9769
  Client 5: layers_shared=6, local_acc=0.9652
  Client 6: layers_shared=2, local_acc=0.9850
  Client 7: layers_shared=1, local_acc=0.9617
  Client 8: layers_shared=3, local_acc=0.9930
  Client 9: layers_shared=1, local_acc=0.9843
  Client 0: mean_dist=7.82, base_reward=-2.9371, violation=0, comm_penalty=0.0000, reward=-2.9371
  Client 1: mean_dist=10.42, base_reward=-4.2351, violation=0, comm_penalty=0.0000, reward=-4.2351
  Client 2: mean_dist=4.00, base_reward=-1.0537, violation=0, comm_penalty=0.0000, reward=-1.0537
  Client 3: mean_dist=3.67, base_reward=-0.8499, violation=0, comm_penalty=0.0000, reward=-0.8499
  Client 4: mean_dist=10.42, base_reward=-4.2329, violation=0, comm_penalty=0.0000, reward=-4.2329
  Client 5: mean_dist=10.63, base_reward=-4.3511, violation=0, comm_penalty=0.0000, reward=-4.3511
  Client 6: mean_dist=8.01, base_reward=-3.0215, violation=1, comm_penalty=1.0000, reward=-4.0215
  Client 7: mean_dist=3.97, base_reward=-1.0254, violation=0, comm_penalty=0.0000, reward=-1.0254
  Client 8: mean_dist=9.71, base_reward=-3.8627, violation=1, comm_penalty=1.0000, reward=-4.8627
  Client 9: mean_dist=3.86, base_reward=-0.9444, violation=0, comm_penalty=0.0000, reward=-0.9444
  RL policy loss: -0.876816
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1392
  Client 1 model accuracy on test set: 0.1327
  Client 2 model accuracy on test set: 0.1438
  Client 3 model accuracy on test set: 0.2088
  Client 4 model accuracy on test set: 0.1769
  Client 5 model accuracy on test set: 0.2568
  Client 6 model accuracy on test set: 0.2065
  Client 7 model accuracy on test set: 0.2009
  Client 8 model accuracy on test set: 0.2434
  Client 9 model accuracy on test set: 0.2570

=== Global Round 73/100 ===
  Client 0: layers_shared=5, local_acc=0.9764
  Client 1: layers_shared=1, local_acc=0.9852
  Client 2: layers_shared=3, local_acc=0.9714
  Client 3: layers_shared=3, local_acc=0.9609
  Client 4: layers_shared=2, local_acc=0.9568
  Client 5: layers_shared=1, local_acc=0.9899
  Client 6: layers_shared=1, local_acc=0.9784
  Client 7: layers_shared=3, local_acc=0.9832
  Client 8: layers_shared=1, local_acc=0.9779
  Client 9: layers_shared=1, local_acc=0.9839
  Client 0: mean_dist=8.93, base_reward=-3.4884, violation=2, comm_penalty=2.0000, reward=-5.4884
  Client 1: mean_dist=4.07, base_reward=-1.0521, violation=0, comm_penalty=0.0000, reward=-1.0521
  Client 2: mean_dist=8.89, base_reward=-3.4744, violation=2, comm_penalty=2.0000, reward=-5.4744
  Client 3: mean_dist=8.80, base_reward=-3.4378, violation=1, comm_penalty=1.0000, reward=-4.4378
  Client 4: mean_dist=6.89, base_reward=-2.4887, violation=0, comm_penalty=0.0000, reward=-2.4887
  Client 5: mean_dist=3.88, base_reward=-0.9502, violation=0, comm_penalty=0.0000, reward=-0.9502
  Client 6: mean_dist=4.06, base_reward=-1.0528, violation=0, comm_penalty=0.0000, reward=-1.0528
  Client 7: mean_dist=9.32, base_reward=-3.6784, violation=0, comm_penalty=0.0000, reward=-3.6784
  Client 8: mean_dist=3.66, base_reward=-0.8540, violation=0, comm_penalty=0.0000, reward=-0.8540
  Client 9: mean_dist=3.86, base_reward=-0.9457, violation=0, comm_penalty=0.0000, reward=-0.9457
  RL policy loss: -0.861970
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1443
  Client 1 model accuracy on test set: 0.1254
  Client 2 model accuracy on test set: 0.1656
  Client 3 model accuracy on test set: 0.2146
  Client 4 model accuracy on test set: 0.1796
  Client 5 model accuracy on test set: 0.2212
  Client 6 model accuracy on test set: 0.2493
  Client 7 model accuracy on test set: 0.1713
  Client 8 model accuracy on test set: 0.2207
  Client 9 model accuracy on test set: 0.1682

=== Global Round 74/100 ===
  Client 0: layers_shared=1, local_acc=0.9903
  Client 1: layers_shared=1, local_acc=0.9769
  Client 2: layers_shared=2, local_acc=0.9808
  Client 3: layers_shared=4, local_acc=0.9828
  Client 4: layers_shared=1, local_acc=0.9733
  Client 5: layers_shared=1, local_acc=0.9810
  Client 6: layers_shared=1, local_acc=0.9820
  Client 7: layers_shared=2, local_acc=0.9816
  Client 8: layers_shared=6, local_acc=0.9804
  Client 9: layers_shared=3, local_acc=0.9918
  Client 0: mean_dist=3.76, base_reward=-0.8898, violation=0, comm_penalty=0.0000, reward=-0.8898
  Client 1: mean_dist=4.08, base_reward=-1.0616, violation=0, comm_penalty=0.0000, reward=-1.0616
  Client 2: mean_dist=7.13, base_reward=-2.5845, violation=1, comm_penalty=1.0000, reward=-3.5845
  Client 3: mean_dist=9.00, base_reward=-3.5151, violation=2, comm_penalty=2.0000, reward=-5.5151
  Client 4: mean_dist=3.71, base_reward=-0.8818, violation=0, comm_penalty=0.0000, reward=-0.8818
  Client 5: mean_dist=3.89, base_reward=-0.9647, violation=0, comm_penalty=0.0000, reward=-0.9647
  Client 6: mean_dist=4.07, base_reward=-1.0530, violation=0, comm_penalty=0.0000, reward=-1.0530
  Client 7: mean_dist=7.44, base_reward=-2.7386, violation=0, comm_penalty=0.0000, reward=-2.7386
  Client 8: mean_dist=9.01, base_reward=-3.5240, violation=4, comm_penalty=4.0000, reward=-7.5240
  Client 9: mean_dist=8.77, base_reward=-3.3929, violation=0, comm_penalty=0.0000, reward=-3.3929
  RL policy loss: -1.327329
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1332
  Client 1 model accuracy on test set: 0.1241
  Client 2 model accuracy on test set: 0.1740
  Client 3 model accuracy on test set: 0.1871
  Client 4 model accuracy on test set: 0.1761
  Client 5 model accuracy on test set: 0.2362
  Client 6 model accuracy on test set: 0.1810
  Client 7 model accuracy on test set: 0.1981
  Client 8 model accuracy on test set: 0.1397
  Client 9 model accuracy on test set: 0.2493

=== Global Round 75/100 ===
  Client 0: layers_shared=1, local_acc=0.9932
  Client 1: layers_shared=1, local_acc=0.9832
  Client 2: layers_shared=6, local_acc=0.9459
  Client 3: layers_shared=3, local_acc=0.9893
  Client 4: layers_shared=3, local_acc=0.9687
  Client 5: layers_shared=6, local_acc=0.9798
  Client 6: layers_shared=5, local_acc=0.9762
  Client 7: layers_shared=1, local_acc=0.9779
  Client 8: layers_shared=5, local_acc=0.9856
  Client 9: layers_shared=3, local_acc=0.9731
  Client 0: mean_dist=3.77, base_reward=-0.8921, violation=0, comm_penalty=0.0000, reward=-0.8921
  Client 1: mean_dist=4.10, base_reward=-1.0665, violation=0, comm_penalty=0.0000, reward=-1.0665
  Client 2: mean_dist=15.87, base_reward=-6.9881, violation=5, comm_penalty=5.0000, reward=-11.9881
  Client 3: mean_dist=12.38, base_reward=-5.1991, violation=1, comm_penalty=1.0000, reward=-6.1991
  Client 4: mean_dist=12.42, base_reward=-5.2419, violation=0, comm_penalty=0.0000, reward=-5.2419
  Client 5: mean_dist=16.22, base_reward=-7.1325, violation=0, comm_penalty=0.0000, reward=-7.1325
  Client 6: mean_dist=16.28, base_reward=-7.1651, violation=4, comm_penalty=4.0000, reward=-11.1651
  Client 7: mean_dist=4.00, base_reward=-1.0198, violation=0, comm_penalty=0.0000, reward=-1.0198
  Client 8: mean_dist=16.01, base_reward=-7.0184, violation=3, comm_penalty=3.0000, reward=-10.0184
  Client 9: mean_dist=13.20, base_reward=-5.6273, violation=0, comm_penalty=0.0000, reward=-5.6273
  RL policy loss: -2.465273
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1343
  Client 1 model accuracy on test set: 0.1799
  Client 2 model accuracy on test set: 0.2074
  Client 3 model accuracy on test set: 0.2010
  Client 4 model accuracy on test set: 0.1888
  Client 5 model accuracy on test set: 0.1770
  Client 6 model accuracy on test set: 0.2240
  Client 7 model accuracy on test set: 0.1382
  Client 8 model accuracy on test set: 0.1898
  Client 9 model accuracy on test set: 0.2918

=== Global Round 76/100 ===
  Client 0: layers_shared=1, local_acc=0.9874
  Client 1: layers_shared=4, local_acc=0.9751
  Client 2: layers_shared=1, local_acc=0.9779
  Client 3: layers_shared=3, local_acc=0.9842
  Client 4: layers_shared=4, local_acc=0.9327
  Client 5: layers_shared=1, local_acc=0.9930
  Client 6: layers_shared=1, local_acc=0.9929
  Client 7: layers_shared=3, local_acc=0.9795
  Client 8: layers_shared=4, local_acc=0.9830
  Client 9: layers_shared=6, local_acc=0.9798
  Client 0: mean_dist=3.78, base_reward=-0.9025, violation=0, comm_penalty=0.0000, reward=-0.9025
  Client 1: mean_dist=14.70, base_reward=-6.3742, violation=0, comm_penalty=0.0000, reward=-6.3742
  Client 2: mean_dist=4.04, base_reward=-1.0408, violation=0, comm_penalty=0.0000, reward=-1.0408
  Client 3: mean_dist=11.29, base_reward=-4.6591, violation=1, comm_penalty=1.0000, reward=-5.6591
  Client 4: mean_dist=13.79, base_reward=-5.9630, violation=0, comm_penalty=0.0000, reward=-5.9630
  Client 5: mean_dist=3.91, base_reward=-0.9639, violation=0, comm_penalty=0.0000, reward=-0.9639
  Client 6: mean_dist=4.10, base_reward=-1.0570, violation=0, comm_penalty=0.0000, reward=-1.0570
  Client 7: mean_dist=11.94, base_reward=-4.9900, violation=0, comm_penalty=0.0000, reward=-4.9900
  Client 8: mean_dist=13.71, base_reward=-5.8726, violation=2, comm_penalty=2.0000, reward=-7.8726
  Client 9: mean_dist=14.46, base_reward=-6.2485, violation=1, comm_penalty=1.0000, reward=-7.2485
  RL policy loss: -1.998091
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1099
  Client 1 model accuracy on test set: 0.1259
  Client 2 model accuracy on test set: 0.1944
  Client 3 model accuracy on test set: 0.1515
  Client 4 model accuracy on test set: 0.1312
  Client 5 model accuracy on test set: 0.1807
  Client 6 model accuracy on test set: 0.2504
  Client 7 model accuracy on test set: 0.2204
  Client 8 model accuracy on test set: 0.2116
  Client 9 model accuracy on test set: 0.2504

=== Global Round 77/100 ===
  Client 0: layers_shared=6, local_acc=0.9731
  Client 1: layers_shared=1, local_acc=0.9879
  Client 2: layers_shared=4, local_acc=0.9748
  Client 3: layers_shared=6, local_acc=0.9867
  Client 4: layers_shared=1, local_acc=0.9857
  Client 5: layers_shared=1, local_acc=0.9866
  Client 6: layers_shared=2, local_acc=0.9929
  Client 7: layers_shared=1, local_acc=0.9797
  Client 8: layers_shared=3, local_acc=0.9904
  Client 9: layers_shared=1, local_acc=0.9908
  Client 0: mean_dist=10.94, base_reward=-4.4952, violation=3, comm_penalty=3.0000, reward=-7.4952
  Client 1: mean_dist=4.13, base_reward=-1.0765, violation=0, comm_penalty=0.0000, reward=-1.0765
  Client 2: mean_dist=10.33, base_reward=-4.1897, violation=3, comm_penalty=3.0000, reward=-7.1897
  Client 3: mean_dist=10.79, base_reward=-4.4060, violation=4, comm_penalty=4.0000, reward=-8.4060
  Client 4: mean_dist=3.75, base_reward=-0.8898, violation=0, comm_penalty=0.0000, reward=-0.8898
  Client 5: mean_dist=3.92, base_reward=-0.9755, violation=0, comm_penalty=0.0000, reward=-0.9755
  Client 6: mean_dist=7.25, base_reward=-2.6323, violation=1, comm_penalty=1.0000, reward=-3.6323
  Client 7: mean_dist=4.02, base_reward=-1.0316, violation=0, comm_penalty=0.0000, reward=-1.0316
  Client 8: mean_dist=8.83, base_reward=-3.4233, violation=1, comm_penalty=1.0000, reward=-4.4233
  Client 9: mean_dist=3.92, base_reward=-0.9668, violation=0, comm_penalty=0.0000, reward=-0.9668
  RL policy loss: -2.157254
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1527
  Client 1 model accuracy on test set: 0.2140
  Client 2 model accuracy on test set: 0.2018
  Client 3 model accuracy on test set: 0.1648
  Client 4 model accuracy on test set: 0.1776
  Client 5 model accuracy on test set: 0.1805
  Client 6 model accuracy on test set: 0.1791
  Client 7 model accuracy on test set: 0.2377
  Client 8 model accuracy on test set: 0.1858
  Client 9 model accuracy on test set: 0.2484

=== Global Round 78/100 ===
  Client 0: layers_shared=1, local_acc=0.9843
  Client 1: layers_shared=3, local_acc=0.9829
  Client 2: layers_shared=2, local_acc=0.9532
  Client 3: layers_shared=2, local_acc=0.9941
  Client 4: layers_shared=1, local_acc=0.9757
  Client 5: layers_shared=1, local_acc=0.9882
  Client 6: layers_shared=1, local_acc=0.9925
  Client 7: layers_shared=1, local_acc=0.9834
  Client 8: layers_shared=2, local_acc=0.9946
  Client 9: layers_shared=2, local_acc=0.9881
  Client 0: mean_dist=3.79, base_reward=-0.9125, violation=0, comm_penalty=0.0000, reward=-0.9125
  Client 1: mean_dist=7.57, base_reward=-2.8010, violation=0, comm_penalty=0.0000, reward=-2.8010
  Client 2: mean_dist=7.20, base_reward=-2.6481, violation=1, comm_penalty=1.0000, reward=-3.6481
  Client 3: mean_dist=7.03, base_reward=-2.5215, violation=0, comm_penalty=0.0000, reward=-2.5215
  Client 4: mean_dist=3.76, base_reward=-0.9048, violation=0, comm_penalty=0.0000, reward=-0.9048
  Client 5: mean_dist=3.93, base_reward=-0.9780, violation=0, comm_penalty=0.0000, reward=-0.9780
  Client 6: mean_dist=4.12, base_reward=-1.0676, violation=0, comm_penalty=0.0000, reward=-1.0676
  Client 7: mean_dist=4.03, base_reward=-1.0326, violation=0, comm_penalty=0.0000, reward=-1.0326
  Client 8: mean_dist=7.04, base_reward=-2.5246, violation=0, comm_penalty=0.0000, reward=-2.5246
  Client 9: mean_dist=7.43, base_reward=-2.7280, violation=0, comm_penalty=0.0000, reward=-2.7280
  RL policy loss: -0.589097
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1394
  Client 1 model accuracy on test set: 0.1848
  Client 2 model accuracy on test set: 0.2059
  Client 3 model accuracy on test set: 0.1819
  Client 4 model accuracy on test set: 0.2079
  Client 5 model accuracy on test set: 0.1602
  Client 6 model accuracy on test set: 0.2298
  Client 7 model accuracy on test set: 0.2255
  Client 8 model accuracy on test set: 0.2368
  Client 9 model accuracy on test set: 0.2590

=== Global Round 79/100 ===
  Client 0: layers_shared=1, local_acc=0.9832
  Client 1: layers_shared=4, local_acc=0.9594
  Client 2: layers_shared=5, local_acc=0.9631
  Client 3: layers_shared=3, local_acc=0.9835
  Client 4: layers_shared=6, local_acc=0.9959
  Client 5: layers_shared=4, local_acc=0.9959
  Client 6: layers_shared=1, local_acc=0.9931
  Client 7: layers_shared=3, local_acc=0.9802
  Client 8: layers_shared=2, local_acc=0.9907
  Client 9: layers_shared=1, local_acc=0.9748
  Client 0: mean_dist=3.80, base_reward=-0.9184, violation=0, comm_penalty=0.0000, reward=-0.9184
  Client 1: mean_dist=15.42, base_reward=-6.7491, violation=0, comm_penalty=0.0000, reward=-6.7491
  Client 2: mean_dist=14.70, base_reward=-6.3863, violation=4, comm_penalty=4.0000, reward=-10.3863
  Client 3: mean_dist=11.94, base_reward=-4.9872, violation=1, comm_penalty=1.0000, reward=-5.9872
  Client 4: mean_dist=14.95, base_reward=-6.4782, violation=2, comm_penalty=2.0000, reward=-8.4782
  Client 5: mean_dist=14.43, base_reward=-6.2167, violation=0, comm_penalty=0.0000, reward=-6.2167
  Client 6: mean_dist=4.13, base_reward=-1.0695, violation=0, comm_penalty=0.0000, reward=-1.0695
  Client 7: mean_dist=12.67, base_reward=-5.3564, violation=0, comm_penalty=0.0000, reward=-5.3564
  Client 8: mean_dist=8.66, base_reward=-3.3400, violation=0, comm_penalty=0.0000, reward=-3.3400
  Client 9: mean_dist=3.93, base_reward=-0.9880, violation=0, comm_penalty=0.0000, reward=-0.9880
  RL policy loss: -1.985577
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1791
  Client 1 model accuracy on test set: 0.2232
  Client 2 model accuracy on test set: 0.1734
  Client 3 model accuracy on test set: 0.1971
  Client 4 model accuracy on test set: 0.1814
  Client 5 model accuracy on test set: 0.2347
  Client 6 model accuracy on test set: 0.2375
  Client 7 model accuracy on test set: 0.1676
  Client 8 model accuracy on test set: 0.2006
  Client 9 model accuracy on test set: 0.2767

=== Global Round 80/100 ===
  Client 0: layers_shared=2, local_acc=0.9843
  Client 1: layers_shared=2, local_acc=0.9697
  Client 2: layers_shared=1, local_acc=0.9704
  Client 3: layers_shared=1, local_acc=0.9849
  Client 4: layers_shared=1, local_acc=0.9926
  Client 5: layers_shared=1, local_acc=0.9909
  Client 6: layers_shared=5, local_acc=0.9936
  Client 7: layers_shared=1, local_acc=0.9818
  Client 8: layers_shared=5, local_acc=0.9872
  Client 9: layers_shared=6, local_acc=0.9915
  Client 0: mean_dist=7.25, base_reward=-2.6402, violation=0, comm_penalty=0.0000, reward=-2.6402
  Client 1: mean_dist=7.67, base_reward=-2.8674, violation=0, comm_penalty=0.0000, reward=-2.8674
  Client 2: mean_dist=4.09, base_reward=-1.0737, violation=0, comm_penalty=0.0000, reward=-1.0737
  Client 3: mean_dist=3.75, base_reward=-0.8884, violation=0, comm_penalty=0.0000, reward=-0.8884
  Client 4: mean_dist=3.77, base_reward=-0.8929, violation=0, comm_penalty=0.0000, reward=-0.8929
  Client 5: mean_dist=3.94, base_reward=-0.9814, violation=0, comm_penalty=0.0000, reward=-0.9814
  Client 6: mean_dist=11.38, base_reward=-4.6966, violation=4, comm_penalty=4.0000, reward=-8.6966
  Client 7: mean_dist=4.06, base_reward=-1.0476, violation=0, comm_penalty=0.0000, reward=-1.0476
  Client 8: mean_dist=11.01, base_reward=-4.5187, violation=3, comm_penalty=3.0000, reward=-7.5187
  Client 9: mean_dist=11.64, base_reward=-4.8263, violation=1, comm_penalty=1.0000, reward=-5.8263
  RL policy loss: -2.028603
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1988
  Client 1 model accuracy on test set: 0.2451
  Client 2 model accuracy on test set: 0.1569
  Client 3 model accuracy on test set: 0.2353
  Client 4 model accuracy on test set: 0.1496
  Client 5 model accuracy on test set: 0.2210
  Client 6 model accuracy on test set: 0.1836
  Client 7 model accuracy on test set: 0.2374
  Client 8 model accuracy on test set: 0.1986
  Client 9 model accuracy on test set: 0.2449

=== Global Round 81/100 ===
  Client 0: layers_shared=1, local_acc=0.9894
  Client 1: layers_shared=1, local_acc=0.9776
  Client 2: layers_shared=5, local_acc=0.9607
  Client 3: layers_shared=1, local_acc=0.9925
  Client 4: layers_shared=1, local_acc=0.9895
  Client 5: layers_shared=1, local_acc=0.9870
  Client 6: layers_shared=1, local_acc=0.9942
  Client 7: layers_shared=3, local_acc=0.9889
  Client 8: layers_shared=6, local_acc=0.9886
  Client 9: layers_shared=1, local_acc=0.9875
  Client 0: mean_dist=3.82, base_reward=-0.9213, violation=0, comm_penalty=0.0000, reward=-0.9213
  Client 1: mean_dist=4.16, base_reward=-1.1022, violation=0, comm_penalty=0.0000, reward=-1.1022
  Client 2: mean_dist=8.15, base_reward=-3.1162, violation=4, comm_penalty=4.0000, reward=-7.1162
  Client 3: mean_dist=3.75, base_reward=-0.8819, violation=0, comm_penalty=0.0000, reward=-0.8819
  Client 4: mean_dist=3.78, base_reward=-0.9023, violation=0, comm_penalty=0.0000, reward=-0.9023
  Client 5: mean_dist=3.95, base_reward=-0.9893, violation=0, comm_penalty=0.0000, reward=-0.9893
  Client 6: mean_dist=4.14, base_reward=-1.0740, violation=0, comm_penalty=0.0000, reward=-1.0740
  Client 7: mean_dist=7.11, base_reward=-2.5658, violation=0, comm_penalty=0.0000, reward=-2.5658
  Client 8: mean_dist=7.89, base_reward=-2.9540, violation=4, comm_penalty=4.0000, reward=-6.9540
  Client 9: mean_dist=3.95, base_reward=-0.9853, violation=0, comm_penalty=0.0000, reward=-0.9853
  RL policy loss: -1.669823
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1395
  Client 1 model accuracy on test set: 0.2158
  Client 2 model accuracy on test set: 0.1524
  Client 3 model accuracy on test set: 0.1917
  Client 4 model accuracy on test set: 0.1418
  Client 5 model accuracy on test set: 0.2283
  Client 6 model accuracy on test set: 0.2366
  Client 7 model accuracy on test set: 0.2133
  Client 8 model accuracy on test set: 0.2479
  Client 9 model accuracy on test set: 0.2535

=== Global Round 82/100 ===
  Client 0: layers_shared=5, local_acc=0.9838
  Client 1: layers_shared=1, local_acc=0.9865
  Client 2: layers_shared=1, local_acc=0.9763
  Client 3: layers_shared=4, local_acc=0.9904
  Client 4: layers_shared=4, local_acc=0.9812
  Client 5: layers_shared=1, local_acc=0.9918
  Client 6: layers_shared=6, local_acc=0.9857
  Client 7: layers_shared=2, local_acc=0.9868
  Client 8: layers_shared=1, local_acc=0.9928
  Client 9: layers_shared=5, local_acc=0.9927
  Client 0: mean_dist=14.89, base_reward=-6.4626, violation=2, comm_penalty=2.0000, reward=-8.4626
  Client 1: mean_dist=4.17, base_reward=-1.0988, violation=0, comm_penalty=0.0000, reward=-1.0988
  Client 2: mean_dist=4.11, base_reward=-1.0799, violation=0, comm_penalty=0.0000, reward=-1.0799
  Client 3: mean_dist=13.60, base_reward=-5.8104, violation=2, comm_penalty=2.0000, reward=-7.8104
  Client 4: mean_dist=13.79, base_reward=-5.9133, violation=0, comm_penalty=0.0000, reward=-5.9133
  Client 5: mean_dist=3.96, base_reward=-0.9892, violation=0, comm_penalty=0.0000, reward=-0.9892
  Client 6: mean_dist=15.04, base_reward=-6.5327, violation=5, comm_penalty=5.0000, reward=-11.5327
  Client 7: mean_dist=8.54, base_reward=-3.2851, violation=0, comm_penalty=0.0000, reward=-3.2851
  Client 8: mean_dist=3.74, base_reward=-0.8789, violation=0, comm_penalty=0.0000, reward=-0.8789
  Client 9: mean_dist=15.67, base_reward=-6.8429, violation=0, comm_penalty=0.0000, reward=-6.8429
  RL policy loss: -2.755326
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.2113
  Client 1 model accuracy on test set: 0.2357
  Client 2 model accuracy on test set: 0.1679
  Client 3 model accuracy on test set: 0.1269
  Client 4 model accuracy on test set: 0.1856
  Client 5 model accuracy on test set: 0.1476
  Client 6 model accuracy on test set: 0.1782
  Client 7 model accuracy on test set: 0.2417
  Client 8 model accuracy on test set: 0.2282
  Client 9 model accuracy on test set: 0.2723

=== Global Round 83/100 ===
  Client 0: layers_shared=1, local_acc=0.9915
  Client 1: layers_shared=1, local_acc=0.9811
  Client 2: layers_shared=2, local_acc=0.9688
  Client 3: layers_shared=3, local_acc=0.9938
  Client 4: layers_shared=1, local_acc=0.9869
  Client 5: layers_shared=1, local_acc=0.9969
  Client 6: layers_shared=4, local_acc=0.9953
  Client 7: layers_shared=1, local_acc=0.9924
  Client 8: layers_shared=3, local_acc=0.9954
  Client 9: layers_shared=4, local_acc=0.9878
  Client 0: mean_dist=3.84, base_reward=-0.9307, violation=0, comm_penalty=0.0000, reward=-0.9307
  Client 1: mean_dist=4.18, base_reward=-1.1083, violation=0, comm_penalty=0.0000, reward=-1.1083
  Client 2: mean_dist=7.26, base_reward=-2.6591, violation=1, comm_penalty=1.0000, reward=-3.6591
  Client 3: mean_dist=9.05, base_reward=-3.5311, violation=1, comm_penalty=1.0000, reward=-4.5311
  Client 4: mean_dist=3.80, base_reward=-0.9111, violation=0, comm_penalty=0.0000, reward=-0.9111
  Client 5: mean_dist=3.97, base_reward=-0.9859, violation=0, comm_penalty=0.0000, reward=-0.9859
  Client 6: mean_dist=10.20, base_reward=-4.1053, violation=3, comm_penalty=3.0000, reward=-7.1053
  Client 7: mean_dist=4.09, base_reward=-1.0514, violation=0, comm_penalty=0.0000, reward=-1.0514
  Client 8: mean_dist=9.10, base_reward=-3.5560, violation=1, comm_penalty=1.0000, reward=-4.5560
  Client 9: mean_dist=10.41, base_reward=-4.2164, violation=0, comm_penalty=0.0000, reward=-4.2164
  RL policy loss: -1.537697
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1397
  Client 1 model accuracy on test set: 0.1607
  Client 2 model accuracy on test set: 0.1716
  Client 3 model accuracy on test set: 0.1915
  Client 4 model accuracy on test set: 0.1203
  Client 5 model accuracy on test set: 0.1620
  Client 6 model accuracy on test set: 0.2316
  Client 7 model accuracy on test set: 0.2050
  Client 8 model accuracy on test set: 0.2492
  Client 9 model accuracy on test set: 0.2316

=== Global Round 84/100 ===
  Client 0: layers_shared=1, local_acc=0.9927
  Client 1: layers_shared=1, local_acc=0.9827
  Client 2: layers_shared=1, local_acc=0.9808
  Client 3: layers_shared=4, local_acc=0.9977
  Client 4: layers_shared=6, local_acc=0.9878
  Client 5: layers_shared=1, local_acc=0.9951
  Client 6: layers_shared=1, local_acc=0.9961
  Client 7: layers_shared=2, local_acc=0.9843
  Client 8: layers_shared=1, local_acc=0.9951
  Client 9: layers_shared=2, local_acc=0.9910
  Client 0: mean_dist=3.85, base_reward=-0.9325, violation=0, comm_penalty=0.0000, reward=-0.9325
  Client 1: mean_dist=4.19, base_reward=-1.1122, violation=0, comm_penalty=0.0000, reward=-1.1122
  Client 2: mean_dist=4.12, base_reward=-1.0808, violation=0, comm_penalty=0.0000, reward=-1.0808
  Client 3: mean_dist=7.77, base_reward=-2.8876, violation=2, comm_penalty=2.0000, reward=-4.8876
  Client 4: mean_dist=7.81, base_reward=-2.9187, violation=2, comm_penalty=2.0000, reward=-4.9187
  Client 5: mean_dist=3.97, base_reward=-0.9908, violation=0, comm_penalty=0.0000, reward=-0.9908
  Client 6: mean_dist=4.16, base_reward=-1.0855, violation=0, comm_penalty=0.0000, reward=-1.0855
  Client 7: mean_dist=6.81, base_reward=-2.4208, violation=0, comm_penalty=0.0000, reward=-2.4208
  Client 8: mean_dist=3.75, base_reward=-0.8821, violation=0, comm_penalty=0.0000, reward=-0.8821
  Client 9: mean_dist=6.72, base_reward=-2.3708, violation=0, comm_penalty=0.0000, reward=-2.3708
  RL policy loss: -1.162328
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1303
  Client 1 model accuracy on test set: 0.2048
  Client 2 model accuracy on test set: 0.1907
  Client 3 model accuracy on test set: 0.1933
  Client 4 model accuracy on test set: 0.1421
  Client 5 model accuracy on test set: 0.1931
  Client 6 model accuracy on test set: 0.2325
  Client 7 model accuracy on test set: 0.2161
  Client 8 model accuracy on test set: 0.2252
  Client 9 model accuracy on test set: 0.2457

=== Global Round 85/100 ===
  Client 0: layers_shared=1, local_acc=0.9963
  Client 1: layers_shared=2, local_acc=0.9874
  Client 2: layers_shared=3, local_acc=0.9719
  Client 3: layers_shared=2, local_acc=0.9909
  Client 4: layers_shared=4, local_acc=0.9871
  Client 5: layers_shared=1, local_acc=0.9953
  Client 6: layers_shared=5, local_acc=0.9844
  Client 7: layers_shared=1, local_acc=0.9954
  Client 8: layers_shared=3, local_acc=0.9954
  Client 9: layers_shared=2, local_acc=0.9915
  Client 0: mean_dist=3.86, base_reward=-0.9320, violation=0, comm_penalty=0.0000, reward=-0.9320
  Client 1: mean_dist=9.45, base_reward=-3.7373, violation=0, comm_penalty=0.0000, reward=-3.7373
  Client 2: mean_dist=10.76, base_reward=-4.4072, violation=2, comm_penalty=2.0000, reward=-6.4072
  Client 3: mean_dist=8.75, base_reward=-3.3847, violation=0, comm_penalty=0.0000, reward=-3.3847
  Client 4: mean_dist=11.53, base_reward=-4.7801, violation=0, comm_penalty=0.0000, reward=-4.7801
  Client 5: mean_dist=3.98, base_reward=-0.9942, violation=0, comm_penalty=0.0000, reward=-0.9942
  Client 6: mean_dist=11.80, base_reward=-4.9148, violation=4, comm_penalty=4.0000, reward=-8.9148
  Client 7: mean_dist=4.10, base_reward=-1.0550, violation=0, comm_penalty=0.0000, reward=-1.0550
  Client 8: mean_dist=10.77, base_reward=-4.3894, violation=1, comm_penalty=1.0000, reward=-5.3894
  Client 9: mean_dist=9.33, base_reward=-3.6749, violation=0, comm_penalty=0.0000, reward=-3.6749
  RL policy loss: -1.417372
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1932
  Client 1 model accuracy on test set: 0.1817
  Client 2 model accuracy on test set: 0.1581
  Client 3 model accuracy on test set: 0.1533
  Client 4 model accuracy on test set: 0.1462
  Client 5 model accuracy on test set: 0.2245
  Client 6 model accuracy on test set: 0.1813
  Client 7 model accuracy on test set: 0.2087
  Client 8 model accuracy on test set: 0.2286
  Client 9 model accuracy on test set: 0.2995

=== Global Round 86/100 ===
  Client 0: layers_shared=3, local_acc=0.9954
  Client 1: layers_shared=1, local_acc=0.9821
  Client 2: layers_shared=2, local_acc=0.9821
  Client 3: layers_shared=1, local_acc=0.9941
  Client 4: layers_shared=6, local_acc=0.9800
  Client 5: layers_shared=1, local_acc=0.9907
  Client 6: layers_shared=3, local_acc=0.9812
  Client 7: layers_shared=1, local_acc=0.9913
  Client 8: layers_shared=1, local_acc=0.9876
  Client 9: layers_shared=1, local_acc=0.9649
  Client 0: mean_dist=7.65, base_reward=-2.8319, violation=0, comm_penalty=0.0000, reward=-2.8319
  Client 1: mean_dist=4.21, base_reward=-1.1205, violation=0, comm_penalty=0.0000, reward=-1.1205
  Client 2: mean_dist=6.48, base_reward=-2.2557, violation=1, comm_penalty=1.0000, reward=-3.2557
  Client 3: mean_dist=3.78, base_reward=-0.8940, violation=0, comm_penalty=0.0000, reward=-0.8940
  Client 4: mean_dist=7.53, base_reward=-2.7853, violation=2, comm_penalty=2.0000, reward=-4.7853
  Client 5: mean_dist=3.98, base_reward=-1.0001, violation=0, comm_penalty=0.0000, reward=-1.0001
  Client 6: mean_dist=7.87, base_reward=-2.9529, violation=2, comm_penalty=2.0000, reward=-4.9529
  Client 7: mean_dist=4.11, base_reward=-1.0618, violation=0, comm_penalty=0.0000, reward=-1.0618
  Client 8: mean_dist=3.77, base_reward=-0.8964, violation=0, comm_penalty=0.0000, reward=-0.8964
  Client 9: mean_dist=3.98, base_reward=-1.0239, violation=0, comm_penalty=0.0000, reward=-1.0239
  RL policy loss: -1.109412
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1244
  Client 1 model accuracy on test set: 0.2264
  Client 2 model accuracy on test set: 0.1908
  Client 3 model accuracy on test set: 0.1789
  Client 4 model accuracy on test set: 0.1432
  Client 5 model accuracy on test set: 0.1328
  Client 6 model accuracy on test set: 0.2138
  Client 7 model accuracy on test set: 0.1896
  Client 8 model accuracy on test set: 0.2124
  Client 9 model accuracy on test set: 0.2412

=== Global Round 87/100 ===
  Client 0: layers_shared=1, local_acc=0.9782
  Client 1: layers_shared=1, local_acc=0.9650
  Client 2: layers_shared=1, local_acc=0.9886
  Client 3: layers_shared=2, local_acc=0.9961
  Client 4: layers_shared=3, local_acc=0.9733
  Client 5: layers_shared=1, local_acc=0.9969
  Client 6: layers_shared=1, local_acc=0.9927
  Client 7: layers_shared=1, local_acc=0.9933
  Client 8: layers_shared=1, local_acc=0.9944
  Client 9: layers_shared=2, local_acc=0.9885
  Client 0: mean_dist=3.87, base_reward=-0.9590, violation=0, comm_penalty=0.0000, reward=-0.9590
  Client 1: mean_dist=4.22, base_reward=-1.1444, violation=0, comm_penalty=0.0000, reward=-1.1444
  Client 2: mean_dist=4.15, base_reward=-1.0871, violation=0, comm_penalty=0.0000, reward=-1.0871
  Client 3: mean_dist=5.50, base_reward=-1.7548, violation=0, comm_penalty=0.0000, reward=-1.7548
  Client 4: mean_dist=5.55, base_reward=-1.8023, violation=0, comm_penalty=0.0000, reward=-1.8023
  Client 5: mean_dist=3.99, base_reward=-0.9968, violation=0, comm_penalty=0.0000, reward=-0.9968
  Client 6: mean_dist=4.19, base_reward=-1.1002, violation=0, comm_penalty=0.0000, reward=-1.1002
  Client 7: mean_dist=4.11, base_reward=-1.0639, violation=0, comm_penalty=0.0000, reward=-1.0639
  Client 8: mean_dist=3.78, base_reward=-0.8967, violation=0, comm_penalty=0.0000, reward=-0.8967
  Client 9: mean_dist=5.79, base_reward=-1.9081, violation=0, comm_penalty=0.0000, reward=-1.9081
  RL policy loss: -0.235631
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1467
  Client 1 model accuracy on test set: 0.1148
  Client 2 model accuracy on test set: 0.1513
  Client 3 model accuracy on test set: 0.2086
  Client 4 model accuracy on test set: 0.1639
  Client 5 model accuracy on test set: 0.2187
  Client 6 model accuracy on test set: 0.2137
  Client 7 model accuracy on test set: 0.1971
  Client 8 model accuracy on test set: 0.2224
  Client 9 model accuracy on test set: 0.2531

=== Global Round 88/100 ===
  Client 0: layers_shared=5, local_acc=0.9853
  Client 1: layers_shared=1, local_acc=0.9885
  Client 2: layers_shared=1, local_acc=0.9948
  Client 3: layers_shared=5, local_acc=0.9732
  Client 4: layers_shared=1, local_acc=0.9804
  Client 5: layers_shared=3, local_acc=0.9934
  Client 6: layers_shared=2, local_acc=0.9934
  Client 7: layers_shared=4, local_acc=0.9954
  Client 8: layers_shared=1, local_acc=0.9972
  Client 9: layers_shared=2, local_acc=0.9946
  Client 0: mean_dist=12.32, base_reward=-5.1737, violation=2, comm_penalty=2.0000, reward=-7.1737
  Client 1: mean_dist=4.23, base_reward=-1.1275, violation=0, comm_penalty=0.0000, reward=-1.1275
  Client 2: mean_dist=4.16, base_reward=-1.0875, violation=0, comm_penalty=0.0000, reward=-1.0875
  Client 3: mean_dist=12.11, base_reward=-5.0824, violation=3, comm_penalty=3.0000, reward=-8.0824
  Client 4: mean_dist=3.83, base_reward=-0.9343, violation=0, comm_penalty=0.0000, reward=-0.9343
  Client 5: mean_dist=10.25, base_reward=-4.1319, violation=0, comm_penalty=0.0000, reward=-4.1319
  Client 6: mean_dist=8.41, base_reward=-3.2114, violation=1, comm_penalty=1.0000, reward=-4.2114
  Client 7: mean_dist=12.30, base_reward=-5.1535, violation=0, comm_penalty=0.0000, reward=-5.1535
  Client 8: mean_dist=3.79, base_reward=-0.8967, violation=0, comm_penalty=0.0000, reward=-0.8967
  Client 9: mean_dist=8.57, base_reward=-3.2908, violation=0, comm_penalty=0.0000, reward=-3.2908
  RL policy loss: -2.047067
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1538
  Client 1 model accuracy on test set: 0.1524
  Client 2 model accuracy on test set: 0.1580
  Client 3 model accuracy on test set: 0.1747
  Client 4 model accuracy on test set: 0.1272
  Client 5 model accuracy on test set: 0.1802
  Client 6 model accuracy on test set: 0.2399
  Client 7 model accuracy on test set: 0.2556
  Client 8 model accuracy on test set: 0.2039
  Client 9 model accuracy on test set: 0.2556

=== Global Round 89/100 ===
  Client 0: layers_shared=3, local_acc=0.9905
  Client 1: layers_shared=5, local_acc=0.9825
  Client 2: layers_shared=4, local_acc=0.9886
  Client 3: layers_shared=4, local_acc=0.9806
  Client 4: layers_shared=6, local_acc=0.9940
  Client 5: layers_shared=3, local_acc=0.9918
  Client 6: layers_shared=1, local_acc=0.9949
  Client 7: layers_shared=4, local_acc=0.9924
  Client 8: layers_shared=6, local_acc=0.9965
  Client 9: layers_shared=1, local_acc=0.9975
  Client 0: mean_dist=14.65, base_reward=-6.3353, violation=0, comm_penalty=0.0000, reward=-6.3353
  Client 1: mean_dist=21.26, base_reward=-9.6458, violation=0, comm_penalty=0.0000, reward=-9.6458
  Client 2: mean_dist=18.13, base_reward=-8.0754, violation=3, comm_penalty=3.0000, reward=-11.0754
  Client 3: mean_dist=18.25, base_reward=-8.1420, violation=2, comm_penalty=2.0000, reward=-10.1420
  Client 4: mean_dist=19.79, base_reward=-8.9032, violation=2, comm_penalty=2.0000, reward=-10.9032
  Client 5: mean_dist=14.55, base_reward=-6.2838, violation=0, comm_penalty=0.0000, reward=-6.2838
  Client 6: mean_dist=4.20, base_reward=-1.1029, violation=0, comm_penalty=0.0000, reward=-1.1029
  Client 7: mean_dist=19.42, base_reward=-8.7186, violation=0, comm_penalty=0.0000, reward=-8.7186
  Client 8: mean_dist=19.57, base_reward=-8.7906, violation=4, comm_penalty=4.0000, reward=-12.7906
  Client 9: mean_dist=4.00, base_reward=-1.0009, violation=0, comm_penalty=0.0000, reward=-1.0009
  RL policy loss: -2.998924
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1792
  Client 1 model accuracy on test set: 0.1309
  Client 2 model accuracy on test set: 0.1390
  Client 3 model accuracy on test set: 0.1468
  Client 4 model accuracy on test set: 0.1660
  Client 5 model accuracy on test set: 0.1647
  Client 6 model accuracy on test set: 0.2410
  Client 7 model accuracy on test set: 0.2370
  Client 8 model accuracy on test set: 0.2196
  Client 9 model accuracy on test set: 0.2572

=== Global Round 90/100 ===
  Client 0: layers_shared=2, local_acc=0.9499
  Client 1: layers_shared=4, local_acc=0.9917
  Client 2: layers_shared=2, local_acc=0.9826
  Client 3: layers_shared=2, local_acc=0.9959
  Client 4: layers_shared=3, local_acc=0.9871
  Client 5: layers_shared=1, local_acc=0.9932
  Client 6: layers_shared=3, local_acc=0.9931
  Client 7: layers_shared=1, local_acc=0.9931
  Client 8: layers_shared=1, local_acc=0.9874
  Client 9: layers_shared=3, local_acc=0.9972
  Client 0: mean_dist=9.06, base_reward=-3.5787, violation=0, comm_penalty=0.0000, reward=-3.5787
  Client 1: mean_dist=11.84, base_reward=-4.9287, violation=0, comm_penalty=0.0000, reward=-4.9287
  Client 2: mean_dist=8.98, base_reward=-3.5075, violation=1, comm_penalty=1.0000, reward=-4.5075
  Client 3: mean_dist=8.84, base_reward=-3.4241, violation=0, comm_penalty=0.0000, reward=-3.4241
  Client 4: mean_dist=11.00, base_reward=-4.5130, violation=0, comm_penalty=0.0000, reward=-4.5130
  Client 5: mean_dist=4.01, base_reward=-1.0110, violation=0, comm_penalty=0.0000, reward=-1.0110
  Client 6: mean_dist=11.29, base_reward=-4.6503, violation=2, comm_penalty=2.0000, reward=-6.6503
  Client 7: mean_dist=4.13, base_reward=-1.0704, violation=0, comm_penalty=0.0000, reward=-1.0704
  Client 8: mean_dist=3.80, base_reward=-0.9147, violation=0, comm_penalty=0.0000, reward=-0.9147
  Client 9: mean_dist=11.66, base_reward=-4.8311, violation=0, comm_penalty=0.0000, reward=-4.8311
  RL policy loss: -1.167956
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1477
  Client 1 model accuracy on test set: 0.1944
  Client 2 model accuracy on test set: 0.1778
  Client 3 model accuracy on test set: 0.1803
  Client 4 model accuracy on test set: 0.1605
  Client 5 model accuracy on test set: 0.2138
  Client 6 model accuracy on test set: 0.2106
  Client 7 model accuracy on test set: 0.1815
  Client 8 model accuracy on test set: 0.1467
  Client 9 model accuracy on test set: 0.2477

=== Global Round 91/100 ===
  Client 0: layers_shared=6, local_acc=0.9758
  Client 1: layers_shared=2, local_acc=0.9939
  Client 2: layers_shared=1, local_acc=0.9930
  Client 3: layers_shared=6, local_acc=0.9879
  Client 4: layers_shared=1, local_acc=0.9828
  Client 5: layers_shared=1, local_acc=0.9938
  Client 6: layers_shared=6, local_acc=0.9848
  Client 7: layers_shared=6, local_acc=0.9924
  Client 8: layers_shared=1, local_acc=0.9974
  Client 9: layers_shared=1, local_acc=0.9902
  Client 0: mean_dist=13.56, base_reward=-5.8043, violation=3, comm_penalty=3.0000, reward=-8.8043
  Client 1: mean_dist=7.87, base_reward=-2.9400, violation=0, comm_penalty=0.0000, reward=-2.9400
  Client 2: mean_dist=4.18, base_reward=-1.0960, violation=0, comm_penalty=0.0000, reward=-1.0960
  Client 3: mean_dist=13.40, base_reward=-5.7119, violation=4, comm_penalty=4.0000, reward=-9.7119
  Client 4: mean_dist=3.85, base_reward=-0.9402, violation=0, comm_penalty=0.0000, reward=-0.9402
  Client 5: mean_dist=4.01, base_reward=-1.0134, violation=0, comm_penalty=0.0000, reward=-1.0134
  Client 6: mean_dist=13.77, base_reward=-5.9019, violation=5, comm_penalty=5.0000, reward=-10.9019
  Client 7: mean_dist=14.21, base_reward=-6.1120, violation=0, comm_penalty=0.0000, reward=-6.1120
  Client 8: mean_dist=3.81, base_reward=-0.9101, violation=0, comm_penalty=0.0000, reward=-0.9101
  Client 9: mean_dist=4.01, base_reward=-1.0144, violation=0, comm_penalty=0.0000, reward=-1.0144
  RL policy loss: -3.667183
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1390
  Client 1 model accuracy on test set: 0.1995
  Client 2 model accuracy on test set: 0.1896
  Client 3 model accuracy on test set: 0.2077
  Client 4 model accuracy on test set: 0.2008
  Client 5 model accuracy on test set: 0.2124
  Client 6 model accuracy on test set: 0.2437
  Client 7 model accuracy on test set: 0.2014
  Client 8 model accuracy on test set: 0.2298
  Client 9 model accuracy on test set: 0.2073

=== Global Round 92/100 ===
  Client 0: layers_shared=5, local_acc=0.9921
  Client 1: layers_shared=1, local_acc=0.9915
  Client 2: layers_shared=1, local_acc=0.9886
  Client 3: layers_shared=1, local_acc=0.9897
  Client 4: layers_shared=3, local_acc=0.9921
  Client 5: layers_shared=1, local_acc=0.9792
  Client 6: layers_shared=1, local_acc=0.9944
  Client 7: layers_shared=3, local_acc=0.9913
  Client 8: layers_shared=1, local_acc=0.9968
  Client 9: layers_shared=1, local_acc=0.9894
  Client 0: mean_dist=7.07, base_reward=-2.5436, violation=2, comm_penalty=2.0000, reward=-4.5436
  Client 1: mean_dist=4.24, base_reward=-1.1283, violation=0, comm_penalty=0.0000, reward=-1.1283
  Client 2: mean_dist=4.19, base_reward=-1.1062, violation=0, comm_penalty=0.0000, reward=-1.1062
  Client 3: mean_dist=3.82, base_reward=-0.9201, violation=0, comm_penalty=0.0000, reward=-0.9201
  Client 4: mean_dist=6.99, base_reward=-2.5040, violation=0, comm_penalty=0.0000, reward=-2.5040
  Client 5: mean_dist=4.02, base_reward=-1.0303, violation=0, comm_penalty=0.0000, reward=-1.0303
  Client 6: mean_dist=4.22, base_reward=-1.1179, violation=0, comm_penalty=0.0000, reward=-1.1179
  Client 7: mean_dist=7.35, base_reward=-2.6850, violation=0, comm_penalty=0.0000, reward=-2.6850
  Client 8: mean_dist=3.81, base_reward=-0.9098, violation=0, comm_penalty=0.0000, reward=-0.9098
  Client 9: mean_dist=4.02, base_reward=-1.0192, violation=0, comm_penalty=0.0000, reward=-1.0192
  RL policy loss: -0.873461
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1613
  Client 1 model accuracy on test set: 0.1983
  Client 2 model accuracy on test set: 0.1725
  Client 3 model accuracy on test set: 0.1810
  Client 4 model accuracy on test set: 0.1826
  Client 5 model accuracy on test set: 0.1943
  Client 6 model accuracy on test set: 0.2055
  Client 7 model accuracy on test set: 0.1833
  Client 8 model accuracy on test set: 0.2202
  Client 9 model accuracy on test set: 0.2320

=== Global Round 93/100 ===
  Client 0: layers_shared=3, local_acc=0.9940
  Client 1: layers_shared=6, local_acc=0.9885
  Client 2: layers_shared=1, local_acc=0.9971
  Client 3: layers_shared=4, local_acc=0.9799
  Client 4: layers_shared=3, local_acc=0.9819
  Client 5: layers_shared=1, local_acc=0.9924
  Client 6: layers_shared=6, local_acc=0.9923
  Client 7: layers_shared=3, local_acc=0.9963
  Client 8: layers_shared=3, local_acc=0.9965
  Client 9: layers_shared=1, local_acc=0.9908
  Client 0: mean_dist=13.35, base_reward=-5.6810, violation=0, comm_penalty=0.0000, reward=-5.6810
  Client 1: mean_dist=16.58, base_reward=-7.3029, violation=1, comm_penalty=1.0000, reward=-8.3029
  Client 2: mean_dist=4.19, base_reward=-1.0999, violation=0, comm_penalty=0.0000, reward=-1.0999
  Client 3: mean_dist=14.70, base_reward=-6.3685, violation=2, comm_penalty=2.0000, reward=-8.3685
  Client 4: mean_dist=13.17, base_reward=-5.6028, violation=0, comm_penalty=0.0000, reward=-5.6028
  Client 5: mean_dist=4.03, base_reward=-1.0222, violation=0, comm_penalty=0.0000, reward=-1.0222
  Client 6: mean_dist=15.68, base_reward=-6.8487, violation=5, comm_penalty=5.0000, reward=-11.8487
  Client 7: mean_dist=13.86, base_reward=-5.9353, violation=0, comm_penalty=0.0000, reward=-5.9353
  Client 8: mean_dist=13.18, base_reward=-5.5935, violation=1, comm_penalty=1.0000, reward=-6.5935
  Client 9: mean_dist=4.03, base_reward=-1.0256, violation=0, comm_penalty=0.0000, reward=-1.0256
  RL policy loss: -2.850400
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.2539
  Client 1 model accuracy on test set: 0.1547
  Client 2 model accuracy on test set: 0.1341
  Client 3 model accuracy on test set: 0.1361
  Client 4 model accuracy on test set: 0.1624
  Client 5 model accuracy on test set: 0.1768
  Client 6 model accuracy on test set: 0.2327
  Client 7 model accuracy on test set: 0.2069
  Client 8 model accuracy on test set: 0.1629
  Client 9 model accuracy on test set: 0.2714

=== Global Round 94/100 ===
  Client 0: layers_shared=2, local_acc=0.9905
  Client 1: layers_shared=4, local_acc=0.9951
  Client 2: layers_shared=1, local_acc=0.9943
  Client 3: layers_shared=3, local_acc=0.9495
  Client 4: layers_shared=1, local_acc=0.9888
  Client 5: layers_shared=1, local_acc=0.9913
  Client 6: layers_shared=3, local_acc=0.9882
  Client 7: layers_shared=3, local_acc=0.9961
  Client 8: layers_shared=3, local_acc=0.9970
  Client 9: layers_shared=1, local_acc=0.9941
  Client 0: mean_dist=8.31, base_reward=-3.1626, violation=0, comm_penalty=0.0000, reward=-3.1626
  Client 1: mean_dist=11.80, base_reward=-4.9038, violation=0, comm_penalty=0.0000, reward=-4.9038
  Client 2: mean_dist=4.20, base_reward=-1.1040, violation=0, comm_penalty=0.0000, reward=-1.1040
  Client 3: mean_dist=10.92, base_reward=-4.5091, violation=1, comm_penalty=1.0000, reward=-5.5091
  Client 4: mean_dist=3.87, base_reward=-0.9481, violation=0, comm_penalty=0.0000, reward=-0.9481
  Client 5: mean_dist=4.04, base_reward=-1.0282, violation=0, comm_penalty=0.0000, reward=-1.0282
  Client 6: mean_dist=11.26, base_reward=-4.6420, violation=2, comm_penalty=2.0000, reward=-6.6420
  Client 7: mean_dist=11.57, base_reward=-4.7871, violation=0, comm_penalty=0.0000, reward=-4.7871
  Client 8: mean_dist=10.96, base_reward=-4.4813, violation=1, comm_penalty=1.0000, reward=-5.4813
  Client 9: mean_dist=4.03, base_reward=-1.0228, violation=0, comm_penalty=0.0000, reward=-1.0228
  RL policy loss: -1.502776
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1265
  Client 1 model accuracy on test set: 0.1873
  Client 2 model accuracy on test set: 0.1305
  Client 3 model accuracy on test set: 0.1509
  Client 4 model accuracy on test set: 0.1580
  Client 5 model accuracy on test set: 0.2404
  Client 6 model accuracy on test set: 0.1861
  Client 7 model accuracy on test set: 0.2254
  Client 8 model accuracy on test set: 0.2217
  Client 9 model accuracy on test set: 0.2932

=== Global Round 95/100 ===
  Client 0: layers_shared=2, local_acc=0.9967
  Client 1: layers_shared=1, local_acc=0.9969
  Client 2: layers_shared=3, local_acc=0.9888
  Client 3: layers_shared=1, local_acc=0.9874
  Client 4: layers_shared=3, local_acc=0.9926
  Client 5: layers_shared=6, local_acc=0.9926
  Client 6: layers_shared=2, local_acc=0.9822
  Client 7: layers_shared=5, local_acc=0.9922
  Client 8: layers_shared=3, local_acc=0.9923
  Client 9: layers_shared=1, local_acc=0.9935
  Client 0: mean_dist=9.07, base_reward=-3.5373, violation=0, comm_penalty=0.0000, reward=-3.5373
  Client 1: mean_dist=4.27, base_reward=-1.1360, violation=0, comm_penalty=0.0000, reward=-1.1360
  Client 2: mean_dist=11.55, base_reward=-4.7875, violation=2, comm_penalty=2.0000, reward=-6.7875
  Client 3: mean_dist=3.85, base_reward=-0.9357, violation=0, comm_penalty=0.0000, reward=-0.9357
  Client 4: mean_dist=11.61, base_reward=-4.8136, violation=0, comm_penalty=0.0000, reward=-4.8136
  Client 5: mean_dist=13.16, base_reward=-5.5856, violation=0, comm_penalty=0.0000, reward=-5.5856
  Client 6: mean_dist=9.20, base_reward=-3.6169, violation=1, comm_penalty=1.0000, reward=-4.6169
  Client 7: mean_dist=13.69, base_reward=-5.8541, violation=0, comm_penalty=0.0000, reward=-5.8541
  Client 8: mean_dist=11.64, base_reward=-4.8274, violation=1, comm_penalty=1.0000, reward=-5.8274
  Client 9: mean_dist=4.04, base_reward=-1.0275, violation=0, comm_penalty=0.0000, reward=-1.0275
  RL policy loss: -1.705889
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1665
  Client 1 model accuracy on test set: 0.1989
  Client 2 model accuracy on test set: 0.1569
  Client 3 model accuracy on test set: 0.2062
  Client 4 model accuracy on test set: 0.1717
  Client 5 model accuracy on test set: 0.2198
  Client 6 model accuracy on test set: 0.1562
  Client 7 model accuracy on test set: 0.2120
  Client 8 model accuracy on test set: 0.2526
  Client 9 model accuracy on test set: 0.2134

=== Global Round 96/100 ===
  Client 0: layers_shared=2, local_acc=0.9956
  Client 1: layers_shared=1, local_acc=0.9968
  Client 2: layers_shared=1, local_acc=0.9925
  Client 3: layers_shared=1, local_acc=0.9902
  Client 4: layers_shared=3, local_acc=0.9959
  Client 5: layers_shared=1, local_acc=0.9926
  Client 6: layers_shared=3, local_acc=0.9921
  Client 7: layers_shared=1, local_acc=0.9940
  Client 8: layers_shared=3, local_acc=0.9956
  Client 9: layers_shared=1, local_acc=0.9892
  Client 0: mean_dist=6.50, base_reward=-2.2553, violation=0, comm_penalty=0.0000, reward=-2.2553
  Client 1: mean_dist=4.27, base_reward=-1.1384, violation=0, comm_penalty=0.0000, reward=-1.1384
  Client 2: mean_dist=4.22, base_reward=-1.1162, violation=0, comm_penalty=0.0000, reward=-1.1162
  Client 3: mean_dist=3.85, base_reward=-0.9367, violation=0, comm_penalty=0.0000, reward=-0.9367
  Client 4: mean_dist=7.76, base_reward=-2.8829, violation=0, comm_penalty=0.0000, reward=-2.8829
  Client 5: mean_dist=4.06, base_reward=-1.0370, violation=0, comm_penalty=0.0000, reward=-1.0370
  Client 6: mean_dist=8.07, base_reward=-3.0437, violation=2, comm_penalty=2.0000, reward=-5.0437
  Client 7: mean_dist=4.16, base_reward=-1.0883, violation=0, comm_penalty=0.0000, reward=-1.0883
  Client 8: mean_dist=7.75, base_reward=-2.8819, violation=1, comm_penalty=1.0000, reward=-3.8819
  Client 9: mean_dist=4.05, base_reward=-1.0337, violation=0, comm_penalty=0.0000, reward=-1.0337
  RL policy loss: -0.846886
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1706
  Client 1 model accuracy on test set: 0.1407
  Client 2 model accuracy on test set: 0.1137
  Client 3 model accuracy on test set: 0.2105
  Client 4 model accuracy on test set: 0.1596
  Client 5 model accuracy on test set: 0.1897
  Client 6 model accuracy on test set: 0.1889
  Client 7 model accuracy on test set: 0.1696
  Client 8 model accuracy on test set: 0.1962
  Client 9 model accuracy on test set: 0.2261

=== Global Round 97/100 ===
  Client 0: layers_shared=3, local_acc=0.9990
  Client 1: layers_shared=1, local_acc=0.9937
  Client 2: layers_shared=4, local_acc=0.9893
  Client 3: layers_shared=1, local_acc=0.9877
  Client 4: layers_shared=1, local_acc=0.9936
  Client 5: layers_shared=1, local_acc=0.9948
  Client 6: layers_shared=2, local_acc=0.9850
  Client 7: layers_shared=5, local_acc=0.9977
  Client 8: layers_shared=1, local_acc=0.9914
  Client 9: layers_shared=1, local_acc=0.9937
  Client 0: mean_dist=7.89, base_reward=-2.9479, violation=0, comm_penalty=0.0000, reward=-2.9479
  Client 1: mean_dist=4.27, base_reward=-1.1433, violation=0, comm_penalty=0.0000, reward=-1.1433
  Client 2: mean_dist=8.81, base_reward=-3.4139, violation=3, comm_penalty=3.0000, reward=-6.4139
  Client 3: mean_dist=3.85, base_reward=-0.9398, violation=0, comm_penalty=0.0000, reward=-0.9398
  Client 4: mean_dist=3.88, base_reward=-0.9472, violation=0, comm_penalty=0.0000, reward=-0.9472
  Client 5: mean_dist=4.07, base_reward=-1.0381, violation=0, comm_penalty=0.0000, reward=-1.0381
  Client 6: mean_dist=6.78, base_reward=-2.4068, violation=1, comm_penalty=1.0000, reward=-3.4068
  Client 7: mean_dist=9.03, base_reward=-3.5163, violation=0, comm_penalty=0.0000, reward=-3.5163
  Client 8: mean_dist=3.84, base_reward=-0.9307, violation=0, comm_penalty=0.0000, reward=-0.9307
  Client 9: mean_dist=4.04, base_reward=-1.0284, violation=0, comm_penalty=0.0000, reward=-1.0284
  RL policy loss: -1.530490
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1216
  Client 1 model accuracy on test set: 0.1662
  Client 2 model accuracy on test set: 0.2100
  Client 3 model accuracy on test set: 0.2305
  Client 4 model accuracy on test set: 0.1640
  Client 5 model accuracy on test set: 0.1668
  Client 6 model accuracy on test set: 0.1883
  Client 7 model accuracy on test set: 0.2327
  Client 8 model accuracy on test set: 0.2696
  Client 9 model accuracy on test set: 0.2489

=== Global Round 98/100 ===
  Client 0: layers_shared=1, local_acc=0.9985
  Client 1: layers_shared=1, local_acc=0.9839
  Client 2: layers_shared=3, local_acc=0.9964
  Client 3: layers_shared=1, local_acc=0.9963
  Client 4: layers_shared=2, local_acc=0.9702
  Client 5: layers_shared=1, local_acc=0.9986
  Client 6: layers_shared=1, local_acc=0.9916
  Client 7: layers_shared=1, local_acc=0.9906
  Client 8: layers_shared=1, local_acc=0.9891
  Client 9: layers_shared=1, local_acc=0.9885
  Client 0: mean_dist=3.95, base_reward=-0.9777, violation=0, comm_penalty=0.0000, reward=-0.9777
  Client 1: mean_dist=4.27, base_reward=-1.1528, violation=0, comm_penalty=0.0000, reward=-1.1528
  Client 2: mean_dist=5.00, base_reward=-1.5035, violation=2, comm_penalty=2.0000, reward=-3.5035
  Client 3: mean_dist=3.86, base_reward=-0.9323, violation=0, comm_penalty=0.0000, reward=-0.9323
  Client 4: mean_dist=4.67, base_reward=-1.3663, violation=0, comm_penalty=0.0000, reward=-1.3663
  Client 5: mean_dist=4.07, base_reward=-1.0345, violation=0, comm_penalty=0.0000, reward=-1.0345
  Client 6: mean_dist=4.26, base_reward=-1.1385, violation=0, comm_penalty=0.0000, reward=-1.1385
  Client 7: mean_dist=4.17, base_reward=-1.0958, violation=0, comm_penalty=0.0000, reward=-1.0958
  Client 8: mean_dist=3.86, base_reward=-0.9396, violation=0, comm_penalty=0.0000, reward=-0.9396
  Client 9: mean_dist=4.05, base_reward=-1.0380, violation=0, comm_penalty=0.0000, reward=-1.0380
  RL policy loss: -0.328747
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1725
  Client 1 model accuracy on test set: 0.1329
  Client 2 model accuracy on test set: 0.1919
  Client 3 model accuracy on test set: 0.1964
  Client 4 model accuracy on test set: 0.1961
  Client 5 model accuracy on test set: 0.2331
  Client 6 model accuracy on test set: 0.1750
  Client 7 model accuracy on test set: 0.2011
  Client 8 model accuracy on test set: 0.2194
  Client 9 model accuracy on test set: 0.2469

=== Global Round 99/100 ===
  Client 0: layers_shared=1, local_acc=0.9983
  Client 1: layers_shared=1, local_acc=0.9908
  Client 2: layers_shared=1, local_acc=0.9670
  Client 3: layers_shared=1, local_acc=0.9954
  Client 4: layers_shared=1, local_acc=0.9936
  Client 5: layers_shared=1, local_acc=0.9971
  Client 6: layers_shared=1, local_acc=0.9884
  Client 7: layers_shared=1, local_acc=0.9981
  Client 8: layers_shared=6, local_acc=0.9965
  Client 9: layers_shared=1, local_acc=0.9891
  Client 0: mean_dist=3.96, base_reward=-0.9795, violation=0, comm_penalty=0.0000, reward=-0.9795
  Client 1: mean_dist=4.28, base_reward=-1.1491, violation=0, comm_penalty=0.0000, reward=-1.1491
  Client 2: mean_dist=4.22, base_reward=-1.1449, violation=0, comm_penalty=0.0000, reward=-1.1449
  Client 3: mean_dist=3.87, base_reward=-0.9372, violation=0, comm_penalty=0.0000, reward=-0.9372
  Client 4: mean_dist=3.89, base_reward=-0.9529, violation=0, comm_penalty=0.0000, reward=-0.9529
  Client 5: mean_dist=4.08, base_reward=-1.0410, violation=0, comm_penalty=0.0000, reward=-1.0410
  Client 6: mean_dist=4.26, base_reward=-1.1421, violation=0, comm_penalty=0.0000, reward=-1.1421
  Client 7: mean_dist=4.18, base_reward=-1.0914, violation=0, comm_penalty=0.0000, reward=-1.0914
  Client 8: mean_dist=3.86, base_reward=-0.9337, violation=4, comm_penalty=4.0000, reward=-4.9337
  Client 9: mean_dist=4.06, base_reward=-1.0427, violation=0, comm_penalty=0.0000, reward=-1.0427
  RL policy loss: -0.870896
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1461
  Client 1 model accuracy on test set: 0.1492
  Client 2 model accuracy on test set: 0.2047
  Client 3 model accuracy on test set: 0.2200
  Client 4 model accuracy on test set: 0.2001
  Client 5 model accuracy on test set: 0.1677
  Client 6 model accuracy on test set: 0.2253
  Client 7 model accuracy on test set: 0.2133
  Client 8 model accuracy on test set: 0.2006
  Client 9 model accuracy on test set: 0.2343

=== Global Round 100/100 ===
  Client 0: layers_shared=1, local_acc=0.9961
  Client 1: layers_shared=1, local_acc=0.9955
  Client 2: layers_shared=1, local_acc=0.9787
  Client 3: layers_shared=1, local_acc=0.9961
  Client 4: layers_shared=1, local_acc=0.9611
  Client 5: layers_shared=1, local_acc=0.9971
  Client 6: layers_shared=1, local_acc=0.9983
  Client 7: layers_shared=1, local_acc=0.9975
  Client 8: layers_shared=5, local_acc=0.9961
  Client 9: layers_shared=1, local_acc=0.9910
  Client 0: mean_dist=3.96, base_reward=-0.9837, violation=0, comm_penalty=0.0000, reward=-0.9837
  Client 1: mean_dist=4.28, base_reward=-1.1465, violation=0, comm_penalty=0.0000, reward=-1.1465
  Client 2: mean_dist=4.23, base_reward=-1.1373, violation=0, comm_penalty=0.0000, reward=-1.1373
  Client 3: mean_dist=3.86, base_reward=-0.9356, violation=0, comm_penalty=0.0000, reward=-0.9356
  Client 4: mean_dist=3.91, base_reward=-0.9917, violation=0, comm_penalty=0.0000, reward=-0.9917
  Client 5: mean_dist=4.08, base_reward=-1.0414, violation=0, comm_penalty=0.0000, reward=-1.0414
  Client 6: mean_dist=4.26, base_reward=-1.1336, violation=0, comm_penalty=0.0000, reward=-1.1336
  Client 7: mean_dist=4.19, base_reward=-1.0950, violation=0, comm_penalty=0.0000, reward=-1.0950
  Client 8: mean_dist=3.86, base_reward=-0.9339, violation=3, comm_penalty=3.0000, reward=-3.9339
  Client 9: mean_dist=4.07, base_reward=-1.0453, violation=0, comm_penalty=0.0000, reward=-1.0453
  RL policy loss: -0.612935
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1622
  Client 1 model accuracy on test set: 0.1626
  Client 2 model accuracy on test set: 0.2047
  Client 3 model accuracy on test set: 0.1941
  Client 4 model accuracy on test set: 0.1788
  Client 5 model accuracy on test set: 0.1951
  Client 6 model accuracy on test set: 0.1833
  Client 7 model accuracy on test set: 0.2038
  Client 8 model accuracy on test set: 0.2112
  Client 9 model accuracy on test set: 0.2343

Training finished.
Saved global model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/global_model.pt
Saved client 0 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_0_model.pt
Saved client 1 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_1_model.pt
Saved client 2 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_2_model.pt
Saved client 3 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_3_model.pt
Saved client 4 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_4_model.pt
Saved client 5 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_5_model.pt
Saved client 6 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_6_model.pt
Saved client 7 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_7_model.pt
Saved client 8 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_8_model.pt
Saved client 9 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_9_model.pt
Saved RL policy network  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/policy_net.pt
