Using device: cuda
Files already downloaded and verified
RL will choose number of shared layers in [1, 6] for each client.

=== Global Round 1/100 ===
  Client 0: layers_shared=2, local_acc=0.3475
  Client 1: layers_shared=3, local_acc=0.4314
  Client 2: layers_shared=3, local_acc=0.3861
  Client 3: layers_shared=3, local_acc=0.6731
  Client 4: layers_shared=2, local_acc=0.7135
  Client 5: layers_shared=4, local_acc=0.4317
  Client 6: layers_shared=6, local_acc=0.4668
  Client 7: layers_shared=5, local_acc=0.5359
  Client 8: layers_shared=3, local_acc=0.8786
  Client 9: layers_shared=3, local_acc=0.7304
  Client 0: mean_dist=1.71, base_reward=-0.5092, violation=0, comm_penalty=0.0000, reward=-0.5092
  Client 1: mean_dist=2.53, base_reward=-0.8346, violation=0, comm_penalty=0.0000, reward=-0.8346
  Client 2: mean_dist=2.66, base_reward=-0.9455, violation=2, comm_penalty=2.0000, reward=-2.9455
  Client 3: mean_dist=2.53, base_reward=-0.5901, violation=1, comm_penalty=1.0000, reward=-1.5901
  Client 4: mean_dist=2.14, base_reward=-0.3546, violation=0, comm_penalty=0.0000, reward=-0.3546
  Client 5: mean_dist=3.11, base_reward=-1.1247, violation=0, comm_penalty=0.0000, reward=-1.1247
  Client 6: mean_dist=2.32, base_reward=-0.6909, violation=5, comm_penalty=5.0000, reward=-5.6909
  Client 7: mean_dist=3.31, base_reward=-1.1173, violation=0, comm_penalty=0.0000, reward=-1.1173
  Client 8: mean_dist=2.34, base_reward=-0.2937, violation=1, comm_penalty=1.0000, reward=-1.2937
  Client 9: mean_dist=2.76, base_reward=-0.6496, violation=0, comm_penalty=0.0000, reward=-0.6496
  RL policy loss: 0.018984
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1006
  Client 1 model accuracy on test set: 0.1059
  Client 2 model accuracy on test set: 0.1002
  Client 3 model accuracy on test set: 0.1000
  Client 4 model accuracy on test set: 0.1540
  Client 5 model accuracy on test set: 0.1016
  Client 6 model accuracy on test set: 0.1260
  Client 7 model accuracy on test set: 0.1832
  Client 8 model accuracy on test set: 0.1436
  Client 9 model accuracy on test set: 0.1595

=== Global Round 2/100 ===
  Client 0: layers_shared=4, local_acc=0.5728
  Client 1: layers_shared=5, local_acc=0.4400
  Client 2: layers_shared=1, local_acc=0.3766
  Client 3: layers_shared=5, local_acc=0.8127
  Client 4: layers_shared=5, local_acc=0.7516
  Client 5: layers_shared=3, local_acc=0.4782
  Client 6: layers_shared=2, local_acc=0.5241
  Client 7: layers_shared=2, local_acc=0.6256
  Client 8: layers_shared=3, local_acc=0.9024
  Client 9: layers_shared=4, local_acc=0.7788
  Client 0: mean_dist=2.71, base_reward=-0.7813, violation=1, comm_penalty=1.0000, reward=-1.7813
  Client 1: mean_dist=3.23, base_reward=-1.1748, violation=0, comm_penalty=0.0000, reward=-1.1748
  Client 2: mean_dist=1.02, base_reward=-0.1321, violation=0, comm_penalty=0.0000, reward=-0.1321
  Client 3: mean_dist=3.20, base_reward=-0.7864, violation=3, comm_penalty=3.0000, reward=-3.7864
  Client 4: mean_dist=3.36, base_reward=-0.9307, violation=1, comm_penalty=1.0000, reward=-1.9307
  Client 5: mean_dist=3.34, base_reward=-1.1906, violation=0, comm_penalty=0.0000, reward=-1.1906
  Client 6: mean_dist=1.95, base_reward=-0.4529, violation=1, comm_penalty=1.0000, reward=-1.4529
  Client 7: mean_dist=2.78, base_reward=-0.7624, violation=0, comm_penalty=0.0000, reward=-0.7624
  Client 8: mean_dist=2.63, base_reward=-0.4110, violation=1, comm_penalty=1.0000, reward=-1.4110
  Client 9: mean_dist=3.51, base_reward=-0.9764, violation=0, comm_penalty=0.0000, reward=-0.9764
  RL policy loss: 0.097672
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1000
  Client 1 model accuracy on test set: 0.1008
  Client 2 model accuracy on test set: 0.1223
  Client 3 model accuracy on test set: 0.1004
  Client 4 model accuracy on test set: 0.1140
  Client 5 model accuracy on test set: 0.1645
  Client 6 model accuracy on test set: 0.1024
  Client 7 model accuracy on test set: 0.1198
  Client 8 model accuracy on test set: 0.1154
  Client 9 model accuracy on test set: 0.1616

=== Global Round 3/100 ===
  Client 0: layers_shared=1, local_acc=0.6241
  Client 1: layers_shared=6, local_acc=0.5013
  Client 2: layers_shared=2, local_acc=0.4548
  Client 3: layers_shared=6, local_acc=0.7964
  Client 4: layers_shared=5, local_acc=0.7699
  Client 5: layers_shared=5, local_acc=0.4654
  Client 6: layers_shared=6, local_acc=0.6191
  Client 7: layers_shared=4, local_acc=0.7011
  Client 8: layers_shared=1, local_acc=0.9062
  Client 9: layers_shared=6, local_acc=0.7945
  Client 0: mean_dist=1.01, base_reward=0.1194, violation=0, comm_penalty=0.0000, reward=0.1194
  Client 1: mean_dist=4.21, base_reward=-1.6040, violation=1, comm_penalty=1.0000, reward=-2.6040
  Client 2: mean_dist=2.45, base_reward=-0.7725, violation=1, comm_penalty=1.0000, reward=-1.7725
  Client 3: mean_dist=4.13, base_reward=-1.2696, violation=4, comm_penalty=4.0000, reward=-5.2696
  Client 4: mean_dist=4.20, base_reward=-1.3297, violation=1, comm_penalty=1.0000, reward=-2.3297
  Client 5: mean_dist=4.82, base_reward=-1.9466, violation=0, comm_penalty=0.0000, reward=-1.9466
  Client 6: mean_dist=3.64, base_reward=-1.2033, violation=5, comm_penalty=5.0000, reward=-6.2033
  Client 7: mean_dist=4.72, base_reward=-1.6590, violation=0, comm_penalty=0.0000, reward=-1.6590
  Client 8: mean_dist=1.11, base_reward=0.3511, violation=0, comm_penalty=0.0000, reward=0.3511
  Client 9: mean_dist=4.64, base_reward=-1.5271, violation=1, comm_penalty=1.0000, reward=-2.5271
  RL policy loss: 0.071087
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1024
  Client 1 model accuracy on test set: 0.1564
  Client 2 model accuracy on test set: 0.1174
  Client 3 model accuracy on test set: 0.1028
  Client 4 model accuracy on test set: 0.1647
  Client 5 model accuracy on test set: 0.1017
  Client 6 model accuracy on test set: 0.1234
  Client 7 model accuracy on test set: 0.1092
  Client 8 model accuracy on test set: 0.1082
  Client 9 model accuracy on test set: 0.1092

=== Global Round 4/100 ===
  Client 0: layers_shared=3, local_acc=0.6278
  Client 1: layers_shared=1, local_acc=0.6145
  Client 2: layers_shared=1, local_acc=0.4970
  Client 3: layers_shared=1, local_acc=0.8145
  Client 4: layers_shared=5, local_acc=0.7668
  Client 5: layers_shared=1, local_acc=0.5150
  Client 6: layers_shared=5, local_acc=0.6499
  Client 7: layers_shared=4, local_acc=0.6832
  Client 8: layers_shared=1, local_acc=0.9075
  Client 9: layers_shared=2, local_acc=0.8254
  Client 0: mean_dist=2.16, base_reward=-0.4499, violation=0, comm_penalty=0.0000, reward=-0.4499
  Client 1: mean_dist=1.20, base_reward=0.0161, violation=0, comm_penalty=0.0000, reward=0.0161
  Client 2: mean_dist=1.23, base_reward=-0.1184, violation=0, comm_penalty=0.0000, reward=-0.1184
  Client 3: mean_dist=1.31, base_reward=0.1618, violation=0, comm_penalty=0.0000, reward=0.1618
  Client 4: mean_dist=2.79, base_reward=-0.6292, violation=1, comm_penalty=1.0000, reward=-1.6292
  Client 5: mean_dist=1.47, base_reward=-0.2178, violation=0, comm_penalty=0.0000, reward=-0.2178
  Client 6: mean_dist=2.37, base_reward=-0.5372, violation=4, comm_penalty=4.0000, reward=-4.5372
  Client 7: mean_dist=3.34, base_reward=-0.9888, violation=0, comm_penalty=0.0000, reward=-0.9888
  Client 8: mean_dist=1.23, base_reward=0.2919, violation=0, comm_penalty=0.0000, reward=0.2919
  Client 9: mean_dist=2.30, base_reward=-0.3247, violation=0, comm_penalty=0.0000, reward=-0.3247
  RL policy loss: 0.101768
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1445
  Client 1 model accuracy on test set: 0.1271
  Client 2 model accuracy on test set: 0.1287
  Client 3 model accuracy on test set: 0.1172
  Client 4 model accuracy on test set: 0.1221
  Client 5 model accuracy on test set: 0.1020
  Client 6 model accuracy on test set: 0.1030
  Client 7 model accuracy on test set: 0.1608
  Client 8 model accuracy on test set: 0.1681
  Client 9 model accuracy on test set: 0.1315

=== Global Round 5/100 ===
  Client 0: layers_shared=5, local_acc=0.6367
  Client 1: layers_shared=3, local_acc=0.6188
  Client 2: layers_shared=1, local_acc=0.5142
  Client 3: layers_shared=2, local_acc=0.8483
  Client 4: layers_shared=5, local_acc=0.7335
  Client 5: layers_shared=2, local_acc=0.6897
  Client 6: layers_shared=4, local_acc=0.5821
  Client 7: layers_shared=5, local_acc=0.7368
  Client 8: layers_shared=4, local_acc=0.9050
  Client 9: layers_shared=6, local_acc=0.8592
  Client 0: mean_dist=4.15, base_reward=-1.4397, violation=2, comm_penalty=2.0000, reward=-3.4397
  Client 1: mean_dist=3.87, base_reward=-1.3184, violation=0, comm_penalty=0.0000, reward=-1.3184
  Client 2: mean_dist=1.31, base_reward=-0.1405, violation=0, comm_penalty=0.0000, reward=-0.1405
  Client 3: mean_dist=3.10, base_reward=-0.7021, violation=0, comm_penalty=0.0000, reward=-0.7021
  Client 4: mean_dist=4.87, base_reward=-1.7015, violation=1, comm_penalty=1.0000, reward=-2.7015
  Client 5: mean_dist=3.76, base_reward=-1.1883, violation=0, comm_penalty=0.0000, reward=-1.1883
  Client 6: mean_dist=3.78, base_reward=-1.3079, violation=3, comm_penalty=3.0000, reward=-4.3079
  Client 7: mean_dist=6.22, base_reward=-2.3729, violation=0, comm_penalty=0.0000, reward=-2.3729
  Client 8: mean_dist=4.07, base_reward=-1.1315, violation=2, comm_penalty=2.0000, reward=-3.1315
  Client 9: mean_dist=5.36, base_reward=-1.8186, violation=1, comm_penalty=1.0000, reward=-2.8186
  RL policy loss: 0.182383
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1491
  Client 1 model accuracy on test set: 0.1741
  Client 2 model accuracy on test set: 0.1156
  Client 3 model accuracy on test set: 0.1001
  Client 4 model accuracy on test set: 0.1055
  Client 5 model accuracy on test set: 0.1805
  Client 6 model accuracy on test set: 0.1016
  Client 7 model accuracy on test set: 0.1675
  Client 8 model accuracy on test set: 0.1722
  Client 9 model accuracy on test set: 0.1217

=== Global Round 6/100 ===
  Client 0: layers_shared=5, local_acc=0.6791
  Client 1: layers_shared=6, local_acc=0.5874
  Client 2: layers_shared=4, local_acc=0.4689
  Client 3: layers_shared=1, local_acc=0.8351
  Client 4: layers_shared=5, local_acc=0.8118
  Client 5: layers_shared=3, local_acc=0.5762
  Client 6: layers_shared=5, local_acc=0.6387
  Client 7: layers_shared=1, local_acc=0.7363
  Client 8: layers_shared=3, local_acc=0.9258
  Client 9: layers_shared=6, local_acc=0.8689
  Client 0: mean_dist=4.34, base_reward=-1.4885, violation=2, comm_penalty=2.0000, reward=-3.4885
  Client 1: mean_dist=5.09, base_reward=-1.9597, violation=1, comm_penalty=1.0000, reward=-2.9597
  Client 2: mean_dist=4.54, base_reward=-1.8007, violation=3, comm_penalty=3.0000, reward=-4.8007
  Client 3: mean_dist=1.51, base_reward=0.0811, violation=0, comm_penalty=0.0000, reward=0.0811
  Client 4: mean_dist=5.12, base_reward=-1.7497, violation=1, comm_penalty=1.0000, reward=-2.7497
  Client 5: mean_dist=4.92, base_reward=-1.8816, violation=0, comm_penalty=0.0000, reward=-1.8816
  Client 6: mean_dist=4.22, base_reward=-1.4733, violation=4, comm_penalty=4.0000, reward=-5.4733
  Client 7: mean_dist=1.96, base_reward=-0.2442, violation=0, comm_penalty=0.0000, reward=-0.2442
  Client 8: mean_dist=3.70, base_reward=-0.9247, violation=1, comm_penalty=1.0000, reward=-1.9247
  Client 9: mean_dist=5.67, base_reward=-1.9648, violation=1, comm_penalty=1.0000, reward=-2.9648
  RL policy loss: 0.018928
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1175
  Client 1 model accuracy on test set: 0.1666
  Client 2 model accuracy on test set: 0.1000
  Client 3 model accuracy on test set: 0.1001
  Client 4 model accuracy on test set: 0.1914
  Client 5 model accuracy on test set: 0.1565
  Client 6 model accuracy on test set: 0.1209
  Client 7 model accuracy on test set: 0.1206
  Client 8 model accuracy on test set: 0.1416
  Client 9 model accuracy on test set: 0.1199

=== Global Round 7/100 ===
  Client 0: layers_shared=4, local_acc=0.6013
  Client 1: layers_shared=6, local_acc=0.6687
  Client 2: layers_shared=3, local_acc=0.5562
  Client 3: layers_shared=2, local_acc=0.8454
  Client 4: layers_shared=3, local_acc=0.7965
  Client 5: layers_shared=3, local_acc=0.6197
  Client 6: layers_shared=4, local_acc=0.6233
  Client 7: layers_shared=6, local_acc=0.7761
  Client 8: layers_shared=2, local_acc=0.9250
  Client 9: layers_shared=5, local_acc=0.8640
  Client 0: mean_dist=4.82, base_reward=-1.8099, violation=1, comm_penalty=1.0000, reward=-2.8099
  Client 1: mean_dist=5.81, base_reward=-2.2343, violation=1, comm_penalty=1.0000, reward=-3.2343
  Client 2: mean_dist=4.80, base_reward=-1.8449, violation=2, comm_penalty=2.0000, reward=-3.8449
  Client 3: mean_dist=3.74, base_reward=-1.0235, violation=0, comm_penalty=0.0000, reward=-1.0235
  Client 4: mean_dist=5.16, base_reward=-1.7858, violation=0, comm_penalty=0.0000, reward=-1.7858
  Client 5: mean_dist=6.01, base_reward=-2.3842, violation=0, comm_penalty=0.0000, reward=-2.3842
  Client 6: mean_dist=4.71, base_reward=-1.7292, violation=3, comm_penalty=3.0000, reward=-4.7292
  Client 7: mean_dist=7.51, base_reward=-2.9769, violation=0, comm_penalty=0.0000, reward=-2.9769
  Client 8: mean_dist=3.54, base_reward=-0.8429, violation=0, comm_penalty=0.0000, reward=-0.8429
  Client 9: mean_dist=6.49, base_reward=-2.3817, violation=0, comm_penalty=0.0000, reward=-2.3817
  RL policy loss: 0.234993
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1350
  Client 1 model accuracy on test set: 0.1387
  Client 2 model accuracy on test set: 0.1175
  Client 3 model accuracy on test set: 0.1189
  Client 4 model accuracy on test set: 0.1074
  Client 5 model accuracy on test set: 0.1536
  Client 6 model accuracy on test set: 0.1179
  Client 7 model accuracy on test set: 0.1378
  Client 8 model accuracy on test set: 0.1499
  Client 9 model accuracy on test set: 0.1681

=== Global Round 8/100 ===
  Client 0: layers_shared=6, local_acc=0.7184
  Client 1: layers_shared=2, local_acc=0.6981
  Client 2: layers_shared=5, local_acc=0.5518
  Client 3: layers_shared=3, local_acc=0.8054
  Client 4: layers_shared=5, local_acc=0.7579
  Client 5: layers_shared=5, local_acc=0.7509
  Client 6: layers_shared=3, local_acc=0.6646
  Client 7: layers_shared=3, local_acc=0.7746
  Client 8: layers_shared=1, local_acc=0.9168
  Client 9: layers_shared=3, local_acc=0.8132
  Client 0: mean_dist=5.04, base_reward=-1.8040, violation=3, comm_penalty=3.0000, reward=-4.8040
  Client 1: mean_dist=3.69, base_reward=-1.1477, violation=0, comm_penalty=0.0000, reward=-1.1477
  Client 2: mean_dist=5.65, base_reward=-2.2707, violation=4, comm_penalty=4.0000, reward=-6.2707
  Client 3: mean_dist=4.83, base_reward=-1.6085, violation=1, comm_penalty=1.0000, reward=-2.6085
  Client 4: mean_dist=5.98, base_reward=-2.2309, violation=1, comm_penalty=1.0000, reward=-3.2309
  Client 5: mean_dist=6.99, base_reward=-2.7445, violation=0, comm_penalty=0.0000, reward=-2.7445
  Client 6: mean_dist=4.27, base_reward=-1.4687, violation=2, comm_penalty=2.0000, reward=-3.4687
  Client 7: mean_dist=6.53, base_reward=-2.4899, violation=0, comm_penalty=0.0000, reward=-2.4899
  Client 8: mean_dist=1.55, base_reward=0.1417, violation=0, comm_penalty=0.0000, reward=0.1417
  Client 9: mean_dist=5.60, base_reward=-1.9877, violation=0, comm_penalty=0.0000, reward=-1.9877
  RL policy loss: 0.121722
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1113
  Client 1 model accuracy on test set: 0.1357
  Client 2 model accuracy on test set: 0.1157
  Client 3 model accuracy on test set: 0.1066
  Client 4 model accuracy on test set: 0.1790
  Client 5 model accuracy on test set: 0.1772
  Client 6 model accuracy on test set: 0.1316
  Client 7 model accuracy on test set: 0.1556
  Client 8 model accuracy on test set: 0.1040
  Client 9 model accuracy on test set: 0.1576

=== Global Round 9/100 ===
  Client 0: layers_shared=1, local_acc=0.6595
  Client 1: layers_shared=5, local_acc=0.7052
  Client 2: layers_shared=3, local_acc=0.5543
  Client 3: layers_shared=4, local_acc=0.7844
  Client 4: layers_shared=6, local_acc=0.7103
  Client 5: layers_shared=6, local_acc=0.7205
  Client 6: layers_shared=6, local_acc=0.7317
  Client 7: layers_shared=3, local_acc=0.7977
  Client 8: layers_shared=2, local_acc=0.8540
  Client 9: layers_shared=4, local_acc=0.8931
  Client 0: mean_dist=1.55, base_reward=-0.1148, violation=0, comm_penalty=0.0000, reward=-0.1148
  Client 1: mean_dist=6.49, base_reward=-2.5396, violation=0, comm_penalty=0.0000, reward=-2.5396
  Client 2: mean_dist=5.17, base_reward=-2.0329, violation=2, comm_penalty=2.0000, reward=-4.0329
  Client 3: mean_dist=5.87, base_reward=-2.1511, violation=2, comm_penalty=2.0000, reward=-4.1511
  Client 4: mean_dist=6.74, base_reward=-2.6612, violation=2, comm_penalty=2.0000, reward=-4.6612
  Client 5: mean_dist=7.88, base_reward=-3.2219, violation=0, comm_penalty=0.0000, reward=-3.2219
  Client 6: mean_dist=5.59, base_reward=-2.0648, violation=5, comm_penalty=5.0000, reward=-7.0648
  Client 7: mean_dist=6.91, base_reward=-2.6553, violation=0, comm_penalty=0.0000, reward=-2.6553
  Client 8: mean_dist=3.72, base_reward=-1.0084, violation=0, comm_penalty=0.0000, reward=-1.0084
  Client 9: mean_dist=6.79, base_reward=-2.5041, violation=0, comm_penalty=0.0000, reward=-2.5041
  RL policy loss: 0.152698
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1694
  Client 1 model accuracy on test set: 0.1338
  Client 2 model accuracy on test set: 0.1022
  Client 3 model accuracy on test set: 0.1291
  Client 4 model accuracy on test set: 0.1654
  Client 5 model accuracy on test set: 0.1624
  Client 6 model accuracy on test set: 0.1297
  Client 7 model accuracy on test set: 0.1074
  Client 8 model accuracy on test set: 0.1005
  Client 9 model accuracy on test set: 0.1579

=== Global Round 10/100 ===
  Client 0: layers_shared=5, local_acc=0.7354
  Client 1: layers_shared=4, local_acc=0.6890
  Client 2: layers_shared=3, local_acc=0.5926
  Client 3: layers_shared=4, local_acc=0.8650
  Client 4: layers_shared=4, local_acc=0.8076
  Client 5: layers_shared=5, local_acc=0.6999
  Client 6: layers_shared=5, local_acc=0.7135
  Client 7: layers_shared=1, local_acc=0.7878
  Client 8: layers_shared=6, local_acc=0.9282
  Client 9: layers_shared=1, local_acc=0.8854
  Client 0: mean_dist=5.26, base_reward=-1.8969, violation=2, comm_penalty=2.0000, reward=-3.8969
  Client 1: mean_dist=5.95, base_reward=-2.2845, violation=0, comm_penalty=0.0000, reward=-2.2845
  Client 2: mean_dist=4.83, base_reward=-1.8213, violation=2, comm_penalty=2.0000, reward=-3.8213
  Client 3: mean_dist=5.58, base_reward=-1.9229, violation=2, comm_penalty=2.0000, reward=-3.9229
  Client 4: mean_dist=6.10, base_reward=-2.2424, violation=0, comm_penalty=0.0000, reward=-2.2424
  Client 5: mean_dist=7.68, base_reward=-3.1398, violation=0, comm_penalty=0.0000, reward=-3.1398
  Client 6: mean_dist=5.15, base_reward=-1.8635, violation=4, comm_penalty=4.0000, reward=-5.8635
  Client 7: mean_dist=2.46, base_reward=-0.4418, violation=0, comm_penalty=0.0000, reward=-0.4418
  Client 8: mean_dist=5.48, base_reward=-1.8139, violation=4, comm_penalty=4.0000, reward=-5.8139
  Client 9: mean_dist=1.97, base_reward=-0.0977, violation=0, comm_penalty=0.0000, reward=-0.0977
  RL policy loss: 0.025929
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1082
  Client 1 model accuracy on test set: 0.1197
  Client 2 model accuracy on test set: 0.1027
  Client 3 model accuracy on test set: 0.1242
  Client 4 model accuracy on test set: 0.1643
  Client 5 model accuracy on test set: 0.1061
  Client 6 model accuracy on test set: 0.1011
  Client 7 model accuracy on test set: 0.1121
  Client 8 model accuracy on test set: 0.1678
  Client 9 model accuracy on test set: 0.1504

=== Global Round 11/100 ===
  Client 0: layers_shared=5, local_acc=0.7057
  Client 1: layers_shared=2, local_acc=0.6986
  Client 2: layers_shared=1, local_acc=0.6067
  Client 3: layers_shared=3, local_acc=0.8311
  Client 4: layers_shared=2, local_acc=0.7277
  Client 5: layers_shared=4, local_acc=0.7659
  Client 6: layers_shared=2, local_acc=0.7114
  Client 7: layers_shared=5, local_acc=0.8392
  Client 8: layers_shared=5, local_acc=0.8812
  Client 9: layers_shared=4, local_acc=0.9078
  Client 0: mean_dist=5.54, base_reward=-2.0651, violation=2, comm_penalty=2.0000, reward=-4.0651
  Client 1: mean_dist=4.25, base_reward=-1.4279, violation=0, comm_penalty=0.0000, reward=-1.4279
  Client 2: mean_dist=1.76, base_reward=-0.2715, violation=0, comm_penalty=0.0000, reward=-0.2715
  Client 3: mean_dist=5.18, base_reward=-1.7611, violation=1, comm_penalty=1.0000, reward=-2.7611
  Client 4: mean_dist=4.60, base_reward=-1.5702, violation=0, comm_penalty=0.0000, reward=-1.5702
  Client 5: mean_dist=7.39, base_reward=-2.9291, violation=0, comm_penalty=0.0000, reward=-2.9291
  Client 6: mean_dist=3.69, base_reward=-1.1314, violation=1, comm_penalty=1.0000, reward=-2.1314
  Client 7: mean_dist=8.31, base_reward=-3.3143, violation=0, comm_penalty=0.0000, reward=-3.3143
  Client 8: mean_dist=5.80, base_reward=-2.0196, violation=3, comm_penalty=3.0000, reward=-5.0196
  Client 9: mean_dist=6.76, base_reward=-2.4717, violation=0, comm_penalty=0.0000, reward=-2.4717
  RL policy loss: 0.226932
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1080
  Client 1 model accuracy on test set: 0.1519
  Client 2 model accuracy on test set: 0.1015
  Client 3 model accuracy on test set: 0.1000
  Client 4 model accuracy on test set: 0.1615
  Client 5 model accuracy on test set: 0.1078
  Client 6 model accuracy on test set: 0.1174
  Client 7 model accuracy on test set: 0.1869
  Client 8 model accuracy on test set: 0.1254
  Client 9 model accuracy on test set: 0.1580

=== Global Round 12/100 ===
  Client 0: layers_shared=5, local_acc=0.6956
  Client 1: layers_shared=6, local_acc=0.6540
  Client 2: layers_shared=4, local_acc=0.6042
  Client 3: layers_shared=3, local_acc=0.7725
  Client 4: layers_shared=3, local_acc=0.8427
  Client 5: layers_shared=5, local_acc=0.7965
  Client 6: layers_shared=6, local_acc=0.7792
  Client 7: layers_shared=1, local_acc=0.8389
  Client 8: layers_shared=4, local_acc=0.9370
  Client 9: layers_shared=6, local_acc=0.9109
  Client 0: mean_dist=6.50, base_reward=-2.5562, violation=2, comm_penalty=2.0000, reward=-4.5562
  Client 1: mean_dist=7.79, base_reward=-3.2409, violation=1, comm_penalty=1.0000, reward=-4.2409
  Client 2: mean_dist=7.00, base_reward=-2.8946, violation=3, comm_penalty=3.0000, reward=-5.8946
  Client 3: mean_dist=5.70, base_reward=-2.0799, violation=1, comm_penalty=1.0000, reward=-3.0799
  Client 4: mean_dist=6.38, base_reward=-2.3473, violation=0, comm_penalty=0.0000, reward=-2.3473
  Client 5: mean_dist=9.33, base_reward=-3.8688, violation=0, comm_penalty=0.0000, reward=-3.8688
  Client 6: mean_dist=6.41, base_reward=-2.4250, violation=5, comm_penalty=5.0000, reward=-7.4250
  Client 7: mean_dist=2.63, base_reward=-0.4767, violation=0, comm_penalty=0.0000, reward=-0.4767
  Client 8: mean_dist=6.31, base_reward=-2.2168, violation=2, comm_penalty=2.0000, reward=-4.2168
  Client 9: mean_dist=8.46, base_reward=-3.3209, violation=1, comm_penalty=1.0000, reward=-4.3209
  RL policy loss: -0.107349
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.0990
  Client 1 model accuracy on test set: 0.1674
  Client 2 model accuracy on test set: 0.1007
  Client 3 model accuracy on test set: 0.1002
  Client 4 model accuracy on test set: 0.1618
  Client 5 model accuracy on test set: 0.1364
  Client 6 model accuracy on test set: 0.1118
  Client 7 model accuracy on test set: 0.1614
  Client 8 model accuracy on test set: 0.1016
  Client 9 model accuracy on test set: 0.1514

=== Global Round 13/100 ===
  Client 0: layers_shared=1, local_acc=0.7582
  Client 1: layers_shared=3, local_acc=0.7318
  Client 2: layers_shared=6, local_acc=0.6201
  Client 3: layers_shared=1, local_acc=0.8869
  Client 4: layers_shared=5, local_acc=0.8543
  Client 5: layers_shared=3, local_acc=0.8114
  Client 6: layers_shared=6, local_acc=0.6415
  Client 7: layers_shared=2, local_acc=0.8632
  Client 8: layers_shared=5, local_acc=0.9347
  Client 9: layers_shared=1, local_acc=0.9032
  Client 0: mean_dist=1.80, base_reward=-0.1430, violation=0, comm_penalty=0.0000, reward=-0.1430
  Client 1: mean_dist=5.11, base_reward=-1.8233, violation=0, comm_penalty=0.0000, reward=-1.8233
  Client 2: mean_dist=5.99, base_reward=-2.3766, violation=5, comm_penalty=5.0000, reward=-7.3766
  Client 3: mean_dist=2.03, base_reward=-0.1277, violation=0, comm_penalty=0.0000, reward=-0.1277
  Client 4: mean_dist=6.23, base_reward=-2.2618, violation=1, comm_penalty=1.0000, reward=-3.2618
  Client 5: mean_dist=6.21, base_reward=-2.2957, violation=0, comm_penalty=0.0000, reward=-2.2957
  Client 6: mean_dist=5.13, base_reward=-1.9232, violation=5, comm_penalty=5.0000, reward=-6.9232
  Client 7: mean_dist=5.28, base_reward=-1.7777, violation=0, comm_penalty=0.0000, reward=-1.7777
  Client 8: mean_dist=5.43, base_reward=-1.7795, violation=3, comm_penalty=3.0000, reward=-4.7795
  Client 9: mean_dist=2.17, base_reward=-0.1801, violation=0, comm_penalty=0.0000, reward=-0.1801
  RL policy loss: -0.011432
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1136
  Client 1 model accuracy on test set: 0.1657
  Client 2 model accuracy on test set: 0.1063
  Client 3 model accuracy on test set: 0.1003
  Client 4 model accuracy on test set: 0.1934
  Client 5 model accuracy on test set: 0.1669
  Client 6 model accuracy on test set: 0.1233
  Client 7 model accuracy on test set: 0.1614
  Client 8 model accuracy on test set: 0.1175
  Client 9 model accuracy on test set: 0.1880

=== Global Round 14/100 ===
  Client 0: layers_shared=6, local_acc=0.7241
  Client 1: layers_shared=6, local_acc=0.7606
  Client 2: layers_shared=1, local_acc=0.5820
  Client 3: layers_shared=3, local_acc=0.8764
  Client 4: layers_shared=5, local_acc=0.8729
  Client 5: layers_shared=5, local_acc=0.7812
  Client 6: layers_shared=1, local_acc=0.7128
  Client 7: layers_shared=5, local_acc=0.8886
  Client 8: layers_shared=2, local_acc=0.9416
  Client 9: layers_shared=2, local_acc=0.9120
  Client 0: mean_dist=6.47, base_reward=-2.5118, violation=3, comm_penalty=3.0000, reward=-5.5118
  Client 1: mean_dist=7.40, base_reward=-2.9379, violation=1, comm_penalty=1.0000, reward=-3.9379
  Client 2: mean_dist=1.95, base_reward=-0.3929, violation=0, comm_penalty=0.0000, reward=-0.3929
  Client 3: mean_dist=5.57, base_reward=-1.9087, violation=1, comm_penalty=1.0000, reward=-2.9087
  Client 4: mean_dist=7.61, base_reward=-2.9328, violation=1, comm_penalty=1.0000, reward=-3.9328
  Client 5: mean_dist=8.72, base_reward=-3.5812, violation=0, comm_penalty=0.0000, reward=-3.5812
  Client 6: mean_dist=1.79, base_reward=-0.1819, violation=0, comm_penalty=0.0000, reward=-0.1819
  Client 7: mean_dist=9.35, base_reward=-3.7883, violation=0, comm_penalty=0.0000, reward=-3.7883
  Client 8: mean_dist=4.23, base_reward=-1.1753, violation=0, comm_penalty=0.0000, reward=-1.1753
  Client 9: mean_dist=5.03, base_reward=-1.6012, violation=0, comm_penalty=0.0000, reward=-1.6012
  RL policy loss: 0.206915
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1015
  Client 1 model accuracy on test set: 0.1193
  Client 2 model accuracy on test set: 0.1338
  Client 3 model accuracy on test set: 0.1001
  Client 4 model accuracy on test set: 0.1579
  Client 5 model accuracy on test set: 0.2183
  Client 6 model accuracy on test set: 0.1567
  Client 7 model accuracy on test set: 0.1491
  Client 8 model accuracy on test set: 0.1012
  Client 9 model accuracy on test set: 0.2008

=== Global Round 15/100 ===
  Client 0: layers_shared=6, local_acc=0.7823
  Client 1: layers_shared=5, local_acc=0.7601
  Client 2: layers_shared=4, local_acc=0.6497
  Client 3: layers_shared=5, local_acc=0.8215
  Client 4: layers_shared=4, local_acc=0.8704
  Client 5: layers_shared=6, local_acc=0.8513
  Client 6: layers_shared=5, local_acc=0.6981
  Client 7: layers_shared=5, local_acc=0.8272
  Client 8: layers_shared=5, local_acc=0.9528
  Client 9: layers_shared=2, local_acc=0.9280
  Client 0: mean_dist=8.33, base_reward=-3.3814, violation=3, comm_penalty=3.0000, reward=-6.3814
  Client 1: mean_dist=10.02, base_reward=-4.2480, violation=0, comm_penalty=0.0000, reward=-4.2480
  Client 2: mean_dist=8.92, base_reward=-3.8083, violation=3, comm_penalty=3.0000, reward=-6.8083
  Client 3: mean_dist=9.13, base_reward=-3.7425, violation=3, comm_penalty=3.0000, reward=-6.7425
  Client 4: mean_dist=9.31, base_reward=-3.7857, violation=0, comm_penalty=0.0000, reward=-3.7857
  Client 5: mean_dist=11.91, base_reward=-5.1060, violation=0, comm_penalty=0.0000, reward=-5.1060
  Client 6: mean_dist=8.16, base_reward=-3.3830, violation=4, comm_penalty=4.0000, reward=-7.3830
  Client 7: mean_dist=12.83, base_reward=-5.5891, violation=0, comm_penalty=0.0000, reward=-5.5891
  Client 8: mean_dist=8.64, base_reward=-3.3687, violation=3, comm_penalty=3.0000, reward=-6.3687
  Client 9: mean_dist=5.92, base_reward=-2.0312, violation=0, comm_penalty=0.0000, reward=-2.0312
  RL policy loss: 0.294269
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1003
  Client 1 model accuracy on test set: 0.1515
  Client 2 model accuracy on test set: 0.1032
  Client 3 model accuracy on test set: 0.1001
  Client 4 model accuracy on test set: 0.1574
  Client 5 model accuracy on test set: 0.1468
  Client 6 model accuracy on test set: 0.1659
  Client 7 model accuracy on test set: 0.1997
  Client 8 model accuracy on test set: 0.1694
  Client 9 model accuracy on test set: 0.1332

=== Global Round 16/100 ===
  Client 0: layers_shared=6, local_acc=0.7272
  Client 1: layers_shared=5, local_acc=0.7756
  Client 2: layers_shared=2, local_acc=0.6613
  Client 3: layers_shared=5, local_acc=0.8936
  Client 4: layers_shared=5, local_acc=0.8672
  Client 5: layers_shared=4, local_acc=0.8718
  Client 6: layers_shared=1, local_acc=0.7736
  Client 7: layers_shared=3, local_acc=0.8455
  Client 8: layers_shared=5, local_acc=0.9306
  Client 9: layers_shared=4, local_acc=0.8858
  Client 0: mean_dist=7.54, base_reward=-3.0415, violation=3, comm_penalty=3.0000, reward=-6.0415
  Client 1: mean_dist=8.97, base_reward=-3.7086, violation=0, comm_penalty=0.0000, reward=-3.7086
  Client 2: mean_dist=5.12, base_reward=-1.8967, violation=1, comm_penalty=1.0000, reward=-2.8967
  Client 3: mean_dist=8.27, base_reward=-3.2428, violation=3, comm_penalty=3.0000, reward=-6.2428
  Client 4: mean_dist=9.18, base_reward=-3.7212, violation=1, comm_penalty=1.0000, reward=-4.7212
  Client 5: mean_dist=9.93, base_reward=-4.0945, violation=0, comm_penalty=0.0000, reward=-4.0945
  Client 6: mean_dist=1.90, base_reward=-0.1764, violation=0, comm_penalty=0.0000, reward=-0.1764
  Client 7: mean_dist=8.99, base_reward=-3.6497, violation=0, comm_penalty=0.0000, reward=-3.6497
  Client 8: mean_dist=7.85, base_reward=-2.9929, violation=3, comm_penalty=3.0000, reward=-5.9929
  Client 9: mean_dist=9.00, base_reward=-3.6160, violation=0, comm_penalty=0.0000, reward=-3.6160
  RL policy loss: 0.072064
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1581
  Client 1 model accuracy on test set: 0.2035
  Client 2 model accuracy on test set: 0.1429
  Client 3 model accuracy on test set: 0.1002
  Client 4 model accuracy on test set: 0.1640
  Client 5 model accuracy on test set: 0.1505
  Client 6 model accuracy on test set: 0.1028
  Client 7 model accuracy on test set: 0.2099
  Client 8 model accuracy on test set: 0.1025
  Client 9 model accuracy on test set: 0.1658

=== Global Round 17/100 ===
  Client 0: layers_shared=4, local_acc=0.7234
  Client 1: layers_shared=1, local_acc=0.7910
  Client 2: layers_shared=1, local_acc=0.5804
  Client 3: layers_shared=3, local_acc=0.9064
  Client 4: layers_shared=1, local_acc=0.8809
  Client 5: layers_shared=3, local_acc=0.8528
  Client 6: layers_shared=6, local_acc=0.7610
  Client 7: layers_shared=3, local_acc=0.8591
  Client 8: layers_shared=5, local_acc=0.9494
  Client 9: layers_shared=2, local_acc=0.9058
  Client 0: mean_dist=5.20, base_reward=-1.8767, violation=1, comm_penalty=1.0000, reward=-2.8767
  Client 1: mean_dist=2.16, base_reward=-0.2886, violation=0, comm_penalty=0.0000, reward=-0.2886
  Client 2: mean_dist=2.13, base_reward=-0.4853, violation=0, comm_penalty=0.0000, reward=-0.4853
  Client 3: mean_dist=5.48, base_reward=-1.8326, violation=1, comm_penalty=1.0000, reward=-2.8326
  Client 4: mean_dist=2.25, base_reward=-0.2456, violation=0, comm_penalty=0.0000, reward=-0.2456
  Client 5: mean_dist=6.89, base_reward=-2.5943, violation=0, comm_penalty=0.0000, reward=-2.5943
  Client 6: mean_dist=5.16, base_reward=-1.8198, violation=5, comm_penalty=5.0000, reward=-6.8198
  Client 7: mean_dist=7.39, base_reward=-2.8349, violation=0, comm_penalty=0.0000, reward=-2.8349
  Client 8: mean_dist=5.53, base_reward=-1.8165, violation=3, comm_penalty=3.0000, reward=-4.8165
  Client 9: mean_dist=4.90, base_reward=-1.5456, violation=0, comm_penalty=0.0000, reward=-1.5456
  RL policy loss: 0.002781
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1021
  Client 1 model accuracy on test set: 0.1455
  Client 2 model accuracy on test set: 0.1011
  Client 3 model accuracy on test set: 0.1177
  Client 4 model accuracy on test set: 0.1628
  Client 5 model accuracy on test set: 0.1892
  Client 6 model accuracy on test set: 0.1671
  Client 7 model accuracy on test set: 0.2069
  Client 8 model accuracy on test set: 0.1117
  Client 9 model accuracy on test set: 0.1568

=== Global Round 18/100 ===
  Client 0: layers_shared=5, local_acc=0.7892
  Client 1: layers_shared=2, local_acc=0.7500
  Client 2: layers_shared=4, local_acc=0.6706
  Client 3: layers_shared=5, local_acc=0.8925
  Client 4: layers_shared=5, local_acc=0.8828
  Client 5: layers_shared=3, local_acc=0.8377
  Client 6: layers_shared=5, local_acc=0.7638
  Client 7: layers_shared=5, local_acc=0.9058
  Client 8: layers_shared=4, local_acc=0.9544
  Client 9: layers_shared=6, local_acc=0.9293
  Client 0: mean_dist=8.70, base_reward=-3.5631, violation=2, comm_penalty=2.0000, reward=-5.5631
  Client 1: mean_dist=5.78, base_reward=-2.1405, violation=0, comm_penalty=0.0000, reward=-2.1405
  Client 2: mean_dist=9.60, base_reward=-4.1318, violation=3, comm_penalty=3.0000, reward=-7.1318
  Client 3: mean_dist=9.57, base_reward=-3.8904, violation=3, comm_penalty=3.0000, reward=-6.8904
  Client 4: mean_dist=10.75, base_reward=-4.4944, violation=1, comm_penalty=1.0000, reward=-5.4944
  Client 5: mean_dist=9.54, base_reward=-3.9315, violation=0, comm_penalty=0.0000, reward=-3.9315
  Client 6: mean_dist=8.54, base_reward=-3.5080, violation=4, comm_penalty=4.0000, reward=-7.5080
  Client 7: mean_dist=13.38, base_reward=-5.7865, violation=0, comm_penalty=0.0000, reward=-5.7865
  Client 8: mean_dist=8.41, base_reward=-3.2520, violation=2, comm_penalty=2.0000, reward=-5.2520
  Client 9: mean_dist=11.16, base_reward=-4.6490, violation=1, comm_penalty=1.0000, reward=-5.6490
  RL policy loss: 0.176765
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1440
  Client 1 model accuracy on test set: 0.1479
  Client 2 model accuracy on test set: 0.1030
  Client 3 model accuracy on test set: 0.0999
  Client 4 model accuracy on test set: 0.1498
  Client 5 model accuracy on test set: 0.1873
  Client 6 model accuracy on test set: 0.1110
  Client 7 model accuracy on test set: 0.1947
  Client 8 model accuracy on test set: 0.1555
  Client 9 model accuracy on test set: 0.1897

=== Global Round 19/100 ===
  Client 0: layers_shared=4, local_acc=0.7943
  Client 1: layers_shared=5, local_acc=0.7730
  Client 2: layers_shared=1, local_acc=0.7178
  Client 3: layers_shared=1, local_acc=0.8988
  Client 4: layers_shared=3, local_acc=0.8801
  Client 5: layers_shared=1, local_acc=0.8414
  Client 6: layers_shared=1, local_acc=0.7855
  Client 7: layers_shared=2, local_acc=0.8921
  Client 8: layers_shared=2, local_acc=0.9546
  Client 9: layers_shared=4, local_acc=0.9247
  Client 0: mean_dist=5.07, base_reward=-1.7384, violation=1, comm_penalty=1.0000, reward=-2.7384
  Client 1: mean_dist=5.69, base_reward=-2.0721, violation=0, comm_penalty=0.0000, reward=-2.0721
  Client 2: mean_dist=2.23, base_reward=-0.3978, violation=0, comm_penalty=0.0000, reward=-0.3978
  Client 3: mean_dist=2.35, base_reward=-0.2755, violation=0, comm_penalty=0.0000, reward=-0.2755
  Client 4: mean_dist=5.49, base_reward=-1.8647, violation=0, comm_penalty=0.0000, reward=-1.8647
  Client 5: mean_dist=2.81, base_reward=-0.5653, violation=0, comm_penalty=0.0000, reward=-0.5653
  Client 6: mean_dist=2.05, base_reward=-0.2413, violation=0, comm_penalty=0.0000, reward=-0.2413
  Client 7: mean_dist=5.62, base_reward=-1.9193, violation=0, comm_penalty=0.0000, reward=-1.9193
  Client 8: mean_dist=4.07, base_reward=-1.0824, violation=0, comm_penalty=0.0000, reward=-1.0824
  Client 9: mean_dist=6.12, base_reward=-2.1354, violation=0, comm_penalty=0.0000, reward=-2.1354
  RL policy loss: -0.048827
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1130
  Client 1 model accuracy on test set: 0.1321
  Client 2 model accuracy on test set: 0.1050
  Client 3 model accuracy on test set: 0.1073
  Client 4 model accuracy on test set: 0.1479
  Client 5 model accuracy on test set: 0.1919
  Client 6 model accuracy on test set: 0.1252
  Client 7 model accuracy on test set: 0.2213
  Client 8 model accuracy on test set: 0.1199
  Client 9 model accuracy on test set: 0.2185

=== Global Round 20/100 ===
  Client 0: layers_shared=4, local_acc=0.7772
  Client 1: layers_shared=1, local_acc=0.8085
  Client 2: layers_shared=6, local_acc=0.6874
  Client 3: layers_shared=6, local_acc=0.9066
  Client 4: layers_shared=2, local_acc=0.8761
  Client 5: layers_shared=3, local_acc=0.8562
  Client 6: layers_shared=1, local_acc=0.7596
  Client 7: layers_shared=4, local_acc=0.9271
  Client 8: layers_shared=5, local_acc=0.9457
  Client 9: layers_shared=5, local_acc=0.9315
  Client 0: mean_dist=7.19, base_reward=-2.8196, violation=1, comm_penalty=1.0000, reward=-3.8196
  Client 1: mean_dist=2.31, base_reward=-0.3479, violation=0, comm_penalty=0.0000, reward=-0.3479
  Client 2: mean_dist=9.01, base_reward=-3.8187, violation=5, comm_penalty=5.0000, reward=-8.8187
  Client 3: mean_dist=8.34, base_reward=-3.2655, violation=4, comm_penalty=4.0000, reward=-7.2655
  Client 4: mean_dist=5.74, base_reward=-1.9921, violation=0, comm_penalty=0.0000, reward=-1.9921
  Client 5: mean_dist=8.45, base_reward=-3.3675, violation=0, comm_penalty=0.0000, reward=-3.3675
  Client 6: mean_dist=2.08, base_reward=-0.2823, violation=0, comm_penalty=0.0000, reward=-0.2823
  Client 7: mean_dist=10.60, base_reward=-4.3751, violation=0, comm_penalty=0.0000, reward=-4.3751
  Client 8: mean_dist=7.92, base_reward=-3.0152, violation=3, comm_penalty=3.0000, reward=-6.0152
  Client 9: mean_dist=9.46, base_reward=-3.8003, violation=0, comm_penalty=0.0000, reward=-3.8003
  RL policy loss: -0.042947
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1006
  Client 1 model accuracy on test set: 0.1556
  Client 2 model accuracy on test set: 0.1427
  Client 3 model accuracy on test set: 0.1043
  Client 4 model accuracy on test set: 0.1703
  Client 5 model accuracy on test set: 0.2270
  Client 6 model accuracy on test set: 0.1010
  Client 7 model accuracy on test set: 0.2371
  Client 8 model accuracy on test set: 0.1270
  Client 9 model accuracy on test set: 0.1642

=== Global Round 21/100 ===
  Client 0: layers_shared=1, local_acc=0.6892
  Client 1: layers_shared=3, local_acc=0.8100
  Client 2: layers_shared=1, local_acc=0.7267
  Client 3: layers_shared=3, local_acc=0.9106
  Client 4: layers_shared=5, local_acc=0.9088
  Client 5: layers_shared=3, local_acc=0.7398
  Client 6: layers_shared=4, local_acc=0.7827
  Client 7: layers_shared=4, local_acc=0.9048
  Client 8: layers_shared=3, local_acc=0.9042
  Client 9: layers_shared=5, local_acc=0.9386
  Client 0: mean_dist=2.24, base_reward=-0.4322, violation=0, comm_penalty=0.0000, reward=-0.4322
  Client 1: mean_dist=7.57, base_reward=-2.9728, violation=0, comm_penalty=0.0000, reward=-2.9728
  Client 2: mean_dist=2.35, base_reward=-0.4500, violation=0, comm_penalty=0.0000, reward=-0.4500
  Client 3: mean_dist=7.18, base_reward=-2.6796, violation=1, comm_penalty=1.0000, reward=-3.6796
  Client 4: mean_dist=9.04, base_reward=-3.6114, violation=1, comm_penalty=1.0000, reward=-4.6114
  Client 5: mean_dist=8.98, base_reward=-3.7510, violation=0, comm_penalty=0.0000, reward=-3.7510
  Client 6: mean_dist=7.13, base_reward=-2.7824, violation=3, comm_penalty=3.0000, reward=-5.7824
  Client 7: mean_dist=10.55, base_reward=-4.3716, violation=0, comm_penalty=0.0000, reward=-4.3716
  Client 8: mean_dist=6.86, base_reward=-2.5277, violation=1, comm_penalty=1.0000, reward=-3.5277
  Client 9: mean_dist=9.17, base_reward=-3.6489, violation=0, comm_penalty=0.0000, reward=-3.6489
  RL policy loss: -0.071600
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1057
  Client 1 model accuracy on test set: 0.1152
  Client 2 model accuracy on test set: 0.1261
  Client 3 model accuracy on test set: 0.1008
  Client 4 model accuracy on test set: 0.1683
  Client 5 model accuracy on test set: 0.1960
  Client 6 model accuracy on test set: 0.1354
  Client 7 model accuracy on test set: 0.2221
  Client 8 model accuracy on test set: 0.1005
  Client 9 model accuracy on test set: 0.1517

=== Global Round 22/100 ===
  Client 0: layers_shared=1, local_acc=0.8025
  Client 1: layers_shared=1, local_acc=0.7703
  Client 2: layers_shared=2, local_acc=0.6346
  Client 3: layers_shared=5, local_acc=0.8863
  Client 4: layers_shared=4, local_acc=0.9043
  Client 5: layers_shared=4, local_acc=0.8160
  Client 6: layers_shared=4, local_acc=0.7512
  Client 7: layers_shared=3, local_acc=0.9044
  Client 8: layers_shared=2, local_acc=0.9532
  Client 9: layers_shared=2, local_acc=0.9372
  Client 0: mean_dist=2.29, base_reward=-0.3428, violation=0, comm_penalty=0.0000, reward=-0.3428
  Client 1: mean_dist=2.43, base_reward=-0.4464, violation=0, comm_penalty=0.0000, reward=-0.4464
  Client 2: mean_dist=5.62, base_reward=-2.1755, violation=1, comm_penalty=1.0000, reward=-3.1755
  Client 3: mean_dist=7.30, base_reward=-2.7619, violation=3, comm_penalty=3.0000, reward=-5.7619
  Client 4: mean_dist=8.07, base_reward=-3.1322, violation=0, comm_penalty=0.0000, reward=-3.1322
  Client 5: mean_dist=9.04, base_reward=-3.7042, violation=0, comm_penalty=0.0000, reward=-3.7042
  Client 6: mean_dist=6.53, base_reward=-2.5138, violation=3, comm_penalty=3.0000, reward=-5.5138
  Client 7: mean_dist=8.62, base_reward=-3.4032, violation=0, comm_penalty=0.0000, reward=-3.4032
  Client 8: mean_dist=5.18, base_reward=-1.6346, violation=0, comm_penalty=0.0000, reward=-1.6346
  Client 9: mean_dist=6.07, base_reward=-2.0975, violation=0, comm_penalty=0.0000, reward=-2.0975
  RL policy loss: 0.004903
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1043
  Client 1 model accuracy on test set: 0.1632
  Client 2 model accuracy on test set: 0.1007
  Client 3 model accuracy on test set: 0.1005
  Client 4 model accuracy on test set: 0.1632
  Client 5 model accuracy on test set: 0.1987
  Client 6 model accuracy on test set: 0.1012
  Client 7 model accuracy on test set: 0.2333
  Client 8 model accuracy on test set: 0.1179
  Client 9 model accuracy on test set: 0.1940

=== Global Round 23/100 ===
  Client 0: layers_shared=4, local_acc=0.8209
  Client 1: layers_shared=5, local_acc=0.7720
  Client 2: layers_shared=6, local_acc=0.7279
  Client 3: layers_shared=6, local_acc=0.9247
  Client 4: layers_shared=6, local_acc=0.8963
  Client 5: layers_shared=3, local_acc=0.9046
  Client 6: layers_shared=4, local_acc=0.7352
  Client 7: layers_shared=1, local_acc=0.9024
  Client 8: layers_shared=4, local_acc=0.9579
  Client 9: layers_shared=2, local_acc=0.9245
  Client 0: mean_dist=7.97, base_reward=-3.1629, violation=1, comm_penalty=1.0000, reward=-4.1629
  Client 1: mean_dist=10.29, base_reward=-4.3711, violation=0, comm_penalty=0.0000, reward=-4.3711
  Client 2: mean_dist=10.40, base_reward=-4.4718, violation=5, comm_penalty=5.0000, reward=-9.4718
  Client 3: mean_dist=9.38, base_reward=-3.7657, violation=4, comm_penalty=4.0000, reward=-7.7657
  Client 4: mean_dist=10.63, base_reward=-4.4204, violation=2, comm_penalty=2.0000, reward=-6.4204
  Client 5: mean_dist=9.57, base_reward=-3.8794, violation=0, comm_penalty=0.0000, reward=-3.8794
  Client 6: mean_dist=7.80, base_reward=-3.1665, violation=3, comm_penalty=3.0000, reward=-6.1665
  Client 7: mean_dist=3.27, base_reward=-0.7327, violation=0, comm_penalty=0.0000, reward=-0.7327
  Client 8: mean_dist=8.33, base_reward=-3.2095, violation=2, comm_penalty=2.0000, reward=-5.2095
  Client 9: mean_dist=6.48, base_reward=-2.3159, violation=0, comm_penalty=0.0000, reward=-2.3159
  RL policy loss: -0.057395
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1052
  Client 1 model accuracy on test set: 0.1297
  Client 2 model accuracy on test set: 0.1000
  Client 3 model accuracy on test set: 0.1117
  Client 4 model accuracy on test set: 0.1188
  Client 5 model accuracy on test set: 0.1830
  Client 6 model accuracy on test set: 0.1055
  Client 7 model accuracy on test set: 0.2026
  Client 8 model accuracy on test set: 0.1037
  Client 9 model accuracy on test set: 0.1708

=== Global Round 24/100 ===
  Client 0: layers_shared=3, local_acc=0.8006
  Client 1: layers_shared=4, local_acc=0.8503
  Client 2: layers_shared=2, local_acc=0.6774
  Client 3: layers_shared=6, local_acc=0.8804
  Client 4: layers_shared=4, local_acc=0.8499
  Client 5: layers_shared=2, local_acc=0.8939
  Client 6: layers_shared=4, local_acc=0.6464
  Client 7: layers_shared=4, local_acc=0.9238
  Client 8: layers_shared=4, local_acc=0.9424
  Client 9: layers_shared=1, local_acc=0.9549
  Client 0: mean_dist=6.79, base_reward=-2.5949, violation=0, comm_penalty=0.0000, reward=-2.5949
  Client 1: mean_dist=9.43, base_reward=-3.8663, violation=0, comm_penalty=0.0000, reward=-3.8663
  Client 2: mean_dist=6.19, base_reward=-2.4195, violation=1, comm_penalty=1.0000, reward=-3.4195
  Client 3: mean_dist=8.69, base_reward=-3.4656, violation=4, comm_penalty=4.0000, reward=-7.4656
  Client 4: mean_dist=9.85, base_reward=-4.0729, violation=0, comm_penalty=0.0000, reward=-4.0729
  Client 5: mean_dist=7.34, base_reward=-2.7783, violation=0, comm_penalty=0.0000, reward=-2.7783
  Client 6: mean_dist=7.73, base_reward=-3.2209, violation=3, comm_penalty=3.0000, reward=-6.2209
  Client 7: mean_dist=11.80, base_reward=-4.9767, violation=0, comm_penalty=0.0000, reward=-4.9767
  Client 8: mean_dist=8.27, base_reward=-3.1906, violation=2, comm_penalty=2.0000, reward=-5.1906
  Client 9: mean_dist=2.69, base_reward=-0.3897, violation=0, comm_penalty=0.0000, reward=-0.3897
  RL policy loss: -0.075448
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1088
  Client 1 model accuracy on test set: 0.1475
  Client 2 model accuracy on test set: 0.1019
  Client 3 model accuracy on test set: 0.1001
  Client 4 model accuracy on test set: 0.1687
  Client 5 model accuracy on test set: 0.2143
  Client 6 model accuracy on test set: 0.1068
  Client 7 model accuracy on test set: 0.1690
  Client 8 model accuracy on test set: 0.1023
  Client 9 model accuracy on test set: 0.1605

=== Global Round 25/100 ===
  Client 0: layers_shared=1, local_acc=0.7835
  Client 1: layers_shared=5, local_acc=0.8734
  Client 2: layers_shared=2, local_acc=0.7517
  Client 3: layers_shared=4, local_acc=0.9265
  Client 4: layers_shared=3, local_acc=0.8708
  Client 5: layers_shared=3, local_acc=0.9139
  Client 6: layers_shared=5, local_acc=0.8148
  Client 7: layers_shared=2, local_acc=0.9118
  Client 8: layers_shared=3, local_acc=0.9567
  Client 9: layers_shared=5, local_acc=0.9543
  Client 0: mean_dist=2.41, base_reward=-0.4223, violation=0, comm_penalty=0.0000, reward=-0.4223
  Client 1: mean_dist=9.60, base_reward=-3.9259, violation=0, comm_penalty=0.0000, reward=-3.9259
  Client 2: mean_dist=6.48, base_reward=-2.4871, violation=1, comm_penalty=1.0000, reward=-3.4871
  Client 3: mean_dist=8.58, base_reward=-3.3612, violation=2, comm_penalty=2.0000, reward=-5.3612
  Client 4: mean_dist=8.90, base_reward=-3.5773, violation=0, comm_penalty=0.0000, reward=-3.5773
  Client 5: mean_dist=9.80, base_reward=-3.9879, violation=0, comm_penalty=0.0000, reward=-3.9879
  Client 6: mean_dist=8.02, base_reward=-3.1961, violation=4, comm_penalty=4.0000, reward=-7.1961
  Client 7: mean_dist=8.04, base_reward=-3.1097, violation=0, comm_penalty=0.0000, reward=-3.1097
  Client 8: mean_dist=7.49, base_reward=-2.7890, violation=1, comm_penalty=1.0000, reward=-3.7890
  Client 9: mean_dist=10.11, base_reward=-4.0993, violation=0, comm_penalty=0.0000, reward=-4.0993
  RL policy loss: -0.025008
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1263
  Client 1 model accuracy on test set: 0.1804
  Client 2 model accuracy on test set: 0.1298
  Client 3 model accuracy on test set: 0.1451
  Client 4 model accuracy on test set: 0.1784
  Client 5 model accuracy on test set: 0.1699
  Client 6 model accuracy on test set: 0.1232
  Client 7 model accuracy on test set: 0.1758
  Client 8 model accuracy on test set: 0.1503
  Client 9 model accuracy on test set: 0.1258

=== Global Round 26/100 ===
  Client 0: layers_shared=1, local_acc=0.8310
  Client 1: layers_shared=4, local_acc=0.8769
  Client 2: layers_shared=5, local_acc=0.7575
  Client 3: layers_shared=3, local_acc=0.8988
  Client 4: layers_shared=2, local_acc=0.8887
  Client 5: layers_shared=3, local_acc=0.9204
  Client 6: layers_shared=3, local_acc=0.8162
  Client 7: layers_shared=6, local_acc=0.9285
  Client 8: layers_shared=5, local_acc=0.9679
  Client 9: layers_shared=3, local_acc=0.9389
  Client 0: mean_dist=2.45, base_reward=-0.3945, violation=0, comm_penalty=0.0000, reward=-0.3945
  Client 1: mean_dist=9.88, base_reward=-4.0653, violation=0, comm_penalty=0.0000, reward=-4.0653
  Client 2: mean_dist=10.59, base_reward=-4.5357, violation=4, comm_penalty=4.0000, reward=-8.5357
  Client 3: mean_dist=8.36, base_reward=-3.2826, violation=1, comm_penalty=1.0000, reward=-4.2826
  Client 4: mean_dist=6.99, base_reward=-2.6053, violation=0, comm_penalty=0.0000, reward=-2.6053
  Client 5: mean_dist=10.42, base_reward=-4.2881, violation=0, comm_penalty=0.0000, reward=-4.2881
  Client 6: mean_dist=7.46, base_reward=-2.9120, violation=2, comm_penalty=2.0000, reward=-4.9120
  Client 7: mean_dist=12.74, base_reward=-5.4405, violation=0, comm_penalty=0.0000, reward=-5.4405
  Client 8: mean_dist=9.31, base_reward=-3.6862, violation=3, comm_penalty=3.0000, reward=-6.6862
  Client 9: mean_dist=9.43, base_reward=-3.7746, violation=0, comm_penalty=0.0000, reward=-3.7746
  RL policy loss: -0.038527
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1094
  Client 1 model accuracy on test set: 0.1815
  Client 2 model accuracy on test set: 0.1128
  Client 3 model accuracy on test set: 0.1014
  Client 4 model accuracy on test set: 0.1782
  Client 5 model accuracy on test set: 0.2107
  Client 6 model accuracy on test set: 0.1104
  Client 7 model accuracy on test set: 0.2205
  Client 8 model accuracy on test set: 0.1503
  Client 9 model accuracy on test set: 0.1159

=== Global Round 27/100 ===
  Client 0: layers_shared=4, local_acc=0.7766
  Client 1: layers_shared=3, local_acc=0.8782
  Client 2: layers_shared=1, local_acc=0.7279
  Client 3: layers_shared=6, local_acc=0.8874
  Client 4: layers_shared=1, local_acc=0.8207
  Client 5: layers_shared=1, local_acc=0.8762
  Client 6: layers_shared=3, local_acc=0.8288
  Client 7: layers_shared=6, local_acc=0.9401
  Client 8: layers_shared=6, local_acc=0.9587
  Client 9: layers_shared=4, local_acc=0.9489
  Client 0: mean_dist=7.22, base_reward=-2.8319, violation=1, comm_penalty=1.0000, reward=-3.8319
  Client 1: mean_dist=7.31, base_reward=-2.7768, violation=0, comm_penalty=0.0000, reward=-2.7768
  Client 2: mean_dist=2.65, base_reward=-0.5982, violation=0, comm_penalty=0.0000, reward=-0.5982
  Client 3: mean_dist=8.35, base_reward=-3.2860, violation=4, comm_penalty=4.0000, reward=-7.2860
  Client 4: mean_dist=2.75, base_reward=-0.5521, violation=0, comm_penalty=0.0000, reward=-0.5521
  Client 5: mean_dist=3.17, base_reward=-0.7107, violation=0, comm_penalty=0.0000, reward=-0.7107
  Client 6: mean_dist=6.09, base_reward=-2.2178, violation=2, comm_penalty=2.0000, reward=-4.2178
  Client 7: mean_dist=11.23, base_reward=-4.6768, violation=0, comm_penalty=0.0000, reward=-4.6768
  Client 8: mean_dist=7.94, base_reward=-3.0095, violation=4, comm_penalty=4.0000, reward=-7.0095
  Client 9: mean_dist=9.00, base_reward=-3.5502, violation=0, comm_penalty=0.0000, reward=-3.5502
  RL policy loss: -0.282255
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1022
  Client 1 model accuracy on test set: 0.1833
  Client 2 model accuracy on test set: 0.1171
  Client 3 model accuracy on test set: 0.1106
  Client 4 model accuracy on test set: 0.1635
  Client 5 model accuracy on test set: 0.1698
  Client 6 model accuracy on test set: 0.1575
  Client 7 model accuracy on test set: 0.1887
  Client 8 model accuracy on test set: 0.1698
  Client 9 model accuracy on test set: 0.1484

=== Global Round 28/100 ===
  Client 0: layers_shared=6, local_acc=0.7766
  Client 1: layers_shared=3, local_acc=0.8609
  Client 2: layers_shared=1, local_acc=0.7482
  Client 3: layers_shared=1, local_acc=0.9175
  Client 4: layers_shared=6, local_acc=0.9077
  Client 5: layers_shared=6, local_acc=0.9309
  Client 6: layers_shared=3, local_acc=0.8616
  Client 7: layers_shared=5, local_acc=0.9438
  Client 8: layers_shared=3, local_acc=0.9677
  Client 9: layers_shared=4, local_acc=0.9438
  Client 0: mean_dist=9.27, base_reward=-3.8590, violation=3, comm_penalty=3.0000, reward=-6.8590
  Client 1: mean_dist=8.59, base_reward=-3.4355, violation=0, comm_penalty=0.0000, reward=-3.4355
  Client 2: mean_dist=2.69, base_reward=-0.5967, violation=0, comm_penalty=0.0000, reward=-0.5967
  Client 3: mean_dist=2.72, base_reward=-0.4418, violation=0, comm_penalty=0.0000, reward=-0.4418
  Client 4: mean_dist=11.28, base_reward=-4.7313, violation=2, comm_penalty=2.0000, reward=-6.7313
  Client 5: mean_dist=12.48, base_reward=-5.3082, violation=0, comm_penalty=0.0000, reward=-5.3082
  Client 6: mean_dist=7.22, base_reward=-2.7477, violation=2, comm_penalty=2.0000, reward=-4.7477
  Client 7: mean_dist=13.14, base_reward=-5.6271, violation=0, comm_penalty=0.0000, reward=-5.6271
  Client 8: mean_dist=7.71, base_reward=-2.8897, violation=1, comm_penalty=1.0000, reward=-3.8897
  Client 9: mean_dist=10.52, base_reward=-4.3166, violation=0, comm_penalty=0.0000, reward=-4.3166
  RL policy loss: -0.235633
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1231
  Client 1 model accuracy on test set: 0.1314
  Client 2 model accuracy on test set: 0.1157
  Client 3 model accuracy on test set: 0.1005
  Client 4 model accuracy on test set: 0.1438
  Client 5 model accuracy on test set: 0.1969
  Client 6 model accuracy on test set: 0.1820
  Client 7 model accuracy on test set: 0.2333
  Client 8 model accuracy on test set: 0.1441
  Client 9 model accuracy on test set: 0.1597

=== Global Round 29/100 ===
  Client 0: layers_shared=6, local_acc=0.8437
  Client 1: layers_shared=3, local_acc=0.8645
  Client 2: layers_shared=3, local_acc=0.7848
  Client 3: layers_shared=3, local_acc=0.9392
  Client 4: layers_shared=5, local_acc=0.9274
  Client 5: layers_shared=3, local_acc=0.8075
  Client 6: layers_shared=3, local_acc=0.7966
  Client 7: layers_shared=2, local_acc=0.9126
  Client 8: layers_shared=3, local_acc=0.9565
  Client 9: layers_shared=5, local_acc=0.9595
  Client 0: mean_dist=9.29, base_reward=-3.8016, violation=3, comm_penalty=3.0000, reward=-6.8016
  Client 1: mean_dist=9.96, base_reward=-4.1174, violation=0, comm_penalty=0.0000, reward=-4.1174
  Client 2: mean_dist=10.32, base_reward=-4.3728, violation=2, comm_penalty=2.0000, reward=-6.3728
  Client 3: mean_dist=9.31, base_reward=-3.7167, violation=1, comm_penalty=1.0000, reward=-4.7167
  Client 4: mean_dist=11.66, base_reward=-4.9033, violation=1, comm_penalty=1.0000, reward=-5.9033
  Client 5: mean_dist=11.71, base_reward=-5.0483, violation=0, comm_penalty=0.0000, reward=-5.0483
  Client 6: mean_dist=8.23, base_reward=-3.3169, violation=2, comm_penalty=2.0000, reward=-5.3169
  Client 7: mean_dist=9.02, base_reward=-3.5992, violation=0, comm_penalty=0.0000, reward=-3.5992
  Client 8: mean_dist=8.86, base_reward=-3.4746, violation=1, comm_penalty=1.0000, reward=-4.4746
  Client 9: mean_dist=11.55, base_reward=-4.8179, violation=0, comm_penalty=0.0000, reward=-4.8179
  RL policy loss: 0.025868
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1081
  Client 1 model accuracy on test set: 0.1824
  Client 2 model accuracy on test set: 0.1353
  Client 3 model accuracy on test set: 0.1051
  Client 4 model accuracy on test set: 0.1475
  Client 5 model accuracy on test set: 0.1356
  Client 6 model accuracy on test set: 0.1477
  Client 7 model accuracy on test set: 0.1487
  Client 8 model accuracy on test set: 0.1100
  Client 9 model accuracy on test set: 0.1649

=== Global Round 30/100 ===
  Client 0: layers_shared=4, local_acc=0.7646
  Client 1: layers_shared=2, local_acc=0.8121
  Client 2: layers_shared=5, local_acc=0.7898
  Client 3: layers_shared=3, local_acc=0.9439
  Client 4: layers_shared=3, local_acc=0.8452
  Client 5: layers_shared=2, local_acc=0.9119
  Client 6: layers_shared=5, local_acc=0.7820
  Client 7: layers_shared=6, local_acc=0.9188
  Client 8: layers_shared=5, local_acc=0.9666
  Client 9: layers_shared=3, local_acc=0.9582
  Client 0: mean_dist=9.32, base_reward=-3.8942, violation=1, comm_penalty=1.0000, reward=-4.8942
  Client 1: mean_dist=7.33, base_reward=-2.8543, violation=0, comm_penalty=0.0000, reward=-2.8543
  Client 2: mean_dist=12.21, base_reward=-5.3168, violation=4, comm_penalty=4.0000, reward=-9.3168
  Client 3: mean_dist=9.18, base_reward=-3.6483, violation=1, comm_penalty=1.0000, reward=-4.6483
  Client 4: mean_dist=10.55, base_reward=-4.4300, violation=0, comm_penalty=0.0000, reward=-4.4300
  Client 5: mean_dist=8.63, base_reward=-3.4036, violation=0, comm_penalty=0.0000, reward=-3.4036
  Client 6: mean_dist=9.72, base_reward=-4.0771, violation=4, comm_penalty=4.0000, reward=-8.0771
  Client 7: mean_dist=14.55, base_reward=-6.3537, violation=0, comm_penalty=0.0000, reward=-6.3537
  Client 8: mean_dist=10.34, base_reward=-4.2033, violation=3, comm_penalty=3.0000, reward=-7.2033
  Client 9: mean_dist=10.39, base_reward=-4.2351, violation=0, comm_penalty=0.0000, reward=-4.2351
  RL policy loss: 0.047927
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1154
  Client 1 model accuracy on test set: 0.1639
  Client 2 model accuracy on test set: 0.1446
  Client 3 model accuracy on test set: 0.1016
  Client 4 model accuracy on test set: 0.1490
  Client 5 model accuracy on test set: 0.2108
  Client 6 model accuracy on test set: 0.1094
  Client 7 model accuracy on test set: 0.1802
  Client 8 model accuracy on test set: 0.1004
  Client 9 model accuracy on test set: 0.1864

=== Global Round 31/100 ===
  Client 0: layers_shared=3, local_acc=0.7449
  Client 1: layers_shared=4, local_acc=0.8941
  Client 2: layers_shared=3, local_acc=0.6805
  Client 3: layers_shared=3, local_acc=0.9276
  Client 4: layers_shared=5, local_acc=0.9237
  Client 5: layers_shared=1, local_acc=0.9341
  Client 6: layers_shared=5, local_acc=0.9071
  Client 7: layers_shared=1, local_acc=0.9574
  Client 8: layers_shared=3, local_acc=0.9591
  Client 9: layers_shared=2, local_acc=0.9617
  Client 0: mean_dist=6.99, base_reward=-2.7478, violation=0, comm_penalty=0.0000, reward=-2.7478
  Client 1: mean_dist=8.88, base_reward=-3.5435, violation=0, comm_penalty=0.0000, reward=-3.5435
  Client 2: mean_dist=8.53, base_reward=-3.5864, violation=2, comm_penalty=2.0000, reward=-5.5864
  Client 3: mean_dist=7.71, base_reward=-2.9272, violation=1, comm_penalty=1.0000, reward=-3.9272
  Client 4: mean_dist=9.64, base_reward=-3.8960, violation=1, comm_penalty=1.0000, reward=-4.8960
  Client 5: mean_dist=3.31, base_reward=-0.7185, violation=0, comm_penalty=0.0000, reward=-0.7185
  Client 6: mean_dist=7.51, base_reward=-2.8469, violation=4, comm_penalty=4.0000, reward=-6.8469
  Client 7: mean_dist=3.55, base_reward=-0.8154, violation=0, comm_penalty=0.0000, reward=-0.8154
  Client 8: mean_dist=7.31, base_reward=-2.6940, violation=1, comm_penalty=1.0000, reward=-3.6940
  Client 9: mean_dist=6.64, base_reward=-2.3572, violation=0, comm_penalty=0.0000, reward=-2.3572
  RL policy loss: -0.087455
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1190
  Client 1 model accuracy on test set: 0.1501
  Client 2 model accuracy on test set: 0.1406
  Client 3 model accuracy on test set: 0.1002
  Client 4 model accuracy on test set: 0.1501
  Client 5 model accuracy on test set: 0.1673
  Client 6 model accuracy on test set: 0.1579
  Client 7 model accuracy on test set: 0.2424
  Client 8 model accuracy on test set: 0.1491
  Client 9 model accuracy on test set: 0.1823

=== Global Round 32/100 ===
  Client 0: layers_shared=2, local_acc=0.8595
  Client 1: layers_shared=5, local_acc=0.8698
  Client 2: layers_shared=2, local_acc=0.7902
  Client 3: layers_shared=3, local_acc=0.9533
  Client 4: layers_shared=3, local_acc=0.9367
  Client 5: layers_shared=3, local_acc=0.9185
  Client 6: layers_shared=6, local_acc=0.8484
  Client 7: layers_shared=4, local_acc=0.9518
  Client 8: layers_shared=3, local_acc=0.9709
  Client 9: layers_shared=3, local_acc=0.9747
  Client 0: mean_dist=6.53, base_reward=-2.4080, violation=0, comm_penalty=0.0000, reward=-2.4080
  Client 1: mean_dist=11.19, base_reward=-4.7237, violation=0, comm_penalty=0.0000, reward=-4.7237
  Client 2: mean_dist=7.79, base_reward=-3.1043, violation=1, comm_penalty=1.0000, reward=-4.1043
  Client 3: mean_dist=9.60, base_reward=-3.8445, violation=1, comm_penalty=1.0000, reward=-4.8445
  Client 4: mean_dist=11.01, base_reward=-4.5659, violation=0, comm_penalty=0.0000, reward=-4.5659
  Client 5: mean_dist=11.87, base_reward=-5.0178, violation=0, comm_penalty=0.0000, reward=-5.0178
  Client 6: mean_dist=9.41, base_reward=-3.8544, violation=5, comm_penalty=5.0000, reward=-8.8544
  Client 7: mean_dist=13.42, base_reward=-5.7598, violation=0, comm_penalty=0.0000, reward=-5.7598
  Client 8: mean_dist=9.14, base_reward=-3.5984, violation=1, comm_penalty=1.0000, reward=-4.5984
  Client 9: mean_dist=10.78, base_reward=-4.4162, violation=0, comm_penalty=0.0000, reward=-4.4162
  RL policy loss: -0.003812
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1343
  Client 1 model accuracy on test set: 0.1176
  Client 2 model accuracy on test set: 0.1295
  Client 3 model accuracy on test set: 0.1033
  Client 4 model accuracy on test set: 0.1711
  Client 5 model accuracy on test set: 0.1614
  Client 6 model accuracy on test set: 0.1433
  Client 7 model accuracy on test set: 0.2276
  Client 8 model accuracy on test set: 0.1702
  Client 9 model accuracy on test set: 0.1831

=== Global Round 33/100 ===
  Client 0: layers_shared=5, local_acc=0.7709
  Client 1: layers_shared=3, local_acc=0.9012
  Client 2: layers_shared=2, local_acc=0.7846
  Client 3: layers_shared=6, local_acc=0.9482
  Client 4: layers_shared=4, local_acc=0.8919
  Client 5: layers_shared=4, local_acc=0.9343
  Client 6: layers_shared=4, local_acc=0.7987
  Client 7: layers_shared=3, local_acc=0.9610
  Client 8: layers_shared=1, local_acc=0.9719
  Client 9: layers_shared=6, local_acc=0.9570
  Client 0: mean_dist=10.10, base_reward=-4.2809, violation=2, comm_penalty=2.0000, reward=-6.2809
  Client 1: mean_dist=9.87, base_reward=-4.0316, violation=0, comm_penalty=0.0000, reward=-4.0316
  Client 2: mean_dist=7.42, base_reward=-2.9270, violation=1, comm_penalty=1.0000, reward=-3.9270
  Client 3: mean_dist=11.08, base_reward=-4.5913, violation=4, comm_penalty=4.0000, reward=-8.5913
  Client 4: mean_dist=12.20, base_reward=-5.2093, violation=0, comm_penalty=0.0000, reward=-5.2093
  Client 5: mean_dist=13.34, base_reward=-5.7342, violation=0, comm_penalty=0.0000, reward=-5.7342
  Client 6: mean_dist=9.57, base_reward=-3.9860, violation=3, comm_penalty=3.0000, reward=-6.9860
  Client 7: mean_dist=12.11, base_reward=-5.0945, violation=0, comm_penalty=0.0000, reward=-5.0945
  Client 8: mean_dist=2.67, base_reward=-0.3647, violation=0, comm_penalty=0.0000, reward=-0.3647
  Client 9: mean_dist=12.49, base_reward=-5.2881, violation=1, comm_penalty=1.0000, reward=-6.2881
  RL policy loss: -0.197947
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1075
  Client 1 model accuracy on test set: 0.1443
  Client 2 model accuracy on test set: 0.1061
  Client 3 model accuracy on test set: 0.1039
  Client 4 model accuracy on test set: 0.1707
  Client 5 model accuracy on test set: 0.1797
  Client 6 model accuracy on test set: 0.1606
  Client 7 model accuracy on test set: 0.2465
  Client 8 model accuracy on test set: 0.1789
  Client 9 model accuracy on test set: 0.1836

=== Global Round 34/100 ===
  Client 0: layers_shared=4, local_acc=0.8690
  Client 1: layers_shared=5, local_acc=0.9075
  Client 2: layers_shared=5, local_acc=0.7985
  Client 3: layers_shared=3, local_acc=0.9064
  Client 4: layers_shared=5, local_acc=0.8716
  Client 5: layers_shared=1, local_acc=0.9587
  Client 6: layers_shared=6, local_acc=0.7952
  Client 7: layers_shared=4, local_acc=0.9633
  Client 8: layers_shared=3, local_acc=0.9701
  Client 9: layers_shared=2, local_acc=0.9236
  Client 0: mean_dist=9.78, base_reward=-4.0211, violation=1, comm_penalty=1.0000, reward=-5.0211
  Client 1: mean_dist=12.41, base_reward=-5.2962, violation=0, comm_penalty=0.0000, reward=-5.2962
  Client 2: mean_dist=12.90, base_reward=-5.6518, violation=4, comm_penalty=4.0000, reward=-9.6518
  Client 3: mean_dist=9.14, base_reward=-3.6645, violation=1, comm_penalty=1.0000, reward=-4.6645
  Client 4: mean_dist=12.95, base_reward=-5.6054, violation=1, comm_penalty=1.0000, reward=-6.6054
  Client 5: mean_dist=3.41, base_reward=-0.7475, violation=0, comm_penalty=0.0000, reward=-0.7475
  Client 6: mean_dist=10.22, base_reward=-4.3139, violation=5, comm_penalty=5.0000, reward=-9.3139
  Client 7: mean_dist=14.18, base_reward=-6.1285, violation=0, comm_penalty=0.0000, reward=-6.1285
  Client 8: mean_dist=8.66, base_reward=-3.3613, violation=1, comm_penalty=1.0000, reward=-4.3613
  Client 9: mean_dist=7.57, base_reward=-2.8625, violation=0, comm_penalty=0.0000, reward=-2.8625
  RL policy loss: -0.273945
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1007
  Client 1 model accuracy on test set: 0.1225
  Client 2 model accuracy on test set: 0.1296
  Client 3 model accuracy on test set: 0.1015
  Client 4 model accuracy on test set: 0.1616
  Client 5 model accuracy on test set: 0.1832
  Client 6 model accuracy on test set: 0.1050
  Client 7 model accuracy on test set: 0.2295
  Client 8 model accuracy on test set: 0.1339
  Client 9 model accuracy on test set: 0.1177

=== Global Round 35/100 ===
  Client 0: layers_shared=4, local_acc=0.8468
  Client 1: layers_shared=3, local_acc=0.8739
  Client 2: layers_shared=1, local_acc=0.7960
  Client 3: layers_shared=5, local_acc=0.9600
  Client 4: layers_shared=6, local_acc=0.9473
  Client 5: layers_shared=1, local_acc=0.9140
  Client 6: layers_shared=4, local_acc=0.7694
  Client 7: layers_shared=3, local_acc=0.9584
  Client 8: layers_shared=1, local_acc=0.9573
  Client 9: layers_shared=5, local_acc=0.9789
  Client 0: mean_dist=8.31, base_reward=-3.3061, violation=1, comm_penalty=1.0000, reward=-4.3061
  Client 1: mean_dist=8.47, base_reward=-3.3598, violation=0, comm_penalty=0.0000, reward=-3.3598
  Client 2: mean_dist=2.99, base_reward=-0.6990, violation=0, comm_penalty=0.0000, reward=-0.6990
  Client 3: mean_dist=9.47, base_reward=-3.7768, violation=3, comm_penalty=3.0000, reward=-6.7768
  Client 4: mean_dist=10.75, base_reward=-4.4270, violation=2, comm_penalty=2.0000, reward=-6.4270
  Client 5: mean_dist=3.44, base_reward=-0.8084, violation=0, comm_penalty=0.0000, reward=-0.8084
  Client 6: mean_dist=8.13, base_reward=-3.2933, violation=3, comm_penalty=3.0000, reward=-6.2933
  Client 7: mean_dist=10.36, base_reward=-4.2205, violation=0, comm_penalty=0.0000, reward=-4.2205
  Client 8: mean_dist=2.73, base_reward=-0.4083, violation=0, comm_penalty=0.0000, reward=-0.4083
  Client 9: mean_dist=10.63, base_reward=-4.3343, violation=0, comm_penalty=0.0000, reward=-4.3343
  RL policy loss: -0.373328
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1213
  Client 1 model accuracy on test set: 0.1483
  Client 2 model accuracy on test set: 0.1160
  Client 3 model accuracy on test set: 0.1019
  Client 4 model accuracy on test set: 0.1609
  Client 5 model accuracy on test set: 0.1710
  Client 6 model accuracy on test set: 0.1018
  Client 7 model accuracy on test set: 0.1829
  Client 8 model accuracy on test set: 0.1089
  Client 9 model accuracy on test set: 0.1802

=== Global Round 36/100 ===
  Client 0: layers_shared=6, local_acc=0.8677
  Client 1: layers_shared=3, local_acc=0.9020
  Client 2: layers_shared=1, local_acc=0.7933
  Client 3: layers_shared=1, local_acc=0.9160
  Client 4: layers_shared=1, local_acc=0.9597
  Client 5: layers_shared=1, local_acc=0.9579
  Client 6: layers_shared=3, local_acc=0.8526
  Client 7: layers_shared=6, local_acc=0.9643
  Client 8: layers_shared=2, local_acc=0.9762
  Client 9: layers_shared=3, local_acc=0.9605
  Client 0: mean_dist=6.98, base_reward=-2.6210, violation=3, comm_penalty=3.0000, reward=-5.6210
  Client 1: mean_dist=7.14, base_reward=-2.6682, violation=0, comm_penalty=0.0000, reward=-2.6682
  Client 2: mean_dist=3.03, base_reward=-0.7230, violation=0, comm_penalty=0.0000, reward=-0.7230
  Client 3: mean_dist=2.98, base_reward=-0.5756, violation=0, comm_penalty=0.0000, reward=-0.5756
  Client 4: mean_dist=3.08, base_reward=-0.5797, violation=0, comm_penalty=0.0000, reward=-0.5797
  Client 5: mean_dist=3.46, base_reward=-0.7714, violation=0, comm_penalty=0.0000, reward=-0.7714
  Client 6: mean_dist=6.08, base_reward=-2.1876, violation=2, comm_penalty=2.0000, reward=-4.1876
  Client 7: mean_dist=9.42, base_reward=-3.7472, violation=0, comm_penalty=0.0000, reward=-3.7472
  Client 8: mean_dist=5.12, base_reward=-1.5839, violation=0, comm_penalty=0.0000, reward=-1.5839
  Client 9: mean_dist=7.49, base_reward=-2.7822, violation=0, comm_penalty=0.0000, reward=-2.7822
  RL policy loss: -0.157986
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1111
  Client 1 model accuracy on test set: 0.1373
  Client 2 model accuracy on test set: 0.1125
  Client 3 model accuracy on test set: 0.1027
  Client 4 model accuracy on test set: 0.1889
  Client 5 model accuracy on test set: 0.1511
  Client 6 model accuracy on test set: 0.1009
  Client 7 model accuracy on test set: 0.1800
  Client 8 model accuracy on test set: 0.1107
  Client 9 model accuracy on test set: 0.1763

=== Global Round 37/100 ===
  Client 0: layers_shared=4, local_acc=0.8696
  Client 1: layers_shared=3, local_acc=0.9250
  Client 2: layers_shared=4, local_acc=0.8072
  Client 3: layers_shared=1, local_acc=0.9274
  Client 4: layers_shared=3, local_acc=0.9225
  Client 5: layers_shared=1, local_acc=0.9477
  Client 6: layers_shared=1, local_acc=0.8022
  Client 7: layers_shared=1, local_acc=0.9474
  Client 8: layers_shared=5, local_acc=0.9746
  Client 9: layers_shared=3, local_acc=0.9815
  Client 0: mean_dist=7.30, base_reward=-2.7781, violation=1, comm_penalty=1.0000, reward=-3.7781
  Client 1: mean_dist=7.71, base_reward=-2.9293, violation=0, comm_penalty=0.0000, reward=-2.9293
  Client 2: mean_dist=8.77, base_reward=-3.5777, violation=3, comm_penalty=3.0000, reward=-6.5777
  Client 3: mean_dist=3.01, base_reward=-0.5754, violation=0, comm_penalty=0.0000, reward=-0.5754
  Client 4: mean_dist=8.26, base_reward=-3.2080, violation=0, comm_penalty=0.0000, reward=-3.2080
  Client 5: mean_dist=3.49, base_reward=-0.7965, violation=0, comm_penalty=0.0000, reward=-0.7965
  Client 6: mean_dist=2.67, base_reward=-0.5346, violation=0, comm_penalty=0.0000, reward=-0.5346
  Client 7: mean_dist=3.71, base_reward=-0.9064, violation=0, comm_penalty=0.0000, reward=-0.9064
  Client 8: mean_dist=7.50, base_reward=-2.7738, violation=3, comm_penalty=3.0000, reward=-5.7738
  Client 9: mean_dist=8.06, base_reward=-3.0472, violation=0, comm_penalty=0.0000, reward=-3.0472
  RL policy loss: -0.280802
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1031
  Client 1 model accuracy on test set: 0.1394
  Client 2 model accuracy on test set: 0.1367
  Client 3 model accuracy on test set: 0.1038
  Client 4 model accuracy on test set: 0.1378
  Client 5 model accuracy on test set: 0.1599
  Client 6 model accuracy on test set: 0.1006
  Client 7 model accuracy on test set: 0.1933
  Client 8 model accuracy on test set: 0.1526
  Client 9 model accuracy on test set: 0.1186

=== Global Round 38/100 ===
  Client 0: layers_shared=4, local_acc=0.8481
  Client 1: layers_shared=4, local_acc=0.9192
  Client 2: layers_shared=6, local_acc=0.7840
  Client 3: layers_shared=1, local_acc=0.9441
  Client 4: layers_shared=1, local_acc=0.9506
  Client 5: layers_shared=3, local_acc=0.9406
  Client 6: layers_shared=3, local_acc=0.8812
  Client 7: layers_shared=4, local_acc=0.9644
  Client 8: layers_shared=3, local_acc=0.9782
  Client 9: layers_shared=3, local_acc=0.9721
  Client 0: mean_dist=9.56, base_reward=-3.9304, violation=1, comm_penalty=1.0000, reward=-4.9304
  Client 1: mean_dist=11.11, base_reward=-4.6352, violation=0, comm_penalty=0.0000, reward=-4.6352
  Client 2: mean_dist=11.68, base_reward=-5.0581, violation=5, comm_penalty=5.0000, reward=-10.0581
  Client 3: mean_dist=3.03, base_reward=-0.5721, violation=0, comm_penalty=0.0000, reward=-0.5721
  Client 4: mean_dist=3.14, base_reward=-0.6186, violation=0, comm_penalty=0.0000, reward=-0.6186
  Client 5: mean_dist=11.28, base_reward=-4.7007, violation=0, comm_penalty=0.0000, reward=-4.7007
  Client 6: mean_dist=8.23, base_reward=-3.2339, violation=2, comm_penalty=2.0000, reward=-5.2339
  Client 7: mean_dist=13.36, base_reward=-5.7137, violation=0, comm_penalty=0.0000, reward=-5.7137
  Client 8: mean_dist=8.78, base_reward=-3.4117, violation=1, comm_penalty=1.0000, reward=-4.4117
  Client 9: mean_dist=10.27, base_reward=-4.1620, violation=0, comm_penalty=0.0000, reward=-4.1620
  RL policy loss: -0.383893
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1312
  Client 1 model accuracy on test set: 0.1107
  Client 2 model accuracy on test set: 0.1238
  Client 3 model accuracy on test set: 0.1007
  Client 4 model accuracy on test set: 0.1643
  Client 5 model accuracy on test set: 0.2029
  Client 6 model accuracy on test set: 0.1018
  Client 7 model accuracy on test set: 0.2611
  Client 8 model accuracy on test set: 0.1192
  Client 9 model accuracy on test set: 0.1501

=== Global Round 39/100 ===
  Client 0: layers_shared=6, local_acc=0.8354
  Client 1: layers_shared=4, local_acc=0.9154
  Client 2: layers_shared=3, local_acc=0.8427
  Client 3: layers_shared=6, local_acc=0.9484
  Client 4: layers_shared=6, local_acc=0.9525
  Client 5: layers_shared=3, local_acc=0.8765
  Client 6: layers_shared=3, local_acc=0.8435
  Client 7: layers_shared=1, local_acc=0.9703
  Client 8: layers_shared=2, local_acc=0.9764
  Client 9: layers_shared=4, local_acc=0.9737
  Client 0: mean_dist=10.45, base_reward=-4.3904, violation=3, comm_penalty=3.0000, reward=-7.3904
  Client 1: mean_dist=11.89, base_reward=-5.0297, violation=0, comm_penalty=0.0000, reward=-5.0297
  Client 2: mean_dist=10.97, base_reward=-4.6420, violation=2, comm_penalty=2.0000, reward=-6.6420
  Client 3: mean_dist=11.46, base_reward=-4.7816, violation=4, comm_penalty=4.0000, reward=-8.7816
  Client 4: mean_dist=13.13, base_reward=-5.6105, violation=2, comm_penalty=2.0000, reward=-7.6105
  Client 5: mean_dist=11.96, base_reward=-5.1038, violation=0, comm_penalty=0.0000, reward=-5.1038
  Client 6: mean_dist=8.63, base_reward=-3.4692, violation=2, comm_penalty=2.0000, reward=-5.4692
  Client 7: mean_dist=3.75, base_reward=-0.9054, violation=0, comm_penalty=0.0000, reward=-0.9054
  Client 8: mean_dist=6.83, base_reward=-2.4367, violation=0, comm_penalty=0.0000, reward=-2.4367
  Client 9: mean_dist=12.34, base_reward=-5.1946, violation=0, comm_penalty=0.0000, reward=-5.1946
  RL policy loss: -0.177296
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1065
  Client 1 model accuracy on test set: 0.1677
  Client 2 model accuracy on test set: 0.1497
  Client 3 model accuracy on test set: 0.1186
  Client 4 model accuracy on test set: 0.1648
  Client 5 model accuracy on test set: 0.2000
  Client 6 model accuracy on test set: 0.1321
  Client 7 model accuracy on test set: 0.2084
  Client 8 model accuracy on test set: 0.1501
  Client 9 model accuracy on test set: 0.1597

=== Global Round 40/100 ===
  Client 0: layers_shared=4, local_acc=0.8728
  Client 1: layers_shared=1, local_acc=0.9225
  Client 2: layers_shared=1, local_acc=0.7482
  Client 3: layers_shared=3, local_acc=0.9482
  Client 4: layers_shared=4, local_acc=0.9408
  Client 5: layers_shared=1, local_acc=0.9646
  Client 6: layers_shared=5, local_acc=0.8337
  Client 7: layers_shared=4, local_acc=0.9363
  Client 8: layers_shared=3, local_acc=0.9640
  Client 9: layers_shared=1, local_acc=0.9767
  Client 0: mean_dist=7.67, base_reward=-2.9609, violation=1, comm_penalty=1.0000, reward=-3.9609
  Client 1: mean_dist=3.06, base_reward=-0.6082, violation=0, comm_penalty=0.0000, reward=-0.6082
  Client 2: mean_dist=3.18, base_reward=-0.8410, violation=0, comm_penalty=0.0000, reward=-0.8410
  Client 3: mean_dist=7.40, base_reward=-2.7524, violation=1, comm_penalty=1.0000, reward=-3.7524
  Client 4: mean_dist=9.45, base_reward=-3.7855, violation=0, comm_penalty=0.0000, reward=-3.7855
  Client 5: mean_dist=3.57, base_reward=-0.8222, violation=0, comm_penalty=0.0000, reward=-0.8222
  Client 6: mean_dist=7.48, base_reward=-2.9050, violation=4, comm_penalty=4.0000, reward=-6.9050
  Client 7: mean_dist=10.77, base_reward=-4.4487, violation=0, comm_penalty=0.0000, reward=-4.4487
  Client 8: mean_dist=6.96, base_reward=-2.5176, violation=1, comm_penalty=1.0000, reward=-3.5176
  Client 9: mean_dist=3.17, base_reward=-0.6098, violation=0, comm_penalty=0.0000, reward=-0.6098
  RL policy loss: -0.412307
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1017
  Client 1 model accuracy on test set: 0.1431
  Client 2 model accuracy on test set: 0.1350
  Client 3 model accuracy on test set: 0.1017
  Client 4 model accuracy on test set: 0.1770
  Client 5 model accuracy on test set: 0.2595
  Client 6 model accuracy on test set: 0.1432
  Client 7 model accuracy on test set: 0.1550
  Client 8 model accuracy on test set: 0.1315
  Client 9 model accuracy on test set: 0.1339

=== Global Round 41/100 ===
  Client 0: layers_shared=1, local_acc=0.8791
  Client 1: layers_shared=5, local_acc=0.8934
  Client 2: layers_shared=4, local_acc=0.8028
  Client 3: layers_shared=4, local_acc=0.9629
  Client 4: layers_shared=5, local_acc=0.9556
  Client 5: layers_shared=3, local_acc=0.9085
  Client 6: layers_shared=3, local_acc=0.8805
  Client 7: layers_shared=5, local_acc=0.9759
  Client 8: layers_shared=1, local_acc=0.9734
  Client 9: layers_shared=5, local_acc=0.9776
  Client 0: mean_dist=2.91, base_reward=-0.5762, violation=0, comm_penalty=0.0000, reward=-0.5762
  Client 1: mean_dist=13.70, base_reward=-5.9559, violation=0, comm_penalty=0.0000, reward=-5.9559
  Client 2: mean_dist=13.44, base_reward=-5.9170, violation=3, comm_penalty=3.0000, reward=-8.9170
  Client 3: mean_dist=11.90, base_reward=-4.9868, violation=2, comm_penalty=2.0000, reward=-6.9868
  Client 4: mean_dist=14.29, base_reward=-6.1902, violation=1, comm_penalty=1.0000, reward=-7.1902
  Client 5: mean_dist=11.98, base_reward=-5.0827, violation=0, comm_penalty=0.0000, reward=-5.0827
  Client 6: mean_dist=8.96, base_reward=-3.5976, violation=2, comm_penalty=2.0000, reward=-5.5976
  Client 7: mean_dist=16.12, base_reward=-7.0839, violation=0, comm_penalty=0.0000, reward=-7.0839
  Client 8: mean_dist=2.90, base_reward=-0.4748, violation=0, comm_penalty=0.0000, reward=-0.4748
  Client 9: mean_dist=13.98, base_reward=-6.0146, violation=0, comm_penalty=0.0000, reward=-6.0146
  RL policy loss: -0.434736
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1001
  Client 1 model accuracy on test set: 0.1337
  Client 2 model accuracy on test set: 0.1185
  Client 3 model accuracy on test set: 0.1002
  Client 4 model accuracy on test set: 0.1428
  Client 5 model accuracy on test set: 0.1722
  Client 6 model accuracy on test set: 0.1401
  Client 7 model accuracy on test set: 0.2714
  Client 8 model accuracy on test set: 0.1797
  Client 9 model accuracy on test set: 0.1515

=== Global Round 42/100 ===
  Client 0: layers_shared=4, local_acc=0.8835
  Client 1: layers_shared=3, local_acc=0.9382
  Client 2: layers_shared=2, local_acc=0.8738
  Client 3: layers_shared=6, local_acc=0.9540
  Client 4: layers_shared=4, local_acc=0.9321
  Client 5: layers_shared=3, local_acc=0.9317
  Client 6: layers_shared=5, local_acc=0.8267
  Client 7: layers_shared=1, local_acc=0.9720
  Client 8: layers_shared=3, local_acc=0.9754
  Client 9: layers_shared=1, local_acc=0.9877
  Client 0: mean_dist=8.93, base_reward=-3.5836, violation=1, comm_penalty=1.0000, reward=-4.5836
  Client 1: mean_dist=9.52, base_reward=-3.8196, violation=0, comm_penalty=0.0000, reward=-3.8196
  Client 2: mean_dist=7.47, base_reward=-2.8596, violation=1, comm_penalty=1.0000, reward=-3.8596
  Client 3: mean_dist=10.01, base_reward=-4.0535, violation=4, comm_penalty=4.0000, reward=-8.0535
  Client 4: mean_dist=11.31, base_reward=-4.7208, violation=0, comm_penalty=0.0000, reward=-4.7208
  Client 5: mean_dist=10.99, base_reward=-4.5623, violation=0, comm_penalty=0.0000, reward=-4.5623
  Client 6: mean_dist=8.87, base_reward=-3.6104, violation=4, comm_penalty=4.0000, reward=-7.6104
  Client 7: mean_dist=3.82, base_reward=-0.9399, violation=0, comm_penalty=0.0000, reward=-0.9399
  Client 8: mean_dist=8.49, base_reward=-3.2701, violation=1, comm_penalty=1.0000, reward=-4.2701
  Client 9: mean_dist=3.23, base_reward=-0.6256, violation=0, comm_penalty=0.0000, reward=-0.6256
  RL policy loss: -0.457210
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.0993
  Client 1 model accuracy on test set: 0.1598
  Client 2 model accuracy on test set: 0.1544
  Client 3 model accuracy on test set: 0.1011
  Client 4 model accuracy on test set: 0.1526
  Client 5 model accuracy on test set: 0.1791
  Client 6 model accuracy on test set: 0.1630
  Client 7 model accuracy on test set: 0.2291
  Client 8 model accuracy on test set: 0.1386
  Client 9 model accuracy on test set: 0.1504

=== Global Round 43/100 ===
  Client 0: layers_shared=6, local_acc=0.8253
  Client 1: layers_shared=1, local_acc=0.9504
  Client 2: layers_shared=1, local_acc=0.8043
  Client 3: layers_shared=1, local_acc=0.9540
  Client 4: layers_shared=3, local_acc=0.9454
  Client 5: layers_shared=3, local_acc=0.9412
  Client 6: layers_shared=5, local_acc=0.8826
  Client 7: layers_shared=3, local_acc=0.9783
  Client 8: layers_shared=2, local_acc=0.9766
  Client 9: layers_shared=3, local_acc=0.9783
  Client 0: mean_dist=8.23, base_reward=-3.2899, violation=3, comm_penalty=3.0000, reward=-6.2899
  Client 1: mean_dist=3.14, base_reward=-0.6186, violation=0, comm_penalty=0.0000, reward=-0.6186
  Client 2: mean_dist=3.28, base_reward=-0.8351, violation=0, comm_penalty=0.0000, reward=-0.8351
  Client 3: mean_dist=3.18, base_reward=-0.6338, violation=0, comm_penalty=0.0000, reward=-0.6338
  Client 4: mean_dist=9.68, base_reward=-3.8951, violation=0, comm_penalty=0.0000, reward=-3.8951
  Client 5: mean_dist=10.24, base_reward=-4.1767, violation=0, comm_penalty=0.0000, reward=-4.1767
  Client 6: mean_dist=8.03, base_reward=-3.1344, violation=4, comm_penalty=4.0000, reward=-7.1344
  Client 7: mean_dist=10.72, base_reward=-4.3839, violation=0, comm_penalty=0.0000, reward=-4.3839
  Client 8: mean_dist=6.20, base_reward=-2.1217, violation=0, comm_penalty=0.0000, reward=-2.1217
  Client 9: mean_dist=9.32, base_reward=-3.6797, violation=0, comm_penalty=0.0000, reward=-3.6797
  RL policy loss: -0.274813
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.0810
  Client 1 model accuracy on test set: 0.1661
  Client 2 model accuracy on test set: 0.1241
  Client 3 model accuracy on test set: 0.1376
  Client 4 model accuracy on test set: 0.1409
  Client 5 model accuracy on test set: 0.1956
  Client 6 model accuracy on test set: 0.1573
  Client 7 model accuracy on test set: 0.1661
  Client 8 model accuracy on test set: 0.1711
  Client 9 model accuracy on test set: 0.1546

=== Global Round 44/100 ===
  Client 0: layers_shared=3, local_acc=0.8443
  Client 1: layers_shared=1, local_acc=0.9225
  Client 2: layers_shared=4, local_acc=0.8500
  Client 3: layers_shared=5, local_acc=0.9569
  Client 4: layers_shared=6, local_acc=0.9404
  Client 5: layers_shared=3, local_acc=0.9536
  Client 6: layers_shared=3, local_acc=0.8959
  Client 7: layers_shared=1, local_acc=0.9767
  Client 8: layers_shared=4, local_acc=0.9858
  Client 9: layers_shared=3, local_acc=0.9686
  Client 0: mean_dist=8.79, base_reward=-3.5529, violation=0, comm_penalty=0.0000, reward=-3.5529
  Client 1: mean_dist=3.16, base_reward=-0.6561, violation=0, comm_penalty=0.0000, reward=-0.6561
  Client 2: mean_dist=12.25, base_reward=-5.2741, violation=3, comm_penalty=3.0000, reward=-8.2741
  Client 3: mean_dist=10.94, base_reward=-4.5109, violation=3, comm_penalty=3.0000, reward=-7.5109
  Client 4: mean_dist=12.50, base_reward=-5.3106, violation=2, comm_penalty=2.0000, reward=-7.3106
  Client 5: mean_dist=11.76, base_reward=-4.9286, violation=0, comm_penalty=0.0000, reward=-4.9286
  Client 6: mean_dist=8.55, base_reward=-3.3771, violation=2, comm_penalty=2.0000, reward=-5.3771
  Client 7: mean_dist=3.87, base_reward=-0.9570, violation=0, comm_penalty=0.0000, reward=-0.9570
  Client 8: mean_dist=10.12, base_reward=-4.0718, violation=2, comm_penalty=2.0000, reward=-6.0718
  Client 9: mean_dist=10.65, base_reward=-4.3570, violation=0, comm_penalty=0.0000, reward=-4.3570
  RL policy loss: -0.648146
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1225
  Client 1 model accuracy on test set: 0.1503
  Client 2 model accuracy on test set: 0.1449
  Client 3 model accuracy on test set: 0.1421
  Client 4 model accuracy on test set: 0.1931
  Client 5 model accuracy on test set: 0.1659
  Client 6 model accuracy on test set: 0.1140
  Client 7 model accuracy on test set: 0.2648
  Client 8 model accuracy on test set: 0.1726
  Client 9 model accuracy on test set: 0.2001

=== Global Round 45/100 ===
  Client 0: layers_shared=2, local_acc=0.8968
  Client 1: layers_shared=1, local_acc=0.9331
  Client 2: layers_shared=1, local_acc=0.8568
  Client 3: layers_shared=4, local_acc=0.9573
  Client 4: layers_shared=5, local_acc=0.9642
  Client 5: layers_shared=1, local_acc=0.9666
  Client 6: layers_shared=3, local_acc=0.8903
  Client 7: layers_shared=6, local_acc=0.9828
  Client 8: layers_shared=4, local_acc=0.9772
  Client 9: layers_shared=4, local_acc=0.9707
  Client 0: mean_dist=5.93, base_reward=-2.0693, violation=0, comm_penalty=0.0000, reward=-2.0693
  Client 1: mean_dist=3.18, base_reward=-0.6558, violation=0, comm_penalty=0.0000, reward=-0.6558
  Client 2: mean_dist=3.35, base_reward=-0.8170, violation=0, comm_penalty=0.0000, reward=-0.8170
  Client 3: mean_dist=9.95, base_reward=-4.0156, violation=2, comm_penalty=2.0000, reward=-6.0156
  Client 4: mean_dist=11.61, base_reward=-4.8433, violation=1, comm_penalty=1.0000, reward=-5.8433
  Client 5: mean_dist=3.68, base_reward=-0.8745, violation=0, comm_penalty=0.0000, reward=-0.8745
  Client 6: mean_dist=7.52, base_reward=-2.8683, violation=2, comm_penalty=2.0000, reward=-4.8683
  Client 7: mean_dist=12.95, base_reward=-5.4934, violation=0, comm_penalty=0.0000, reward=-5.4934
  Client 8: mean_dist=9.39, base_reward=-3.7166, violation=2, comm_penalty=2.0000, reward=-5.7166
  Client 9: mean_dist=10.91, base_reward=-4.4856, violation=0, comm_penalty=0.0000, reward=-4.4856
  RL policy loss: -0.561330
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1012
  Client 1 model accuracy on test set: 0.1545
  Client 2 model accuracy on test set: 0.1089
  Client 3 model accuracy on test set: 0.1291
  Client 4 model accuracy on test set: 0.1803
  Client 5 model accuracy on test set: 0.1921
  Client 6 model accuracy on test set: 0.1757
  Client 7 model accuracy on test set: 0.2213
  Client 8 model accuracy on test set: 0.1026
  Client 9 model accuracy on test set: 0.1203

=== Global Round 46/100 ===
  Client 0: layers_shared=3, local_acc=0.8259
  Client 1: layers_shared=5, local_acc=0.9392
  Client 2: layers_shared=3, local_acc=0.9090
  Client 3: layers_shared=1, local_acc=0.9600
  Client 4: layers_shared=4, local_acc=0.9711
  Client 5: layers_shared=6, local_acc=0.9403
  Client 6: layers_shared=6, local_acc=0.8784
  Client 7: layers_shared=5, local_acc=0.9819
  Client 8: layers_shared=1, local_acc=0.9756
  Client 9: layers_shared=1, local_acc=0.9667
  Client 0: mean_dist=8.58, base_reward=-3.4628, violation=0, comm_penalty=0.0000, reward=-3.4628
  Client 1: mean_dist=12.69, base_reward=-5.4054, violation=0, comm_penalty=0.0000, reward=-5.4054
  Client 2: mean_dist=10.49, base_reward=-4.3346, violation=2, comm_penalty=2.0000, reward=-6.3346
  Client 3: mean_dist=3.24, base_reward=-0.6610, violation=0, comm_penalty=0.0000, reward=-0.6610
  Client 4: mean_dist=12.39, base_reward=-5.2236, violation=0, comm_penalty=0.0000, reward=-5.2236
  Client 5: mean_dist=14.21, base_reward=-6.1661, violation=0, comm_penalty=0.0000, reward=-6.1661
  Client 6: mean_dist=10.87, base_reward=-4.5583, violation=5, comm_penalty=5.0000, reward=-9.5583
  Client 7: mean_dist=14.84, base_reward=-6.4399, violation=0, comm_penalty=0.0000, reward=-6.4399
  Client 8: mean_dist=3.00, base_reward=-0.5242, violation=0, comm_penalty=0.0000, reward=-0.5242
  Client 9: mean_dist=3.31, base_reward=-0.6865, violation=0, comm_penalty=0.0000, reward=-0.6865
  RL policy loss: -0.737014
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1164
  Client 1 model accuracy on test set: 0.1380
  Client 2 model accuracy on test set: 0.1478
  Client 3 model accuracy on test set: 0.1030
  Client 4 model accuracy on test set: 0.1592
  Client 5 model accuracy on test set: 0.2079
  Client 6 model accuracy on test set: 0.1444
  Client 7 model accuracy on test set: 0.2199
  Client 8 model accuracy on test set: 0.1097
  Client 9 model accuracy on test set: 0.1140

=== Global Round 47/100 ===
  Client 0: layers_shared=3, local_acc=0.9272
  Client 1: layers_shared=2, local_acc=0.9043
  Client 2: layers_shared=6, local_acc=0.8330
  Client 3: layers_shared=2, local_acc=0.9709
  Client 4: layers_shared=5, local_acc=0.9735
  Client 5: layers_shared=1, local_acc=0.9697
  Client 6: layers_shared=4, local_acc=0.8707
  Client 7: layers_shared=3, local_acc=0.9832
  Client 8: layers_shared=3, local_acc=0.9725
  Client 9: layers_shared=1, local_acc=0.9877
  Client 0: mean_dist=8.39, base_reward=-3.2654, violation=0, comm_penalty=0.0000, reward=-3.2654
  Client 1: mean_dist=7.42, base_reward=-2.8041, violation=0, comm_penalty=0.0000, reward=-2.8041
  Client 2: mean_dist=11.62, base_reward=-4.9769, violation=5, comm_penalty=5.0000, reward=-9.9769
  Client 3: mean_dist=7.24, base_reward=-2.6481, violation=0, comm_penalty=0.0000, reward=-2.6481
  Client 4: mean_dist=11.66, base_reward=-4.8565, violation=1, comm_penalty=1.0000, reward=-5.8565
  Client 5: mean_dist=3.75, base_reward=-0.9036, violation=0, comm_penalty=0.0000, reward=-0.9036
  Client 6: mean_dist=8.91, base_reward=-3.5839, violation=3, comm_penalty=3.0000, reward=-6.5839
  Client 7: mean_dist=11.65, base_reward=-4.8394, violation=0, comm_penalty=0.0000, reward=-4.8394
  Client 8: mean_dist=8.71, base_reward=-3.3843, violation=1, comm_penalty=1.0000, reward=-4.3843
  Client 9: mean_dist=3.33, base_reward=-0.6764, violation=0, comm_penalty=0.0000, reward=-0.6764
  RL policy loss: -0.501250
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1056
  Client 1 model accuracy on test set: 0.1589
  Client 2 model accuracy on test set: 0.1386
  Client 3 model accuracy on test set: 0.1062
  Client 4 model accuracy on test set: 0.1638
  Client 5 model accuracy on test set: 0.1603
  Client 6 model accuracy on test set: 0.1449
  Client 7 model accuracy on test set: 0.2433
  Client 8 model accuracy on test set: 0.1694
  Client 9 model accuracy on test set: 0.1920

=== Global Round 48/100 ===
  Client 0: layers_shared=1, local_acc=0.7886
  Client 1: layers_shared=1, local_acc=0.9521
  Client 2: layers_shared=1, local_acc=0.8901
  Client 3: layers_shared=3, local_acc=0.9656
  Client 4: layers_shared=6, local_acc=0.9620
  Client 5: layers_shared=2, local_acc=0.9627
  Client 6: layers_shared=2, local_acc=0.8679
  Client 7: layers_shared=4, local_acc=0.9691
  Client 8: layers_shared=6, local_acc=0.9880
  Client 9: layers_shared=6, local_acc=0.9792
  Client 0: mean_dist=3.06, base_reward=-0.7403, violation=0, comm_penalty=0.0000, reward=-0.7403
  Client 1: mean_dist=3.25, base_reward=-0.6728, violation=0, comm_penalty=0.0000, reward=-0.6728
  Client 2: mean_dist=3.44, base_reward=-0.8294, violation=0, comm_penalty=0.0000, reward=-0.8294
  Client 3: mean_dist=8.67, base_reward=-3.3700, violation=1, comm_penalty=1.0000, reward=-4.3700
  Client 4: mean_dist=11.58, base_reward=-4.8303, violation=2, comm_penalty=2.0000, reward=-6.8303
  Client 5: mean_dist=8.10, base_reward=-3.0896, violation=0, comm_penalty=0.0000, reward=-3.0896
  Client 6: mean_dist=6.15, base_reward=-2.2053, violation=1, comm_penalty=1.0000, reward=-3.2053
  Client 7: mean_dist=12.17, base_reward=-5.1171, violation=0, comm_penalty=0.0000, reward=-5.1171
  Client 8: mean_dist=9.87, base_reward=-3.9487, violation=4, comm_penalty=4.0000, reward=-7.9487
  Client 9: mean_dist=11.20, base_reward=-4.6189, violation=1, comm_penalty=1.0000, reward=-5.6189
  RL policy loss: -0.724373
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.0960
  Client 1 model accuracy on test set: 0.1137
  Client 2 model accuracy on test set: 0.1507
  Client 3 model accuracy on test set: 0.1051
  Client 4 model accuracy on test set: 0.1872
  Client 5 model accuracy on test set: 0.1982
  Client 6 model accuracy on test set: 0.1659
  Client 7 model accuracy on test set: 0.1959
  Client 8 model accuracy on test set: 0.1726
  Client 9 model accuracy on test set: 0.1560

=== Global Round 49/100 ===
  Client 0: layers_shared=3, local_acc=0.9025
  Client 1: layers_shared=1, local_acc=0.9450
  Client 2: layers_shared=1, local_acc=0.8463
  Client 3: layers_shared=5, local_acc=0.9698
  Client 4: layers_shared=4, local_acc=0.9620
  Client 5: layers_shared=1, local_acc=0.9544
  Client 6: layers_shared=1, local_acc=0.9343
  Client 7: layers_shared=6, local_acc=0.9436
  Client 8: layers_shared=6, local_acc=0.9911
  Client 9: layers_shared=3, local_acc=0.9827
  Client 0: mean_dist=7.65, base_reward=-2.9241, violation=0, comm_penalty=0.0000, reward=-2.9241
  Client 1: mean_dist=3.27, base_reward=-0.6893, violation=0, comm_penalty=0.0000, reward=-0.6893
  Client 2: mean_dist=3.46, base_reward=-0.8858, violation=0, comm_penalty=0.0000, reward=-0.8858
  Client 3: mean_dist=9.99, base_reward=-4.0257, violation=3, comm_penalty=3.0000, reward=-7.0257
  Client 4: mean_dist=10.67, base_reward=-4.3728, violation=0, comm_penalty=0.0000, reward=-4.3728
  Client 5: mean_dist=3.79, base_reward=-0.9393, violation=0, comm_penalty=0.0000, reward=-0.9393
  Client 6: mean_dist=2.95, base_reward=-0.5413, violation=0, comm_penalty=0.0000, reward=-0.5413
  Client 7: mean_dist=12.50, base_reward=-5.3053, violation=0, comm_penalty=0.0000, reward=-5.3053
  Client 8: mean_dist=9.50, base_reward=-3.7610, violation=4, comm_penalty=4.0000, reward=-7.7610
  Client 9: mean_dist=8.96, base_reward=-3.4959, violation=0, comm_penalty=0.0000, reward=-3.4959
  RL policy loss: -0.868395
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1014
  Client 1 model accuracy on test set: 0.1354
  Client 2 model accuracy on test set: 0.1197
  Client 3 model accuracy on test set: 0.1238
  Client 4 model accuracy on test set: 0.1876
  Client 5 model accuracy on test set: 0.1965
  Client 6 model accuracy on test set: 0.1090
  Client 7 model accuracy on test set: 0.2517
  Client 8 model accuracy on test set: 0.1525
  Client 9 model accuracy on test set: 0.1612

=== Global Round 50/100 ===
  Client 0: layers_shared=1, local_acc=0.8671
  Client 1: layers_shared=6, local_acc=0.9635
  Client 2: layers_shared=2, local_acc=0.8299
  Client 3: layers_shared=1, local_acc=0.9721
  Client 4: layers_shared=3, local_acc=0.9533
  Client 5: layers_shared=4, local_acc=0.9790
  Client 6: layers_shared=1, local_acc=0.9294
  Client 7: layers_shared=6, local_acc=0.9758
  Client 8: layers_shared=1, local_acc=0.9927
  Client 9: layers_shared=1, local_acc=0.9912
  Client 0: mean_dist=3.09, base_reward=-0.6799, violation=0, comm_penalty=0.0000, reward=-0.6799
  Client 1: mean_dist=9.35, base_reward=-3.7090, violation=1, comm_penalty=1.0000, reward=-4.7090
  Client 2: mean_dist=6.56, base_reward=-2.4503, violation=1, comm_penalty=1.0000, reward=-3.4503
  Client 3: mean_dist=3.33, base_reward=-0.6943, violation=0, comm_penalty=0.0000, reward=-0.6943
  Client 4: mean_dist=8.33, base_reward=-3.2115, violation=0, comm_penalty=0.0000, reward=-3.2115
  Client 5: mean_dist=9.86, base_reward=-3.9527, violation=0, comm_penalty=0.0000, reward=-3.9527
  Client 6: mean_dist=2.98, base_reward=-0.5581, violation=0, comm_penalty=0.0000, reward=-0.5581
  Client 7: mean_dist=10.71, base_reward=-4.3781, violation=0, comm_penalty=0.0000, reward=-4.3781
  Client 8: mean_dist=3.08, base_reward=-0.5463, violation=0, comm_penalty=0.0000, reward=-0.5463
  Client 9: mean_dist=3.38, base_reward=-0.6995, violation=0, comm_penalty=0.0000, reward=-0.6995
  RL policy loss: -0.656668
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.0994
  Client 1 model accuracy on test set: 0.1053
  Client 2 model accuracy on test set: 0.1208
  Client 3 model accuracy on test set: 0.1025
  Client 4 model accuracy on test set: 0.1872
  Client 5 model accuracy on test set: 0.2008
  Client 6 model accuracy on test set: 0.1422
  Client 7 model accuracy on test set: 0.2009
  Client 8 model accuracy on test set: 0.2073
  Client 9 model accuracy on test set: 0.1393

=== Global Round 51/100 ===
  Client 0: layers_shared=3, local_acc=0.9203
  Client 1: layers_shared=5, local_acc=0.9643
  Client 2: layers_shared=1, local_acc=0.8974
  Client 3: layers_shared=6, local_acc=0.9709
  Client 4: layers_shared=1, local_acc=0.9707
  Client 5: layers_shared=5, local_acc=0.9750
  Client 6: layers_shared=3, local_acc=0.9329
  Client 7: layers_shared=1, local_acc=0.9680
  Client 8: layers_shared=2, local_acc=0.9896
  Client 9: layers_shared=6, local_acc=0.9889
  Client 0: mean_dist=7.90, base_reward=-3.0306, violation=0, comm_penalty=0.0000, reward=-3.0306
  Client 1: mean_dist=11.53, base_reward=-4.7987, violation=0, comm_penalty=0.0000, reward=-4.7987
  Client 2: mean_dist=3.51, base_reward=-0.8588, violation=0, comm_penalty=0.0000, reward=-0.8588
  Client 3: mean_dist=10.88, base_reward=-4.4674, violation=4, comm_penalty=4.0000, reward=-8.4674
  Client 4: mean_dist=3.50, base_reward=-0.7793, violation=0, comm_penalty=0.0000, reward=-0.7793
  Client 5: mean_dist=12.95, base_reward=-5.5022, violation=0, comm_penalty=0.0000, reward=-5.5022
  Client 6: mean_dist=7.67, base_reward=-2.9019, violation=2, comm_penalty=2.0000, reward=-4.9019
  Client 7: mean_dist=4.00, base_reward=-1.0313, violation=0, comm_penalty=0.0000, reward=-1.0313
  Client 8: mean_dist=6.29, base_reward=-2.1574, violation=0, comm_penalty=0.0000, reward=-2.1574
  Client 9: mean_dist=11.77, base_reward=-4.8939, violation=1, comm_penalty=1.0000, reward=-5.8939
  RL policy loss: -0.716489
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1024
  Client 1 model accuracy on test set: 0.1158
  Client 2 model accuracy on test set: 0.1439
  Client 3 model accuracy on test set: 0.1289
  Client 4 model accuracy on test set: 0.2155
  Client 5 model accuracy on test set: 0.2046
  Client 6 model accuracy on test set: 0.1030
  Client 7 model accuracy on test set: 0.2118
  Client 8 model accuracy on test set: 0.1420
  Client 9 model accuracy on test set: 0.1660

=== Global Round 52/100 ===
  Client 0: layers_shared=5, local_acc=0.9310
  Client 1: layers_shared=1, local_acc=0.9301
  Client 2: layers_shared=3, local_acc=0.8858
  Client 3: layers_shared=1, local_acc=0.9779
  Client 4: layers_shared=3, local_acc=0.9594
  Client 5: layers_shared=3, local_acc=0.9470
  Client 6: layers_shared=1, local_acc=0.9525
  Client 7: layers_shared=1, local_acc=0.9809
  Client 8: layers_shared=1, local_acc=0.9847
  Client 9: layers_shared=2, local_acc=0.9876
  Client 0: mean_dist=6.87, base_reward=-2.5028, violation=2, comm_penalty=2.0000, reward=-4.5028
  Client 1: mean_dist=3.33, base_reward=-0.7325, violation=0, comm_penalty=0.0000, reward=-0.7325
  Client 2: mean_dist=8.09, base_reward=-3.1584, violation=2, comm_penalty=2.0000, reward=-5.1584
  Client 3: mean_dist=3.38, base_reward=-0.7100, violation=0, comm_penalty=0.0000, reward=-0.7100
  Client 4: mean_dist=8.12, base_reward=-3.1025, violation=0, comm_penalty=0.0000, reward=-3.1025
  Client 5: mean_dist=8.50, base_reward=-3.3023, violation=0, comm_penalty=0.0000, reward=-3.3023
  Client 6: mean_dist=3.01, base_reward=-0.5531, violation=0, comm_penalty=0.0000, reward=-0.5531
  Client 7: mean_dist=4.02, base_reward=-1.0311, violation=0, comm_penalty=0.0000, reward=-1.0311
  Client 8: mean_dist=3.11, base_reward=-0.5710, violation=0, comm_penalty=0.0000, reward=-0.5710
  Client 9: mean_dist=6.23, base_reward=-2.1267, violation=0, comm_penalty=0.0000, reward=-2.1267
  RL policy loss: -0.281155
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1119
  Client 1 model accuracy on test set: 0.1439
  Client 2 model accuracy on test set: 0.1390
  Client 3 model accuracy on test set: 0.1140
  Client 4 model accuracy on test set: 0.1740
  Client 5 model accuracy on test set: 0.2158
  Client 6 model accuracy on test set: 0.1395
  Client 7 model accuracy on test set: 0.2774
  Client 8 model accuracy on test set: 0.1799
  Client 9 model accuracy on test set: 0.1730

=== Global Round 53/100 ===
  Client 0: layers_shared=3, local_acc=0.9184
  Client 1: layers_shared=6, local_acc=0.9397
  Client 2: layers_shared=2, local_acc=0.7540
  Client 3: layers_shared=1, local_acc=0.9763
  Client 4: layers_shared=1, local_acc=0.9775
  Client 5: layers_shared=1, local_acc=0.8519
  Client 6: layers_shared=3, local_acc=0.9357
  Client 7: layers_shared=4, local_acc=0.9846
  Client 8: layers_shared=1, local_acc=0.9906
  Client 9: layers_shared=5, local_acc=0.9927
  Client 0: mean_dist=7.40, base_reward=-2.7815, violation=0, comm_penalty=0.0000, reward=-2.7815
  Client 1: mean_dist=9.79, base_reward=-3.9558, violation=1, comm_penalty=1.0000, reward=-4.9558
  Client 2: mean_dist=7.00, base_reward=-2.7443, violation=1, comm_penalty=1.0000, reward=-3.7443
  Client 3: mean_dist=3.40, base_reward=-0.7234, violation=0, comm_penalty=0.0000, reward=-0.7234
  Client 4: mean_dist=3.54, base_reward=-0.7904, violation=0, comm_penalty=0.0000, reward=-0.7904
  Client 5: mean_dist=3.86, base_reward=-1.0766, violation=0, comm_penalty=0.0000, reward=-1.0766
  Client 6: mean_dist=7.19, base_reward=-2.6610, violation=2, comm_penalty=2.0000, reward=-4.6610
  Client 7: mean_dist=11.08, base_reward=-4.5542, violation=0, comm_penalty=0.0000, reward=-4.5542
  Client 8: mean_dist=3.13, base_reward=-0.5761, violation=0, comm_penalty=0.0000, reward=-0.5761
  Client 9: mean_dist=10.02, base_reward=-4.0166, violation=0, comm_penalty=0.0000, reward=-4.0166
  RL policy loss: -0.629397
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.0985
  Client 1 model accuracy on test set: 0.1495
  Client 2 model accuracy on test set: 0.1495
  Client 3 model accuracy on test set: 0.1255
  Client 4 model accuracy on test set: 0.1622
  Client 5 model accuracy on test set: 0.1812
  Client 6 model accuracy on test set: 0.1451
  Client 7 model accuracy on test set: 0.2192
  Client 8 model accuracy on test set: 0.1679
  Client 9 model accuracy on test set: 0.1518

=== Global Round 54/100 ===
  Client 0: layers_shared=3, local_acc=0.9323
  Client 1: layers_shared=3, local_acc=0.9542
  Client 2: layers_shared=1, local_acc=0.8829
  Client 3: layers_shared=5, local_acc=0.9620
  Client 4: layers_shared=6, local_acc=0.9113
  Client 5: layers_shared=1, local_acc=0.9828
  Client 6: layers_shared=4, local_acc=0.9294
  Client 7: layers_shared=1, local_acc=0.9830
  Client 8: layers_shared=6, local_acc=0.9878
  Client 9: layers_shared=2, local_acc=0.9827
  Client 0: mean_dist=7.92, base_reward=-3.0294, violation=0, comm_penalty=0.0000, reward=-3.0294
  Client 1: mean_dist=9.13, base_reward=-3.6086, violation=0, comm_penalty=0.0000, reward=-3.6086
  Client 2: mean_dist=3.60, base_reward=-0.9148, violation=0, comm_penalty=0.0000, reward=-0.9148
  Client 3: mean_dist=10.16, base_reward=-4.1174, violation=3, comm_penalty=3.0000, reward=-7.1174
  Client 4: mean_dist=11.66, base_reward=-4.9188, violation=2, comm_penalty=2.0000, reward=-6.9188
  Client 5: mean_dist=3.88, base_reward=-0.9558, violation=0, comm_penalty=0.0000, reward=-0.9558
  Client 6: mean_dist=8.61, base_reward=-3.3762, violation=3, comm_penalty=3.0000, reward=-6.3762
  Client 7: mean_dist=4.04, base_reward=-1.0395, violation=0, comm_penalty=0.0000, reward=-1.0395
  Client 8: mean_dist=9.54, base_reward=-3.7823, violation=4, comm_penalty=4.0000, reward=-7.7823
  Client 9: mean_dist=7.29, base_reward=-2.6618, violation=0, comm_penalty=0.0000, reward=-2.6618
  RL policy loss: -0.993927
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1001
  Client 1 model accuracy on test set: 0.1579
  Client 2 model accuracy on test set: 0.1437
  Client 3 model accuracy on test set: 0.1323
  Client 4 model accuracy on test set: 0.1858
  Client 5 model accuracy on test set: 0.2030
  Client 6 model accuracy on test set: 0.1531
  Client 7 model accuracy on test set: 0.2596
  Client 8 model accuracy on test set: 0.1361
  Client 9 model accuracy on test set: 0.1404

=== Global Round 55/100 ===
  Client 0: layers_shared=1, local_acc=0.9196
  Client 1: layers_shared=1, local_acc=0.9564
  Client 2: layers_shared=5, local_acc=0.8409
  Client 3: layers_shared=1, local_acc=0.9258
  Client 4: layers_shared=5, local_acc=0.9704
  Client 5: layers_shared=1, local_acc=0.9711
  Client 6: layers_shared=1, local_acc=0.8938
  Client 7: layers_shared=1, local_acc=0.9867
  Client 8: layers_shared=1, local_acc=0.9825
  Client 9: layers_shared=1, local_acc=0.9857
  Client 0: mean_dist=3.19, base_reward=-0.6778, violation=0, comm_penalty=0.0000, reward=-0.6778
  Client 1: mean_dist=3.39, base_reward=-0.7390, violation=0, comm_penalty=0.0000, reward=-0.7390
  Client 2: mean_dist=5.92, base_reward=-2.1190, violation=4, comm_penalty=4.0000, reward=-6.1190
  Client 3: mean_dist=3.43, base_reward=-0.7885, violation=0, comm_penalty=0.0000, reward=-0.7885
  Client 4: mean_dist=5.87, base_reward=-1.9669, violation=1, comm_penalty=1.0000, reward=-2.9669
  Client 5: mean_dist=3.88, base_reward=-0.9708, violation=0, comm_penalty=0.0000, reward=-0.9708
  Client 6: mean_dist=3.07, base_reward=-0.6403, violation=0, comm_penalty=0.0000, reward=-0.6403
  Client 7: mean_dist=4.06, base_reward=-1.0439, violation=0, comm_penalty=0.0000, reward=-1.0439
  Client 8: mean_dist=3.17, base_reward=-0.6010, violation=0, comm_penalty=0.0000, reward=-0.6010
  Client 9: mean_dist=3.47, base_reward=-0.7502, violation=0, comm_penalty=0.0000, reward=-0.7502
  RL policy loss: -0.537024
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1143
  Client 1 model accuracy on test set: 0.1159
  Client 2 model accuracy on test set: 0.1490
  Client 3 model accuracy on test set: 0.1180
  Client 4 model accuracy on test set: 0.1814
  Client 5 model accuracy on test set: 0.2258
  Client 6 model accuracy on test set: 0.1236
  Client 7 model accuracy on test set: 0.1940
  Client 8 model accuracy on test set: 0.1659
  Client 9 model accuracy on test set: 0.1430

=== Global Round 56/100 ===
  Client 0: layers_shared=1, local_acc=0.9386
  Client 1: layers_shared=1, local_acc=0.9625
  Client 2: layers_shared=6, local_acc=0.8717
  Client 3: layers_shared=3, local_acc=0.9868
  Client 4: layers_shared=6, local_acc=0.9855
  Client 5: layers_shared=2, local_acc=0.9797
  Client 6: layers_shared=1, local_acc=0.7421
  Client 7: layers_shared=4, local_acc=0.9777
  Client 8: layers_shared=6, local_acc=0.9896
  Client 9: layers_shared=1, local_acc=0.9885
  Client 0: mean_dist=3.21, base_reward=-0.6680, violation=0, comm_penalty=0.0000, reward=-0.6680
  Client 1: mean_dist=3.40, base_reward=-0.7382, violation=0, comm_penalty=0.0000, reward=-0.7382
  Client 2: mean_dist=12.13, base_reward=-5.1915, violation=5, comm_penalty=5.0000, reward=-10.1915
  Client 3: mean_dist=8.79, base_reward=-3.4065, violation=1, comm_penalty=1.0000, reward=-4.4065
  Client 4: mean_dist=11.88, base_reward=-4.9521, violation=2, comm_penalty=2.0000, reward=-6.9521
  Client 5: mean_dist=7.86, base_reward=-2.9517, violation=0, comm_penalty=0.0000, reward=-2.9517
  Client 6: mean_dist=3.09, base_reward=-0.8026, violation=0, comm_penalty=0.0000, reward=-0.8026
  Client 7: mean_dist=12.25, base_reward=-5.1450, violation=0, comm_penalty=0.0000, reward=-5.1450
  Client 8: mean_dist=10.23, base_reward=-4.1275, violation=4, comm_penalty=4.0000, reward=-8.1275
  Client 9: mean_dist=3.49, base_reward=-0.7569, violation=0, comm_penalty=0.0000, reward=-0.7569
  RL policy loss: -1.364797
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1002
  Client 1 model accuracy on test set: 0.1205
  Client 2 model accuracy on test set: 0.1420
  Client 3 model accuracy on test set: 0.1035
  Client 4 model accuracy on test set: 0.1759
  Client 5 model accuracy on test set: 0.1698
  Client 6 model accuracy on test set: 0.1644
  Client 7 model accuracy on test set: 0.2279
  Client 8 model accuracy on test set: 0.1642
  Client 9 model accuracy on test set: 0.1267

=== Global Round 57/100 ===
  Client 0: layers_shared=2, local_acc=0.9127
  Client 1: layers_shared=3, local_acc=0.9536
  Client 2: layers_shared=2, local_acc=0.9009
  Client 3: layers_shared=3, local_acc=0.9817
  Client 4: layers_shared=5, local_acc=0.9773
  Client 5: layers_shared=4, local_acc=0.9120
  Client 6: layers_shared=3, local_acc=0.8945
  Client 7: layers_shared=6, local_acc=0.9883
  Client 8: layers_shared=1, local_acc=0.9906
  Client 9: layers_shared=3, local_acc=0.9894
  Client 0: mean_dist=7.76, base_reward=-2.9655, violation=0, comm_penalty=0.0000, reward=-2.9655
  Client 1: mean_dist=11.85, base_reward=-4.9714, violation=0, comm_penalty=0.0000, reward=-4.9714
  Client 2: mean_dist=9.54, base_reward=-3.8699, violation=1, comm_penalty=1.0000, reward=-4.8699
  Client 3: mean_dist=11.40, base_reward=-4.7172, violation=1, comm_penalty=1.0000, reward=-5.7172
  Client 4: mean_dist=14.45, base_reward=-6.2500, violation=1, comm_penalty=1.0000, reward=-7.2500
  Client 5: mean_dist=14.57, base_reward=-6.3729, violation=0, comm_penalty=0.0000, reward=-6.3729
  Client 6: mean_dist=10.08, base_reward=-4.1450, violation=2, comm_penalty=2.0000, reward=-6.1450
  Client 7: mean_dist=15.60, base_reward=-6.8109, violation=0, comm_penalty=0.0000, reward=-6.8109
  Client 8: mean_dist=3.20, base_reward=-0.6088, violation=0, comm_penalty=0.0000, reward=-0.6088
  Client 9: mean_dist=12.22, base_reward=-5.1200, violation=0, comm_penalty=0.0000, reward=-5.1200
  RL policy loss: -0.376262
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1108
  Client 1 model accuracy on test set: 0.1771
  Client 2 model accuracy on test set: 0.1288
  Client 3 model accuracy on test set: 0.1441
  Client 4 model accuracy on test set: 0.1764
  Client 5 model accuracy on test set: 0.2301
  Client 6 model accuracy on test set: 0.1081
  Client 7 model accuracy on test set: 0.1993
  Client 8 model accuracy on test set: 0.1593
  Client 9 model accuracy on test set: 0.1703

=== Global Round 58/100 ===
  Client 0: layers_shared=1, local_acc=0.9032
  Client 1: layers_shared=1, local_acc=0.9694
  Client 2: layers_shared=5, local_acc=0.8831
  Client 3: layers_shared=4, local_acc=0.9756
  Client 4: layers_shared=1, local_acc=0.9608
  Client 5: layers_shared=5, local_acc=0.9709
  Client 6: layers_shared=4, local_acc=0.9168
  Client 7: layers_shared=2, local_acc=0.9914
  Client 8: layers_shared=4, local_acc=0.9888
  Client 9: layers_shared=3, local_acc=0.9868
  Client 0: mean_dist=3.24, base_reward=-0.7175, violation=0, comm_penalty=0.0000, reward=-0.7175
  Client 1: mean_dist=3.45, base_reward=-0.7547, violation=0, comm_penalty=0.0000, reward=-0.7547
  Client 2: mean_dist=13.31, base_reward=-5.7724, violation=4, comm_penalty=4.0000, reward=-9.7724
  Client 3: mean_dist=11.16, base_reward=-4.6026, violation=2, comm_penalty=2.0000, reward=-6.6026
  Client 4: mean_dist=3.64, base_reward=-0.8600, violation=0, comm_penalty=0.0000, reward=-0.8600
  Client 5: mean_dist=13.66, base_reward=-5.8588, violation=0, comm_penalty=0.0000, reward=-5.8588
  Client 6: mean_dist=10.00, base_reward=-4.0830, violation=3, comm_penalty=3.0000, reward=-7.0830
  Client 7: mean_dist=8.90, base_reward=-3.4607, violation=0, comm_penalty=0.0000, reward=-3.4607
  Client 8: mean_dist=10.47, base_reward=-4.2460, violation=2, comm_penalty=2.0000, reward=-6.2460
  Client 9: mean_dist=10.15, base_reward=-4.0891, violation=0, comm_penalty=0.0000, reward=-4.0891
  RL policy loss: -1.192692
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1077
  Client 1 model accuracy on test set: 0.1153
  Client 2 model accuracy on test set: 0.1129
  Client 3 model accuracy on test set: 0.1292
  Client 4 model accuracy on test set: 0.1713
  Client 5 model accuracy on test set: 0.1923
  Client 6 model accuracy on test set: 0.1584
  Client 7 model accuracy on test set: 0.2166
  Client 8 model accuracy on test set: 0.1187
  Client 9 model accuracy on test set: 0.1481

=== Global Round 59/100 ===
  Client 0: layers_shared=1, local_acc=0.9152
  Client 1: layers_shared=4, local_acc=0.9845
  Client 2: layers_shared=6, local_acc=0.9143
  Client 3: layers_shared=1, local_acc=0.9709
  Client 4: layers_shared=1, local_acc=0.9638
  Client 5: layers_shared=1, local_acc=0.9924
  Client 6: layers_shared=1, local_acc=0.9203
  Client 7: layers_shared=1, local_acc=0.9919
  Client 8: layers_shared=2, local_acc=0.9882
  Client 9: layers_shared=6, local_acc=0.9776
  Client 0: mean_dist=3.25, base_reward=-0.7109, violation=0, comm_penalty=0.0000, reward=-0.7109
  Client 1: mean_dist=7.67, base_reward=-2.8516, violation=0, comm_penalty=0.0000, reward=-2.8516
  Client 2: mean_dist=8.59, base_reward=-3.3782, violation=5, comm_penalty=5.0000, reward=-8.3782
  Client 3: mean_dist=3.50, base_reward=-0.7789, violation=0, comm_penalty=0.0000, reward=-0.7789
  Client 4: mean_dist=3.66, base_reward=-0.8644, violation=0, comm_penalty=0.0000, reward=-0.8644
  Client 5: mean_dist=3.94, base_reward=-0.9775, violation=0, comm_penalty=0.0000, reward=-0.9775
  Client 6: mean_dist=3.13, base_reward=-0.6469, violation=0, comm_penalty=0.0000, reward=-0.6469
  Client 7: mean_dist=4.12, base_reward=-1.0675, violation=0, comm_penalty=0.0000, reward=-1.0675
  Client 8: mean_dist=5.09, base_reward=-1.5566, violation=0, comm_penalty=0.0000, reward=-1.5566
  Client 9: mean_dist=8.20, base_reward=-3.1216, violation=1, comm_penalty=1.0000, reward=-4.1216
  RL policy loss: -0.915023
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.0981
  Client 1 model accuracy on test set: 0.1173
  Client 2 model accuracy on test set: 0.1591
  Client 3 model accuracy on test set: 0.1025
  Client 4 model accuracy on test set: 0.1823
  Client 5 model accuracy on test set: 0.2460
  Client 6 model accuracy on test set: 0.1500
  Client 7 model accuracy on test set: 0.2547
  Client 8 model accuracy on test set: 0.1171
  Client 9 model accuracy on test set: 0.1598

=== Global Round 60/100 ===
  Client 0: layers_shared=3, local_acc=0.9171
  Client 1: layers_shared=6, local_acc=0.9564
  Client 2: layers_shared=3, local_acc=0.8539
  Client 3: layers_shared=1, local_acc=0.9774
  Client 4: layers_shared=2, local_acc=0.9510
  Client 5: layers_shared=1, local_acc=0.9884
  Client 6: layers_shared=3, local_acc=0.9133
  Client 7: layers_shared=3, local_acc=0.9916
  Client 8: layers_shared=6, local_acc=0.9892
  Client 9: layers_shared=5, local_acc=0.9725
  Client 0: mean_dist=9.64, base_reward=-3.9027, violation=0, comm_penalty=0.0000, reward=-3.9027
  Client 1: mean_dist=12.71, base_reward=-5.4001, violation=1, comm_penalty=1.0000, reward=-6.4001
  Client 2: mean_dist=12.21, base_reward=-5.2517, violation=2, comm_penalty=2.0000, reward=-7.2517
  Client 3: mean_dist=3.51, base_reward=-0.7772, violation=0, comm_penalty=0.0000, reward=-0.7772
  Client 4: mean_dist=8.94, base_reward=-3.5187, violation=0, comm_penalty=0.0000, reward=-3.5187
  Client 5: mean_dist=3.95, base_reward=-0.9873, violation=0, comm_penalty=0.0000, reward=-0.9873
  Client 6: mean_dist=9.37, base_reward=-3.7726, violation=2, comm_penalty=2.0000, reward=-5.7726
  Client 7: mean_dist=13.11, base_reward=-5.5638, violation=0, comm_penalty=0.0000, reward=-5.5638
  Client 8: mean_dist=11.35, base_reward=-4.6860, violation=4, comm_penalty=4.0000, reward=-8.6860
  Client 9: mean_dist=12.92, base_reward=-5.4855, violation=0, comm_penalty=0.0000, reward=-5.4855
  RL policy loss: -0.718238
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1224
  Client 1 model accuracy on test set: 0.1624
  Client 2 model accuracy on test set: 0.1515
  Client 3 model accuracy on test set: 0.1282
  Client 4 model accuracy on test set: 0.1872
  Client 5 model accuracy on test set: 0.2200
  Client 6 model accuracy on test set: 0.1616
  Client 7 model accuracy on test set: 0.1880
  Client 8 model accuracy on test set: 0.1404
  Client 9 model accuracy on test set: 0.1512

=== Global Round 61/100 ===
  Client 0: layers_shared=5, local_acc=0.9513
  Client 1: layers_shared=3, local_acc=0.9699
  Client 2: layers_shared=3, local_acc=0.9398
  Client 3: layers_shared=1, local_acc=0.9542
  Client 4: layers_shared=1, local_acc=0.9693
  Client 5: layers_shared=1, local_acc=0.9695
  Client 6: layers_shared=2, local_acc=0.9581
  Client 7: layers_shared=3, local_acc=0.9895
  Client 8: layers_shared=5, local_acc=0.9845
  Client 9: layers_shared=3, local_acc=0.9958
  Client 0: mean_dist=9.20, base_reward=-3.6464, violation=2, comm_penalty=2.0000, reward=-5.6464
  Client 1: mean_dist=9.94, base_reward=-4.0024, violation=0, comm_penalty=0.0000, reward=-4.0024
  Client 2: mean_dist=10.95, base_reward=-4.5334, violation=2, comm_penalty=2.0000, reward=-6.5334
  Client 3: mean_dist=3.53, base_reward=-0.8097, violation=0, comm_penalty=0.0000, reward=-0.8097
  Client 4: mean_dist=3.69, base_reward=-0.8754, violation=0, comm_penalty=0.0000, reward=-0.8754
  Client 5: mean_dist=3.97, base_reward=-1.0152, violation=0, comm_penalty=0.0000, reward=-1.0152
  Client 6: mean_dist=6.37, base_reward=-2.2287, violation=1, comm_penalty=1.0000, reward=-3.2287
  Client 7: mean_dist=11.75, base_reward=-4.8849, violation=0, comm_penalty=0.0000, reward=-4.8849
  Client 8: mean_dist=9.45, base_reward=-3.7387, violation=3, comm_penalty=3.0000, reward=-6.7387
  Client 9: mean_dist=10.24, base_reward=-4.1227, violation=0, comm_penalty=0.0000, reward=-4.1227
  RL policy loss: -0.672395
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1117
  Client 1 model accuracy on test set: 0.1376
  Client 2 model accuracy on test set: 0.1519
  Client 3 model accuracy on test set: 0.1103
  Client 4 model accuracy on test set: 0.1711
  Client 5 model accuracy on test set: 0.1712
  Client 6 model accuracy on test set: 0.1073
  Client 7 model accuracy on test set: 0.2150
  Client 8 model accuracy on test set: 0.1841
  Client 9 model accuracy on test set: 0.1568

=== Global Round 62/100 ===
  Client 0: layers_shared=4, local_acc=0.9646
  Client 1: layers_shared=1, local_acc=0.9861
  Client 2: layers_shared=4, local_acc=0.9139
  Client 3: layers_shared=2, local_acc=0.9801
  Client 4: layers_shared=3, local_acc=0.9773
  Client 5: layers_shared=1, local_acc=0.9813
  Client 6: layers_shared=3, local_acc=0.9280
  Client 7: layers_shared=3, local_acc=0.9840
  Client 8: layers_shared=4, local_acc=0.9911
  Client 9: layers_shared=3, local_acc=0.9928
  Client 0: mean_dist=10.53, base_reward=-4.3021, violation=1, comm_penalty=1.0000, reward=-5.3021
  Client 1: mean_dist=3.49, base_reward=-0.7588, violation=0, comm_penalty=0.0000, reward=-0.7588
  Client 2: mean_dist=13.37, base_reward=-5.7707, violation=3, comm_penalty=3.0000, reward=-8.7707
  Client 3: mean_dist=8.03, base_reward=-3.0335, violation=0, comm_penalty=0.0000, reward=-3.0335
  Client 4: mean_dist=12.32, base_reward=-5.1808, violation=0, comm_penalty=0.0000, reward=-5.1808
  Client 5: mean_dist=3.98, base_reward=-1.0068, violation=0, comm_penalty=0.0000, reward=-1.0068
  Client 6: mean_dist=9.50, base_reward=-3.8215, violation=2, comm_penalty=2.0000, reward=-5.8215
  Client 7: mean_dist=13.24, base_reward=-5.6373, violation=0, comm_penalty=0.0000, reward=-5.6373
  Client 8: mean_dist=10.85, base_reward=-4.4328, violation=2, comm_penalty=2.0000, reward=-6.4328
  Client 9: mean_dist=11.52, base_reward=-4.7659, violation=0, comm_penalty=0.0000, reward=-4.7659
  RL policy loss: -0.709187
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1027
  Client 1 model accuracy on test set: 0.1321
  Client 2 model accuracy on test set: 0.1523
  Client 3 model accuracy on test set: 0.1505
  Client 4 model accuracy on test set: 0.1454
  Client 5 model accuracy on test set: 0.1529
  Client 6 model accuracy on test set: 0.1343
  Client 7 model accuracy on test set: 0.2394
  Client 8 model accuracy on test set: 0.1854
  Client 9 model accuracy on test set: 0.1743

=== Global Round 63/100 ===
  Client 0: layers_shared=3, local_acc=0.8918
  Client 1: layers_shared=3, local_acc=0.9838
  Client 2: layers_shared=1, local_acc=0.9437
  Client 3: layers_shared=3, local_acc=0.9596
  Client 4: layers_shared=5, local_acc=0.9669
  Client 5: layers_shared=5, local_acc=0.9785
  Client 6: layers_shared=1, local_acc=0.9092
  Client 7: layers_shared=1, local_acc=0.9912
  Client 8: layers_shared=1, local_acc=0.9721
  Client 9: layers_shared=3, local_acc=0.9960
  Client 0: mean_dist=8.47, base_reward=-3.3428, violation=0, comm_penalty=0.0000, reward=-3.3428
  Client 1: mean_dist=9.51, base_reward=-3.7708, violation=0, comm_penalty=0.0000, reward=-3.7708
  Client 2: mean_dist=3.80, base_reward=-0.9587, violation=0, comm_penalty=0.0000, reward=-0.9587
  Client 3: mean_dist=9.24, base_reward=-3.6594, violation=1, comm_penalty=1.0000, reward=-4.6594
  Client 4: mean_dist=11.30, base_reward=-4.6850, violation=1, comm_penalty=1.0000, reward=-5.6850
  Client 5: mean_dist=11.62, base_reward=-4.8308, violation=0, comm_penalty=0.0000, reward=-4.8308
  Client 6: mean_dist=3.19, base_reward=-0.6861, violation=0, comm_penalty=0.0000, reward=-0.6861
  Client 7: mean_dist=4.18, base_reward=-1.0976, violation=0, comm_penalty=0.0000, reward=-1.0976
  Client 8: mean_dist=3.28, base_reward=-0.6683, violation=0, comm_penalty=0.0000, reward=-0.6683
  Client 9: mean_dist=9.76, base_reward=-3.8858, violation=0, comm_penalty=0.0000, reward=-3.8858
  RL policy loss: -0.692526
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1305
  Client 1 model accuracy on test set: 0.1391
  Client 2 model accuracy on test set: 0.1298
  Client 3 model accuracy on test set: 0.1006
  Client 4 model accuracy on test set: 0.1828
  Client 5 model accuracy on test set: 0.1852
  Client 6 model accuracy on test set: 0.1569
  Client 7 model accuracy on test set: 0.2595
  Client 8 model accuracy on test set: 0.1509
  Client 9 model accuracy on test set: 0.1731

=== Global Round 64/100 ===
  Client 0: layers_shared=2, local_acc=0.8715
  Client 1: layers_shared=2, local_acc=0.9863
  Client 2: layers_shared=4, local_acc=0.9466
  Client 3: layers_shared=2, local_acc=0.9759
  Client 4: layers_shared=1, local_acc=0.9090
  Client 5: layers_shared=1, local_acc=0.9938
  Client 6: layers_shared=6, local_acc=0.9706
  Client 7: layers_shared=1, local_acc=0.9907
  Client 8: layers_shared=6, local_acc=0.9906
  Client 9: layers_shared=2, local_acc=0.9954
  Client 0: mean_dist=6.49, base_reward=-2.3743, violation=0, comm_penalty=0.0000, reward=-2.3743
  Client 1: mean_dist=7.27, base_reward=-2.6507, violation=0, comm_penalty=0.0000, reward=-2.6507
  Client 2: mean_dist=10.05, base_reward=-4.0781, violation=3, comm_penalty=3.0000, reward=-7.0781
  Client 3: mean_dist=7.20, base_reward=-2.6223, violation=0, comm_penalty=0.0000, reward=-2.6223
  Client 4: mean_dist=3.73, base_reward=-0.9574, violation=0, comm_penalty=0.0000, reward=-0.9574
  Client 5: mean_dist=4.00, base_reward=-1.0043, violation=0, comm_penalty=0.0000, reward=-1.0043
  Client 6: mean_dist=8.10, base_reward=-3.0779, violation=5, comm_penalty=5.0000, reward=-8.0779
  Client 7: mean_dist=4.19, base_reward=-1.1028, violation=0, comm_penalty=0.0000, reward=-1.1028
  Client 8: mean_dist=8.55, base_reward=-3.2866, violation=4, comm_penalty=4.0000, reward=-7.2866
  Client 9: mean_dist=7.61, base_reward=-2.8078, violation=0, comm_penalty=0.0000, reward=-2.8078
  RL policy loss: -1.065905
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1071
  Client 1 model accuracy on test set: 0.1428
  Client 2 model accuracy on test set: 0.1454
  Client 3 model accuracy on test set: 0.1050
  Client 4 model accuracy on test set: 0.1592
  Client 5 model accuracy on test set: 0.1837
  Client 6 model accuracy on test set: 0.1606
  Client 7 model accuracy on test set: 0.2605
  Client 8 model accuracy on test set: 0.1452
  Client 9 model accuracy on test set: 0.1836

=== Global Round 65/100 ===
  Client 0: layers_shared=1, local_acc=0.9032
  Client 1: layers_shared=4, local_acc=0.9749
  Client 2: layers_shared=6, local_acc=0.8574
  Client 3: layers_shared=1, local_acc=0.9426
  Client 4: layers_shared=5, local_acc=0.9663
  Client 5: layers_shared=3, local_acc=0.9924
  Client 6: layers_shared=3, local_acc=0.9602
  Client 7: layers_shared=6, local_acc=0.9887
  Client 8: layers_shared=3, local_acc=0.9933
  Client 9: layers_shared=6, local_acc=0.9921
  Client 0: mean_dist=3.33, base_reward=-0.7607, violation=0, comm_penalty=0.0000, reward=-0.7607
  Client 1: mean_dist=14.58, base_reward=-6.3165, violation=0, comm_penalty=0.0000, reward=-6.3165
  Client 2: mean_dist=17.37, base_reward=-7.8264, violation=5, comm_penalty=5.0000, reward=-12.8264
  Client 3: mean_dist=3.58, base_reward=-0.8481, violation=0, comm_penalty=0.0000, reward=-0.8481
  Client 4: mean_dist=16.80, base_reward=-7.4345, violation=1, comm_penalty=1.0000, reward=-8.4345
  Client 5: mean_dist=13.76, base_reward=-5.8892, violation=0, comm_penalty=0.0000, reward=-5.8892
  Client 6: mean_dist=10.53, base_reward=-4.3042, violation=2, comm_penalty=2.0000, reward=-6.3042
  Client 7: mean_dist=18.21, base_reward=-8.1170, violation=0, comm_penalty=0.0000, reward=-8.1170
  Client 8: mean_dist=11.13, base_reward=-4.5706, violation=1, comm_penalty=1.0000, reward=-5.5706
  Client 9: mean_dist=15.97, base_reward=-6.9954, violation=1, comm_penalty=1.0000, reward=-7.9954
  RL policy loss: -1.487579
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1017
  Client 1 model accuracy on test set: 0.1303
  Client 2 model accuracy on test set: 0.1404
  Client 3 model accuracy on test set: 0.1370
  Client 4 model accuracy on test set: 0.1708
  Client 5 model accuracy on test set: 0.1770
  Client 6 model accuracy on test set: 0.1805
  Client 7 model accuracy on test set: 0.2683
  Client 8 model accuracy on test set: 0.1288
  Client 9 model accuracy on test set: 0.1868

=== Global Round 66/100 ===
  Client 0: layers_shared=5, local_acc=0.9013
  Client 1: layers_shared=1, local_acc=0.9795
  Client 2: layers_shared=3, local_acc=0.9328
  Client 3: layers_shared=1, local_acc=0.9705
  Client 4: layers_shared=6, local_acc=0.9845
  Client 5: layers_shared=1, local_acc=0.9895
  Client 6: layers_shared=3, local_acc=0.9804
  Client 7: layers_shared=1, local_acc=0.9884
  Client 8: layers_shared=4, local_acc=0.9939
  Client 9: layers_shared=3, local_acc=0.9948
  Client 0: mean_dist=9.16, base_reward=-3.6812, violation=2, comm_penalty=2.0000, reward=-5.6812
  Client 1: mean_dist=3.54, base_reward=-0.7921, violation=0, comm_penalty=0.0000, reward=-0.7921
  Client 2: mean_dist=10.36, base_reward=-4.2454, violation=2, comm_penalty=2.0000, reward=-6.2454
  Client 3: mean_dist=3.60, base_reward=-0.8279, violation=0, comm_penalty=0.0000, reward=-0.8279
  Client 4: mean_dist=11.31, base_reward=-4.6723, violation=2, comm_penalty=2.0000, reward=-6.6723
  Client 5: mean_dist=4.02, base_reward=-1.0202, violation=0, comm_penalty=0.0000, reward=-1.0202
  Client 6: mean_dist=7.98, base_reward=-3.0107, violation=2, comm_penalty=2.0000, reward=-5.0107
  Client 7: mean_dist=4.21, base_reward=-1.1164, violation=0, comm_penalty=0.0000, reward=-1.1164
  Client 8: mean_dist=9.12, base_reward=-3.5643, violation=2, comm_penalty=2.0000, reward=-5.5643
  Client 9: mean_dist=9.54, base_reward=-3.7756, violation=0, comm_penalty=0.0000, reward=-3.7756
  RL policy loss: -1.227839
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1041
  Client 1 model accuracy on test set: 0.1529
  Client 2 model accuracy on test set: 0.1231
  Client 3 model accuracy on test set: 0.1069
  Client 4 model accuracy on test set: 0.1785
  Client 5 model accuracy on test set: 0.2158
  Client 6 model accuracy on test set: 0.1584
  Client 7 model accuracy on test set: 0.2847
  Client 8 model accuracy on test set: 0.1360
  Client 9 model accuracy on test set: 0.1261

=== Global Round 67/100 ===
  Client 0: layers_shared=1, local_acc=0.9601
  Client 1: layers_shared=2, local_acc=0.9648
  Client 2: layers_shared=4, local_acc=0.9288
  Client 3: layers_shared=2, local_acc=0.9622
  Client 4: layers_shared=3, local_acc=0.9671
  Client 5: layers_shared=1, local_acc=0.9943
  Client 6: layers_shared=5, local_acc=0.9623
  Client 7: layers_shared=4, local_acc=0.9937
  Client 8: layers_shared=4, local_acc=0.9941
  Client 9: layers_shared=1, local_acc=0.9952
  Client 0: mean_dist=3.34, base_reward=-0.7117, violation=0, comm_penalty=0.0000, reward=-0.7117
  Client 1: mean_dist=7.71, base_reward=-2.8912, violation=0, comm_penalty=0.0000, reward=-2.8912
  Client 2: mean_dist=12.67, base_reward=-5.4073, violation=3, comm_penalty=3.0000, reward=-8.4073
  Client 3: mean_dist=7.66, base_reward=-2.8685, violation=0, comm_penalty=0.0000, reward=-2.8685
  Client 4: mean_dist=10.84, base_reward=-4.4507, violation=0, comm_penalty=0.0000, reward=-4.4507
  Client 5: mean_dist=4.02, base_reward=-1.0166, violation=0, comm_penalty=0.0000, reward=-1.0166
  Client 6: mean_dist=9.88, base_reward=-3.9777, violation=4, comm_penalty=4.0000, reward=-7.9777
  Client 7: mean_dist=13.33, base_reward=-5.6722, violation=0, comm_penalty=0.0000, reward=-5.6722
  Client 8: mean_dist=10.37, base_reward=-4.1924, violation=2, comm_penalty=2.0000, reward=-6.1924
  Client 9: mean_dist=3.61, base_reward=-0.8088, violation=0, comm_penalty=0.0000, reward=-0.8088
  RL policy loss: -1.302529
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1149
  Client 1 model accuracy on test set: 0.1359
  Client 2 model accuracy on test set: 0.1270
  Client 3 model accuracy on test set: 0.1238
  Client 4 model accuracy on test set: 0.1806
  Client 5 model accuracy on test set: 0.1907
  Client 6 model accuracy on test set: 0.1410
  Client 7 model accuracy on test set: 0.2089
  Client 8 model accuracy on test set: 0.1079
  Client 9 model accuracy on test set: 0.1866

=== Global Round 68/100 ===
  Client 0: layers_shared=5, local_acc=0.9658
  Client 1: layers_shared=1, local_acc=0.9681
  Client 2: layers_shared=3, local_acc=0.9419
  Client 3: layers_shared=1, local_acc=0.9832
  Client 4: layers_shared=1, local_acc=0.9878
  Client 5: layers_shared=2, local_acc=0.9683
  Client 6: layers_shared=3, local_acc=0.9371
  Client 7: layers_shared=3, local_acc=0.9981
  Client 8: layers_shared=3, local_acc=0.9963
  Client 9: layers_shared=5, local_acc=0.9912
  Client 0: mean_dist=9.72, base_reward=-3.8946, violation=2, comm_penalty=2.0000, reward=-5.8946
  Client 1: mean_dist=3.57, base_reward=-0.8166, violation=0, comm_penalty=0.0000, reward=-0.8166
  Client 2: mean_dist=11.42, base_reward=-4.7661, violation=2, comm_penalty=2.0000, reward=-6.7661
  Client 3: mean_dist=3.63, base_reward=-0.8318, violation=0, comm_penalty=0.0000, reward=-0.8318
  Client 4: mean_dist=3.79, base_reward=-0.9058, violation=0, comm_penalty=0.0000, reward=-0.9058
  Client 5: mean_dist=8.70, base_reward=-3.3819, violation=0, comm_penalty=0.0000, reward=-3.3819
  Client 6: mean_dist=8.77, base_reward=-3.4501, violation=2, comm_penalty=2.0000, reward=-5.4501
  Client 7: mean_dist=12.03, base_reward=-5.0176, violation=0, comm_penalty=0.0000, reward=-5.0176
  Client 8: mean_dist=9.30, base_reward=-3.6533, violation=1, comm_penalty=1.0000, reward=-4.6533
  Client 9: mean_dist=11.16, base_reward=-4.5878, violation=0, comm_penalty=0.0000, reward=-4.5878
  RL policy loss: -0.714592
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1005
  Client 1 model accuracy on test set: 0.1416
  Client 2 model accuracy on test set: 0.1473
  Client 3 model accuracy on test set: 0.1017
  Client 4 model accuracy on test set: 0.1878
  Client 5 model accuracy on test set: 0.1823
  Client 6 model accuracy on test set: 0.1634
  Client 7 model accuracy on test set: 0.2195
  Client 8 model accuracy on test set: 0.1825
  Client 9 model accuracy on test set: 0.1808

=== Global Round 69/100 ===
  Client 0: layers_shared=1, local_acc=0.9196
  Client 1: layers_shared=1, local_acc=0.9498
  Client 2: layers_shared=1, local_acc=0.9586
  Client 3: layers_shared=1, local_acc=0.9484
  Client 4: layers_shared=1, local_acc=0.9703
  Client 5: layers_shared=6, local_acc=0.9780
  Client 6: layers_shared=3, local_acc=0.9574
  Client 7: layers_shared=4, local_acc=0.9929
  Client 8: layers_shared=1, local_acc=0.9953
  Client 9: layers_shared=1, local_acc=0.9975
  Client 0: mean_dist=3.37, base_reward=-0.7662, violation=0, comm_penalty=0.0000, reward=-0.7662
  Client 1: mean_dist=3.58, base_reward=-0.8403, violation=0, comm_penalty=0.0000, reward=-0.8403
  Client 2: mean_dist=3.93, base_reward=-1.0051, violation=0, comm_penalty=0.0000, reward=-1.0051
  Client 3: mean_dist=3.63, base_reward=-0.8691, violation=0, comm_penalty=0.0000, reward=-0.8691
  Client 4: mean_dist=3.80, base_reward=-0.9303, violation=0, comm_penalty=0.0000, reward=-0.9303
  Client 5: mean_dist=7.46, base_reward=-2.7544, violation=0, comm_penalty=0.0000, reward=-2.7544
  Client 6: mean_dist=5.63, base_reward=-1.8567, violation=2, comm_penalty=2.0000, reward=-3.8567
  Client 7: mean_dist=7.73, base_reward=-2.8700, violation=0, comm_penalty=0.0000, reward=-2.8700
  Client 8: mean_dist=3.35, base_reward=-0.6798, violation=0, comm_penalty=0.0000, reward=-0.6798
  Client 9: mean_dist=3.63, base_reward=-0.8172, violation=0, comm_penalty=0.0000, reward=-0.8172
  RL policy loss: -0.544443
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1027
  Client 1 model accuracy on test set: 0.1690
  Client 2 model accuracy on test set: 0.1598
  Client 3 model accuracy on test set: 0.1006
  Client 4 model accuracy on test set: 0.1971
  Client 5 model accuracy on test set: 0.1639
  Client 6 model accuracy on test set: 0.1569
  Client 7 model accuracy on test set: 0.2516
  Client 8 model accuracy on test set: 0.1748
  Client 9 model accuracy on test set: 0.1735

=== Global Round 70/100 ===
  Client 0: layers_shared=1, local_acc=0.9646
  Client 1: layers_shared=2, local_acc=0.9782
  Client 2: layers_shared=2, local_acc=0.9648
  Client 3: layers_shared=3, local_acc=0.9730
  Client 4: layers_shared=1, local_acc=0.9851
  Client 5: layers_shared=1, local_acc=0.9708
  Client 6: layers_shared=1, local_acc=0.9630
  Client 7: layers_shared=1, local_acc=0.9975
  Client 8: layers_shared=3, local_acc=0.9959
  Client 9: layers_shared=1, local_acc=0.9937
  Client 0: mean_dist=3.38, base_reward=-0.7278, violation=0, comm_penalty=0.0000, reward=-0.7278
  Client 1: mean_dist=5.64, base_reward=-1.8411, violation=0, comm_penalty=0.0000, reward=-1.8411
  Client 2: mean_dist=6.16, base_reward=-2.1154, violation=1, comm_penalty=1.0000, reward=-3.1154
  Client 3: mean_dist=6.04, base_reward=-2.0466, violation=1, comm_penalty=1.0000, reward=-3.0466
  Client 4: mean_dist=3.82, base_reward=-0.9249, violation=0, comm_penalty=0.0000, reward=-0.9249
  Client 5: mean_dist=4.07, base_reward=-1.0621, violation=0, comm_penalty=0.0000, reward=-1.0621
  Client 6: mean_dist=3.27, base_reward=-0.6731, violation=0, comm_penalty=0.0000, reward=-0.6731
  Client 7: mean_dist=4.23, base_reward=-1.1198, violation=0, comm_penalty=0.0000, reward=-1.1198
  Client 8: mean_dist=5.66, base_reward=-1.8328, violation=1, comm_penalty=1.0000, reward=-2.8328
  Client 9: mean_dist=3.64, base_reward=-0.8260, violation=0, comm_penalty=0.0000, reward=-0.8260
  RL policy loss: -0.362970
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1024
  Client 1 model accuracy on test set: 0.1550
  Client 2 model accuracy on test set: 0.1453
  Client 3 model accuracy on test set: 0.1012
  Client 4 model accuracy on test set: 0.2001
  Client 5 model accuracy on test set: 0.1694
  Client 6 model accuracy on test set: 0.1459
  Client 7 model accuracy on test set: 0.2167
  Client 8 model accuracy on test set: 0.2012
  Client 9 model accuracy on test set: 0.1305

=== Global Round 71/100 ===
  Client 0: layers_shared=6, local_acc=0.9278
  Client 1: layers_shared=4, local_acc=0.9813
  Client 2: layers_shared=1, local_acc=0.9247
  Client 3: layers_shared=3, local_acc=0.9877
  Client 4: layers_shared=1, local_acc=0.9758
  Client 5: layers_shared=1, local_acc=0.9819
  Client 6: layers_shared=1, local_acc=0.9357
  Client 7: layers_shared=1, local_acc=0.9911
  Client 8: layers_shared=5, local_acc=0.9974
  Client 9: layers_shared=1, local_acc=0.9946
  Client 0: mean_dist=7.11, base_reward=-2.6270, violation=3, comm_penalty=3.0000, reward=-5.6270
  Client 1: mean_dist=7.75, base_reward=-2.8954, violation=0, comm_penalty=0.0000, reward=-2.8954
  Client 2: mean_dist=3.96, base_reward=-1.0552, violation=0, comm_penalty=0.0000, reward=-1.0552
  Client 3: mean_dist=6.74, base_reward=-2.3808, violation=1, comm_penalty=1.0000, reward=-3.3808
  Client 4: mean_dist=3.83, base_reward=-0.9390, violation=0, comm_penalty=0.0000, reward=-0.9390
  Client 5: mean_dist=4.08, base_reward=-1.0584, violation=0, comm_penalty=0.0000, reward=-1.0584
  Client 6: mean_dist=3.28, base_reward=-0.7053, violation=0, comm_penalty=0.0000, reward=-0.7053
  Client 7: mean_dist=4.25, base_reward=-1.1320, violation=0, comm_penalty=0.0000, reward=-1.1320
  Client 8: mean_dist=7.20, base_reward=-2.6023, violation=3, comm_penalty=3.0000, reward=-5.6023
  Client 9: mean_dist=3.65, base_reward=-0.8285, violation=0, comm_penalty=0.0000, reward=-0.8285
  RL policy loss: -1.114573
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1038
  Client 1 model accuracy on test set: 0.1394
  Client 2 model accuracy on test set: 0.1599
  Client 3 model accuracy on test set: 0.1004
  Client 4 model accuracy on test set: 0.1549
  Client 5 model accuracy on test set: 0.2282
  Client 6 model accuracy on test set: 0.1643
  Client 7 model accuracy on test set: 0.1994
  Client 8 model accuracy on test set: 0.1838
  Client 9 model accuracy on test set: 0.1574

=== Global Round 72/100 ===
  Client 0: layers_shared=2, local_acc=0.9608
  Client 1: layers_shared=3, local_acc=0.9833
  Client 2: layers_shared=1, local_acc=0.9404
  Client 3: layers_shared=1, local_acc=0.9893
  Client 4: layers_shared=4, local_acc=0.9847
  Client 5: layers_shared=6, local_acc=0.9777
  Client 6: layers_shared=2, local_acc=0.9308
  Client 7: layers_shared=1, local_acc=0.9887
  Client 8: layers_shared=3, local_acc=0.9890
  Client 9: layers_shared=1, local_acc=0.9933
  Client 0: mean_dist=6.24, base_reward=-2.1601, violation=0, comm_penalty=0.0000, reward=-2.1601
  Client 1: mean_dist=8.61, base_reward=-3.3228, violation=0, comm_penalty=0.0000, reward=-3.3228
  Client 2: mean_dist=3.97, base_reward=-1.0436, violation=0, comm_penalty=0.0000, reward=-1.0436
  Client 3: mean_dist=3.68, base_reward=-0.8515, violation=0, comm_penalty=0.0000, reward=-0.8515
  Client 4: mean_dist=10.01, base_reward=-4.0215, violation=0, comm_penalty=0.0000, reward=-4.0215
  Client 5: mean_dist=10.27, base_reward=-4.1573, violation=0, comm_penalty=0.0000, reward=-4.1573
  Client 6: mean_dist=6.04, base_reward=-2.0907, violation=1, comm_penalty=1.0000, reward=-3.0907
  Client 7: mean_dist=4.26, base_reward=-1.1425, violation=0, comm_penalty=0.0000, reward=-1.1425
  Client 8: mean_dist=7.93, base_reward=-2.9747, violation=1, comm_penalty=1.0000, reward=-3.9747
  Client 9: mean_dist=3.66, base_reward=-0.8343, violation=0, comm_penalty=0.0000, reward=-0.8343
  RL policy loss: -0.756165
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1007
  Client 1 model accuracy on test set: 0.1432
  Client 2 model accuracy on test set: 0.1642
  Client 3 model accuracy on test set: 0.1254
  Client 4 model accuracy on test set: 0.1718
  Client 5 model accuracy on test set: 0.2149
  Client 6 model accuracy on test set: 0.1350
  Client 7 model accuracy on test set: 0.2205
  Client 8 model accuracy on test set: 0.1606
  Client 9 model accuracy on test set: 0.1722

=== Global Round 73/100 ===
  Client 0: layers_shared=5, local_acc=0.9646
  Client 1: layers_shared=1, local_acc=0.9868
  Client 2: layers_shared=3, local_acc=0.9630
  Client 3: layers_shared=3, local_acc=0.9915
  Client 4: layers_shared=2, local_acc=0.9822
  Client 5: layers_shared=1, local_acc=0.9295
  Client 6: layers_shared=1, local_acc=0.9797
  Client 7: layers_shared=3, local_acc=0.9954
  Client 8: layers_shared=1, local_acc=0.9949
  Client 9: layers_shared=1, local_acc=0.9955
  Client 0: mean_dist=7.53, base_reward=-2.7987, violation=2, comm_penalty=2.0000, reward=-4.7987
  Client 1: mean_dist=3.63, base_reward=-0.8293, violation=0, comm_penalty=0.0000, reward=-0.8293
  Client 2: mean_dist=9.13, base_reward=-3.6016, violation=2, comm_penalty=2.0000, reward=-5.6016
  Client 3: mean_dist=8.16, base_reward=-3.0902, violation=1, comm_penalty=1.0000, reward=-4.0902
  Client 4: mean_dist=7.16, base_reward=-2.5975, violation=0, comm_penalty=0.0000, reward=-2.5975
  Client 5: mean_dist=4.10, base_reward=-1.1221, violation=0, comm_penalty=0.0000, reward=-1.1221
  Client 6: mean_dist=3.30, base_reward=-0.6718, violation=0, comm_penalty=0.0000, reward=-0.6718
  Client 7: mean_dist=9.57, base_reward=-3.7871, violation=0, comm_penalty=0.0000, reward=-3.7871
  Client 8: mean_dist=3.40, base_reward=-0.7034, violation=0, comm_penalty=0.0000, reward=-0.7034
  Client 9: mean_dist=3.67, base_reward=-0.8399, violation=0, comm_penalty=0.0000, reward=-0.8399
  RL policy loss: -0.821636
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.0917
  Client 1 model accuracy on test set: 0.1547
  Client 2 model accuracy on test set: 0.1444
  Client 3 model accuracy on test set: 0.1175
  Client 4 model accuracy on test set: 0.1741
  Client 5 model accuracy on test set: 0.1437
  Client 6 model accuracy on test set: 0.1677
  Client 7 model accuracy on test set: 0.2207
  Client 8 model accuracy on test set: 0.1885
  Client 9 model accuracy on test set: 0.2321

=== Global Round 74/100 ===
  Client 0: layers_shared=1, local_acc=0.9652
  Client 1: layers_shared=1, local_acc=0.9807
  Client 2: layers_shared=2, local_acc=0.9270
  Client 3: layers_shared=4, local_acc=0.9888
  Client 4: layers_shared=1, local_acc=0.9855
  Client 5: layers_shared=1, local_acc=0.9754
  Client 6: layers_shared=1, local_acc=0.9483
  Client 7: layers_shared=2, local_acc=0.9947
  Client 8: layers_shared=6, local_acc=0.9892
  Client 9: layers_shared=3, local_acc=0.9925
  Client 0: mean_dist=3.42, base_reward=-0.7462, violation=0, comm_penalty=0.0000, reward=-0.7462
  Client 1: mean_dist=3.65, base_reward=-0.8436, violation=0, comm_penalty=0.0000, reward=-0.8436
  Client 2: mean_dist=7.26, base_reward=-2.7019, violation=1, comm_penalty=1.0000, reward=-3.7019
  Client 3: mean_dist=7.82, base_reward=-2.9228, violation=2, comm_penalty=2.0000, reward=-4.9228
  Client 4: mean_dist=3.87, base_reward=-0.9501, violation=0, comm_penalty=0.0000, reward=-0.9501
  Client 5: mean_dist=4.11, base_reward=-1.0820, violation=0, comm_penalty=0.0000, reward=-1.0820
  Client 6: mean_dist=3.31, base_reward=-0.7077, violation=0, comm_penalty=0.0000, reward=-0.7077
  Client 7: mean_dist=7.70, base_reward=-2.8561, violation=0, comm_penalty=0.0000, reward=-2.8561
  Client 8: mean_dist=7.34, base_reward=-2.6795, violation=4, comm_penalty=4.0000, reward=-6.6795
  Client 9: mean_dist=7.68, base_reward=-2.8479, violation=0, comm_penalty=0.0000, reward=-2.8479
  RL policy loss: -1.222903
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1138
  Client 1 model accuracy on test set: 0.1671
  Client 2 model accuracy on test set: 0.1423
  Client 3 model accuracy on test set: 0.1064
  Client 4 model accuracy on test set: 0.1744
  Client 5 model accuracy on test set: 0.2195
  Client 6 model accuracy on test set: 0.1340
  Client 7 model accuracy on test set: 0.2254
  Client 8 model accuracy on test set: 0.1599
  Client 9 model accuracy on test set: 0.1340

=== Global Round 75/100 ===
  Client 0: layers_shared=1, local_acc=0.9430
  Client 1: layers_shared=1, local_acc=0.9704
  Client 2: layers_shared=6, local_acc=0.9652
  Client 3: layers_shared=3, local_acc=0.9792
  Client 4: layers_shared=3, local_acc=0.9525
  Client 5: layers_shared=6, local_acc=0.9819
  Client 6: layers_shared=5, local_acc=0.9280
  Client 7: layers_shared=1, local_acc=0.9964
  Client 8: layers_shared=5, local_acc=0.9931
  Client 9: layers_shared=3, local_acc=0.9854
  Client 0: mean_dist=3.44, base_reward=-0.7784, violation=0, comm_penalty=0.0000, reward=-0.7784
  Client 1: mean_dist=3.66, base_reward=-0.8598, violation=0, comm_penalty=0.0000, reward=-0.8598
  Client 2: mean_dist=15.59, base_reward=-6.8290, violation=5, comm_penalty=5.0000, reward=-11.8290
  Client 3: mean_dist=10.93, base_reward=-4.4880, violation=1, comm_penalty=1.0000, reward=-5.4880
  Client 4: mean_dist=12.36, base_reward=-5.2256, violation=0, comm_penalty=0.0000, reward=-5.2256
  Client 5: mean_dist=15.51, base_reward=-6.7731, violation=0, comm_penalty=0.0000, reward=-6.7731
  Client 6: mean_dist=11.93, base_reward=-5.0352, violation=4, comm_penalty=4.0000, reward=-9.0352
  Client 7: mean_dist=4.30, base_reward=-1.1518, violation=0, comm_penalty=0.0000, reward=-1.1518
  Client 8: mean_dist=12.45, base_reward=-5.2319, violation=3, comm_penalty=3.0000, reward=-8.2319
  Client 9: mean_dist=11.44, base_reward=-4.7346, violation=0, comm_penalty=0.0000, reward=-4.7346
  RL policy loss: -2.182604
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1235
  Client 1 model accuracy on test set: 0.1510
  Client 2 model accuracy on test set: 0.1498
  Client 3 model accuracy on test set: 0.1231
  Client 4 model accuracy on test set: 0.1636
  Client 5 model accuracy on test set: 0.2001
  Client 6 model accuracy on test set: 0.1419
  Client 7 model accuracy on test set: 0.2271
  Client 8 model accuracy on test set: 0.1354
  Client 9 model accuracy on test set: 0.1931

=== Global Round 76/100 ===
  Client 0: layers_shared=1, local_acc=0.9329
  Client 1: layers_shared=4, local_acc=0.9658
  Client 2: layers_shared=1, local_acc=0.9350
  Client 3: layers_shared=3, local_acc=0.9832
  Client 4: layers_shared=4, local_acc=0.9852
  Client 5: layers_shared=1, local_acc=0.9835
  Client 6: layers_shared=1, local_acc=0.9490
  Client 7: layers_shared=3, local_acc=0.9907
  Client 8: layers_shared=4, local_acc=0.9990
  Client 9: layers_shared=6, local_acc=0.9927
  Client 0: mean_dist=3.45, base_reward=-0.7928, violation=0, comm_penalty=0.0000, reward=-0.7928
  Client 1: mean_dist=11.75, base_reward=-4.9072, violation=0, comm_penalty=0.0000, reward=-4.9072
  Client 2: mean_dist=4.05, base_reward=-1.0879, violation=0, comm_penalty=0.0000, reward=-1.0879
  Client 3: mean_dist=9.91, base_reward=-3.9696, violation=1, comm_penalty=1.0000, reward=-4.9696
  Client 4: mean_dist=12.62, base_reward=-5.3239, violation=0, comm_penalty=0.0000, reward=-5.3239
  Client 5: mean_dist=4.14, base_reward=-1.0847, violation=0, comm_penalty=0.0000, reward=-1.0847
  Client 6: mean_dist=3.34, base_reward=-0.7190, violation=0, comm_penalty=0.0000, reward=-0.7190
  Client 7: mean_dist=11.71, base_reward=-4.8640, violation=0, comm_penalty=0.0000, reward=-4.8640
  Client 8: mean_dist=10.60, base_reward=-4.2989, violation=2, comm_penalty=2.0000, reward=-6.2989
  Client 9: mean_dist=11.85, base_reward=-4.9306, violation=1, comm_penalty=1.0000, reward=-5.9306
  RL policy loss: -1.580473
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.0989
  Client 1 model accuracy on test set: 0.1300
  Client 2 model accuracy on test set: 0.1298
  Client 3 model accuracy on test set: 0.1024
  Client 4 model accuracy on test set: 0.1341
  Client 5 model accuracy on test set: 0.1918
  Client 6 model accuracy on test set: 0.1549
  Client 7 model accuracy on test set: 0.2028
  Client 8 model accuracy on test set: 0.1768
  Client 9 model accuracy on test set: 0.1212

=== Global Round 77/100 ===
  Client 0: layers_shared=6, local_acc=0.9601
  Client 1: layers_shared=1, local_acc=0.9557
  Client 2: layers_shared=4, local_acc=0.9648
  Client 3: layers_shared=6, local_acc=0.9915
  Client 4: layers_shared=1, local_acc=0.9889
  Client 5: layers_shared=1, local_acc=0.9909
  Client 6: layers_shared=2, local_acc=0.9783
  Client 7: layers_shared=1, local_acc=0.9895
  Client 8: layers_shared=3, local_acc=0.9939
  Client 9: layers_shared=1, local_acc=0.9948
  Client 0: mean_dist=8.07, base_reward=-3.0769, violation=3, comm_penalty=3.0000, reward=-6.0769
  Client 1: mean_dist=3.69, base_reward=-0.8873, violation=0, comm_penalty=0.0000, reward=-0.8873
  Client 2: mean_dist=9.79, base_reward=-3.9293, violation=3, comm_penalty=3.0000, reward=-6.9293
  Client 3: mean_dist=8.79, base_reward=-3.4024, violation=4, comm_penalty=4.0000, reward=-7.4024
  Client 4: mean_dist=3.91, base_reward=-0.9641, violation=0, comm_penalty=0.0000, reward=-0.9641
  Client 5: mean_dist=4.15, base_reward=-1.0843, violation=0, comm_penalty=0.0000, reward=-1.0843
  Client 6: mean_dist=5.44, base_reward=-1.7398, violation=1, comm_penalty=1.0000, reward=-2.7398
  Client 7: mean_dist=4.32, base_reward=-1.1683, violation=0, comm_penalty=0.0000, reward=-1.1683
  Client 8: mean_dist=7.09, base_reward=-2.5523, violation=1, comm_penalty=1.0000, reward=-3.5523
  Client 9: mean_dist=3.71, base_reward=-0.8602, violation=0, comm_penalty=0.0000, reward=-0.8602
  RL policy loss: -1.801369
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1109
  Client 1 model accuracy on test set: 0.1915
  Client 2 model accuracy on test set: 0.1720
  Client 3 model accuracy on test set: 0.1147
  Client 4 model accuracy on test set: 0.1998
  Client 5 model accuracy on test set: 0.1764
  Client 6 model accuracy on test set: 0.1651
  Client 7 model accuracy on test set: 0.2346
  Client 8 model accuracy on test set: 0.1710
  Client 9 model accuracy on test set: 0.1313

=== Global Round 78/100 ===
  Client 0: layers_shared=1, local_acc=0.9253
  Client 1: layers_shared=3, local_acc=0.9770
  Client 2: layers_shared=2, local_acc=0.9512
  Client 3: layers_shared=2, local_acc=0.9911
  Client 4: layers_shared=1, local_acc=0.9951
  Client 5: layers_shared=1, local_acc=0.9930
  Client 6: layers_shared=1, local_acc=0.9825
  Client 7: layers_shared=1, local_acc=0.9848
  Client 8: layers_shared=2, local_acc=0.9947
  Client 9: layers_shared=2, local_acc=0.9951
  Client 0: mean_dist=3.48, base_reward=-0.8125, violation=0, comm_penalty=0.0000, reward=-0.8125
  Client 1: mean_dist=6.55, base_reward=-2.3001, violation=0, comm_penalty=0.0000, reward=-2.3001
  Client 2: mean_dist=7.21, base_reward=-2.6517, violation=1, comm_penalty=1.0000, reward=-3.6517
  Client 3: mean_dist=6.55, base_reward=-2.2817, violation=0, comm_penalty=0.0000, reward=-2.2817
  Client 4: mean_dist=3.92, base_reward=-0.9631, violation=0, comm_penalty=0.0000, reward=-0.9631
  Client 5: mean_dist=4.15, base_reward=-1.0837, violation=0, comm_penalty=0.0000, reward=-1.0837
  Client 6: mean_dist=3.36, base_reward=-0.6968, violation=0, comm_penalty=0.0000, reward=-0.6968
  Client 7: mean_dist=4.33, base_reward=-1.1783, violation=0, comm_penalty=0.0000, reward=-1.1783
  Client 8: mean_dist=6.10, base_reward=-2.0561, violation=0, comm_penalty=0.0000, reward=-2.0561
  Client 9: mean_dist=6.70, base_reward=-2.3571, violation=0, comm_penalty=0.0000, reward=-2.3571
  RL policy loss: -0.495703
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1058
  Client 1 model accuracy on test set: 0.1742
  Client 2 model accuracy on test set: 0.1117
  Client 3 model accuracy on test set: 0.1346
  Client 4 model accuracy on test set: 0.1769
  Client 5 model accuracy on test set: 0.1789
  Client 6 model accuracy on test set: 0.1541
  Client 7 model accuracy on test set: 0.2222
  Client 8 model accuracy on test set: 0.1946
  Client 9 model accuracy on test set: 0.2046

=== Global Round 79/100 ===
  Client 0: layers_shared=1, local_acc=0.9462
  Client 1: layers_shared=4, local_acc=0.9790
  Client 2: layers_shared=5, local_acc=0.9756
  Client 3: layers_shared=3, local_acc=0.9904
  Client 4: layers_shared=6, local_acc=0.9931
  Client 5: layers_shared=4, local_acc=0.9947
  Client 6: layers_shared=1, local_acc=0.9734
  Client 7: layers_shared=3, local_acc=0.9942
  Client 8: layers_shared=2, local_acc=0.9937
  Client 9: layers_shared=1, local_acc=0.9934
  Client 0: mean_dist=3.48, base_reward=-0.7950, violation=0, comm_penalty=0.0000, reward=-0.7950
  Client 1: mean_dist=13.28, base_reward=-5.6605, violation=0, comm_penalty=0.0000, reward=-5.6605
  Client 2: mean_dist=15.08, base_reward=-6.5635, violation=4, comm_penalty=4.0000, reward=-10.5635
  Client 3: mean_dist=11.17, base_reward=-4.5936, violation=1, comm_penalty=1.0000, reward=-5.5936
  Client 4: mean_dist=14.66, base_reward=-6.3350, violation=2, comm_penalty=2.0000, reward=-8.3350
  Client 5: mean_dist=14.61, base_reward=-6.3079, violation=0, comm_penalty=0.0000, reward=-6.3079
  Client 6: mean_dist=3.37, base_reward=-0.7110, violation=0, comm_penalty=0.0000, reward=-0.7110
  Client 7: mean_dist=13.11, base_reward=-5.5591, violation=0, comm_penalty=0.0000, reward=-5.5591
  Client 8: mean_dist=7.73, base_reward=-2.8738, violation=0, comm_penalty=0.0000, reward=-2.8738
  Client 9: mean_dist=3.74, base_reward=-0.8785, violation=0, comm_penalty=0.0000, reward=-0.8785
  RL policy loss: -1.944812
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1493
  Client 1 model accuracy on test set: 0.1423
  Client 2 model accuracy on test set: 0.1146
  Client 3 model accuracy on test set: 0.1074
  Client 4 model accuracy on test set: 0.1740
  Client 5 model accuracy on test set: 0.1796
  Client 6 model accuracy on test set: 0.1255
  Client 7 model accuracy on test set: 0.1416
  Client 8 model accuracy on test set: 0.1916
  Client 9 model accuracy on test set: 0.1938

=== Global Round 80/100 ===
  Client 0: layers_shared=2, local_acc=0.9772
  Client 1: layers_shared=2, local_acc=0.9838
  Client 2: layers_shared=1, local_acc=0.9537
  Client 3: layers_shared=1, local_acc=0.9899
  Client 4: layers_shared=1, local_acc=0.9942
  Client 5: layers_shared=1, local_acc=0.9904
  Client 6: layers_shared=5, local_acc=0.9581
  Client 7: layers_shared=1, local_acc=0.9928
  Client 8: layers_shared=5, local_acc=0.9986
  Client 9: layers_shared=6, local_acc=0.9970
  Client 0: mean_dist=5.65, base_reward=-1.8491, violation=0, comm_penalty=0.0000, reward=-1.8491
  Client 1: mean_dist=6.26, base_reward=-2.1459, violation=0, comm_penalty=0.0000, reward=-2.1459
  Client 2: mean_dist=4.09, base_reward=-1.0933, violation=0, comm_penalty=0.0000, reward=-1.0933
  Client 3: mean_dist=3.77, base_reward=-0.8969, violation=0, comm_penalty=0.0000, reward=-0.8969
  Client 4: mean_dist=3.94, base_reward=-0.9777, violation=0, comm_penalty=0.0000, reward=-0.9777
  Client 5: mean_dist=4.18, base_reward=-1.0987, violation=0, comm_penalty=0.0000, reward=-1.0987
  Client 6: mean_dist=7.45, base_reward=-2.7680, violation=4, comm_penalty=4.0000, reward=-6.7680
  Client 7: mean_dist=4.35, base_reward=-1.1801, violation=0, comm_penalty=0.0000, reward=-1.1801
  Client 8: mean_dist=7.79, base_reward=-2.8953, violation=3, comm_penalty=3.0000, reward=-5.8953
  Client 9: mean_dist=8.74, base_reward=-3.3750, violation=1, comm_penalty=1.0000, reward=-4.3750
  RL policy loss: -1.410694
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1023
  Client 1 model accuracy on test set: 0.1548
  Client 2 model accuracy on test set: 0.1381
  Client 3 model accuracy on test set: 0.1047
  Client 4 model accuracy on test set: 0.1794
  Client 5 model accuracy on test set: 0.1361
  Client 6 model accuracy on test set: 0.1218
  Client 7 model accuracy on test set: 0.2200
  Client 8 model accuracy on test set: 0.1372
  Client 9 model accuracy on test set: 0.1873

=== Global Round 81/100 ===
  Client 0: layers_shared=1, local_acc=0.9772
  Client 1: layers_shared=1, local_acc=0.9873
  Client 2: layers_shared=5, local_acc=0.9313
  Client 3: layers_shared=1, local_acc=0.9911
  Client 4: layers_shared=1, local_acc=0.9957
  Client 5: layers_shared=1, local_acc=0.9545
  Client 6: layers_shared=1, local_acc=0.9602
  Client 7: layers_shared=3, local_acc=0.9924
  Client 8: layers_shared=6, local_acc=0.9947
  Client 9: layers_shared=1, local_acc=0.9949
  Client 0: mean_dist=3.49, base_reward=-0.7692, violation=0, comm_penalty=0.0000, reward=-0.7692
  Client 1: mean_dist=3.73, base_reward=-0.8789, violation=0, comm_penalty=0.0000, reward=-0.8789
  Client 2: mean_dist=8.08, base_reward=-3.1089, violation=4, comm_penalty=4.0000, reward=-7.1089
  Client 3: mean_dist=3.78, base_reward=-0.8987, violation=0, comm_penalty=0.0000, reward=-0.8987
  Client 4: mean_dist=3.94, base_reward=-0.9765, violation=0, comm_penalty=0.0000, reward=-0.9765
  Client 5: mean_dist=4.19, base_reward=-1.1403, violation=0, comm_penalty=0.0000, reward=-1.1403
  Client 6: mean_dist=3.39, base_reward=-0.7324, violation=0, comm_penalty=0.0000, reward=-0.7324
  Client 7: mean_dist=7.44, base_reward=-2.7264, violation=0, comm_penalty=0.0000, reward=-2.7264
  Client 8: mean_dist=7.10, base_reward=-2.5540, violation=4, comm_penalty=4.0000, reward=-6.5540
  Client 9: mean_dist=3.75, base_reward=-0.8800, violation=0, comm_penalty=0.0000, reward=-0.8800
  RL policy loss: -1.638380
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1092
  Client 1 model accuracy on test set: 0.1691
  Client 2 model accuracy on test set: 0.1089
  Client 3 model accuracy on test set: 0.1156
  Client 4 model accuracy on test set: 0.1907
  Client 5 model accuracy on test set: 0.1776
  Client 6 model accuracy on test set: 0.1641
  Client 7 model accuracy on test set: 0.1527
  Client 8 model accuracy on test set: 0.1649
  Client 9 model accuracy on test set: 0.1795

=== Global Round 82/100 ===
  Client 0: layers_shared=5, local_acc=0.9854
  Client 1: layers_shared=1, local_acc=0.9795
  Client 2: layers_shared=1, local_acc=0.9537
  Client 3: layers_shared=4, local_acc=0.9777
  Client 4: layers_shared=4, local_acc=0.9855
  Client 5: layers_shared=1, local_acc=0.8896
  Client 6: layers_shared=6, local_acc=0.9616
  Client 7: layers_shared=2, local_acc=0.9878
  Client 8: layers_shared=1, local_acc=0.9990
  Client 9: layers_shared=5, local_acc=0.9973
  Client 0: mean_dist=10.40, base_reward=-4.2133, violation=2, comm_penalty=2.0000, reward=-6.2133
  Client 1: mean_dist=3.74, base_reward=-0.8912, violation=0, comm_penalty=0.0000, reward=-0.8912
  Client 2: mean_dist=4.12, base_reward=-1.1073, violation=0, comm_penalty=0.0000, reward=-1.1073
  Client 3: mean_dist=10.84, base_reward=-4.4402, violation=2, comm_penalty=2.0000, reward=-6.4402
  Client 4: mean_dist=12.22, base_reward=-5.1225, violation=0, comm_penalty=0.0000, reward=-5.1225
  Client 5: mean_dist=4.20, base_reward=-1.2129, violation=0, comm_penalty=0.0000, reward=-1.2129
  Client 6: mean_dist=10.17, base_reward=-4.1216, violation=5, comm_penalty=5.0000, reward=-9.1216
  Client 7: mean_dist=8.55, base_reward=-3.2891, violation=0, comm_penalty=0.0000, reward=-3.2891
  Client 8: mean_dist=3.49, base_reward=-0.7484, violation=0, comm_penalty=0.0000, reward=-0.7484
  Client 9: mean_dist=11.97, base_reward=-4.9886, violation=0, comm_penalty=0.0000, reward=-4.9886
  RL policy loss: -2.088758
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1088
  Client 1 model accuracy on test set: 0.1043
  Client 2 model accuracy on test set: 0.1151
  Client 3 model accuracy on test set: 0.1389
  Client 4 model accuracy on test set: 0.1197
  Client 5 model accuracy on test set: 0.1642
  Client 6 model accuracy on test set: 0.1580
  Client 7 model accuracy on test set: 0.1953
  Client 8 model accuracy on test set: 0.1733
  Client 9 model accuracy on test set: 0.1932

=== Global Round 83/100 ===
  Client 0: layers_shared=1, local_acc=0.9956
  Client 1: layers_shared=1, local_acc=0.9696
  Client 2: layers_shared=2, local_acc=0.9375
  Client 3: layers_shared=3, local_acc=0.9920
  Client 4: layers_shared=1, local_acc=0.9830
  Client 5: layers_shared=1, local_acc=0.9889
  Client 6: layers_shared=4, local_acc=0.9504
  Client 7: layers_shared=1, local_acc=0.9977
  Client 8: layers_shared=3, local_acc=0.9992
  Client 9: layers_shared=4, local_acc=0.9976
  Client 0: mean_dist=3.51, base_reward=-0.7576, violation=0, comm_penalty=0.0000, reward=-0.7576
  Client 1: mean_dist=3.75, base_reward=-0.9074, violation=0, comm_penalty=0.0000, reward=-0.9074
  Client 2: mean_dist=7.18, base_reward=-2.6522, violation=1, comm_penalty=1.0000, reward=-3.6522
  Client 3: mean_dist=7.82, base_reward=-2.9175, violation=1, comm_penalty=1.0000, reward=-3.9175
  Client 4: mean_dist=3.96, base_reward=-0.9992, violation=0, comm_penalty=0.0000, reward=-0.9992
  Client 5: mean_dist=4.21, base_reward=-1.1159, violation=0, comm_penalty=0.0000, reward=-1.1159
  Client 6: mean_dist=7.34, base_reward=-2.7216, violation=3, comm_penalty=3.0000, reward=-5.7216
  Client 7: mean_dist=4.37, base_reward=-1.1855, violation=0, comm_penalty=0.0000, reward=-1.1855
  Client 8: mean_dist=7.25, base_reward=-2.6237, violation=1, comm_penalty=1.0000, reward=-3.6237
  Client 9: mean_dist=8.50, base_reward=-3.2535, violation=0, comm_penalty=0.0000, reward=-3.2535
  RL policy loss: -1.182050
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1051
  Client 1 model accuracy on test set: 0.1548
  Client 2 model accuracy on test set: 0.1407
  Client 3 model accuracy on test set: 0.1325
  Client 4 model accuracy on test set: 0.1988
  Client 5 model accuracy on test set: 0.1982
  Client 6 model accuracy on test set: 0.1624
  Client 7 model accuracy on test set: 0.2508
  Client 8 model accuracy on test set: 0.1606
  Client 9 model accuracy on test set: 0.2062

=== Global Round 84/100 ===
  Client 0: layers_shared=1, local_acc=0.9918
  Client 1: layers_shared=1, local_acc=0.9701
  Client 2: layers_shared=1, local_acc=0.9692
  Client 3: layers_shared=4, local_acc=0.9935
  Client 4: layers_shared=6, local_acc=0.9843
  Client 5: layers_shared=1, local_acc=0.9889
  Client 6: layers_shared=1, local_acc=0.9686
  Client 7: layers_shared=2, local_acc=0.9971
  Client 8: layers_shared=1, local_acc=0.9978
  Client 9: layers_shared=2, local_acc=0.9978
  Client 0: mean_dist=3.52, base_reward=-0.7676, violation=0, comm_penalty=0.0000, reward=-0.7676
  Client 1: mean_dist=3.77, base_reward=-0.9130, violation=0, comm_penalty=0.0000, reward=-0.9130
  Client 2: mean_dist=4.15, base_reward=-1.1062, violation=0, comm_penalty=0.0000, reward=-1.1062
  Client 3: mean_dist=7.28, base_reward=-2.6484, violation=2, comm_penalty=2.0000, reward=-4.6484
  Client 4: mean_dist=7.72, base_reward=-2.8776, violation=2, comm_penalty=2.0000, reward=-4.8776
  Client 5: mean_dist=4.22, base_reward=-1.1212, violation=0, comm_penalty=0.0000, reward=-1.1212
  Client 6: mean_dist=3.41, base_reward=-0.7373, violation=0, comm_penalty=0.0000, reward=-0.7373
  Client 7: mean_dist=7.09, base_reward=-2.5503, violation=0, comm_penalty=0.0000, reward=-2.5503
  Client 8: mean_dist=3.52, base_reward=-0.7602, violation=0, comm_penalty=0.0000, reward=-0.7602
  Client 9: mean_dist=6.26, base_reward=-2.1321, violation=0, comm_penalty=0.0000, reward=-2.1321
  RL policy loss: -1.158273
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1003
  Client 1 model accuracy on test set: 0.1364
  Client 2 model accuracy on test set: 0.1242
  Client 3 model accuracy on test set: 0.1157
  Client 4 model accuracy on test set: 0.1816
  Client 5 model accuracy on test set: 0.2117
  Client 6 model accuracy on test set: 0.1699
  Client 7 model accuracy on test set: 0.1866
  Client 8 model accuracy on test set: 0.1757
  Client 9 model accuracy on test set: 0.1334

=== Global Round 85/100 ===
  Client 0: layers_shared=1, local_acc=0.9462
  Client 1: layers_shared=2, local_acc=0.9726
  Client 2: layers_shared=3, local_acc=0.9551
  Client 3: layers_shared=2, local_acc=0.9846
  Client 4: layers_shared=4, local_acc=0.9948
  Client 5: layers_shared=1, local_acc=0.9481
  Client 6: layers_shared=5, local_acc=0.9734
  Client 7: layers_shared=1, local_acc=0.9992
  Client 8: layers_shared=3, local_acc=0.9961
  Client 9: layers_shared=2, local_acc=0.9975
  Client 0: mean_dist=3.52, base_reward=-0.8153, violation=0, comm_penalty=0.0000, reward=-0.8153
  Client 1: mean_dist=8.10, base_reward=-3.0775, violation=0, comm_penalty=0.0000, reward=-3.0775
  Client 2: mean_dist=10.92, base_reward=-4.5040, violation=2, comm_penalty=2.0000, reward=-6.5040
  Client 3: mean_dist=8.04, base_reward=-3.0356, violation=0, comm_penalty=0.0000, reward=-3.0356
  Client 4: mean_dist=11.19, base_reward=-4.6004, violation=0, comm_penalty=0.0000, reward=-4.6004
  Client 5: mean_dist=4.22, base_reward=-1.1632, violation=0, comm_penalty=0.0000, reward=-1.1632
  Client 6: mean_dist=8.94, base_reward=-3.4965, violation=4, comm_penalty=4.0000, reward=-7.4965
  Client 7: mean_dist=4.37, base_reward=-1.1871, violation=0, comm_penalty=0.0000, reward=-1.1871
  Client 8: mean_dist=8.95, base_reward=-3.4781, violation=1, comm_penalty=1.0000, reward=-4.4781
  Client 9: mean_dist=8.31, base_reward=-3.1589, violation=0, comm_penalty=0.0000, reward=-3.1589
  RL policy loss: -1.175828
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1161
  Client 1 model accuracy on test set: 0.1601
  Client 2 model accuracy on test set: 0.1134
  Client 3 model accuracy on test set: 0.1065
  Client 4 model accuracy on test set: 0.1846
  Client 5 model accuracy on test set: 0.2073
  Client 6 model accuracy on test set: 0.1667
  Client 7 model accuracy on test set: 0.2572
  Client 8 model accuracy on test set: 0.1655
  Client 9 model accuracy on test set: 0.1884

=== Global Round 86/100 ===
  Client 0: layers_shared=3, local_acc=0.9633
  Client 1: layers_shared=1, local_acc=0.9858
  Client 2: layers_shared=2, local_acc=0.9559
  Client 3: layers_shared=1, local_acc=0.9940
  Client 4: layers_shared=6, local_acc=0.9963
  Client 5: layers_shared=1, local_acc=0.9876
  Client 6: layers_shared=3, local_acc=0.9532
  Client 7: layers_shared=1, local_acc=0.9954
  Client 8: layers_shared=1, local_acc=0.9886
  Client 9: layers_shared=1, local_acc=0.9955
  Client 0: mean_dist=6.27, base_reward=-2.1719, violation=0, comm_penalty=0.0000, reward=-2.1719
  Client 1: mean_dist=3.79, base_reward=-0.9068, violation=0, comm_penalty=0.0000, reward=-0.9068
  Client 2: mean_dist=6.49, base_reward=-2.2890, violation=1, comm_penalty=1.0000, reward=-3.2890
  Client 3: mean_dist=3.82, base_reward=-0.9152, violation=0, comm_penalty=0.0000, reward=-0.9152
  Client 4: mean_dist=7.43, base_reward=-2.7209, violation=2, comm_penalty=2.0000, reward=-4.7209
  Client 5: mean_dist=4.23, base_reward=-1.1271, violation=0, comm_penalty=0.0000, reward=-1.1271
  Client 6: mean_dist=6.11, base_reward=-2.1033, violation=2, comm_penalty=2.0000, reward=-4.1033
  Client 7: mean_dist=4.38, base_reward=-1.1967, violation=0, comm_penalty=0.0000, reward=-1.1967
  Client 8: mean_dist=3.53, base_reward=-0.7769, violation=0, comm_penalty=0.0000, reward=-0.7769
  Client 9: mean_dist=3.78, base_reward=-0.8924, violation=0, comm_penalty=0.0000, reward=-0.8924
  RL policy loss: -1.025814
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1018
  Client 1 model accuracy on test set: 0.1499
  Client 2 model accuracy on test set: 0.1492
  Client 3 model accuracy on test set: 0.1112
  Client 4 model accuracy on test set: 0.1826
  Client 5 model accuracy on test set: 0.2232
  Client 6 model accuracy on test set: 0.1553
  Client 7 model accuracy on test set: 0.3012
  Client 8 model accuracy on test set: 0.1705
  Client 9 model accuracy on test set: 0.1269

=== Global Round 87/100 ===
  Client 0: layers_shared=1, local_acc=0.9563
  Client 1: layers_shared=1, local_acc=0.9924
  Client 2: layers_shared=1, local_acc=0.9650
  Client 3: layers_shared=2, local_acc=0.9870
  Client 4: layers_shared=3, local_acc=0.9948
  Client 5: layers_shared=1, local_acc=0.9668
  Client 6: layers_shared=1, local_acc=0.9818
  Client 7: layers_shared=1, local_acc=0.9958
  Client 8: layers_shared=1, local_acc=0.9976
  Client 9: layers_shared=2, local_acc=0.9978
  Client 0: mean_dist=3.55, base_reward=-0.8191, violation=0, comm_penalty=0.0000, reward=-0.8191
  Client 1: mean_dist=3.79, base_reward=-0.9026, violation=0, comm_penalty=0.0000, reward=-0.9026
  Client 2: mean_dist=4.19, base_reward=-1.1284, violation=0, comm_penalty=0.0000, reward=-1.1284
  Client 3: mean_dist=5.40, base_reward=-1.7133, violation=0, comm_penalty=0.0000, reward=-1.7133
  Client 4: mean_dist=5.70, base_reward=-1.8551, violation=0, comm_penalty=0.0000, reward=-1.8551
  Client 5: mean_dist=4.25, base_reward=-1.1558, violation=0, comm_penalty=0.0000, reward=-1.1558
  Client 6: mean_dist=3.44, base_reward=-0.7359, violation=0, comm_penalty=0.0000, reward=-0.7359
  Client 7: mean_dist=4.40, base_reward=-1.2021, violation=0, comm_penalty=0.0000, reward=-1.2021
  Client 8: mean_dist=3.54, base_reward=-0.7710, violation=0, comm_penalty=0.0000, reward=-0.7710
  Client 9: mean_dist=5.41, base_reward=-1.7059, violation=0, comm_penalty=0.0000, reward=-1.7059
  RL policy loss: -0.229573
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1053
  Client 1 model accuracy on test set: 0.1601
  Client 2 model accuracy on test set: 0.1549
  Client 3 model accuracy on test set: 0.1006
  Client 4 model accuracy on test set: 0.1802
  Client 5 model accuracy on test set: 0.1519
  Client 6 model accuracy on test set: 0.1539
  Client 7 model accuracy on test set: 0.2272
  Client 8 model accuracy on test set: 0.1754
  Client 9 model accuracy on test set: 0.1090

=== Global Round 88/100 ===
  Client 0: layers_shared=5, local_acc=0.9063
  Client 1: layers_shared=1, local_acc=0.9845
  Client 2: layers_shared=1, local_acc=0.9698
  Client 3: layers_shared=5, local_acc=0.9853
  Client 4: layers_shared=1, local_acc=0.9962
  Client 5: layers_shared=3, local_acc=0.9898
  Client 6: layers_shared=2, local_acc=0.9651
  Client 7: layers_shared=4, local_acc=0.9967
  Client 8: layers_shared=1, local_acc=0.9996
  Client 9: layers_shared=2, local_acc=0.9979
  Client 0: mean_dist=9.37, base_reward=-3.7803, violation=2, comm_penalty=2.0000, reward=-5.7803
  Client 1: mean_dist=3.81, base_reward=-0.9181, violation=0, comm_penalty=0.0000, reward=-0.9181
  Client 2: mean_dist=4.20, base_reward=-1.1316, violation=0, comm_penalty=0.0000, reward=-1.1316
  Client 3: mean_dist=10.21, base_reward=-4.1215, violation=3, comm_penalty=3.0000, reward=-7.1215
  Client 4: mean_dist=4.00, base_reward=-1.0057, violation=0, comm_penalty=0.0000, reward=-1.0057
  Client 5: mean_dist=10.21, base_reward=-4.1172, violation=0, comm_penalty=0.0000, reward=-4.1172
  Client 6: mean_dist=6.51, base_reward=-2.2891, violation=1, comm_penalty=1.0000, reward=-3.2891
  Client 7: mean_dist=11.69, base_reward=-4.8458, violation=0, comm_penalty=0.0000, reward=-4.8458
  Client 8: mean_dist=3.54, base_reward=-0.7706, violation=0, comm_penalty=0.0000, reward=-0.7706
  Client 9: mean_dist=7.58, base_reward=-2.7923, violation=0, comm_penalty=0.0000, reward=-2.7923
  RL policy loss: -1.746196
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1079
  Client 1 model accuracy on test set: 0.1356
  Client 2 model accuracy on test set: 0.1261
  Client 3 model accuracy on test set: 0.1057
  Client 4 model accuracy on test set: 0.1805
  Client 5 model accuracy on test set: 0.1972
  Client 6 model accuracy on test set: 0.1657
  Client 7 model accuracy on test set: 0.2803
  Client 8 model accuracy on test set: 0.1917
  Client 9 model accuracy on test set: 0.1207

=== Global Round 89/100 ===
  Client 0: layers_shared=3, local_acc=0.9570
  Client 1: layers_shared=5, local_acc=0.9921
  Client 2: layers_shared=4, local_acc=0.9824
  Client 3: layers_shared=4, local_acc=0.9928
  Client 4: layers_shared=6, local_acc=0.9966
  Client 5: layers_shared=3, local_acc=0.9615
  Client 6: layers_shared=1, local_acc=0.9686
  Client 7: layers_shared=4, local_acc=0.9988
  Client 8: layers_shared=6, local_acc=0.9996
  Client 9: layers_shared=1, local_acc=0.9948
  Client 0: mean_dist=11.74, base_reward=-4.9120, violation=0, comm_penalty=0.0000, reward=-4.9120
  Client 1: mean_dist=17.05, base_reward=-7.5321, violation=0, comm_penalty=0.0000, reward=-7.5321
  Client 2: mean_dist=18.36, base_reward=-8.1996, violation=3, comm_penalty=3.0000, reward=-11.1996
  Client 3: mean_dist=15.51, base_reward=-6.7623, violation=2, comm_penalty=2.0000, reward=-8.7623
  Client 4: mean_dist=18.19, base_reward=-8.0997, violation=2, comm_penalty=2.0000, reward=-10.0997
  Client 5: mean_dist=14.82, base_reward=-6.4494, violation=0, comm_penalty=0.0000, reward=-6.4494
  Client 6: mean_dist=3.45, base_reward=-0.7564, violation=0, comm_penalty=0.0000, reward=-0.7564
  Client 7: mean_dist=18.58, base_reward=-8.2889, violation=0, comm_penalty=0.0000, reward=-8.2889
  Client 8: mean_dist=15.16, base_reward=-6.5795, violation=4, comm_penalty=4.0000, reward=-10.5795
  Client 9: mean_dist=3.81, base_reward=-0.9103, violation=0, comm_penalty=0.0000, reward=-0.9103
  RL policy loss: -2.682176
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.0978
  Client 1 model accuracy on test set: 0.1481
  Client 2 model accuracy on test set: 0.1440
  Client 3 model accuracy on test set: 0.1371
  Client 4 model accuracy on test set: 0.1637
  Client 5 model accuracy on test set: 0.2367
  Client 6 model accuracy on test set: 0.1564
  Client 7 model accuracy on test set: 0.2806
  Client 8 model accuracy on test set: 0.1889
  Client 9 model accuracy on test set: 0.1654

=== Global Round 90/100 ===
  Client 0: layers_shared=2, local_acc=0.9456
  Client 1: layers_shared=4, local_acc=0.9932
  Client 2: layers_shared=2, local_acc=0.9377
  Client 3: layers_shared=2, local_acc=0.9899
  Client 4: layers_shared=3, local_acc=0.9802
  Client 5: layers_shared=1, local_acc=0.9960
  Client 6: layers_shared=3, local_acc=0.9532
  Client 7: layers_shared=1, local_acc=0.9981
  Client 8: layers_shared=1, local_acc=0.9996
  Client 9: layers_shared=3, local_acc=0.9970
  Client 0: mean_dist=7.31, base_reward=-2.7069, violation=0, comm_penalty=0.0000, reward=-2.7069
  Client 1: mean_dist=9.86, base_reward=-3.9352, violation=0, comm_penalty=0.0000, reward=-3.9352
  Client 2: mean_dist=9.08, base_reward=-3.6020, violation=1, comm_penalty=1.0000, reward=-4.6020
  Client 3: mean_dist=8.11, base_reward=-3.0646, violation=0, comm_penalty=0.0000, reward=-3.0646
  Client 4: mean_dist=10.79, base_reward=-4.4171, violation=0, comm_penalty=0.0000, reward=-4.4171
  Client 5: mean_dist=4.28, base_reward=-1.1418, violation=0, comm_penalty=0.0000, reward=-1.1418
  Client 6: mean_dist=8.53, base_reward=-3.3106, violation=2, comm_penalty=2.0000, reward=-5.3106
  Client 7: mean_dist=4.41, base_reward=-1.2056, violation=0, comm_penalty=0.0000, reward=-1.2056
  Client 8: mean_dist=3.55, base_reward=-0.7772, violation=0, comm_penalty=0.0000, reward=-0.7772
  Client 9: mean_dist=10.05, base_reward=-4.0279, violation=0, comm_penalty=0.0000, reward=-4.0279
  RL policy loss: -0.937593
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1003
  Client 1 model accuracy on test set: 0.1241
  Client 2 model accuracy on test set: 0.1459
  Client 3 model accuracy on test set: 0.1219
  Client 4 model accuracy on test set: 0.1593
  Client 5 model accuracy on test set: 0.2437
  Client 6 model accuracy on test set: 0.1645
  Client 7 model accuracy on test set: 0.2540
  Client 8 model accuracy on test set: 0.1923
  Client 9 model accuracy on test set: 0.1436

=== Global Round 91/100 ===
  Client 0: layers_shared=6, local_acc=0.9791
  Client 1: layers_shared=2, local_acc=0.9949
  Client 2: layers_shared=1, local_acc=0.9692
  Client 3: layers_shared=6, local_acc=0.9844
  Client 4: layers_shared=1, local_acc=0.9950
  Client 5: layers_shared=1, local_acc=0.9719
  Client 6: layers_shared=6, local_acc=0.9916
  Client 7: layers_shared=6, local_acc=0.9970
  Client 8: layers_shared=1, local_acc=1.0000
  Client 9: layers_shared=1, local_acc=0.9990
  Client 0: mean_dist=9.53, base_reward=-3.7860, violation=3, comm_penalty=3.0000, reward=-6.7860
  Client 1: mean_dist=6.62, base_reward=-2.3127, violation=0, comm_penalty=0.0000, reward=-2.3127
  Client 2: mean_dist=4.23, base_reward=-1.1442, violation=0, comm_penalty=0.0000, reward=-1.1442
  Client 3: mean_dist=10.30, base_reward=-4.1659, violation=4, comm_penalty=4.0000, reward=-8.1659
  Client 4: mean_dist=4.02, base_reward=-1.0153, violation=0, comm_penalty=0.0000, reward=-1.0153
  Client 5: mean_dist=4.28, base_reward=-1.1667, violation=0, comm_penalty=0.0000, reward=-1.1667
  Client 6: mean_dist=9.32, base_reward=-3.6695, violation=5, comm_penalty=5.0000, reward=-8.6695
  Client 7: mean_dist=12.42, base_reward=-5.2141, violation=0, comm_penalty=0.0000, reward=-5.2141
  Client 8: mean_dist=3.56, base_reward=-0.7811, violation=0, comm_penalty=0.0000, reward=-0.7811
  Client 9: mean_dist=3.83, base_reward=-0.9147, violation=0, comm_penalty=0.0000, reward=-0.9147
  RL policy loss: -2.881993
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.0962
  Client 1 model accuracy on test set: 0.1276
  Client 2 model accuracy on test set: 0.1417
  Client 3 model accuracy on test set: 0.1023
  Client 4 model accuracy on test set: 0.1854
  Client 5 model accuracy on test set: 0.1783
  Client 6 model accuracy on test set: 0.1545
  Client 7 model accuracy on test set: 0.2049
  Client 8 model accuracy on test set: 0.1634
  Client 9 model accuracy on test set: 0.1893

=== Global Round 92/100 ===
  Client 0: layers_shared=5, local_acc=0.9753
  Client 1: layers_shared=1, local_acc=0.9944
  Client 2: layers_shared=1, local_acc=0.9861
  Client 3: layers_shared=1, local_acc=0.9973
  Client 4: layers_shared=5, local_acc=0.9917
  Client 5: layers_shared=1, local_acc=0.9377
  Client 6: layers_shared=1, local_acc=0.9916
  Client 7: layers_shared=3, local_acc=0.9952
  Client 8: layers_shared=1, local_acc=0.9988
  Client 9: layers_shared=1, local_acc=0.9990
  Client 0: mean_dist=6.96, base_reward=-2.5066, violation=2, comm_penalty=2.0000, reward=-4.5066
  Client 1: mean_dist=3.83, base_reward=-0.9225, violation=0, comm_penalty=0.0000, reward=-0.9225
  Client 2: mean_dist=4.24, base_reward=-1.1327, violation=0, comm_penalty=0.0000, reward=-1.1327
  Client 3: mean_dist=3.88, base_reward=-0.9418, violation=0, comm_penalty=0.0000, reward=-0.9418
  Client 4: mean_dist=7.79, base_reward=-2.9011, violation=1, comm_penalty=1.0000, reward=-3.9011
  Client 5: mean_dist=4.29, base_reward=-1.2059, violation=0, comm_penalty=0.0000, reward=-1.2059
  Client 6: mean_dist=3.47, base_reward=-0.7427, violation=0, comm_penalty=0.0000, reward=-0.7427
  Client 7: mean_dist=7.48, base_reward=-2.7461, violation=0, comm_penalty=0.0000, reward=-2.7461
  Client 8: mean_dist=3.56, base_reward=-0.7829, violation=0, comm_penalty=0.0000, reward=-0.7829
  Client 9: mean_dist=3.83, base_reward=-0.9150, violation=0, comm_penalty=0.0000, reward=-0.9150
  RL policy loss: -1.186927
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1149
  Client 1 model accuracy on test set: 0.1165
  Client 2 model accuracy on test set: 0.1245
  Client 3 model accuracy on test set: 0.1220
  Client 4 model accuracy on test set: 0.1732
  Client 5 model accuracy on test set: 0.2644
  Client 6 model accuracy on test set: 0.1579
  Client 7 model accuracy on test set: 0.1849
  Client 8 model accuracy on test set: 0.1453
  Client 9 model accuracy on test set: 0.1256

=== Global Round 93/100 ===
  Client 0: layers_shared=3, local_acc=0.9886
  Client 1: layers_shared=6, local_acc=0.9980
  Client 2: layers_shared=1, local_acc=0.9779
  Client 3: layers_shared=4, local_acc=0.9987
  Client 4: layers_shared=3, local_acc=0.9803
  Client 5: layers_shared=1, local_acc=0.9612
  Client 6: layers_shared=6, local_acc=0.9944
  Client 7: layers_shared=3, local_acc=0.9978
  Client 8: layers_shared=3, local_acc=0.9833
  Client 9: layers_shared=1, local_acc=0.9964
  Client 0: mean_dist=10.03, base_reward=-4.0287, violation=0, comm_penalty=0.0000, reward=-4.0287
  Client 1: mean_dist=12.87, base_reward=-5.4377, violation=1, comm_penalty=1.0000, reward=-6.4377
  Client 2: mean_dist=4.25, base_reward=-1.1467, violation=0, comm_penalty=0.0000, reward=-1.1467
  Client 3: mean_dist=12.05, base_reward=-5.0283, violation=2, comm_penalty=2.0000, reward=-7.0283
  Client 4: mean_dist=12.62, base_reward=-5.3319, violation=0, comm_penalty=0.0000, reward=-5.3319
  Client 5: mean_dist=4.30, base_reward=-1.1890, violation=0, comm_penalty=0.0000, reward=-1.1890
  Client 6: mean_dist=10.99, base_reward=-4.5030, violation=5, comm_penalty=5.0000, reward=-9.5030
  Client 7: mean_dist=13.26, base_reward=-5.6323, violation=0, comm_penalty=0.0000, reward=-5.6323
  Client 8: mean_dist=10.26, base_reward=-4.1469, violation=1, comm_penalty=1.0000, reward=-5.1469
  Client 9: mean_dist=3.84, base_reward=-0.9259, violation=0, comm_penalty=0.0000, reward=-0.9259
  RL policy loss: -2.239511
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1013
  Client 1 model accuracy on test set: 0.1644
  Client 2 model accuracy on test set: 0.1379
  Client 3 model accuracy on test set: 0.1120
  Client 4 model accuracy on test set: 0.1602
  Client 5 model accuracy on test set: 0.1968
  Client 6 model accuracy on test set: 0.1747
  Client 7 model accuracy on test set: 0.1933
  Client 8 model accuracy on test set: 0.1260
  Client 9 model accuracy on test set: 0.1225

=== Global Round 94/100 ===
  Client 0: layers_shared=2, local_acc=0.9873
  Client 1: layers_shared=4, local_acc=0.9977
  Client 2: layers_shared=1, local_acc=0.9806
  Client 3: layers_shared=3, local_acc=0.9987
  Client 4: layers_shared=1, local_acc=0.9913
  Client 5: layers_shared=1, local_acc=0.9887
  Client 6: layers_shared=3, local_acc=0.9965
  Client 7: layers_shared=3, local_acc=0.9976
  Client 8: layers_shared=3, local_acc=0.9990
  Client 9: layers_shared=1, local_acc=0.9888
  Client 0: mean_dist=6.56, base_reward=-2.2915, violation=0, comm_penalty=0.0000, reward=-2.2915
  Client 1: mean_dist=9.45, base_reward=-3.7253, violation=0, comm_penalty=0.0000, reward=-3.7253
  Client 2: mean_dist=4.27, base_reward=-1.1520, violation=0, comm_penalty=0.0000, reward=-1.1520
  Client 3: mean_dist=9.30, base_reward=-3.6499, violation=1, comm_penalty=1.0000, reward=-4.6499
  Client 4: mean_dist=4.06, base_reward=-1.0400, violation=0, comm_penalty=0.0000, reward=-1.0400
  Client 5: mean_dist=4.31, base_reward=-1.1667, violation=0, comm_penalty=0.0000, reward=-1.1667
  Client 6: mean_dist=8.11, base_reward=-3.0599, violation=2, comm_penalty=2.0000, reward=-5.0599
  Client 7: mean_dist=10.97, base_reward=-4.4883, violation=0, comm_penalty=0.0000, reward=-4.4883
  Client 8: mean_dist=8.57, base_reward=-3.2860, violation=1, comm_penalty=1.0000, reward=-4.2860
  Client 9: mean_dist=3.85, base_reward=-0.9366, violation=0, comm_penalty=0.0000, reward=-0.9366
  RL policy loss: -1.112612
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1007
  Client 1 model accuracy on test set: 0.1627
  Client 2 model accuracy on test set: 0.1488
  Client 3 model accuracy on test set: 0.1121
  Client 4 model accuracy on test set: 0.1603
  Client 5 model accuracy on test set: 0.1775
  Client 6 model accuracy on test set: 0.1596
  Client 7 model accuracy on test set: 0.1942
  Client 8 model accuracy on test set: 0.1903
  Client 9 model accuracy on test set: 0.1732

=== Global Round 95/100 ===
  Client 0: layers_shared=2, local_acc=0.9981
  Client 1: layers_shared=1, local_acc=0.9972
  Client 2: layers_shared=3, local_acc=0.9766
  Client 3: layers_shared=1, local_acc=0.9937
  Client 4: layers_shared=3, local_acc=0.9813
  Client 5: layers_shared=6, local_acc=0.9935
  Client 6: layers_shared=2, local_acc=0.9972
  Client 7: layers_shared=5, local_acc=0.9936
  Client 8: layers_shared=3, local_acc=0.9888
  Client 9: layers_shared=1, local_acc=0.9975
  Client 0: mean_dist=7.55, base_reward=-2.7781, violation=0, comm_penalty=0.0000, reward=-2.7781
  Client 1: mean_dist=3.85, base_reward=-0.9260, violation=0, comm_penalty=0.0000, reward=-0.9260
  Client 2: mean_dist=12.32, base_reward=-5.1819, violation=2, comm_penalty=2.0000, reward=-7.1819
  Client 3: mean_dist=3.90, base_reward=-0.9587, violation=0, comm_penalty=0.0000, reward=-0.9587
  Client 4: mean_dist=12.03, base_reward=-5.0316, violation=0, comm_penalty=0.0000, reward=-5.0316
  Client 5: mean_dist=13.44, base_reward=-5.7257, violation=0, comm_penalty=0.0000, reward=-5.7257
  Client 6: mean_dist=7.30, base_reward=-2.6527, violation=1, comm_penalty=1.0000, reward=-3.6527
  Client 7: mean_dist=13.83, base_reward=-5.9214, violation=0, comm_penalty=0.0000, reward=-5.9214
  Client 8: mean_dist=10.09, base_reward=-4.0583, violation=1, comm_penalty=1.0000, reward=-5.0583
  Client 9: mean_dist=3.85, base_reward=-0.9297, violation=0, comm_penalty=0.0000, reward=-0.9297
  RL policy loss: -1.720188
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1132
  Client 1 model accuracy on test set: 0.1499
  Client 2 model accuracy on test set: 0.1751
  Client 3 model accuracy on test set: 0.1356
  Client 4 model accuracy on test set: 0.1756
  Client 5 model accuracy on test set: 0.2323
  Client 6 model accuracy on test set: 0.1602
  Client 7 model accuracy on test set: 0.2184
  Client 8 model accuracy on test set: 0.1865
  Client 9 model accuracy on test set: 0.2008

=== Global Round 96/100 ===
  Client 0: layers_shared=2, local_acc=0.9772
  Client 1: layers_shared=1, local_acc=0.9985
  Client 2: layers_shared=1, local_acc=0.9534
  Client 3: layers_shared=1, local_acc=0.9933
  Client 4: layers_shared=3, local_acc=0.9965
  Client 5: layers_shared=1, local_acc=0.9951
  Client 6: layers_shared=3, local_acc=0.9986
  Client 7: layers_shared=1, local_acc=0.9975
  Client 8: layers_shared=3, local_acc=0.9986
  Client 9: layers_shared=1, local_acc=0.9993
  Client 0: mean_dist=5.34, base_reward=-1.6908, violation=0, comm_penalty=0.0000, reward=-1.6908
  Client 1: mean_dist=3.85, base_reward=-0.9257, violation=0, comm_penalty=0.0000, reward=-0.9257
  Client 2: mean_dist=4.29, base_reward=-1.1929, violation=0, comm_penalty=0.0000, reward=-1.1929
  Client 3: mean_dist=3.92, base_reward=-0.9649, violation=0, comm_penalty=0.0000, reward=-0.9649
  Client 4: mean_dist=7.43, base_reward=-2.7198, violation=0, comm_penalty=0.0000, reward=-2.7198
  Client 5: mean_dist=4.32, base_reward=-1.1659, violation=0, comm_penalty=0.0000, reward=-1.1659
  Client 6: mean_dist=6.06, base_reward=-2.0303, violation=2, comm_penalty=2.0000, reward=-4.0303
  Client 7: mean_dist=4.45, base_reward=-1.2297, violation=0, comm_penalty=0.0000, reward=-1.2297
  Client 8: mean_dist=6.32, base_reward=-2.1603, violation=1, comm_penalty=1.0000, reward=-3.1603
  Client 9: mean_dist=3.86, base_reward=-0.9290, violation=0, comm_penalty=0.0000, reward=-0.9290
  RL policy loss: -0.636517
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1010
  Client 1 model accuracy on test set: 0.1483
  Client 2 model accuracy on test set: 0.1708
  Client 3 model accuracy on test set: 0.1016
  Client 4 model accuracy on test set: 0.1895
  Client 5 model accuracy on test set: 0.1899
  Client 6 model accuracy on test set: 0.1592
  Client 7 model accuracy on test set: 0.2556
  Client 8 model accuracy on test set: 0.1768
  Client 9 model accuracy on test set: 0.1698

=== Global Round 97/100 ===
  Client 0: layers_shared=3, local_acc=0.9930
  Client 1: layers_shared=1, local_acc=0.9972
  Client 2: layers_shared=4, local_acc=0.9472
  Client 3: layers_shared=1, local_acc=0.9926
  Client 4: layers_shared=1, local_acc=0.9173
  Client 5: layers_shared=1, local_acc=0.9779
  Client 6: layers_shared=2, local_acc=0.9958
  Client 7: layers_shared=5, local_acc=0.9969
  Client 8: layers_shared=1, local_acc=0.9986
  Client 9: layers_shared=1, local_acc=0.9976
  Client 0: mean_dist=6.78, base_reward=-2.3955, violation=0, comm_penalty=0.0000, reward=-2.3955
  Client 1: mean_dist=3.85, base_reward=-0.9295, violation=0, comm_penalty=0.0000, reward=-0.9295
  Client 2: mean_dist=8.92, base_reward=-3.5143, violation=3, comm_penalty=3.0000, reward=-6.5143
  Client 3: mean_dist=3.92, base_reward=-0.9686, violation=0, comm_penalty=0.0000, reward=-0.9686
  Client 4: mean_dist=4.08, base_reward=-1.1212, violation=0, comm_penalty=0.0000, reward=-1.1212
  Client 5: mean_dist=4.32, base_reward=-1.1840, violation=0, comm_penalty=0.0000, reward=-1.1840
  Client 6: mean_dist=5.40, base_reward=-1.7022, violation=1, comm_penalty=1.0000, reward=-2.7022
  Client 7: mean_dist=9.15, base_reward=-3.5778, violation=0, comm_penalty=0.0000, reward=-3.5778
  Client 8: mean_dist=3.60, base_reward=-0.7992, violation=0, comm_penalty=0.0000, reward=-0.7992
  Client 9: mean_dist=3.86, base_reward=-0.9321, violation=0, comm_penalty=0.0000, reward=-0.9321
  RL policy loss: -1.435528
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1007
  Client 1 model accuracy on test set: 0.1692
  Client 2 model accuracy on test set: 0.1560
  Client 3 model accuracy on test set: 0.1273
  Client 4 model accuracy on test set: 0.1038
  Client 5 model accuracy on test set: 0.2370
  Client 6 model accuracy on test set: 0.1641
  Client 7 model accuracy on test set: 0.2095
  Client 8 model accuracy on test set: 0.1813
  Client 9 model accuracy on test set: 0.2045

=== Global Round 98/100 ===
  Client 0: layers_shared=1, local_acc=0.9823
  Client 1: layers_shared=1, local_acc=0.9944
  Client 2: layers_shared=3, local_acc=0.9853
  Client 3: layers_shared=1, local_acc=0.9783
  Client 4: layers_shared=2, local_acc=0.9933
  Client 5: layers_shared=1, local_acc=0.9992
  Client 6: layers_shared=1, local_acc=0.9895
  Client 7: layers_shared=1, local_acc=0.9986
  Client 8: layers_shared=1, local_acc=0.9988
  Client 9: layers_shared=1, local_acc=0.9978
  Client 0: mean_dist=3.63, base_reward=-0.8340, violation=0, comm_penalty=0.0000, reward=-0.8340
  Client 1: mean_dist=3.86, base_reward=-0.9341, violation=0, comm_penalty=0.0000, reward=-0.9341
  Client 2: mean_dist=5.29, base_reward=-1.6593, violation=2, comm_penalty=2.0000, reward=-3.6593
  Client 3: mean_dist=3.93, base_reward=-0.9866, violation=0, comm_penalty=0.0000, reward=-0.9866
  Client 4: mean_dist=5.06, base_reward=-1.5381, violation=0, comm_penalty=0.0000, reward=-1.5381
  Client 5: mean_dist=4.33, base_reward=-1.1650, violation=0, comm_penalty=0.0000, reward=-1.1650
  Client 6: mean_dist=3.51, base_reward=-0.7652, violation=0, comm_penalty=0.0000, reward=-0.7652
  Client 7: mean_dist=4.47, base_reward=-1.2349, violation=0, comm_penalty=0.0000, reward=-1.2349
  Client 8: mean_dist=3.60, base_reward=-0.8023, violation=0, comm_penalty=0.0000, reward=-0.8023
  Client 9: mean_dist=3.87, base_reward=-0.9357, violation=0, comm_penalty=0.0000, reward=-0.9357
  RL policy loss: -0.381553
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1037
  Client 1 model accuracy on test set: 0.1385
  Client 2 model accuracy on test set: 0.1331
  Client 3 model accuracy on test set: 0.1003
  Client 4 model accuracy on test set: 0.1808
  Client 5 model accuracy on test set: 0.2156
  Client 6 model accuracy on test set: 0.1588
  Client 7 model accuracy on test set: 0.2306
  Client 8 model accuracy on test set: 0.1597
  Client 9 model accuracy on test set: 0.1864

=== Global Round 99/100 ===
  Client 0: layers_shared=1, local_acc=0.9677
  Client 1: layers_shared=1, local_acc=0.9982
  Client 2: layers_shared=1, local_acc=0.9698
  Client 3: layers_shared=1, local_acc=0.9984
  Client 4: layers_shared=1, local_acc=0.9938
  Client 5: layers_shared=1, local_acc=0.9793
  Client 6: layers_shared=1, local_acc=0.9853
  Client 7: layers_shared=1, local_acc=0.9946
  Client 8: layers_shared=6, local_acc=0.9986
  Client 9: layers_shared=1, local_acc=0.9985
  Client 0: mean_dist=3.64, base_reward=-0.8518, violation=0, comm_penalty=0.0000, reward=-0.8518
  Client 1: mean_dist=3.86, base_reward=-0.9314, violation=0, comm_penalty=0.0000, reward=-0.9314
  Client 2: mean_dist=4.33, base_reward=-1.1946, violation=0, comm_penalty=0.0000, reward=-1.1946
  Client 3: mean_dist=3.94, base_reward=-0.9701, violation=0, comm_penalty=0.0000, reward=-0.9701
  Client 4: mean_dist=4.10, base_reward=-1.0542, violation=0, comm_penalty=0.0000, reward=-1.0542
  Client 5: mean_dist=4.33, base_reward=-1.1879, violation=0, comm_penalty=0.0000, reward=-1.1879
  Client 6: mean_dist=3.51, base_reward=-0.7699, violation=0, comm_penalty=0.0000, reward=-0.7699
  Client 7: mean_dist=4.48, base_reward=-1.2443, violation=0, comm_penalty=0.0000, reward=-1.2443
  Client 8: mean_dist=3.61, base_reward=-0.8050, violation=4, comm_penalty=4.0000, reward=-4.8050
  Client 9: mean_dist=3.87, base_reward=-0.9360, violation=0, comm_penalty=0.0000, reward=-0.9360
  RL policy loss: -0.847621
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1011
  Client 1 model accuracy on test set: 0.1502
  Client 2 model accuracy on test set: 0.1599
  Client 3 model accuracy on test set: 0.1004
  Client 4 model accuracy on test set: 0.1870
  Client 5 model accuracy on test set: 0.1961
  Client 6 model accuracy on test set: 0.1574
  Client 7 model accuracy on test set: 0.2622
  Client 8 model accuracy on test set: 0.1576
  Client 9 model accuracy on test set: 0.1893

=== Global Round 100/100 ===
  Client 0: layers_shared=1, local_acc=0.9886
  Client 1: layers_shared=1, local_acc=0.9944
  Client 2: layers_shared=1, local_acc=0.9845
  Client 3: layers_shared=1, local_acc=0.9942
  Client 4: layers_shared=1, local_acc=0.9957
  Client 5: layers_shared=1, local_acc=0.9991
  Client 6: layers_shared=1, local_acc=0.9888
  Client 7: layers_shared=1, local_acc=0.9993
  Client 8: layers_shared=5, local_acc=0.9984
  Client 9: layers_shared=1, local_acc=0.9991
  Client 0: mean_dist=3.64, base_reward=-0.8313, violation=0, comm_penalty=0.0000, reward=-0.8313
  Client 1: mean_dist=3.87, base_reward=-0.9398, violation=0, comm_penalty=0.0000, reward=-0.9398
  Client 2: mean_dist=4.33, base_reward=-1.1812, violation=0, comm_penalty=0.0000, reward=-1.1812
  Client 3: mean_dist=3.94, base_reward=-0.9751, violation=0, comm_penalty=0.0000, reward=-0.9751
  Client 4: mean_dist=4.10, base_reward=-1.0526, violation=0, comm_penalty=0.0000, reward=-1.0526
  Client 5: mean_dist=4.33, base_reward=-1.1670, violation=0, comm_penalty=0.0000, reward=-1.1670
  Client 6: mean_dist=3.52, base_reward=-0.7687, violation=0, comm_penalty=0.0000, reward=-0.7687
  Client 7: mean_dist=4.48, base_reward=-1.2406, violation=0, comm_penalty=0.0000, reward=-1.2406
  Client 8: mean_dist=3.62, base_reward=-0.8094, violation=3, comm_penalty=3.0000, reward=-3.8094
  Client 9: mean_dist=3.87, base_reward=-0.9368, violation=0, comm_penalty=0.0000, reward=-0.9368
  RL policy loss: -0.585680
Global model accuracy (test set): 0.1403
  Client 0 model accuracy on test set: 0.1009
  Client 1 model accuracy on test set: 0.1620
  Client 2 model accuracy on test set: 0.1729
  Client 3 model accuracy on test set: 0.1022
  Client 4 model accuracy on test set: 0.1655
  Client 5 model accuracy on test set: 0.2434
  Client 6 model accuracy on test set: 0.1688
  Client 7 model accuracy on test set: 0.2630
  Client 8 model accuracy on test set: 0.1487
  Client 9 model accuracy on test set: 0.1498

Training finished.
Saved global model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/global_model.pt
Saved client 0 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_0_model.pt
Saved client 1 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_1_model.pt
Saved client 2 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_2_model.pt
Saved client 3 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_3_model.pt
Saved client 4 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_4_model.pt
Saved client 5 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_5_model.pt
Saved client 6 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_6_model.pt
Saved client 7 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_7_model.pt
Saved client 8 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_8_model.pt
Saved client 9 model  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/client_9_model.pt
Saved RL policy network  /local/scratch/a/dalwis/single_agent_RL_for_pFL/src/weights/split_10_clients_resnet18_MNIST_alpha_5/policy_net.pt
